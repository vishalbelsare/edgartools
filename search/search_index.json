{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"EdgarTools","text":"<p>Powerful Python library for SEC data analysis and financial research</p> <p>EdgarTools makes it simple to access, analyze, and extract insights from SEC filings. Whether you're analyzing company financials, tracking insider trading, or researching investment funds, edgartools provides the tools you need.</p>"},{"location":"#what-you-can-do","title":"What You Can Do","text":"<p>Analyze Company Financials</p> <p>Extract financial statements, calculate ratios, and track performance over time.</p> <pre><code>company = Company(\"AAPL\")\nfinancials = company.get_financials()\nincome_statement = financials.income_statement()\n</code></pre> <p>Track Insider Trading</p> <p>Monitor insider transactions from Forms 3, 4, and 5 with structured data objects.</p> <pre><code>filings = company.get_filings(form=\"4\").head(10)\ntransactions = pd.concat([f.obj()\n                         .to_dataframe()\n                         .fillna('')\n                for f in filings])\n</code></pre> <p>Research Investment Funds</p> <p>Analyze 13F holdings, track portfolio changes, and compare fund strategies.</p> <pre><code>fund = Company(\"BRK-A\")\nholdings = fund.get_filings(form=\"13F-HR\").latest().obj()\n</code></pre> <p>Extract Filing Data</p> <p>Access any SEC filing since 1994 with clean, structured data extraction.</p> <pre><code>filing = company.get_filings(form=\"10-K\").latest()\ntext = filing.text()  # Clean, readable text\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#easy-to-use","title":"\ud83d\ude80 Easy to Use","text":"<ul> <li>Simple, intuitive API designed for both beginners and experts</li> <li>Comprehensive documentation with real-world examples</li> <li>Smart defaults that handle edge cases automatically</li> </ul>"},{"location":"#complete-sec-data-access","title":"\ud83d\udcca Complete SEC Data Access","text":"<ul> <li>All filing types: 10-K, 10-Q, 8-K, 13F, Form 4, S-1, and more</li> <li>Historical data: Access filings back to 1994</li> <li>Real-time data: Get the latest filings as they're published</li> </ul>"},{"location":"#advanced-xbrl-support","title":"\ud83d\udd0d Advanced XBRL Support","text":"<ul> <li>Extract structured financial data from XBRL filings</li> <li>Query individual financial line items with standardized concepts</li> <li>Handle complex financial statement hierarchies automatically</li> </ul>"},{"location":"#performance-optimized","title":"\u26a1 Performance Optimized","text":"<ul> <li>Efficient data handling for large datasets</li> <li>Local caching to minimize API calls</li> <li>Batch processing capabilities for bulk analysis</li> </ul>"},{"location":"#developer-friendly","title":"\ud83d\udee0 Developer Friendly","text":"<ul> <li>Type hints and comprehensive error handling</li> <li>Jupyter notebook integration with rich display</li> <li>Pandas DataFrames for seamless data analysis</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Install edgartools with pip:</p> <pre><code>pip install edgartools\n</code></pre> <p>Or use uv for faster installation:</p> <pre><code>uv pip install edgartools\n</code></pre>"},{"location":"#get-started-in-2-minutes","title":"Get Started in 2 Minutes","text":"<ol> <li>Install and set your identity (required by SEC):</li> </ol> <pre><code>from edgar import *\nset_identity(\"your.name@email.com\")\n</code></pre> <ol> <li>Find a company and get their latest financial data:</li> </ol> <pre><code>company = Company(\"TSLA\")\nlatest_10k = company.get_filings(form=\"10-K\").latest()\nfinancials = latest_10k.obj().financials()\n</code></pre> <p>`</p>"},{"location":"#popular-use-cases","title":"Popular Use Cases","text":""},{"location":"#financial-analysis","title":"Financial Analysis","text":"<ul> <li>Compare companies across industries</li> <li>Track financial performance over time</li> <li>Calculate and analyze financial ratios</li> <li>Build custom financial dashboards</li> </ul>"},{"location":"#investment-research","title":"Investment Research","text":"<ul> <li>Analyze fund holdings and strategy changes</li> <li>Track insider buying and selling activity</li> <li>Monitor material events through 8-K filings</li> <li>Research IPOs and new offerings</li> </ul>"},{"location":"#academic-research","title":"Academic Research","text":"<ul> <li>Large-scale financial data analysis</li> <li>Corporate governance studies</li> <li>Market efficiency research</li> <li>Regulatory compliance analysis</li> </ul>"},{"location":"#aiml-applications","title":"AI/ML Applications","text":"<ul> <li>Extract clean text for natural language processing</li> <li>Build predictive models with financial data</li> <li>Automate document analysis workflows</li> <li>Create training datasets for financial AI</li> <li>Advanced ranking search with BM25 and semantic structure awareness</li> </ul>"},{"location":"#why-choose-edgartools","title":"Why Choose EdgarTools?","text":"Feature EdgarTools Alternative Solutions Ease of Use \u2705 Simple, Pythonic API \u274c Complex setup required Data Quality \u2705 Clean, standardized data \u26a0\ufe0f Raw data needs processing Performance \u2705 Optimized for large datasets \u274c Slow for bulk operations Documentation \u2705 Comprehensive with examples \u26a0\ufe0f Limited examples Active Development \u2705 Regular updates and features \u274c Infrequent updates Community \u2705 Growing user base \u26a0\ufe0f Limited community"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>\ud83d\udcd6 Documentation: Comprehensive guides and API reference</li> <li>\ud83d\udcac GitHub Discussions: Ask questions and share insights</li> <li>\ud83d\udc1b Issue Tracker: Report bugs and request features</li> <li>\ud83d\udce7 Email Support: Direct support for enterprise users</li> </ul>"},{"location":"#support-the-project","title":"Support the Project","text":"<p>If you find EdgarTools useful, please consider supporting its development:</p> <p> </p> <p>Your support helps maintain and improve EdgarTools for the entire community!</p>"},{"location":"#whats-next","title":"What's Next?","text":"<p>Installation Guide</p> <p>Complete setup instructions and troubleshooting</p> <p>Quick Start Tutorial</p> <p>Your first analysis in 5 minutes</p> <p>API Reference</p> <p>Complete documentation of all classes and methods</p> <p>Examples &amp; Recipes</p> <p>Real-world analysis patterns and code templates</p> <p>Advanced Search</p> <p>BM25 ranking, semantic search, and intelligent caching</p> <p>Ready to start analyzing SEC data? Install EdgarTools and begin your first analysis today.</p>"},{"location":"13f-filings/","title":"13F Holdings Reports","text":"<p>13F filings are quarterly reports filed by institutional investment managers that disclose their equity holdings. These reports provide valuable insights into how large institutions allocate their capital and are essential for investment research, portfolio tracking, and market analysis.</p>"},{"location":"13f-filings/#what-are-13f-filings","title":"What are 13F Filings?","text":"<p>13F-HR (Holdings Report) filings are required for institutional investment managers with over $100 million in qualifying assets under management. These reports must be filed within 45 days of the end of each quarter and disclose all equity holdings as of the quarter's end.</p>"},{"location":"13f-filings/#types-of-13f-filings","title":"Types of 13F Filings","text":"<p>EdgarTools supports all 13F filing types:</p> Form Description Has Holdings Data 13F-HR Holdings Report \u2705 Yes 13F-HR/A Amended Holdings Report \u2705 Yes 13F-NT Notice Report (no holdings to report) \u274c No 13F-NT/A Amended Notice Report \u274c No"},{"location":"13f-filings/#getting-13f-filings","title":"Getting 13F Filings","text":""},{"location":"13f-filings/#search-all-13f-filings","title":"Search All 13F Filings","text":"<p>Find 13F filings across all institutional managers:</p> <pre><code>from edgar import get_filings\n\n# Get recent 13F holdings reports\nholdings_reports = get_filings(form=\"13F-HR\")\nprint(holdings_reports)\n</code></pre>"},{"location":"13f-filings/#get-13f-filings-for-specific-fund","title":"Get 13F Filings for Specific Fund","text":"<p>Search for a specific institutional manager by company name:</p> <pre><code>from edgar import Company\n\n# Berkshire Hathaway's 13F filings\nberkshire = Company(\"BRK.A\")\nfilings = berkshire.get_filings(form=\"13F-HR\")\nprint(filings)\n</code></pre>"},{"location":"13f-filings/#filter-by-date-range","title":"Filter by Date Range","text":"<p>Focus on specific time periods:</p> <pre><code># Get Q3 2024 13F filings\nq3_filings = get_filings(\n    form=\"13F-HR\",\n    filing_date=\"2024-11-01:2024-11-15\"  # Typical Q3 filing window\n)\n</code></pre>"},{"location":"13f-filings/#working-with-thirteenf-objects","title":"Working with ThirteenF Objects","text":"<p>Convert a 13F filing to a structured data object for analysis:</p> <pre><code># Get the latest 13F filing\nfiling = holdings_reports.latest()\nthirteenf = filing.obj()  # Convert to ThirteenF object\n\nprint(thirteenf)\n</code></pre>"},{"location":"13f-filings/#basic-information","title":"Basic Information","text":"<p>Access key details about the 13F filing:</p> <pre><code># Fund/Manager information\nfund_name = thirteenf.investment_manager.name\nfund_address = thirteenf.investment_manager.address\n\n# Filing details\nreport_period = thirteenf.report_period      # \"2024-09-30\"\nfiling_date = thirteenf.filing_date          # \"2024-11-14\"\nform_type = thirteenf.form                   # \"13F-HR\"\n\n# Portfolio summary\ntotal_value = thirteenf.total_value          # Total portfolio value\nholdings_count = thirteenf.total_holdings    # Number of holdings\nsigner = thirteenf.signer                    # Person who signed the filing\n\nprint(f\"{fund_name} reported ${total_value:,.0f} across {holdings_count} holdings\")\n</code></pre>"},{"location":"13f-filings/#checking-for-holdings-data","title":"Checking for Holdings Data","text":"<p>Not all 13F filings contain holdings data (NT forms are notice reports):</p> <pre><code>if thirteenf.has_infotable():\n    print(f\"Filing contains {len(thirteenf.infotable)} holdings\")\n    holdings = thirteenf.infotable\nelse:\n    print(\"This is a notice filing with no holdings data\")\n</code></pre>"},{"location":"13f-filings/#accessing-holdings-data","title":"Accessing Holdings Data","text":"<p>The core value of 13F filings is the detailed holdings information:</p>"},{"location":"13f-filings/#get-all-holdings","title":"Get All Holdings","text":"<pre><code># Holdings as pandas DataFrame\nholdings = thirteenf.infotable\nprint(f\"Found {len(holdings)} holdings\")\n\n# Display top holdings by value\ntop_10 = holdings.sort_values('Value', ascending=False).head(10)\nprint(top_10[['Issuer', 'Ticker', 'Value', 'Shares']])\n</code></pre>"},{"location":"13f-filings/#holdings-data-structure","title":"Holdings Data Structure","text":"<p>Each holding contains detailed information:</p> <pre><code>for _, holding in holdings.head(5).iterrows():\n    print(f\"Company: {holding['Issuer']}\")\n    print(f\"Ticker: {holding['Ticker']}\")\n    print(f\"CUSIP: {holding['Cusip']}\")\n    print(f\"Value: ${holding['Value']:,.0f}\")\n    print(f\"Shares: {holding['Shares']:,.0f}\")\n    print(f\"Security Type: {holding['Type']}\")\n    print(f\"Put/Call: {holding['PutCall']}\")\n    print(\"---\")\n</code></pre>"},{"location":"13f-filings/#holdings-dataframe-columns","title":"Holdings DataFrame Columns","text":"<p>The holdings DataFrame includes these columns:</p> Column Description Example <code>Issuer</code> Company name \"APPLE INC\" <code>Class</code> Security class \"COM\" <code>Cusip</code> CUSIP identifier \"037833100\" <code>Ticker</code> Stock ticker symbol \"AAPL\" <code>Value</code> Market value (thousands) 1500000 <code>Shares</code> Number of shares 1234567 <code>Type</code> Security type \"Shares\" or \"Principal\" <code>PutCall</code> Options type \"Put\", \"Call\", or \"\" <code>SoleVoting</code> Sole voting authority 1234567 <code>SharedVoting</code> Shared voting authority 0 <code>NonVoting</code> No voting authority 0"},{"location":"13f-filings/#common-use-cases","title":"Common Use Cases","text":""},{"location":"13f-filings/#1-portfolio-analysis","title":"1. Portfolio Analysis","text":"<p>Analyze a fund's portfolio composition:</p> <pre><code># Portfolio concentration\ntotal_portfolio = holdings['Value'].sum()\nholdings['Weight'] = holdings['Value'] / total_portfolio * 100\n\n# Top 10 holdings by weight\ntop_holdings = holdings.nlargest(10, 'Weight')\nprint(\"Top 10 Holdings:\")\nfor _, holding in top_holdings.iterrows():\n    print(f\"{holding['Ticker']:&gt;6}: {holding['Weight']:&gt;5.1f}% (${holding['Value']:&gt;10,.0f}K)\")\n\n# Sector analysis (if you have sector mapping)\nprint(f\"\\nPortfolio concentration: Top 10 = {top_holdings['Weight'].sum():.1f}%\")\n</code></pre>"},{"location":"13f-filings/#2-position-tracking","title":"2. Position Tracking","text":"<p>Track specific positions across time:</p> <pre><code># Find Apple positions across multiple quarters\napple_positions = []\n\nfor filing in berkshire.get_filings(form=\"13F-HR\").head(4):\n    thirteenf = filing.obj()\n    if thirteenf.has_infotable():\n        apple_holding = thirteenf.infotable.query(\"Ticker == 'AAPL'\")\n        if not apple_holding.empty:\n            position = {\n                'date': thirteenf.report_period,\n                'shares': apple_holding.iloc[0]['Shares'],\n                'value': apple_holding.iloc[0]['Value']\n            }\n            apple_positions.append(position)\n\n# Convert to DataFrame for analysis\nimport pandas as pd\napple_df = pd.DataFrame(apple_positions)\nprint(\"Apple position over time:\")\nprint(apple_df)\n</code></pre>"},{"location":"13f-filings/#3-new-positions-changes","title":"3. New Positions &amp; Changes","text":"<p>Identify new positions by comparing quarters:</p> <pre><code># Get current and previous quarter\ncurrent_13f = berkshire.get_filings(form=\"13F-HR\").latest().obj()\nprevious_13f = current_13f.previous_holding_report()\n\nif previous_13f:\n    current_tickers = set(current_13f.infotable['Ticker'].dropna())\n    previous_tickers = set(previous_13f.infotable['Ticker'].dropna())\n\n    new_positions = current_tickers - previous_tickers\n    closed_positions = previous_tickers - current_tickers\n\n    print(f\"New positions: {len(new_positions)}\")\n    for ticker in new_positions:\n        if ticker:  # Skip NaN tickers\n            print(f\"  {ticker}\")\n\n    print(f\"Closed positions: {len(closed_positions)}\")\n    for ticker in closed_positions:\n        if ticker:\n            print(f\"  {ticker}\")\n</code></pre>"},{"location":"13f-filings/#4-options-analysis","title":"4. Options Analysis","text":"<p>Analyze put and call option holdings:</p> <pre><code># Filter for options positions\noptions = holdings.query(\"PutCall in ['Put', 'Call']\")\n\nif not options.empty:\n    puts = options.query(\"PutCall == 'Put'\")\n    calls = options.query(\"PutCall == 'Call'\")\n\n    print(f\"Options positions: {len(options)}\")\n    print(f\"  Puts: {len(puts)} (${puts['Value'].sum():,.0f}K)\")\n    print(f\"  Calls: {len(calls)} (${calls['Value'].sum():,.0f}K)\")\n\n    # Top options positions\n    print(\"\\nTop Options Positions:\")\n    for _, option in options.nlargest(5, 'Value').iterrows():\n        print(f\"  {option['Ticker']} {option['PutCall']}: ${option['Value']:,.0f}K\")\n</code></pre>"},{"location":"13f-filings/#data-structure-overview","title":"Data Structure Overview","text":""},{"location":"13f-filings/#thirteenf-object-properties","title":"ThirteenF Object Properties","text":"Property Type Description <code>form</code> str Filing form type (\"13F-HR\", \"13F-NT\", etc.) <code>investment_manager</code> FilingManager Fund/manager information and address <code>report_period</code> str Quarter end date (\"2024-09-30\") <code>filing_date</code> str Date filed with SEC <code>total_value</code> Decimal Total portfolio value (in thousands) <code>total_holdings</code> int Number of holdings reported <code>signer</code> str Name of person who signed the filing <code>infotable</code> DataFrame Holdings data (if available)"},{"location":"13f-filings/#filingmanager-object","title":"FilingManager Object","text":"<pre><code>manager = thirteenf.investment_manager\nprint(f\"Name: {manager.name}\")\nprint(f\"Address: {manager.address.street1}\")\nprint(f\"City: {manager.address.city}, {manager.address.state_or_country}\")\n</code></pre>"},{"location":"13f-filings/#previous-period-reports","title":"Previous Period Reports","text":"<p>Access historical filings from the same manager:</p> <pre><code># Get the previous quarter's filing\nprevious = thirteenf.previous_holding_report()\n\nif previous:\n    print(f\"Previous report: {previous.report_period}\")\n    print(f\"Previous holdings: {previous.total_holdings}\")\nelse:\n    print(\"No previous report available\")\n</code></pre>"},{"location":"13f-filings/#advanced-features","title":"Advanced Features","text":""},{"location":"13f-filings/#raw-xml-access","title":"Raw XML Access","text":"<p>Access the underlying XML data for custom parsing:</p> <pre><code># Primary document XML (cover page, summary, signature)\nprimary_xml = thirteenf.filing.xml()\n\n# Holdings information table XML\nif thirteenf.has_infotable():\n    infotable_xml = thirteenf.infotable_xml\n    infotable_html = thirteenf.infotable_html  # HTML version if available\n</code></pre>"},{"location":"13f-filings/#related-filings","title":"Related Filings","text":"<p>13F filings often have related filings (amendments, combined reports):</p> <pre><code># Get all related filings on the same filing date\nrelated = thirteenf._related_filings\nprint(f\"Related filings: {len(related)}\")\n\nfor filing in related:\n    print(f\"  {filing.accession_no}: {filing.form}\")\n</code></pre>"},{"location":"13f-filings/#rich-display-output","title":"Rich Display Output","text":"<p>EdgarTools provides beautiful formatted output for 13F data:</p> <pre><code># Display the complete 13F report\nprint(thirteenf)  # Rich formatted table with holdings\n\n# Display just the holdings table\nif thirteenf.has_infotable():\n    print(thirteenf.infotable)  # Pandas DataFrame with rich formatting\n</code></pre> <p>The output includes: - \ud83d\udcca Summary table with key metrics - \ud83d\udcc8 Top holdings by value - \ud83c\udfaf Options positions (puts/calls) - \ud83d\udcbc Portfolio statistics</p>"},{"location":"13f-filings/#limitations-notes","title":"Limitations &amp; Notes","text":""},{"location":"13f-filings/#current-limitations","title":"Current Limitations","text":"<ul> <li>Discovery: Finding 13F filers by name requires knowing the exact company name or CIK. There's no built-in search for \"all hedge funds\" or \"top asset managers\"</li> <li>Sector Classification: Holdings don't include automatic sector/industry classification</li> <li>Historical Comparisons: Comparing positions across multiple periods requires manual analysis</li> </ul>"},{"location":"13f-filings/#performance-tips","title":"Performance Tips","text":"<ul> <li>Caching: Large 13F files are cached automatically to improve performance</li> <li>Filtering: Use <code>.query()</code> on DataFrames for efficient filtering</li> <li>Batch Processing: Process multiple filings using list comprehensions</li> </ul>"},{"location":"13f-filings/#data-quality-notes","title":"Data Quality Notes","text":"<ul> <li>Ticker Symbols: Not all holdings have ticker symbols (private companies, bonds)</li> <li>CUSIP Mapping: Ticker mapping is based on CUSIP identifiers which may not be current</li> <li>Amendments: Always check for amended filings (13F-HR/A) for the most accurate data</li> </ul>"},{"location":"13f-filings/#error-handling","title":"Error Handling","text":"<p>Handle common issues gracefully:</p> <pre><code>try:\n    thirteenf = filing.obj()\n\n    if thirteenf.has_infotable():\n        holdings = thirteenf.infotable\n        print(f\"Successfully loaded {len(holdings)} holdings\")\n    else:\n        print(\"Filing contains no holdings data (notice report)\")\n\nexcept Exception as e:\n    print(f\"Error parsing 13F filing: {e}\")\n    # Fall back to raw filing content\n    content = filing.text\n</code></pre>"},{"location":"13f-filings/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 API Reference: Complete method documentation</li> <li>\ud83d\udcac GitHub Discussions: Ask questions about 13F analysis</li> <li>\ud83d\udc1b Issues: Report bugs or request 13F enhancements</li> </ul> <p>\ud83c\udfaf Pro Tip: 13F filings are powerful for tracking institutional investment trends, but remember they're filed quarterly with a 45-day delay. For real-time analysis, combine with other data sources.</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/","title":"AI-Native Crowdfunding Workflow Implementation Plan","text":"<p>Date: 2025-11-04 Status: \u2705 COMPLETED (Phases 1-3) Goal: Enable AI agents to independently discover and navigate the crowdfunding workflow from Company \u2192 FormC \u2192 Offering without code generation or manual hints.</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#executive-summary","title":"Executive Summary","text":"<p>Initial State: 40% AI-native ready (2 of 5 classes have <code>to_context()</code>) Final State: \u2705 100% AI-native ready (all navigation classes have context methods) Impact Achieved: 58% token reduction, zero manual intervention needed for agent workflows</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#implementation-complete","title":"Implementation Complete! \u2705","text":"Class Has to_context()? Status Implementation Company \u2705 Complete Renamed from .text() with deprecation Filings \u2705 Complete Hints at .latest(), .filter() Filing \u2705 Complete Hints at .obj() with return type FormC \u2705 Complete Hints at .get_offering() Offering \u2705 Complete Full lifecycle works XBRL \u2705 Complete Renamed from .text() with deprecation"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#research-findings-summary","title":"Research Findings Summary","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#current-ai-native-coverage","title":"Current AI-Native Coverage","text":"<p>Classes WITH <code>to_context()</code>: \u2705 - <code>FormC</code> (<code>edgar/offerings/formc.py:686-879</code>) - Excellent, 3 detail levels - <code>Offering</code> (<code>edgar/offerings/campaign.py:509-629</code>) - Excellent, timeline support</p> <p>Classes WITHOUT <code>to_context()</code>: \u274c - <code>Company</code> - Has <code>.text()</code> but different naming convention - <code>Filings</code> - No context method - <code>Filing</code> - No context method - <code>EntityFilings</code> - No context method</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#agent-navigation-workflow","title":"Agent Navigation Workflow","text":"<p>Ideal Discovery Pattern:</p> <pre><code>Company.to_context()\n  \u2192 hints at .get_filings()\n  \u2192 EntityFilings.to_context()\n    \u2192 hints at .latest() or [index]\n    \u2192 Filing.to_context()\n      \u2192 hints at .obj() returns FormC\n      \u2192 FormC.to_context()\n        \u2192 hints at .get_offering()\n        \u2192 Offering.to_context()\n          \u2192 Complete lifecycle analysis\n</code></pre> <p>Current Reality (where agent gets stuck \u274c):</p> <pre><code>Company.text()\n  \u274c No .get_filings() hint\n  \u2192 EntityFilings (no context)\n    \u274c Must guess .latest()\n    \u2192 Filing (no context)\n      \u274c Must guess .obj()\n      \u2192 FormC.to_context() \u2705\n        \u26a0\ufe0f No .get_offering() mention\n        \u2192 Offering.to_context() \u2705\n</code></pre>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#token-efficiency-analysis","title":"Token Efficiency Analysis","text":"<p>Current (with manual help): ~1400 tokens - Exploratory code generation: 500 tokens - User hints: 200 tokens - Failed method attempts: 300 tokens - Eventual success: 400 tokens</p> <p>With Full Coverage: ~600 tokens (58% reduction) - to_context() at each step: 150 tokens - Immediate discovery: 50 tokens - No failed attempts: 0 tokens - Report generation: 400 tokens</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#implementation-plan","title":"Implementation Plan","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#phase-1-critical-navigation-blockers","title":"Phase 1: Critical Navigation Blockers \ud83d\udd34","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-11-implement-filingto_context","title":"Task 1.1: Implement <code>Filing.to_context()</code>","text":"<p>File: <code>edgar/_filings.py</code> Location: Add method to <code>Filing</code> class Priority: CRITICAL - Biggest blocker</p> <p>Implementation:</p> <pre><code>def to_context(self, detail: str = 'standard') -&gt; str:\n    \"\"\"\n    Returns AI-optimized filing metadata.\n\n    Args:\n        detail: 'minimal' (~100 tokens), 'standard' (~250 tokens), 'full' (~500 tokens)\n\n    Returns:\n        Markdown-KV formatted context string\n    \"\"\"\n    lines = []\n\n    # Header\n    lines.append(f\"FILING: Form {self.form}\")\n    lines.append(\"\")\n\n    # Always include\n    lines.append(f\"Company: {self.company}\")\n    lines.append(f\"CIK: {self.cik}\")\n    lines.append(f\"Filed: {self.filing_date}\")\n    lines.append(f\"Accession: {self.accession_no}\")\n\n    if detail in ['standard', 'full']:\n        lines.append(\"\")\n        lines.append(\"AVAILABLE ACTIONS:\")\n        lines.append(f\"  - Use .obj() to parse as structured data\")\n\n        # Form-specific hints\n        if self.form in ['C', 'C/A', 'C-U', 'C-AR', 'C-TR']:\n            lines.append(f\"    Returns: FormC object with offering details\")\n        elif self.form in ['10-K', '10-Q']:\n            lines.append(f\"    Returns: {self.form.replace('-', '')} object\")\n\n        lines.append(f\"  - Use .xbrl() for financial statements (if available)\")\n        lines.append(f\"  - Use .document() for structured text extraction\")\n        lines.append(f\"  - Use .attachments for exhibits ({len(self.attachments) if hasattr(self, 'attachments') else '?'} documents)\")\n\n    if detail == 'full':\n        lines.append(\"\")\n        lines.append(\"DOCUMENTS:\")\n        lines.append(f\"  Primary: {getattr(self, 'primary_document', 'N/A')}\")\n        lines.append(f\"  Size: {getattr(self, 'size', 'N/A')}\")\n        if hasattr(self, 'is_xbrl') and self.is_xbrl:\n            lines.append(f\"  XBRL: Available\")\n\n    return \"\\n\".join(lines)\n</code></pre> <p>Key Information to Include: - Form type, company, CIK, filing date - Critical: <code>.obj()</code> method hint with return type - Available methods: <code>.xbrl()</code>, <code>.document()</code>, <code>.attachments</code> - Document count and type</p> <p>Estimated Effort: 2 hours (including tests)</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-12-implement-filingsto_context","title":"Task 1.2: Implement <code>Filings.to_context()</code>","text":"<p>File: <code>edgar/_filings.py</code> Location: Add method to <code>Filings</code> class Priority: CRITICAL - Blocks collection understanding</p> <p>Implementation:</p> <pre><code>def to_context(self, detail: str = 'standard') -&gt; str:\n    \"\"\"\n    Returns AI-optimized collection summary.\n\n    Args:\n        detail: 'minimal' (~100 tokens), 'standard' (~250 tokens), 'full' (~600 tokens)\n\n    Returns:\n        Markdown-KV formatted context string\n    \"\"\"\n    lines = []\n\n    # Header\n    lines.append(f\"FILINGS COLLECTION\")\n    lines.append(\"\")\n\n    # Always include\n    lines.append(f\"Total: {len(self)} filings\")\n\n    # Get unique form types\n    forms = sorted(set(f.form for f in self))\n    lines.append(f\"Forms: {', '.join(forms)}\")\n\n    if len(self) &gt; 0:\n        dates = [f.filing_date for f in self]\n        lines.append(f\"Date Range: {min(dates)} to {max(dates)}\")\n\n    lines.append(\"\")\n    lines.append(\"AVAILABLE ACTIONS:\")\n    lines.append(\"  - Use .latest() to get most recent filing\")\n    lines.append(\"  - Use [index] to access specific filing (e.g., filings[0])\")\n    lines.append(\"  - Use .filter(form='C') to narrow by form type\")\n\n    if detail in ['standard', 'full']:\n        # Show sample entries\n        lines.append(\"\")\n        lines.append(\"SAMPLE FILINGS:\")\n        for i, filing in enumerate(self[:3]):  # First 3\n            lines.append(f\"  {i}. Form {filing.form} - {filing.filing_date} - {filing.company}\")\n\n        if len(self) &gt; 3:\n            lines.append(f\"  ... ({len(self) - 3} more)\")\n\n    if detail == 'full':\n        # Form breakdown\n        from collections import Counter\n        form_counts = Counter(f.form for f in self)\n        lines.append(\"\")\n        lines.append(\"FORM BREAKDOWN:\")\n        for form, count in sorted(form_counts.items()):\n            lines.append(f\"  {form}: {count} filings\")\n\n    return \"\\n\".join(lines)\n</code></pre> <p>Key Information to Include: - Total count and unique form types - Date range (earliest to latest) - Critical: <code>.latest()</code>, <code>[index]</code>, <code>.filter()</code> method hints - Sample entries (first 2-3 filings) - Form breakdown (full detail)</p> <p>Estimated Effort: 1.5 hours (including tests)</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#phase-2-complete-discovery-chain","title":"Phase 2: Complete Discovery Chain \ud83d\udfe1","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-21-implement-entityfilingsto_context","title":"Task 2.1: Implement <code>EntityFilings.to_context()</code>","text":"<p>File: <code>edgar/entity/filings.py</code> Location: Add method to <code>EntityFilings</code> class (inherits from <code>Filings</code>) Priority: IMPORTANT - Entity-specific context</p> <p>Implementation:</p> <pre><code>def to_context(self, detail: str = 'standard') -&gt; str:\n    \"\"\"\n    Returns AI-optimized entity filings summary.\n\n    Extends Filings.to_context() with entity-specific context.\n    \"\"\"\n    lines = []\n\n    # Header with entity info\n    lines.append(f\"FILINGS FOR: {self.company_name}\")\n    lines.append(f\"CIK: {self.cik}\")\n    lines.append(\"\")\n\n    # Get base context from parent (without header)\n    base_context = super().to_context(detail=detail)\n    # Skip first 2 lines (header) from parent\n    base_lines = base_context.split('\\n')[2:]\n    lines.extend(base_lines)\n\n    # Add entity-specific insights for standard/full\n    if detail in ['standard', 'full'] and len(self) &gt; 0:\n        # Crowdfunding-specific breakdown\n        cf_forms = [f for f in self if f.form in ['C', 'C/A', 'C-U', 'C-AR', 'C-TR']]\n        if cf_forms:\n            lines.append(\"\")\n            lines.append(\"CROWDFUNDING FILINGS:\")\n            from collections import Counter\n            cf_counts = Counter(f.form for f in cf_forms)\n            for form in ['C', 'C/A', 'C-U', 'C-AR', 'C-TR']:\n                if form in cf_counts:\n                    lines.append(f\"  {form}: {cf_counts[form]} filings\")\n\n    return \"\\n\".join(lines)\n</code></pre> <p>Key Additions: - Company name and CIK at top - Inherits all Filings functionality - Adds crowdfunding-specific breakdown - Entity context for better understanding</p> <p>Estimated Effort: 1 hour (leverages Filings implementation)</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-22-update-formcto_context","title":"Task 2.2: Update <code>FormC.to_context()</code>","text":"<p>File: <code>edgar/offerings/formc.py</code> Location: Line ~850 (in existing <code>to_context()</code> method) Priority: IMPORTANT - Complete the chain</p> <p>Change Required: Add method hints section at the end of the context string:</p> <pre><code># At the end of to_context() method, before return:\nif detail in ['standard', 'full']:\n    lines.append(\"\")\n    lines.append(\"AVAILABLE ACTIONS:\")\n    lines.append(\"  - Use .get_offering() for complete campaign lifecycle\")\n    lines.append(\"  - Use .issuer for IssuerCompany information\")\n    if self.offering_information:\n        lines.append(\"  - Use .offering_information for offering terms\")\n    if self.annual_report_disclosure:\n        lines.append(\"  - Use .annual_report_disclosure for financial data\")\n\nreturn \"\\n\".join(lines)\n</code></pre> <p>Key Addition: - Explicitly mentions <code>.get_offering()</code> method - Guides agent to next step (Offering object) - Lists other available navigation paths</p> <p>Estimated Effort: 15 minutes</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#phase-3-polish-and-consistency","title":"Phase 3: Polish and Consistency \ud83d\udfe2","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-31-add-companyto_context-or-enhance-text","title":"Task 3.1: Add <code>Company.to_context()</code> or Enhance <code>.text()</code>","text":"<p>File: <code>edgar/entity/core.py</code> Location: <code>Company</code> class Priority: NICE-TO-HAVE - Entry point improvement</p> <p>Option A (Recommended): Add alias</p> <pre><code>def to_context(self, detail: str = 'standard') -&gt; str:\n    \"\"\"Alias for .text() - AI-native naming convention.\"\"\"\n    context = self.text()\n\n    # Add method hints if not present\n    if detail in ['standard', 'full']:\n        lines = [context, \"\"]\n        lines.append(\"AVAILABLE ACTIONS:\")\n        lines.append(\"  - Use .get_filings(form='C') for crowdfunding filings\")\n        lines.append(\"  - Use .get_filings(form='10-K') for annual reports\")\n        lines.append(\"  - Use .get_facts() for financial facts API\")\n        return \"\\n\".join(lines)\n\n    return context\n</code></pre> <p>Option B: Enhance existing <code>.text()</code> method to include hints</p> <p>Recommendation: Option A for consistency with FormC/Offering naming</p> <p>Estimated Effort: 30 minutes</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-32-add-test-coverage","title":"Task 3.2: Add Test Coverage","text":"<p>File: Create <code>tests/test_ai_native_context.py</code> Priority: NICE-TO-HAVE - Quality assurance</p> <p>Test Cases:</p> <pre><code>import pytest\nfrom edgar import Company, get_filings\n\nclass TestAINativeContext:\n    \"\"\"Test to_context() methods across workflow.\"\"\"\n\n    def test_filing_to_context_minimal(self):\n        \"\"\"Filing.to_context(detail='minimal') under 150 tokens.\"\"\"\n        filings = get_filings(2024, 1, form='C')\n        filing = filings[0]\n        context = filing.to_context(detail='minimal')\n\n        assert len(context.split()) &lt; 150  # Rough token count\n        assert '.obj()' in context\n        assert filing.form in context\n\n    def test_filing_to_context_standard(self):\n        \"\"\"Filing.to_context(detail='standard') under 350 tokens.\"\"\"\n        filings = get_filings(2024, 1, form='C')\n        filing = filings[0]\n        context = filing.to_context(detail='standard')\n\n        assert len(context.split()) &lt; 350\n        assert 'AVAILABLE ACTIONS' in context\n        assert '.obj()' in context\n        assert '.xbrl()' in context or '.document()' in context\n\n    def test_filings_to_context_has_navigation_hints(self):\n        \"\"\"Filings.to_context() includes .latest() hint.\"\"\"\n        filings = get_filings(2024, 1, form='C')\n        context = filings.to_context()\n\n        assert '.latest()' in context\n        assert '[index]' in context or 'filings[0]' in context\n        assert '.filter(' in context\n\n    def test_formc_mentions_get_offering(self):\n        \"\"\"FormC.to_context() mentions .get_offering() method.\"\"\"\n        filings = get_filings(2024, 1, form='C')\n        formc = filings[0].obj()\n        context = formc.to_context()\n\n        assert '.get_offering()' in context\n\n    def test_full_workflow_discoverable(self):\n        \"\"\"Agent can discover full workflow through context.\"\"\"\n        company = Company(1881570)\n\n        # Step 1: Company hints at .get_filings()\n        if hasattr(company, 'to_context'):\n            context = company.to_context()\n            assert '.get_filings' in context\n\n        # Step 2: Filings hints at .latest()\n        filings = company.get_filings(form='C')\n        context = filings.to_context()\n        assert '.latest()' in context\n\n        # Step 3: Filing hints at .obj()\n        filing = filings.latest()\n        context = filing.to_context()\n        assert '.obj()' in context\n\n        # Step 4: FormC hints at .get_offering()\n        formc = filing.obj()\n        context = formc.to_context()\n        assert '.get_offering()' in context\n\n        # Step 5: Offering provides lifecycle\n        offering = formc.get_offering()\n        context = offering.to_context()\n        assert 'lifecycle' in context.lower() or 'stage' in context.lower()\n</code></pre> <p>Estimated Effort: 1 hour</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#task-33-create-ai-agent-navigation-guide","title":"Task 3.3: Create AI Agent Navigation Guide","text":"<p>File: Create <code>docs/AI_AGENT_NAVIGATION_GUIDE.md</code> Priority: NICE-TO-HAVE - Documentation</p> <p>Content Structure:</p> <pre><code># AI Agent Navigation Guide: Crowdfunding Workflow\n\n## Overview\nEdgarTools provides AI-native navigation through `.to_context()` methods.\n\n## Discovery Pattern\n\n### Step 1: Start with Company\n```python\ncompany = Company(1881570)\nprint(company.to_context())\n</code></pre> <p>Output Shows: - Company name, CIK, information - Available Actions: <code>.get_filings()</code> method</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#step-2-get-filings-collection","title":"Step 2: Get Filings Collection","text":"<pre><code>filings = company.get_filings(form='C')\nprint(filings.to_context())\n</code></pre> <p>Output Shows: - Total count, form types, date range - Available Actions: <code>.latest()</code>, <code>[index]</code>, <code>.filter()</code></p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#step-3-select-a-filing","title":"Step 3: Select a Filing","text":"<pre><code>filing = filings.latest()\nprint(filing.to_context())\n</code></pre> <p>Output Shows: - Form type, company, filing date - Available Actions: <code>.obj()</code> for FormC</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#step-4-parse-formc","title":"Step 4: Parse FormC","text":"<pre><code>formc = filing.obj()\nprint(formc.to_context())\n</code></pre> <p>Output Shows: - Offering details, issuer info, financial data - Available Actions: <code>.get_offering()</code> for lifecycle</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#step-5-get-complete-lifecycle","title":"Step 5: Get Complete Lifecycle","text":"<pre><code>offering = formc.get_offering()\nprint(offering.to_context())\n</code></pre> <p>Output Shows: - Campaign status, lifecycle stages - Timeline of all filings</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#token-efficiency","title":"Token Efficiency","text":"Approach Tokens Time Code Generation ~1400 5-10 min Context Navigation ~600 2-3 min Savings 58% 60%"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#example-agent-workflow","title":"Example Agent Workflow","text":"<p>See <code>docs/examples/offering_lifecycle.py</code> for complete implementation.</p> <pre><code>\n**Estimated Effort**: 1 hour\n\n---\n\n## Implementation Priority\n\n### Week 1: Critical Path \ud83d\udd34\n**Goal**: Unblock agent navigation\n\n1. `Filing.to_context()` - 2 hours\n2. `Filings.to_context()` - 1.5 hours\n3. Basic testing - 30 minutes\n\n**Outcome**: Agent can navigate Company \u2192 Filings \u2192 Filing \u2192 FormC\n\n---\n\n### Week 2: Complete Chain \ud83d\udfe1\n**Goal**: Full workflow discovery\n\n4. `EntityFilings.to_context()` - 1 hour\n5. Update `FormC.to_context()` - 15 minutes\n6. Integration testing - 30 minutes\n\n**Outcome**: Agent can complete full workflow without hints\n\n---\n\n### Week 3: Polish \ud83d\udfe2\n**Goal**: Professional experience\n\n7. `Company.to_context()` - 30 minutes\n8. Comprehensive tests - 1 hour\n9. Documentation - 1 hour\n\n**Outcome**: Production-ready AI-native API\n\n---\n\n## Success Criteria\n\n### Functional Requirements\n- \u2705 Agent can start with `Company(cik)` and discover `.get_filings()`\n- \u2705 Agent can explore `filings` and discover `.latest()` or `[index]`\n- \u2705 Agent can inspect `filing` and discover `.obj()` returns FormC\n- \u2705 Agent can read `formc` and discover `.get_offering()` method\n- \u2705 Agent can analyze `offering` and access complete lifecycle\n\n### Performance Requirements\n- \u2705 `to_context(detail='minimal')` under 150 tokens\n- \u2705 `to_context(detail='standard')` under 350 tokens\n- \u2705 `to_context(detail='full')` under 800 tokens\n- \u2705 Overall workflow uses &lt; 600 tokens (vs 1400 today)\n\n### Quality Requirements\n- \u2705 All `to_context()` methods handle missing data gracefully\n- \u2705 Method hints appear in standard+ detail levels\n- \u2705 Consistent Markdown-KV format across all classes\n- \u2705 Test coverage for all new methods\n\n---\n\n## Testing Strategy\n\n### Unit Tests\nTest each `to_context()` method individually:\n- Token budget compliance\n- Missing data handling\n- Method hints present\n- Detail level variations\n\n### Integration Tests\nTest full workflow discovery:\n- Start \u2192 End navigation without hints\n- Agent can discover each next step\n- No dead ends or missing links\n\n### Performance Tests\nMeasure token efficiency:\n- Baseline: Current agent workflow (~1400 tokens)\n- Target: Context-driven workflow (~600 tokens)\n- Verify 58% improvement\n\n---\n\n## Risk Assessment\n\n### Low Risk \u2705\n- **Adding new methods**: No breaking changes to existing API\n- **Backward compatible**: All existing code continues to work\n- **Well-tested pattern**: FormC and Offering already demonstrate success\n\n### Medium Risk \u26a0\ufe0f\n- **Token budget**: Need to balance detail vs. brevity\n  - **Mitigation**: Start conservative, gather feedback\n- **Maintenance**: Need to update context when methods change\n  - **Mitigation**: Add to method change checklist\n\n### No Risk \ud83d\udfe2\n- **Performance**: Context generation is cheap (no network calls)\n- **Security**: Read-only information exposure\n- **Dependencies**: No new external dependencies\n\n---\n\n## Rollout Plan\n\n### Phase 1: Implementation (Week 1)\n- Implement critical methods\n- Basic testing\n- Internal validation\n\n### Phase 2: Validation (Week 2)\n- Complete workflow testing\n- Token efficiency measurement\n- Bug fixes\n\n### Phase 3: Documentation (Week 3)\n- Update guides\n- Add examples\n- Publish patterns\n\n### Phase 4: Monitoring (Ongoing)\n- Track agent usage patterns\n- Gather feedback\n- Iterate improvements\n\n---\n\n## Metrics for Success\n\n### Before Implementation\n- **AI-Native Coverage**: 40% (2/5 classes)\n- **Token Cost**: ~1400 tokens per workflow\n- **Manual Hints Needed**: 3-4 per workflow\n- **Agent Success Rate**: ~20% without hints\n\n### After Implementation\n- **AI-Native Coverage**: 95% (5/5 classes)\n- **Token Cost**: ~600 tokens per workflow (-58%)\n- **Manual Hints Needed**: 0\n- **Agent Success Rate**: 90%+ without hints\n\n---\n\n## Appendix A: Implementation Checklist\n\n### Critical Items \ud83d\udd34\n- [ ] Implement `Filing.to_context()`\n- [ ] Implement `Filings.to_context()`\n- [ ] Add basic tests\n- [ ] Verify token budgets\n\n### Important Items \ud83d\udfe1\n- [ ] Implement `EntityFilings.to_context()`\n- [ ] Update `FormC.to_context()` with method hints\n- [ ] Add integration tests\n- [ ] Test full workflow discovery\n\n### Nice-to-Have Items \ud83d\udfe2\n- [ ] Add `Company.to_context()` or enhance `.text()`\n- [ ] Create comprehensive test suite\n- [ ] Write AI Agent Navigation Guide\n- [ ] Add to main documentation\n\n---\n\n## Appendix B: Code Examples\n\n### Example: Filing.to_context() Output\n\n**Minimal**:\n</code></pre> <p>FILING: Form C</p> <p>Company: ViiT Health Inc CIK: 1881570 Filed: 2025-06-11 Accession: 0001670254-25-000647</p> <pre><code>\n**Standard**:\n</code></pre> <p>FILING: Form C</p> <p>Company: ViiT Health Inc CIK: 1881570 Filed: 2025-06-11 Accession: 0001670254-25-000647</p> <p>AVAILABLE ACTIONS:   - Use .obj() to parse as structured data     Returns: FormC object with offering details   - Use .xbrl() for financial statements (if available)   - Use .document() for structured text extraction   - Use .attachments for exhibits (5 documents)</p> <pre><code>\n**Full** (adds):\n</code></pre> <p>DOCUMENTS:   Primary: formc.xml   Size: 45KB   XBRL: Not available ```</p>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#appendix-c-related-documentation","title":"Appendix C: Related Documentation","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#existing-documentation","title":"Existing Documentation","text":"<ul> <li><code>AI_PATTERNS_DOCUMENTATION.md</code> - Current AI-native features</li> <li><code>AI_PATTERNS_SUMMARY.md</code> - Feature overview</li> <li><code>docs/examples/ai_native_api_patterns.md</code> - Design patterns</li> <li><code>docs/examples/offering_lifecycle.py</code> - Workflow example</li> </ul>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#documentation-to-create","title":"Documentation to Create","text":"<ul> <li><code>docs/AI_AGENT_NAVIGATION_GUIDE.md</code> - How agents should navigate</li> <li><code>tests/test_ai_native_context.py</code> - Test suite</li> <li>Updated <code>CLAUDE.md</code> - Include navigation patterns</li> </ul>"},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#appendix-d-future-enhancements","title":"Appendix D: Future Enhancements","text":""},{"location":"AI_NATIVE_WORKFLOW_IMPLEMENTATION_PLAN/#beyond-this-plan","title":"Beyond This Plan","text":"<ol> <li>Add to_context() to more classes</li> <li>XBRL, Statement, Document classes</li> <li> <p>Standardize across entire codebase</p> </li> <li> <p>Context-aware filtering</p> </li> <li><code>filings.to_context(focus='crowdfunding')</code></li> <li> <p>Smart relevance filtering</p> </li> <li> <p>Interactive exploration</p> </li> <li><code>.explore()</code> method for guided navigation</li> <li> <p>Relationship graph visualization</p> </li> <li> <p>Token optimization</p> </li> <li>Adaptive detail levels based on context window</li> <li> <p>Compression for repeated information</p> </li> <li> <p>Multi-language support</p> </li> <li>Context in different languages</li> <li>Domain-specific terminology</li> </ol> <p>Plan Created: 2025-11-04 Author: Claude (via research agent) Status: Ready for Implementation Estimated Total Effort: 8-10 hours Expected Completion: 3 weeks (at 3-4 hours/week)</p>"},{"location":"FormType-Quick-Reference/","title":"FormType Quick Reference Guide","text":""},{"location":"FormType-Quick-Reference/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<pre><code>from edgar import Company\nfrom edgar.enums import FormType\n\ncompany = Company(\"AAPL\")\n\n# New: IDE autocomplete for form types\nfilings = company.get_filings(form=FormType.ANNUAL_REPORT)\n\n# Old: Still works perfectly\nfilings = company.get_filings(form=\"10-K\")\n</code></pre>"},{"location":"FormType-Quick-Reference/#all-available-formtypes","title":"\ud83d\udccb All Available FormTypes","text":""},{"location":"FormType-Quick-Reference/#periodic-reports","title":"Periodic Reports","text":"<pre><code>FormType.ANNUAL_REPORT              # \"10-K\"\nFormType.QUARTERLY_REPORT           # \"10-Q\" \nFormType.ANNUAL_REPORT_AMENDED      # \"10-K/A\"\nFormType.QUARTERLY_REPORT_AMENDED   # \"10-Q/A\"\nFormType.FOREIGN_ANNUAL             # \"20-F\"\nFormType.CANADIAN_ANNUAL            # \"40-F\"\nFormType.EMPLOYEE_BENEFIT_PLAN      # \"11-K\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#current-reports","title":"Current Reports","text":"<pre><code>FormType.CURRENT_REPORT             # \"8-K\"\nFormType.FOREIGN_CURRENT_REPORT     # \"6-K\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#proxy-statements","title":"Proxy Statements","text":"<pre><code>FormType.PROXY_STATEMENT            # \"DEF 14A\"\nFormType.PRELIMINARY_PROXY          # \"PRE 14A\"\nFormType.ADDITIONAL_PROXY           # \"DEFA14A\"\nFormType.MERGER_PROXY               # \"DEFM14A\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#registration-statements","title":"Registration Statements","text":"<pre><code>FormType.REGISTRATION_S1            # \"S-1\"\nFormType.REGISTRATION_S3            # \"S-3\"\nFormType.REGISTRATION_S4            # \"S-4\" \nFormType.REGISTRATION_S8            # \"S-8\"\nFormType.FOREIGN_REGISTRATION_F1    # \"F-1\"\nFormType.FOREIGN_REGISTRATION_F3    # \"F-3\"\nFormType.FOREIGN_REGISTRATION_F4    # \"F-4\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#prospectuses","title":"Prospectuses","text":"<pre><code>FormType.PROSPECTUS_424B1           # \"424B1\"\nFormType.PROSPECTUS_424B2           # \"424B2\"\nFormType.PROSPECTUS_424B3           # \"424B3\"\nFormType.PROSPECTUS_424B4           # \"424B4\"\nFormType.PROSPECTUS_424B5           # \"424B5\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#ownership-reports","title":"Ownership Reports","text":"<pre><code>FormType.BENEFICIAL_OWNERSHIP_13D   # \"SC 13D\"\nFormType.BENEFICIAL_OWNERSHIP_13G   # \"SC 13G\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#other-important-forms","title":"Other Important Forms","text":"<pre><code>FormType.SPECIALIZED_DISCLOSURE     # \"SD\"\nFormType.ASSET_BACKED_SECURITIES    # \"ARS\"\nFormType.LATE_10K_NOTICE           # \"NT 10-K\"\nFormType.LATE_10Q_NOTICE           # \"NT 10-Q\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#form-collections","title":"\ud83d\udcda Form Collections","text":"<pre><code>from edgar.enums import PERIODIC_FORMS, PROXY_FORMS, REGISTRATION_FORMS\n\n# Pre-defined collections for common workflows\nPERIODIC_FORMS      # [10-K, 10-Q, 10-K/A, 10-Q/A]\nPROXY_FORMS         # [DEF 14A, PRE 14A, DEFA14A, DEFM14A]  \nREGISTRATION_FORMS  # [S-1, S-3, S-4, S-8]\n</code></pre>"},{"location":"FormType-Quick-Reference/#usage-examples","title":"\u26a1 Usage Examples","text":""},{"location":"FormType-Quick-Reference/#basic-usage","title":"Basic Usage","text":"<pre><code># Annual reports with autocomplete\nannual_filings = company.get_filings(form=FormType.ANNUAL_REPORT)\n\n# Quarterly reports  \nquarterly_filings = company.get_filings(form=FormType.QUARTERLY_REPORT)\n\n# Current reports (8-Ks)\ncurrent_filings = company.get_filings(form=FormType.CURRENT_REPORT)\n</code></pre>"},{"location":"FormType-Quick-Reference/#combined-filters","title":"Combined Filters","text":"<pre><code># Recent annual reports\nfilings = company.get_filings(\n    form=FormType.ANNUAL_REPORT,\n    year=[2022, 2023]\n)\n\n# Proxy statements this year\nproxies = company.get_filings(\n    form=FormType.PROXY_STATEMENT,\n    year=2023\n)\n</code></pre>"},{"location":"FormType-Quick-Reference/#multiple-form-types","title":"Multiple Form Types","text":"<pre><code># Mix FormType and strings\nfilings = company.get_filings(form=[\n    FormType.ANNUAL_REPORT,\n    FormType.QUARTERLY_REPORT,\n    \"8-K\"  # String still works\n])\n\n# Using form collections\nperiodic_filings = company.get_filings(form=PERIODIC_FORMS)\n</code></pre>"},{"location":"FormType-Quick-Reference/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":"<pre><code># Typos get helpful suggestions\ntry:\n    filings = company.get_filings(form=\"10k\")  # Missing hyphen\nexcept ValueError as e:\n    print(e)\n    # \"Invalid form type '10k'. Use FormType enum for autocomplete...\"\n</code></pre>"},{"location":"FormType-Quick-Reference/#migration-guide","title":"\ud83d\udd04 Migration Guide","text":""},{"location":"FormType-Quick-Reference/#no-breaking-changes","title":"No Breaking Changes","text":"<pre><code># ALL existing code works unchanged:\ncompany.get_filings(form=\"10-K\")                    # \u2705 Works\ncompany.get_filings(form=[\"10-K\", \"10-Q\"])          # \u2705 Works  \ncompany.get_filings(form=\"8-K\", year=2023)          # \u2705 Works\n</code></pre>"},{"location":"FormType-Quick-Reference/#gradual-adoption","title":"Gradual Adoption","text":"<pre><code># Option 1: Keep using strings\nfilings = company.get_filings(form=\"10-K\")\n\n# Option 2: Migrate to FormType for autocomplete\nfilings = company.get_filings(form=FormType.ANNUAL_REPORT)\n\n# Option 3: Mix as convenient\nfilings = company.get_filings(form=[FormType.ANNUAL_REPORT, \"8-K\"])\n</code></pre>"},{"location":"FormType-Quick-Reference/#ide-benefits","title":"\ud83d\udca1 IDE Benefits","text":"<ul> <li>Autocomplete: Type <code>FormType.</code> to see all 31 options</li> <li>Documentation: Hover over enums to see SEC form codes  </li> <li>Type Safety: mypy/PyCharm catches invalid form parameters</li> <li>Refactoring: Find all usages of specific form types</li> </ul>"},{"location":"FormType-Quick-Reference/#links","title":"\ud83d\udd17 Links","text":"<ul> <li>GitHub Discussion: #423 Type Hinting Implementation</li> <li>Feature Branch: <code>feat/strenum-type-hinting</code></li> <li>Test Files: Run <code>python formtype_demo_examples.py</code> for live examples</li> </ul> <p>Perfect backwards compatibility + modern Python typing = Happy developers! \ud83c\udf89</p>"},{"location":"PeriodType-Quick-Reference/","title":"PeriodType Quick Reference","text":"<p>FEAT-003: PeriodType Enum for EdgarTools Enhanced developer experience through IDE autocomplete and parameter validation for financial reporting periods.</p>"},{"location":"PeriodType-Quick-Reference/#available-period-types","title":"\ud83d\udccb Available Period Types","text":"Enum Value String Value Description Use Case <code>PeriodType.ANNUAL</code> <code>\"annual\"</code> Annual reporting periods Full fiscal year financial data <code>PeriodType.QUARTERLY</code> <code>\"quarterly\"</code> Quarterly reporting periods 3-month period financial data <code>PeriodType.MONTHLY</code> <code>\"monthly\"</code> Monthly reporting periods Monthly financial data (rare) <code>PeriodType.TTM</code> <code>\"ttm\"</code> Trailing Twelve Months Rolling 12-month performance <code>PeriodType.YTD</code> <code>\"ytd\"</code> Year to Date Current year performance"},{"location":"PeriodType-Quick-Reference/#convenience-aliases","title":"Convenience Aliases","text":"Alias Same As Notes <code>PeriodType.YEARLY</code> <code>PeriodType.ANNUAL</code> Alternative naming <code>PeriodType.QUARTER</code> <code>PeriodType.QUARTERLY</code> Shorter form"},{"location":"PeriodType-Quick-Reference/#basic-usage","title":"\ud83d\ude80 Basic Usage","text":""},{"location":"PeriodType-Quick-Reference/#import","title":"Import","text":"<pre><code>from edgar.enums import PeriodType, PeriodInput, validate_period_type\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#function-parameters-new-style","title":"Function Parameters (New Style)","text":"<pre><code>from edgar import Company\nfrom edgar.enums import PeriodType\n\n# Enhanced with autocomplete for financial statements\ncompany = Company(\"AAPL\")\n\n# NEW: Direct period type filtering in get_facts()\nannual_facts = company.get_facts(period_type=PeriodType.ANNUAL)\nquarterly_facts = company.get_facts(period_type=PeriodType.QUARTERLY)\n\n# NEW: Export facts to DataFrame for custom analysis\ndf = annual_facts.to_dataframe()\nprint(df.head())\n\n# Filter and analyze\nrevenue_facts = df[df['concept'].str.contains('Revenue')]\nprint(revenue_facts[['fiscal_year', 'numeric_value']])\n\n# NEW: Query interface with PeriodType enum\nfacts = company.get_facts()\nannual_facts = facts.query().by_period_type(PeriodType.ANNUAL).execute()\nquarterly_facts = facts.query().by_period_type(PeriodType.QUARTERLY).execute()\n\n# Existing methods still work (backward compatibility)\nannual_income = facts.income_statement(annual=True)       # Annual periods\nquarterly_income = facts.income_statement(annual=False)   # Quarterly periods\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#backwards-compatibility-existing-style","title":"Backwards Compatibility (Existing Style)","text":"<pre><code># Still works - no breaking changes\nfrom edgar import Company\n\ncompany = Company(\"AAPL\")\nfacts = company.get_facts()\nannual_income = facts.income_statement(annual=True)\nquarterly_income = facts.income_statement(annual=False)\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#enhanced-validation","title":"\ud83d\udee1\ufe0f Enhanced Validation","text":""},{"location":"PeriodType-Quick-Reference/#smart-error-messages","title":"Smart Error Messages","text":"<pre><code>from edgar.enums import validate_period_type\n\n# Typo detection\ntry:\n    validate_period_type(\"anual\")  # misspelled\nexcept ValueError as e:\n    print(e)  # Error: \"Invalid period type 'anual'. Did you mean: annual?\"\n\n# Invalid input\ntry:\n    validate_period_type(\"invalid\")\nexcept ValueError as e:\n    print(e)  # Error: \"Invalid period type 'invalid'. Use PeriodType enum for autocomplete...\"\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#function-integration","title":"\ud83d\udd27 Function Integration","text":""},{"location":"PeriodType-Quick-Reference/#type-hints","title":"Type Hints","text":"<pre><code>from edgar.enums import PeriodInput, PeriodType, validate_period_type\n\ndef analyze_financials(ticker: str, period: PeriodInput = PeriodType.ANNUAL) -&gt; str:\n    \"\"\"Function with PeriodType parameter.\"\"\"\n    validated_period = validate_period_type(period)\n    return f\"Analyzing {ticker} {validated_period} financials\"\n\n# Usage\nresult1 = analyze_financials(\"AAPL\", PeriodType.QUARTERLY)  # IDE autocomplete\nresult2 = analyze_financials(\"MSFT\", \"ttm\")                 # String still works\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#migration-from-boolean-annual","title":"Migration from Boolean Annual","text":"<pre><code>from edgar.enums import PeriodInput, PeriodType, validate_period_type\n\n# Old pattern\ndef old_style(annual: bool = True) -&gt; str:\n    period = \"annual\" if annual else \"quarterly\"\n    return f\"Getting {period} data\"\n\n# New pattern - more expressive\ndef new_style(period: PeriodInput = PeriodType.ANNUAL) -&gt; str:\n    period_str = validate_period_type(period)\n    return f\"Getting {period_str} data\"\n\n# Benefits:\n# \u2705 Support for TTM, YTD, monthly (not just annual/quarterly)\n# \u2705 IDE autocomplete \n# \u2705 Validation prevents typos\n# \u2705 Self-documenting code\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#convenience-collections","title":"\ud83d\udcda Convenience Collections","text":"<pre><code>from edgar.enums import STANDARD_PERIODS, SPECIAL_PERIODS, ALL_PERIODS\n\n# Most common periods\nfor period in STANDARD_PERIODS:\n    print(f\"Standard: {period}\")  # ANNUAL, QUARTERLY\n\n# Special analysis periods  \nfor period in SPECIAL_PERIODS:\n    print(f\"Special: {period}\")   # TTM, YTD\n\n# All available periods\nfor period in ALL_PERIODS:\n    print(f\"Available: {period}\") # All 5 period types\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#real-world-examples","title":"\ud83c\udf0d Real-World Examples","text":""},{"location":"PeriodType-Quick-Reference/#financial-analysis","title":"Financial Analysis","text":"<pre><code>from edgar.enums import PeriodInput, PeriodType\n\ndef compare_performance(ticker: str, periods: list[PeriodInput]) -&gt; dict:\n    \"\"\"Compare company performance across different periods.\"\"\"\n    from edgar import Company\n\n    company = Company(ticker)\n    results = {}\n\n    for period in periods:\n        # NEW: Direct period filtering in get_facts()\n        try:\n            period_facts = company.get_facts(period_type=period)\n            if period_facts:\n                # Get income statement data from filtered facts\n                income_stmt = period_facts.income_statement(periods=1)\n                results[str(period)] = income_stmt\n        except NotImplementedError:\n            # Handle TTM/YTD (not yet implemented)\n            facts = company.get_facts()\n            if str(period) == \"ttm\":\n                # Get last 4 quarters for TTM calculation\n                data = facts.income_statement(annual=False, periods=4)\n                results[\"ttm\"] = data\n\n    return results\n\n# Usage with mixed types\nanalysis = compare_performance(\"AAPL\", [\n    PeriodType.ANNUAL,     # Enum\n    \"quarterly\",           # String\n    PeriodType.MONTHLY     # Enum - now supported!\n])\n\n# NEW: Enhanced query combinations\ncompany = Company(\"AAPL\")\nfacts = company.get_facts()\n\n# Combine period filtering with concept filtering\nannual_revenue = facts.query().by_period_type(PeriodType.ANNUAL).by_concept(\"Revenue\").execute()\nquarterly_revenue = facts.query().by_period_type(\"quarterly\").by_concept(\"Revenue\").execute()\n\n# Filter specific period types directly\nannual_facts = facts.filter_by_period_type(PeriodType.ANNUAL)\nquarterly_facts = facts.filter_by_period_type(PeriodType.QUARTERLY)\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#batch-processing","title":"Batch Processing","text":"<pre><code>from edgar.enums import PeriodInput, PeriodType\n\ndef process_companies(tickers: list[str],\n                     period: PeriodInput = PeriodType.QUARTERLY) -&gt; dict:\n    \"\"\"Process multiple companies for specified period.\"\"\"\n    from edgar import Company\n    from edgar.enums import validate_period_type\n\n    period_str = validate_period_type(period)\n    results = {}\n\n    for ticker in tickers:\n        company = Company(ticker)\n        facts = company.get_facts()\n        statement = None  # Initialize statement variable\n\n        if period_str == \"annual\":\n            statement = facts.income_statement(annual=True, periods=1)\n        elif period_str == \"quarterly\":\n            statement = facts.income_statement(annual=False, periods=1)\n\n        if statement is not None:\n            results[ticker] = statement\n\n    return results\n\n# Usage\nfrom edgar.enums import PeriodType\n\ntech_stocks = [\"AAPL\", \"MSFT\", \"GOOGL\"]\nresult = process_companies(tech_stocks, PeriodType.QUARTERLY)\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#period-iteration","title":"Period Iteration","text":"<pre><code>def comprehensive_analysis(ticker: str) -&gt; dict:\n    \"\"\"Analyze company across all standard periods.\"\"\"\n    from edgar import Company\n    from edgar.enums import STANDARD_PERIODS\n\n    company = Company(ticker)\n    facts = company.get_facts()\n    results = {}\n\n    for period in STANDARD_PERIODS:\n        # Each period provides IDE autocomplete when used\n        statement = None  # Initialize statement variable\n\n        if period.value == \"annual\":\n            statement = facts.income_statement(annual=True, periods=2)\n        elif period.value == \"quarterly\":\n            statement = facts.income_statement(annual=False, periods=4)\n\n        if statement is not None:\n            results[period.value] = statement\n\n    return results\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#ide-benefits","title":"\ud83d\udca1 IDE Benefits","text":"<p>With PeriodType, your IDE will provide:</p>"},{"location":"PeriodType-Quick-Reference/#autocomplete","title":"Autocomplete","text":"<p>When you type <code>PeriodType.</code>, your IDE shows:</p> <pre><code>PeriodType.ANNUAL     # 'annual' - Full fiscal year\nPeriodType.QUARTERLY  # 'quarterly' - 3-month periods  \nPeriodType.MONTHLY    # 'monthly' - Monthly periods\nPeriodType.TTM        # 'ttm' - Trailing twelve months\nPeriodType.YTD        # 'ytd' - Year to date\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#documentation","title":"Documentation","text":"<p>Hover over enum values to see descriptions: - ANNUAL: Annual reporting periods (full fiscal year) - QUARTERLY: Quarterly reporting periods (3-month periods) - TTM: Trailing Twelve Months for rolling performance analysis</p>"},{"location":"PeriodType-Quick-Reference/#type-safety","title":"Type Safety","text":"<p>Your IDE will warn about: - Invalid period types - Wrong parameter types - Potential typos before runtime</p>"},{"location":"PeriodType-Quick-Reference/#migration-guide","title":"\ud83d\udd04 Migration Guide","text":""},{"location":"PeriodType-Quick-Reference/#from-boolean-annual-parameter","title":"From Boolean Annual Parameter","text":"<p>Before:</p> <pre><code># Limited to annual/quarterly only\nfrom edgar import Company\n\ncompany = Company(\"AAPL\")\nfacts = company.get_facts()\nannual_income = facts.income_statement(annual=True)    # Annual data\nquarterly_income = facts.income_statement(annual=False)   # Quarterly data\n</code></pre> <p>After:</p> <pre><code># Rich period support with enhanced querying\nfrom edgar import Company\n\ncompany = Company(\"AAPL\")\nfacts = company.get_facts()\n\n# Financial statement methods with boolean parameters\nannual_income = facts.income_statement(annual=True)     # Annual\nquarterly_income = facts.income_statement(annual=False) # Quarterly\n\n# Advanced period filtering with query interface\nttm_facts = facts.query().by_period_length(12).get()   # Trailing twelve months\nquarterly_facts = facts.query().by_period_length(3).get() # Quarterly periods\n\n# Individual fact retrieval with period specification\nrevenue_2023 = facts.get_fact(\"Revenue\", period=\"2023-FY\")\nrevenue_q4 = facts.get_fact(\"Revenue\", period=\"2023-Q4\")\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#from-string-parameters","title":"From String Parameters","text":"<p>Before:</p> <pre><code># Typo-prone, no autocomplete\ndef analyze_data(period: str) -&gt; str:\n    return f\"Analyzing {period} data\"\n\nanalyze_data(\"annual\")     # Could typo as \"anual\"\nanalyze_data(\"quarterly\")  # Could typo as \"quartly\"\n</code></pre> <p>After:</p> <pre><code># Autocomplete prevents typos\nfrom edgar.enums import PeriodType, PeriodInput, validate_period_type\n\ndef analyze_data(period: PeriodInput) -&gt; str:\n    validated_period = validate_period_type(period)\n    return f\"Analyzing {validated_period} data\"\n\nanalyze_data(PeriodType.ANNUAL)     # IDE autocomplete\nanalyze_data(PeriodType.QUARTERLY)  # IDE autocomplete\n\n# Strings still work with validation\nanalyze_data(\"annual\")     # Validated, helpful errors if typo\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#consistency-with-formtype","title":"\u2696\ufe0f Consistency with FormType","text":"<p>PeriodType follows the same design pattern as FormType:</p> Feature FormType PeriodType Enum Type <code>StrEnum</code> <code>StrEnum</code> Validation <code>validate_form_type()</code> <code>validate_period_type()</code> Type Hints <code>FormInput</code> <code>PeriodInput</code> Collections <code>PERIODIC_FORMS</code>, etc. <code>STANDARD_PERIODS</code>, etc. Error Handling Smart suggestions Smart suggestions Backwards Compat \u2705 Union types \u2705 Union types"},{"location":"PeriodType-Quick-Reference/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"PeriodType-Quick-Reference/#1-use-enums-for-new-code","title":"1. Use Enums for New Code","text":"<pre><code># Recommended: Enhanced developer experience\nfrom edgar.enums import PeriodInput, PeriodType\n\ndef analyze_trends(period: PeriodInput = PeriodType.ANNUAL) -&gt; str:\n    return f\"Analyzing trends for {period}\"\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#2-maintain-string-compatibility","title":"2. Maintain String Compatibility","text":"<pre><code># Support both for flexibility\nfrom edgar.enums import PeriodInput, validate_period_type\n\ndef flexible_function(period: PeriodInput) -&gt; str:\n    validated = validate_period_type(period)  # Handles both\n    return f\"Processing {validated} data\"\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#3-leverage-collections","title":"3. Leverage Collections","text":"<pre><code># Use predefined collections\nfrom edgar.enums import STANDARD_PERIODS\n\ndef process_period(period_type):\n    return f\"Processing {period_type}\"\n\nfor period in STANDARD_PERIODS:\n    result = process_period(period)\n    print(result)\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#4-provide-good-defaults","title":"4. Provide Good Defaults","text":"<pre><code># Use meaningful defaults\nfrom edgar.enums import PeriodInput, PeriodType\n\ndef get_financials(period: PeriodInput = PeriodType.ANNUAL) -&gt; str:\n    \"\"\"Default to annual for most financial analysis.\"\"\"\n    return f\"Getting {period} financials\"\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#error-handling","title":"\ud83d\udea6 Error Handling","text":""},{"location":"PeriodType-Quick-Reference/#common-errors-and-solutions","title":"Common Errors and Solutions","text":"<pre><code>from edgar.enums import validate_period_type, PeriodType\n\n# Typo in string\ntry:\n    validate_period_type(\"anual\")\nexcept ValueError as e:\n    print(e)  # \"Did you mean: annual?\"\n\n# Wrong type\ntry:\n    validate_period_type(\"123\")  # Use string instead of int\nexcept ValueError as e:\n    print(e)  # \"Invalid period type '123'...\"\n\n# Completely invalid\ntry:\n    validate_period_type(\"invalid\")\nexcept ValueError as e:\n    print(e)  # \"Use PeriodType enum for autocomplete...\"\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#api-enhancements","title":"\ud83c\udd95 API Enhancements","text":"<p>Period-Type Filtering Feature adds direct filtering capabilities:</p>"},{"location":"PeriodType-Quick-Reference/#new-methods","title":"New Methods","text":"<pre><code># Direct filtering in get_facts()\nannual_facts = company.get_facts(period_type=PeriodType.ANNUAL)\n\n# Query interface filtering\nfacts.query().by_period_type(PeriodType.QUARTERLY)\n\n# EntityFacts filtering\nfacts.filter_by_period_type(PeriodType.ANNUAL)\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#enhanced-workflow","title":"Enhanced Workflow","text":"<pre><code>from edgar import Company\nfrom edgar.enums import PeriodType\n\n# Before: Multi-step process\ncompany = Company(\"AAPL\")\nfacts = company.get_facts()\nannual_income = facts.income_statement(annual=True)\n\n# After: Direct, intuitive filtering\nannual_facts = company.get_facts(period_type=PeriodType.ANNUAL)\nannual_income = annual_facts.income_statement()\n\n# Advanced: Query combinations\nrevenue_annual = company.get_facts().query()\\\n    .by_concept(\"Revenue\")\\\n    .by_period_type(PeriodType.ANNUAL)\\\n    .execute()\n</code></pre>"},{"location":"PeriodType-Quick-Reference/#impact-summary","title":"\ud83d\udcc8 Impact Summary","text":"<p>Period-Type Filtering delivers on EdgarTools principles:</p> <ul> <li>\u2705 Simple yet powerful: Direct filtering eliminates multi-step processes</li> <li>\u2705 Beginner-friendly: IDE autocomplete reveals filtering options</li> <li>\u2705 Joyful UX: Intuitive API that works as expected</li> <li>\u2705 Accurate financials: Type-safe period specification</li> </ul> <p>Key improvements: - \ud83c\udfaf IDE autocomplete for period types - \ud83d\udee1\ufe0f Enhanced validation with smart error messages - \u26a1 Direct period filtering in get_facts() - \ud83d\udd0d Query interface period filtering - \ud83d\udd27 Seamless integration with existing API - \ud83d\udd04 Clear migration path from boolean parameters - \u2696\ufe0f Consistent design with FormType enum</p>"},{"location":"StatementType-Quick-Reference/","title":"StatementType Quick Reference","text":"<p>FEAT-005: Statement Type Classifications for EdgarTools Enhanced developer experience through IDE autocomplete and parameter validation for financial statement types.</p>"},{"location":"StatementType-Quick-Reference/#available-statement-types","title":"Available Statement Types","text":""},{"location":"StatementType-Quick-Reference/#primary-financial-statements-the-big-four","title":"Primary Financial Statements (The Big Four)","text":"Enum Value String Value Description Use Case <code>StatementType.INCOME_STATEMENT</code> <code>\"income_statement\"</code> Profit &amp; Loss Statement Revenue, expenses, net income analysis <code>StatementType.BALANCE_SHEET</code> <code>\"balance_sheet\"</code> Statement of Financial Position Assets, liabilities, equity analysis <code>StatementType.CASH_FLOW</code> <code>\"cash_flow_statement\"</code> Statement of Cash Flows Cash inflows, outflows, liquidity analysis <code>StatementType.CHANGES_IN_EQUITY</code> <code>\"changes_in_equity\"</code> Statement of Changes in Equity Equity movements, dividends, retained earnings"},{"location":"StatementType-Quick-Reference/#comprehensive-statements","title":"Comprehensive Statements","text":"Enum Value String Value Description Use Case <code>StatementType.COMPREHENSIVE_INCOME</code> <code>\"comprehensive_income\"</code> Statement of Comprehensive Income Total comprehensive income including OCI"},{"location":"StatementType-Quick-Reference/#analytical-statements","title":"Analytical Statements","text":"Enum Value String Value Description Use Case <code>StatementType.SEGMENTS</code> <code>\"segment_reporting\"</code> Segment Information Business segment performance <code>StatementType.SUBSIDIARIES</code> <code>\"subsidiaries\"</code> Subsidiary Information Subsidiary company details <code>StatementType.FOOTNOTES</code> <code>\"footnotes\"</code> Notes to Financial Statements Detailed disclosures and notes <code>StatementType.ACCOUNTING_POLICIES</code> <code>\"accounting_policies\"</code> Significant Accounting Policies Accounting methods and principles"},{"location":"StatementType-Quick-Reference/#specialized-statements","title":"Specialized Statements","text":"Enum Value String Value Description Use Case <code>StatementType.REGULATORY_CAPITAL</code> <code>\"regulatory_capital\"</code> Regulatory Capital Bank capital adequacy ratios <code>StatementType.INSURANCE_RESERVES</code> <code>\"insurance_reserves\"</code> Insurance Reserves Insurance loss reserves"},{"location":"StatementType-Quick-Reference/#convenience-aliases","title":"Convenience Aliases","text":"Alias Same As Notes <code>StatementType.PROFIT_LOSS</code> <code>StatementType.INCOME_STATEMENT</code> Common P&amp;L terminology <code>StatementType.PL_STATEMENT</code> <code>StatementType.INCOME_STATEMENT</code> Abbreviated P&amp;L <code>StatementType.FINANCIAL_POSITION</code> <code>StatementType.BALANCE_SHEET</code> IFRS terminology <code>StatementType.STATEMENT_OF_POSITION</code> <code>StatementType.BALANCE_SHEET</code> Alternative naming <code>StatementType.CASH_FLOWS</code> <code>StatementType.CASH_FLOW</code> Plural form <code>StatementType.EQUITY_CHANGES</code> <code>StatementType.CHANGES_IN_EQUITY</code> Shorter form"},{"location":"StatementType-Quick-Reference/#basic-usage","title":"Basic Usage","text":""},{"location":"StatementType-Quick-Reference/#import","title":"Import","text":"<pre><code>from edgar.enums import StatementType, StatementInput, validate_statement_type\n</code></pre>"},{"location":"StatementType-Quick-Reference/#two-ways-to-access-financial-statements","title":"Two Ways to Access Financial Statements","text":"<p>EdgarTools provides two different APIs for accessing financial statements, each with different use cases:</p>"},{"location":"StatementType-Quick-Reference/#1-company-facts-api-multi-period-historical-data","title":"1. Company Facts API (Multi-Period Historical Data)","text":"<p>Use the Company class for historical financial data across multiple periods. This uses the SEC's Company Facts API.</p> <pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\n\n# Direct convenience methods (recommended for beginners)\nincome = company.income_statement(periods=4, annual=True)\nbalance = company.balance_sheet(periods=4, annual=True)\ncash = company.cash_flow(periods=4, annual=True)\n\n# These return MultiPeriodStatement objects with rich display\nprint(income)  # Beautiful table output\n</code></pre> <p>Best for: - Multi-period trend analysis - Quick access to historical financials - Beginners who want simple API</p> <p>Limitations: - Only supports primary statements (income, balance sheet, cash flow) - Does not support segment or analytical statements</p>"},{"location":"StatementType-Quick-Reference/#2-xbrl-api-full-statement-access","title":"2. XBRL API (Full Statement Access)","text":"<p>Use the XBRL class for complete access to all statement types from a specific filing. This is where <code>StatementType</code> and <code>get_statement()</code> are used.</p> <pre><code>from edgar import Company\nfrom edgar.enums import StatementType\n\ncompany = Company(\"AAPL\")\nfiling = company.get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\n\n# Using StatementType enum with get_statement()\nincome = xbrl.get_statement(StatementType.INCOME_STATEMENT)\nbalance = xbrl.get_statement(StatementType.BALANCE_SHEET)\ncash_flow = xbrl.get_statement(StatementType.CASH_FLOW)\n\n# Analytical statements (only available via XBRL)\nsegments = xbrl.get_statement(StatementType.SEGMENTS)\nfootnotes = xbrl.get_statement(StatementType.FOOTNOTES)\n\n# Or use the statements property for common statements\nincome = xbrl.statements.income_statement()\nbalance = xbrl.statements.balance_sheet()\n</code></pre> <p>Best for: - Accessing specific filing periods - Analytical statements (segments, footnotes, etc.) - Full XBRL dimensional data - Advanced analysis</p>"},{"location":"StatementType-Quick-Reference/#accessing-segment-statements","title":"Accessing Segment Statements","text":"<p>Segment data is only available through the XBRL API:</p> <pre><code>from edgar import Company\nfrom edgar.enums import StatementType\n\ncompany = Company(\"AAPL\")\nfiling = company.get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\n\n# Get segment statement data\nsegment_data = xbrl.get_statement(StatementType.SEGMENTS)\n# Or use the string value\nsegment_data = xbrl.get_statement(\"segment_reporting\")\n\n# Segment dimensional data also appears in income statements\nincome = xbrl.statements.income_statement()\n# Shows segment breakdowns by product, geography, etc.\nprint(income)\n</code></pre>"},{"location":"StatementType-Quick-Reference/#enhanced-validation","title":"Enhanced Validation","text":""},{"location":"StatementType-Quick-Reference/#smart-error-messages","title":"Smart Error Messages","text":"<pre><code>from edgar.enums import validate_statement_type\n\n# Typo detection\ntry:\n    validate_statement_type(\"income\")  # partial match\nexcept ValidationError as e:\n    # Error: \"Invalid statement type 'income'. Did you mean: income_statement?\"\n\ntry:\n    validate_statement_type(\"balanc\")  # misspelling\nexcept ValidationError as e:\n    # Error: \"Invalid statement type 'balanc'. Did you mean: balance_sheet?\"\n\n# Context-aware help\ntry:\n    validate_statement_type(\"unknown\")\nexcept ValidationError as e:\n    # Error: \"Invalid statement type 'unknown'. Primary statements:\n    # 'income_statement' (P&amp;L), 'balance_sheet' (financial position), ...\"\n</code></pre>"},{"location":"StatementType-Quick-Reference/#function-integration","title":"Function Integration","text":""},{"location":"StatementType-Quick-Reference/#type-hints","title":"Type Hints","text":"<pre><code>from edgar.enums import StatementInput\n\ndef analyze_statement(filing, statement: StatementInput) -&gt; dict:\n    \"\"\"Function with StatementType parameter.\"\"\"\n    xbrl = filing.xbrl()\n    validated_statement = validate_statement_type(statement)\n    statement_data = xbrl.get_statement(validated_statement)\n    return {\"statement\": validated_statement, \"data\": statement_data}\n\n# Usage\nresult = analyze_statement(filing, StatementType.INCOME_STATEMENT)  # IDE autocomplete\nresult = analyze_statement(filing, \"balance_sheet\")                  # String still works\n</code></pre>"},{"location":"StatementType-Quick-Reference/#convenience-collections","title":"Convenience Collections","text":"<pre><code>from edgar.enums import (\n    PRIMARY_STATEMENTS,\n    COMPREHENSIVE_STATEMENTS,\n    ANALYTICAL_STATEMENTS,\n    SPECIALIZED_STATEMENTS,\n    ALL_STATEMENTS\n)\n\n# Analyze primary financial statements\nfor statement_type in PRIMARY_STATEMENTS:\n    try:\n        result = xbrl.get_statement(statement_type)\n        print(f\"Found: {statement_type.name}\")\n    except Exception:\n        print(f\"Not available: {statement_type.name}\")\n\n# Check comprehensive statement availability\navailable_statements = []\nfor statement_type in COMPREHENSIVE_STATEMENTS:\n    try:\n        result = xbrl.get_statement(statement_type)\n        available_statements.append(statement_type)\n    except Exception:\n        pass\n</code></pre>"},{"location":"StatementType-Quick-Reference/#real-world-examples","title":"Real-World Examples","text":""},{"location":"StatementType-Quick-Reference/#financial-analysis-workflow","title":"Financial Analysis Workflow","text":"<pre><code>from edgar import Company\nfrom edgar.enums import StatementType, PRIMARY_STATEMENTS\n\ndef comprehensive_financial_analysis(ticker: str) -&gt; dict:\n    \"\"\"Analyze company across all primary statements from latest 10-K.\"\"\"\n    company = Company(ticker)\n    filing = company.get_filings(form=\"10-K\").latest()\n    xbrl = filing.xbrl()\n\n    results = {}\n    for statement_type in PRIMARY_STATEMENTS:\n        try:\n            statement = xbrl.get_statement(statement_type)\n            results[statement_type.value] = statement\n        except Exception as e:\n            results[statement_type.value] = f\"Not available: {e}\"\n\n    return results\n\n# Usage\nanalysis = comprehensive_financial_analysis(\"AAPL\")\n</code></pre>"},{"location":"StatementType-Quick-Reference/#multi-period-historical-analysis","title":"Multi-Period Historical Analysis","text":"<pre><code>from edgar import Company\n\ndef trend_analysis(ticker: str, periods: int = 5) -&gt; dict:\n    \"\"\"Analyze company trends using Company Facts API.\"\"\"\n    company = Company(ticker)\n\n    return {\n        \"income\": company.income_statement(periods=periods, annual=True),\n        \"balance\": company.balance_sheet(periods=periods, annual=True),\n        \"cash_flow\": company.cash_flow(periods=periods, annual=True)\n    }\n\n# Usage - returns MultiPeriodStatement objects\ntrends = trend_analysis(\"AAPL\", periods=5)\nprint(trends[\"income\"])  # Shows 5 years of income statement data\n</code></pre>"},{"location":"StatementType-Quick-Reference/#statement-categorization","title":"Statement Categorization","text":"<pre><code>from edgar.enums import PRIMARY_STATEMENTS, ANALYTICAL_STATEMENTS\n\ndef categorize_available_statements(xbrl) -&gt; dict:\n    \"\"\"Categorize available statements by type.\"\"\"\n    categories = {\n        \"primary\": [],\n        \"analytical\": [],\n    }\n\n    # Check primary statements\n    for statement_type in PRIMARY_STATEMENTS:\n        try:\n            xbrl.get_statement(statement_type)\n            categories[\"primary\"].append(statement_type.value)\n        except Exception:\n            pass\n\n    # Check analytical statements\n    for statement_type in ANALYTICAL_STATEMENTS:\n        try:\n            xbrl.get_statement(statement_type)\n            categories[\"analytical\"].append(statement_type.value)\n        except Exception:\n            pass\n\n    return categories\n</code></pre>"},{"location":"StatementType-Quick-Reference/#ide-benefits","title":"IDE Benefits","text":"<p>With StatementType, your IDE will provide:</p>"},{"location":"StatementType-Quick-Reference/#autocomplete","title":"Autocomplete","text":"<p>When you type <code>StatementType.</code>, your IDE shows:</p> <pre><code>StatementType.INCOME_STATEMENT     # 'income_statement' - P&amp;L Statement\nStatementType.BALANCE_SHEET        # 'balance_sheet' - Financial Position\nStatementType.CASH_FLOW            # 'cash_flow_statement' - Cash Flows\nStatementType.CHANGES_IN_EQUITY    # 'changes_in_equity' - Equity Changes\nStatementType.COMPREHENSIVE_INCOME # 'comprehensive_income' - Total Income\n...\n</code></pre>"},{"location":"StatementType-Quick-Reference/#documentation","title":"Documentation","text":"<p>Hover over enum values to see descriptions: - INCOME_STATEMENT: Profit &amp; Loss Statement showing revenues and expenses - BALANCE_SHEET: Statement of Financial Position showing assets and liabilities - CASH_FLOW: Statement of Cash Flows showing cash movements</p>"},{"location":"StatementType-Quick-Reference/#type-safety","title":"Type Safety","text":"<p>Your IDE will warn about: - Invalid statement types - Wrong parameter types - Potential typos before runtime</p>"},{"location":"StatementType-Quick-Reference/#api-comparison","title":"API Comparison","text":"Feature Company API XBRL API Methods <code>income_statement()</code>, <code>balance_sheet()</code>, <code>cash_flow()</code> <code>get_statement(StatementType.XXX)</code> Source Company Facts API Filing XBRL data Multi-Period Yes (built-in) No (single filing) Segments No Yes Footnotes No Yes StatementType Enum Not used Used Best For Historical trends Full statement access"},{"location":"StatementType-Quick-Reference/#migration-guide","title":"Migration Guide","text":""},{"location":"StatementType-Quick-Reference/#choosing-the-right-api","title":"Choosing the Right API","text":"<p>Use Company API when:</p> <pre><code># You need multi-period historical data\ncompany = Company(\"AAPL\")\nincome = company.income_statement(periods=5, annual=True)  # 5 years of data\n</code></pre> <p>Use XBRL API when:</p> <pre><code># You need specific filing data or analytical statements\nfiling = company.get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\nsegments = xbrl.get_statement(StatementType.SEGMENTS)  # Only available here\n</code></pre>"},{"location":"StatementType-Quick-Reference/#consistency-with-other-types","title":"Consistency with Other Types","text":"<p>StatementType follows the same design pattern as FormType and PeriodType:</p> Feature FormType PeriodType StatementType Enum Type <code>StrEnum</code> <code>StrEnum</code> <code>StrEnum</code> Validation <code>validate_form_type()</code> <code>validate_period_type()</code> <code>validate_statement_type()</code> Type Hints <code>FormInput</code> <code>PeriodInput</code> <code>StatementInput</code> Collections <code>PRIMARY_FORMS</code>, etc. <code>STANDARD_PERIODS</code>, etc. <code>PRIMARY_STATEMENTS</code>, etc. Error Handling Smart suggestions Smart suggestions Smart suggestions Backwards Compat Union types Union types Union types"},{"location":"StatementType-Quick-Reference/#best-practices","title":"Best Practices","text":""},{"location":"StatementType-Quick-Reference/#1-use-appropriate-api-for-your-use-case","title":"1. Use Appropriate API for Your Use Case","text":"<pre><code># Historical analysis - use Company API\ncompany = Company(\"AAPL\")\nincome = company.income_statement(periods=4)\n\n# Specific filing analysis - use XBRL API\nxbrl = company.get_filings(form=\"10-K\").latest().xbrl()\nincome = xbrl.get_statement(StatementType.INCOME_STATEMENT)\n</code></pre>"},{"location":"StatementType-Quick-Reference/#2-use-enums-for-ide-support","title":"2. Use Enums for IDE Support","text":"<pre><code># Recommended: Enhanced developer experience\nfrom edgar.enums import StatementType\nsegment = xbrl.get_statement(StatementType.SEGMENTS)\n</code></pre>"},{"location":"StatementType-Quick-Reference/#3-leverage-collections","title":"3. Leverage Collections","text":"<pre><code># Use predefined collections\nfor statement_type in PRIMARY_STATEMENTS:\n    process_statement(xbrl.get_statement(statement_type))\n</code></pre>"},{"location":"StatementType-Quick-Reference/#error-handling","title":"Error Handling","text":""},{"location":"StatementType-Quick-Reference/#common-errors-and-solutions","title":"Common Errors and Solutions","text":"<pre><code>from edgar.enums import validate_statement_type, StatementType\n\n# Typo in string\ntry:\n    validate_statement_type(\"income\")\nexcept ValidationError as e:\n    print(e)  # \"Did you mean: income_statement?\"\n\n# Wrong type\ntry:\n    validate_statement_type(123)\nexcept TypeError as e:\n    print(e)  # \"Statement must be StatementType or str\"\n\n# Completely invalid\ntry:\n    validate_statement_type(\"invalid_statement\")\nexcept ValidationError as e:\n    print(e)  # \"Use StatementType enum for autocomplete...\"\n</code></pre>"},{"location":"StatementType-Quick-Reference/#impact-summary","title":"Impact Summary","text":"<p>FEAT-005 delivers on EdgarTools principles:</p> <ul> <li>Beginner-friendly: Makes financial statement exploration discoverable</li> <li>Simple yet powerful: Two APIs for different use cases</li> <li>Joyful UX: IDE autocomplete and helpful error messages</li> </ul> <p>Key improvements: - IDE autocomplete for financial statement types - Enhanced validation with financial context - Clear separation between Company and XBRL APIs - Educational categorization of statement types - Full backwards compatibility maintained - Consistent design with FormType and PeriodType</p>"},{"location":"advanced-search/","title":"Advanced Ranking Search","text":"<p>EdgarTools provides advanced search capabilities with BM25-based ranking and semantic structure awareness. This is designed specifically for financial documents to help you find the most relevant information quickly.</p>"},{"location":"advanced-search/#overview","title":"Overview","text":"<p>The ranking search system offers:</p> <ul> <li>Three ranking algorithms: BM25 (text-focused), Hybrid (text + structure), and Semantic (structure-focused)</li> <li>Intelligent caching: 10x+ faster repeated searches with automatic index caching</li> <li>Structure-aware boosting: Prioritizes headings, cross-references, and gateway content</li> <li>Agent-friendly results: Full section context for investigation and navigation</li> <li>Performance optimized: Instant results from cache, minimal memory overhead</li> </ul>"},{"location":"advanced-search/#quick-start","title":"Quick Start","text":"<pre><code>from edgar import Company\nfrom edgar.documents.search import DocumentSearch\n\n# Get a filing\ncompany = Company(\"AAPL\")\nfiling = company.get_filings(form=\"10-K\").latest(1)\n\n# Create search interface\ndocument = filing.document\nsearcher = DocumentSearch(document)\n\n# Search with ranking\nresults = searcher.ranked_search(\n    query=\"revenue growth\",\n    algorithm=\"hybrid\",\n    top_k=5\n)\n\n# Access results\nfor result in results:\n    print(f\"Score: {result.score:.3f}\")\n    print(f\"Section: {result.section}\")\n    print(f\"Snippet: {result.snippet}\")\n</code></pre>"},{"location":"advanced-search/#ranking-algorithms","title":"Ranking Algorithms","text":""},{"location":"advanced-search/#bm25-best-for-exact-term-matching","title":"BM25 (Best for Exact Term Matching)","text":"<p>BM25 is a probabilistic retrieval function that ranks documents based on term frequency and inverse document frequency. It's excellent for finding exact matches of financial terms and concepts.</p> <pre><code>results = searcher.ranked_search(\n    query=\"operating expenses depreciation\",\n    algorithm=\"bm25\",\n    top_k=10\n)\n</code></pre> <p>Best for: - Finding specific financial terms - Exact phrase matching - Traditional keyword search</p> <p>Parameters: - <code>k1</code> (default: 1.5): Controls term frequency saturation - <code>b</code> (default: 0.75): Controls document length normalization</p>"},{"location":"advanced-search/#hybrid-recommended-for-most-use-cases","title":"Hybrid (Recommended for Most Use Cases)","text":"<p>Hybrid combines BM25 text matching with semantic structure boosting. It understands document structure and boosts:</p> <ul> <li>Headings and section markers (e.g., \"Item 1A - Risk Factors\")</li> <li>Cross-references (e.g., \"See Item 7 for discussion\")</li> <li>Gateway content (summaries, overviews, introductions)</li> <li>Tables and XBRL data (structured financial information)</li> </ul> <pre><code>results = searcher.ranked_search(\n    query=\"cybersecurity risks\",\n    algorithm=\"hybrid\",\n    top_k=5\n)\n</code></pre> <p>Best for: - General-purpose search - Finding gateway content for investigation - Balancing exact matches with structural importance - Agent/LLM workflows</p> <p>Weights (customizable): - <code>bm25_weight</code> (default: 0.8): Weight for text matching - <code>semantic_weight</code> (default: 0.2): Weight for structure boosting</p>"},{"location":"advanced-search/#semantic-best-for-structure-navigation","title":"Semantic (Best for Structure Navigation)","text":"<p>Semantic ranking prioritizes document structure without text matching. It finds structurally important sections regardless of query terms.</p> <pre><code>results = searcher.ranked_search(\n    query=\"business overview\",\n    algorithm=\"semantic\",\n    top_k=5\n)\n</code></pre> <p>Best for: - Understanding document organization - Finding section boundaries - Structural navigation - Overview and summary content</p>"},{"location":"advanced-search/#advanced-search-options","title":"Advanced Search Options","text":""},{"location":"advanced-search/#section-specific-search","title":"Section-Specific Search","text":"<p>Limit search to specific sections:</p> <pre><code>results = searcher.ranked_search(\n    query=\"supply chain risks\",\n    in_section=\"Risk Factors\",\n    top_k=5\n)\n</code></pre>"},{"location":"advanced-search/#section-boosting","title":"Section Boosting","text":"<p>Give higher weight to matches in certain sections:</p> <pre><code>results = searcher.ranked_search(\n    query=\"revenue recognition\",\n    algorithm=\"hybrid\",\n    boost_sections=[\"MD&amp;A\", \"Critical Accounting Policies\"],\n    top_k=5\n)\n</code></pre>"},{"location":"advanced-search/#node-type-filtering","title":"Node Type Filtering","text":"<p>Search only specific node types:</p> <pre><code>from edgar.documents.types import NodeType\n\nresults = searcher.ranked_search(\n    query=\"financial data\",\n    node_types=[NodeType.TABLE, NodeType.XBRL],\n    top_k=5\n)\n</code></pre>"},{"location":"advanced-search/#working-with-results","title":"Working with Results","text":"<p>Each result contains:</p> <pre><code>result.score           # Relevance score (higher = more relevant)\nresult.snippet         # Short text snippet (first 200 chars)\nresult.section         # Section name (e.g., \"Risk Factors\")\nresult.node            # Original document node\nresult.context         # Full text context (up to 500 chars)\n</code></pre>"},{"location":"advanced-search/#accessing-full-context","title":"Accessing Full Context","text":"<p>For agent workflows, results include full section access:</p> <pre><code>results = searcher.ranked_search(\"AI strategy\", algorithm=\"hybrid\")\n\nfor result in results:\n    # Access full section for investigation\n    if hasattr(result, '_section_obj') and result._section_obj:\n        section = result._section_obj\n        full_text = section.text()\n\n        # Navigate section structure\n        for child in section.children:\n            # Process subsections\n            pass\n</code></pre>"},{"location":"advanced-search/#performance-and-caching","title":"Performance and Caching","text":""},{"location":"advanced-search/#how-caching-works","title":"How Caching Works","text":"<p>EdgarTools automatically caches search indices for fast repeated searches:</p> <ol> <li>Instance cache: Stores engines for same DocumentSearch session</li> <li>Global cache: Stores indices across documents (memory + disk)</li> <li>LRU eviction: Automatically manages memory (default: 10 cached indices)</li> <li>TTL expiration: Automatic cleanup after 24 hours</li> </ol>"},{"location":"advanced-search/#cache-performance","title":"Cache Performance","text":"<p>Typical speedup:</p> <pre><code>import time\n\n# First search (cold cache) - builds index\nstart = time.perf_counter()\nresults1 = searcher.ranked_search(\"revenue\", algorithm=\"bm25\")\ncold_time = time.perf_counter() - start  # ~0.5s\n\n# Second search (warm cache) - uses cached index\nstart = time.perf_counter()\nresults2 = searcher.ranked_search(\"revenue\", algorithm=\"bm25\")\nwarm_time = time.perf_counter() - start  # ~0.05s\n\n# 10x faster!\n</code></pre>"},{"location":"advanced-search/#cache-statistics","title":"Cache Statistics","text":"<p>Monitor cache performance:</p> <pre><code>stats = searcher.get_cache_stats()\n\nprint(f\"Cache hits: {stats['global_cache_stats']['cache_hits']}\")\nprint(f\"Cache misses: {stats['global_cache_stats']['cache_misses']}\")\nprint(f\"Hit rate: {stats['global_cache_stats']['hit_rate']:.1%}\")\nprint(f\"Memory usage: {stats['global_cache_stats']['memory_size_mb']:.2f} MB\")\n</code></pre>"},{"location":"advanced-search/#cache-management","title":"Cache Management","text":"<pre><code># Clear instance cache only\nsearcher.clear_cache(memory_only=True)\n\n# Clear all caches (memory + disk)\nsearcher.clear_cache(memory_only=False)\n\n# Disable caching (for testing)\nsearcher = DocumentSearch(document, use_cache=False)\n</code></pre>"},{"location":"advanced-search/#custom-cache-configuration","title":"Custom Cache Configuration","text":"<pre><code>from edgar.documents.ranking.cache import SearchIndexCache, set_search_cache\n\n# Create custom cache\ncache = SearchIndexCache(\n    memory_cache_size=20,      # Store 20 indices in memory\n    disk_cache_enabled=True,   # Enable disk persistence\n    ttl_hours=48              # Keep cached for 48 hours\n)\n\n# Set as global cache\nset_search_cache(cache)\n</code></pre>"},{"location":"advanced-search/#best-practices","title":"Best Practices","text":""},{"location":"advanced-search/#choosing-the-right-algorithm","title":"Choosing the Right Algorithm","text":"Use Case Algorithm Why Finding specific terms BM25 Exact text matching General document search Hybrid Balance text + structure Understanding document structure Semantic Pure structure focus Agent/LLM workflows Hybrid Finds gateway content Financial term lookup BM25 Best for exact matches"},{"location":"advanced-search/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use caching (enabled by default) for repeated searches</li> <li>Use Hybrid algorithm for most use cases (best results)</li> <li>Filter by section to reduce search space</li> <li>Limit top_k to needed results (default: 10)</li> <li>Monitor cache stats to optimize cache size</li> </ol>"},{"location":"advanced-search/#agent-workflows","title":"Agent Workflows","text":"<p>For AI agents investigating documents:</p> <pre><code># Step 1: Find relevant sections\nresults = searcher.ranked_search(\n    query=\"climate risk disclosures\",\n    algorithm=\"hybrid\",\n    top_k=3\n)\n\n# Step 2: Investigate full sections\nfor result in results:\n    if result._section_obj:\n        section = result._section_obj\n\n        # Read full section\n        full_content = section.text()\n\n        # Navigate subsections\n        for subsection in section.children:\n            # Process hierarchically\n            pass\n</code></pre>"},{"location":"advanced-search/#api-reference","title":"API Reference","text":""},{"location":"advanced-search/#documentsearch","title":"DocumentSearch","text":"<pre><code>DocumentSearch(document, use_cache=True)\n</code></pre> <p>Creates a search interface for a document.</p> <p>Parameters: - <code>document</code>: Parsed SEC document - <code>use_cache</code> (bool): Enable index caching (default: True)</p>"},{"location":"advanced-search/#ranked_search","title":"ranked_search()","text":"<pre><code>searcher.ranked_search(\n    query: str,\n    algorithm: str = \"hybrid\",\n    top_k: int = 10,\n    node_types: Optional[List[NodeType]] = None,\n    in_section: Optional[str] = None,\n    boost_sections: Optional[List[str]] = None\n) -&gt; List[SearchResult]\n</code></pre> <p>Perform ranked search with BM25-based ranking.</p> <p>Parameters: - <code>query</code>: Search query string - <code>algorithm</code>: Ranking algorithm (\"bm25\", \"hybrid\", \"semantic\") - <code>top_k</code>: Maximum results to return (default: 10) - <code>node_types</code>: Limit to specific node types (optional) - <code>in_section</code>: Limit to specific section (optional) - <code>boost_sections</code>: Sections to boost in ranking (optional)</p> <p>Returns: - List of <code>SearchResult</code> objects with scores and context</p>"},{"location":"advanced-search/#get_cache_stats","title":"get_cache_stats()","text":"<pre><code>searcher.get_cache_stats() -&gt; Dict[str, Any]\n</code></pre> <p>Get cache performance statistics.</p> <p>Returns: - Dictionary with cache metrics:   - <code>memory_entries</code>: Indices in memory   - <code>disk_entries</code>: Indices on disk   - <code>cache_hits</code>: Total cache hits   - <code>cache_misses</code>: Total cache misses   - <code>hit_rate</code>: Cache hit rate (0-1)   - <code>memory_size_mb</code>: Memory usage in MB</p>"},{"location":"advanced-search/#clear_cache","title":"clear_cache()","text":"<pre><code>searcher.clear_cache(memory_only: bool = False)\n</code></pre> <p>Clear search caches.</p> <p>Parameters: - <code>memory_only</code>: If True, only clear memory cache (default: False)</p>"},{"location":"advanced-search/#examples","title":"Examples","text":"<p>See ranking_search_examples.py for comprehensive examples including:</p> <ol> <li>Basic BM25 ranked search</li> <li>Hybrid search with structure boosting</li> <li>Semantic structure search</li> <li>Section-specific search</li> <li>Section boosting</li> <li>Cache performance demonstration</li> <li>Agent-friendly workflows</li> <li>Comparing algorithms</li> <li>Disabling cache</li> <li>Cache management</li> </ol>"},{"location":"advanced-search/#migration-from-old-search","title":"Migration from Old Search","text":"<p>If you're currently using the basic <code>search()</code> method:</p>"},{"location":"advanced-search/#old-way-basic-text-search","title":"Old Way (Basic Text Search)","text":"<pre><code>results = searcher.search(\n    query=\"revenue\",\n    mode=SearchMode.TEXT,\n    limit=10\n)\n</code></pre>"},{"location":"advanced-search/#new-way-ranked-search","title":"New Way (Ranked Search)","text":"<pre><code>results = searcher.ranked_search(\n    query=\"revenue growth trends\",\n    algorithm=\"hybrid\",\n    top_k=10\n)\n</code></pre> <p>Benefits: - Relevance scores (not just presence/absence) - Structure-aware boosting - Better results for financial documents - 10x faster with caching - Full section context</p> <p>Note: The old <code>search()</code> method is still available for backwards compatibility.</p>"},{"location":"advanced-search/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced-search/#cache-not-working","title":"Cache Not Working","text":"<p>Check if caching is enabled:</p> <pre><code>searcher = DocumentSearch(document, use_cache=True)  # Make sure use_cache=True\n</code></pre>"},{"location":"advanced-search/#memory-issues","title":"Memory Issues","text":"<p>Reduce cache size:</p> <pre><code>from edgar.documents.ranking.cache import SearchIndexCache, set_search_cache\n\ncache = SearchIndexCache(memory_cache_size=5)  # Reduce from default 10\nset_search_cache(cache)\n</code></pre> <p>Or disable disk cache:</p> <pre><code>cache = SearchIndexCache(disk_cache_enabled=False)\nset_search_cache(cache)\n</code></pre>"},{"location":"advanced-search/#slow-first-search","title":"Slow First Search","text":"<p>First search builds the index (0.2-1.0s depending on document size). Subsequent searches are instant (~0.05s).</p> <p>This is normal and expected - the index is cached for future searches.</p>"},{"location":"advanced-search/#technical-details","title":"Technical Details","text":""},{"location":"advanced-search/#bm25-algorithm","title":"BM25 Algorithm","text":"<p>EdgarTools uses the Okapi BM25 variant with default parameters: - k1 = 1.5 (term frequency saturation) - b = 0.75 (length normalization)</p> <p>These parameters are optimized for financial documents.</p>"},{"location":"advanced-search/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Memory cache: LRU eviction, configurable size (default: 10)</li> <li>Disk cache: Pickle serialization in <code>~/.edgar_cache/search/</code></li> <li>TTL: 24 hours default (configurable)</li> <li>Index data: Tokenized corpus + parameters (~5MB per index)</li> </ul>"},{"location":"advanced-search/#semantic-boosting","title":"Semantic Boosting","text":"<p>Structure-aware boosting uses: - Node type scoring (headings &gt; text &gt; etc.) - Semantic type detection (item headers, section headers) - Cross-reference detection (regex patterns for \"See Item X\") - Position importance (earlier sections ranked higher)</p>"},{"location":"advanced-search/#see-also","title":"See Also","text":"<ul> <li>Document Parsing</li> <li>XBRL Querying</li> <li>Examples</li> </ul>"},{"location":"ai-integration/","title":"AI Integration Guide","text":"<p>EdgarTools is designed from the ground up to work seamlessly with AI agents and Large Language Models (LLMs). This guide covers all AI-native features and best practices for integrating EdgarTools with your AI applications.</p>"},{"location":"ai-integration/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Interactive Documentation (.docs Property)</li> <li>AI-Optimized Text Output (.text() Methods)</li> <li>AI Skills System</li> <li>Model Context Protocol (MCP) Server</li> <li>Helper Functions</li> <li>Best Practices</li> <li>Token Optimization</li> </ul>"},{"location":"ai-integration/#overview","title":"Overview","text":"<p>EdgarTools provides three levels of AI integration:</p> <ol> <li>Interactive Documentation: Rich, searchable docs via <code>.docs</code> property</li> <li>Token-Efficient Text Export: AI-optimized context via <code>.text()</code> methods</li> <li>Specialized Skills: Curated workflows for AI agents via Skills system</li> <li>MCP Integration: Native support for Claude Desktop and MCP clients</li> </ol> <p>All AI features are optional dependencies:</p> <pre><code># Install with AI features\npip install edgartools[ai]\n\n# Core EdgarTools works without AI dependencies\npip install edgartools\n</code></pre>"},{"location":"ai-integration/#interactive-documentation-docs-property","title":"Interactive Documentation (.docs Property)","text":"<p>Every major EdgarTools object includes comprehensive API documentation accessible via the <code>.docs</code> property.</p>"},{"location":"ai-integration/#basic-usage","title":"Basic Usage","text":"<pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\n\n# Display rich documentation in terminal\ncompany.docs\n</code></pre> <p>This displays beautifully formatted documentation with: - Complete API reference (methods, parameters, return types) - Usage examples - Best practices - Related concepts</p>"},{"location":"ai-integration/#searching-documentation","title":"Searching Documentation","text":"<p>Use BM25 semantic search to find relevant information instantly:</p> <pre><code># Search for specific functionality\nresults = company.docs.search(\"get financials\")\n\n# Search returns ranked results\nfor result in results:\n    print(result)\n</code></pre>"},{"location":"ai-integration/#available-documentation","title":"Available Documentation","text":"<p>Documentation is available on these objects:</p> Object Documentation Size Coverage <code>Company</code> ~1,070 lines Complete class reference <code>EntityFiling</code> ~557 lines Filing access methods <code>EntityFilings</code> ~671 lines Collection operations <code>XBRL</code> ~587 lines XBRL parsing and statements <code>Statement</code> ~567 lines Financial statement operations <p>Total: 3,450+ lines of comprehensive API documentation</p>"},{"location":"ai-integration/#documentation-structure","title":"Documentation Structure","text":"<p>Each documentation file includes:</p> <pre><code># Class Overview\nBrief description and purpose\n\n## Key Concepts\nImportant concepts and terminology\n\n## Basic Usage\nQuick start examples\n\n## Methods\n### method_name(param1, param2)\nDescription, parameters, returns, examples\n\n## Properties\n### property_name\nDescription, return type, examples\n\n## Advanced Usage\nComplex scenarios and patterns\n\n## Common Patterns\nFrequently used workflows\n\n## Examples\nReal-world usage examples\n</code></pre>"},{"location":"ai-integration/#ai-optimized-text-output-text-methods","title":"AI-Optimized Text Output (.text() Methods)","text":"<p>The <code>.text()</code> method provides token-efficient context optimized for LLM consumption.</p>"},{"location":"ai-integration/#basic-usage_1","title":"Basic Usage","text":"<pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\n\n# Get AI-optimized context output\ncontext = company.to_context()\nprint(context)\n</code></pre> <p>Note: The older <code>company.text()</code> method is deprecated. Use <code>company.to_context()</code> for consistent naming across all EdgarTools classes.</p>"},{"location":"ai-integration/#detail-levels","title":"Detail Levels","text":"<p>Three progressive disclosure levels for different use cases:</p> <pre><code># Minimal - Just the essentials (~100-200 tokens)\nminimal = company.to_context(detail='minimal')\n\n# Standard - Balanced overview (~300-500 tokens)\nstandard = company.to_context(detail='standard')\n\n# Detailed - Comprehensive information (~800-1200 tokens)\ndetailed = company.to_context(detail='detailed')\n</code></pre>"},{"location":"ai-integration/#token-limiting","title":"Token Limiting","text":"<p>Control output size for LLM context windows:</p> <pre><code># Limit to specific token count\ncontext = company.to_context(max_tokens=500)\n\n# Automatically truncates while preserving structure\n</code></pre>"},{"location":"ai-integration/#output-format-markdown-kv","title":"Output Format: Markdown-KV","text":"<p>EdgarTools uses markdown-kv format (research-backed as optimal for LLM comprehension):</p> <pre><code>## Company Information\nname: Apple Inc.\nticker: AAPL\ncik: 0000320193\nsic: 3571 - Electronic Computers\n\n## Recent Financials\nrevenue_fy2023: $383,285,000,000\nnet_income_fy2023: $96,995,000,000\n</code></pre> <p>Why markdown-kv? - Research shows it's most effective for LLM understanding - Combines human readability with machine parseability - Preserves hierarchical structure - Token-efficient compared to JSON or prose</p>"},{"location":"ai-integration/#available-text-methods","title":"Available Text Methods","text":"<pre><code># Company context\ncompany_text = company.to_context(detail='standard')\n\n# Filing context\nfiling = company.get_filings(form=\"10-K\").latest()\nfiling_text = filing.text(detail='standard')\n\n# XBRL context\nxbrl = filing.xbrl()\nxbrl_text = xbrl.to_context(detail='standard')\n\n# Statement context\nincome = xbrl.statements.income_statement()\nstatement_text = income.text(detail='standard')\n</code></pre>"},{"location":"ai-integration/#ai-skills-system","title":"AI Skills System","text":"<p>Skills package documentation and helper functions for specialized SEC analysis.</p>"},{"location":"ai-integration/#listing-available-skills","title":"Listing Available Skills","text":"<pre><code>from edgar.ai import list_skills\n\n# Get all available skills\nskills = list_skills()\nprint(skills)\n# [EdgarToolsSkill(name='EdgarTools')]\n</code></pre>"},{"location":"ai-integration/#getting-a-specific-skill","title":"Getting a Specific Skill","text":"<pre><code>from edgar.ai import get_skill\n\nskill = get_skill(\"EdgarTools\")\nprint(skill)\n# Skill: EdgarTools\n# Description: Query and analyze SEC filings and financial statements...\n# Documents: 4\n# Helper Functions: 5\n</code></pre>"},{"location":"ai-integration/#using-helper-functions","title":"Using Helper Functions","text":"<p>Skills provide pre-built workflow wrappers:</p> <pre><code># Get helper functions from skill\nhelpers = skill.get_helpers()\n\n# Use helper function for common workflow\nget_revenue_trend = helpers['get_revenue_trend']\nincome = get_revenue_trend(\"AAPL\", periods=3)\nprint(income)\n</code></pre>"},{"location":"ai-integration/#available-helper-functions","title":"Available Helper Functions","text":"<p>The EdgarTools skill includes:</p> <pre><code>from edgar.ai.helpers import (\n    get_filings_by_period,      # Get published filings for specific quarter\n    get_today_filings,           # Get recent filings (last ~24 hours)\n    get_revenue_trend,           # Get multi-period income statement\n    get_filing_statement,        # Get statement from specific filing\n    compare_companies_revenue,   # Compare revenue across companies\n)\n\n# Get filings for Q1 2023\nfilings = get_filings_by_period(2023, 1, form=\"10-K\")\n\n# Get today's filings\ncurrent = get_today_filings()\n\n# Get 3-year revenue trend\nincome = get_revenue_trend(\"AAPL\", periods=3)\n\n# Get specific statement\nbalance = get_filing_statement(\"AAPL\", 2023, \"10-K\", \"balance\")\n\n# Compare companies\ncomparison = compare_companies_revenue([\"AAPL\", \"MSFT\", \"GOOGL\"], periods=3)\n</code></pre>"},{"location":"ai-integration/#skill-documentation","title":"Skill Documentation","text":"<p>Access skill documentation:</p> <pre><code># List available documents\ndocs = skill.get_documents()\nprint(docs)\n# ['skill', 'objects', 'workflows', 'readme']\n\n# Get specific document content\nskill_content = skill.get_document_content(\"skill\")\nprint(skill_content)\n</code></pre>"},{"location":"ai-integration/#exporting-skills","title":"Exporting Skills","text":"<p>Export skills for use with AI tools like Claude Desktop and Claude Code.</p>"},{"location":"ai-integration/#simple-api-recommended","title":"Simple API (Recommended)","text":"<pre><code>from edgar.ai import install_skill, package_skill\n\n# Install to ~/.claude/skills/ for automatic discovery\ninstall_skill()\n# Output: /Users/username/.claude/skills/edgartools\n\n# Create ZIP for Claude Desktop upload\npackage_skill()\n# Output: edgartools.zip (ready to upload)\n\n# Custom locations\ninstall_skill(to=\"~/my-skills\")\npackage_skill(output=\"~/Desktop\")\n</code></pre>"},{"location":"ai-integration/#advanced-api","title":"Advanced API","text":"<pre><code>from edgar.ai import export_skill, edgartools_skill\n\n# Official Claude Skills format (installs to ~/.claude/skills/)\npath = export_skill(\n    edgartools_skill,\n    format=\"claude-skills\"  # Default format\n)\n\n# Claude Desktop upload format (creates ZIP with SKILL.md)\nzip_path = export_skill(\n    edgartools_skill,\n    format=\"claude-desktop\"\n)\n\n# Export to custom location\npath = export_skill(\n    edgartools_skill,\n    format=\"claude-skills\",\n    output_dir=\"~/my-skills\",\n    install=False\n)\n</code></pre>"},{"location":"ai-integration/#export-formats","title":"Export Formats","text":"<p>claude-skills (Official Anthropic Format): - Installs to <code>~/.claude/skills/</code> by default - Main file: <code>SKILL.md</code> (uppercase, per Anthropic spec) - Includes all supporting markdown files - Includes API reference documentation in <code>api-reference/</code> directory - YAML frontmatter with name and description - Ready for Claude Desktop and Claude Code</p> <p>claude-desktop (Claude Desktop Upload Format): - Creates ZIP file by default (required by Claude Desktop upload UI) - Main file: <code>SKILL.md</code> (uppercase, per Anthropic spec) - All supporting files and API reference included - Ready for upload via Claude Desktop's skill upload interface - Can export as directory with <code>create_zip=False</code></p> <p>Exported skills include: - Tutorial documentation (skill.md/SKILL.md, workflows.md, objects.md) - API reference documentation (api-reference/ directory) - YAML frontmatter for tool integration - Helper function documentation</p>"},{"location":"ai-integration/#model-context-protocol-mcp-server","title":"Model Context Protocol (MCP) Server","text":"<p>Run EdgarTools as an MCP server for Claude Desktop and other MCP clients.</p>"},{"location":"ai-integration/#installation","title":"Installation","text":"<pre><code>pip install edgartools[ai]\n</code></pre>"},{"location":"ai-integration/#starting-the-server","title":"Starting the Server","text":"<pre><code># Start MCP server\npython -m edgar.ai\n\n# The server will start and wait for MCP client connections\n</code></pre>"},{"location":"ai-integration/#claude-desktop-configuration","title":"Claude Desktop Configuration","text":"<p>Add to <code>~/Library/Application Support/Claude/claude_desktop_config.json</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"edgartools\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"edgar.ai\"],\n      \"env\": {\n        \"EDGAR_IDENTITY\": \"Your Name your.email@example.com\"\n      }\n    }\n  }\n}\n</code></pre> <p>Important: The <code>EDGAR_IDENTITY</code> environment variable is required by SEC regulations.</p>"},{"location":"ai-integration/#available-mcp-tools","title":"Available MCP Tools","text":"<p>Once configured, Claude Desktop can use these tools:</p> <ol> <li>edgar_company_research - Get comprehensive company intelligence</li> <li>Company profile and metadata</li> <li>3-year financial trends</li> <li>Last 5 filings</li> <li> <p>Recent activity summary</p> </li> <li> <p>edgar_analyze_financials - Detailed financial statement analysis</p> </li> <li>Income statement, balance sheet, or cash flow</li> <li>Annual or quarterly periods</li> <li>Multi-period trend analysis</li> </ol>"},{"location":"ai-integration/#example-prompts","title":"Example Prompts","text":"<p>After configuring the MCP server, try these prompts in Claude Desktop:</p> <pre><code>\"Research Apple Inc with financials\"\n\n\"Analyze Tesla's revenue trends over the last 4 quarters\"\n\n\"Compare Microsoft and Google's cash flow statements\"\n\n\"Get Nvidia's balance sheet trends for the past 3 years\"\n\n\"Show me today's 10-K filings\"\n</code></pre>"},{"location":"ai-integration/#other-mcp-clients","title":"Other MCP Clients","text":"<p>EdgarTools MCP server works with any MCP-compatible client:</p> <ul> <li>Claude Desktop (MacOS/Windows)</li> <li>Cline (VS Code extension)</li> <li>Continue.dev (IDE integration)</li> <li>Any other MCP v1.0 compatible client</li> </ul> <p>See MCP Quickstart for complete setup instructions.</p>"},{"location":"ai-integration/#helper-functions","title":"Helper Functions","text":"<p>Pre-built functions for common SEC analysis workflows.</p>"},{"location":"ai-integration/#filing-access-helpers","title":"Filing Access Helpers","text":"<pre><code>from edgar.ai.helpers import get_filings_by_period, get_today_filings\n\n# Get published filings for specific period\nfilings = get_filings_by_period(\n    year=2023,\n    quarter=1,\n    form=\"10-K\",\n    filing_date=None  # Optional: filter by specific date\n)\n\n# Get current filings (last ~24 hours)\ncurrent = get_today_filings()\nprint(f\"Found {len(current)} recent filings\")\n</code></pre>"},{"location":"ai-integration/#financial-analysis-helpers","title":"Financial Analysis Helpers","text":"<pre><code>from edgar.ai.helpers import (\n    get_revenue_trend,\n    get_filing_statement,\n    compare_companies_revenue\n)\n\n# Get revenue trend analysis\nincome = get_revenue_trend(\n    ticker=\"AAPL\",\n    periods=3,\n    quarterly=False  # Set True for quarterly data\n)\n\n# Get specific statement from filing\nbalance = get_filing_statement(\n    ticker=\"AAPL\",\n    year=2023,\n    form=\"10-K\",\n    statement_type=\"balance\"  # or \"income\", \"cash_flow\"\n)\n\n# Compare companies\ncomparison = compare_companies_revenue(\n    tickers=[\"AAPL\", \"MSFT\", \"GOOGL\"],\n    periods=3\n)\nfor ticker, income in comparison.items():\n    print(f\"\\n{ticker} Revenue Trend:\")\n    print(income)\n</code></pre>"},{"location":"ai-integration/#best-practices","title":"Best Practices","text":""},{"location":"ai-integration/#1-choose-the-right-tool-for-the-job","title":"1. Choose the Right Tool for the Job","text":"<pre><code># For interactive learning -&gt; Use .docs\ncompany.docs.search(\"get filings\")\n\n# For AI context -&gt; Use .text()\ncontext = company.to_context(detail='standard')\n\n# For specialized workflows -&gt; Use helpers\nfrom edgar.ai.helpers import get_revenue_trend\nincome = get_revenue_trend(\"AAPL\", periods=3)\n\n# For AI agents -&gt; Use MCP server or Skills\n</code></pre>"},{"location":"ai-integration/#2-use-progressive-disclosure","title":"2. Use Progressive Disclosure","text":"<pre><code># Start minimal, add detail as needed\noverview = company.to_context(detail='minimal')  # Quick overview\n\n# Need more context?\nstandard = company.to_context(detail='standard')  # Balanced view\n\n# Need everything?\ndetailed = company.to_context(detail='detailed')  # Comprehensive\n</code></pre>"},{"location":"ai-integration/#3-respect-token-limits","title":"3. Respect Token Limits","text":"<pre><code># Always specify max_tokens for LLM context\ncontext = company.to_context(max_tokens=500)\n\n# For multiple objects, budget tokens:\ncompany_context = company.to_context(max_tokens=300)\nfiling_context = filing.text(max_tokens=200)\ntotal_context = company_context + \"\\n\\n\" + filing_context\n# Total: ~500 tokens\n</code></pre>"},{"location":"ai-integration/#4-cache-expensive-operations","title":"4. Cache Expensive Operations","text":"<pre><code># Cache company objects\nfrom functools import lru_cache\n\n@lru_cache(maxsize=100)\ndef get_company(ticker: str):\n    return Company(ticker)\n\n# Reuse cached company\napple = get_company(\"AAPL\")\n</code></pre>"},{"location":"ai-integration/#5-use-entity-facts-api-for-multi-period-data","title":"5. Use Entity Facts API for Multi-Period Data","text":"<pre><code># More efficient than fetching multiple filings\ncompany = Company(\"AAPL\")\nincome = company.income_statement(periods=3)\n# Single API call, ~500 tokens\n\n# Less efficient:\n# filing1 = company.get_filings(form=\"10-K\")[0]\n# filing2 = company.get_filings(form=\"10-K\")[1]\n# filing3 = company.get_filings(form=\"10-K\")[2]\n# 3 API calls, ~3,750 tokens\n</code></pre>"},{"location":"ai-integration/#token-optimization","title":"Token Optimization","text":""},{"location":"ai-integration/#understanding-token-costs","title":"Understanding Token Costs","text":"<p>Approximate token sizes for common operations:</p> Operation Tokens (approx) <code>Company.text(detail='minimal')</code> 100-200 <code>Company.text(detail='standard')</code> 300-500 <code>Company.text(detail='detailed')</code> 800-1200 <code>Filing.text(detail='standard')</code> 200-400 <code>Statement.to_dataframe()</code> (3 periods) 500-1000 <code>XBRL.text(detail='standard')</code> 400-600"},{"location":"ai-integration/#optimization-strategies","title":"Optimization Strategies","text":"<p>1. Use .head() to limit collections:</p> <pre><code># Limit filing output\nfilings = company.get_filings(form=\"10-K\")\nprint(filings.head(5))  # Only show 5 filings\n</code></pre> <p>2. Prefer Entity Facts API:</p> <pre><code># Efficient: Single API call\nincome = company.income_statement(periods=3)  # ~500 tokens\n\n# Less efficient: Multiple filing accesses\n# ~3,750 tokens for 3 separate filings\n</code></pre> <p>3. Filter before displaying:</p> <pre><code># Filter first\ntech_companies = filings.filter(ticker=[\"AAPL\", \"MSFT\", \"GOOGL\"])\nprint(tech_companies)  # Much smaller output\n</code></pre> <p>4. Use specific statements vs full XBRL:</p> <pre><code># Efficient\nincome = xbrl.statements.income_statement()  # ~1,250 tokens\n\n# Less efficient\nprint(xbrl)  # Full XBRL object, ~2,500 tokens\n</code></pre> <p>5. Control detail levels:</p> <pre><code># For overview tasks\noverview = company.to_context(detail='minimal')\n\n# For detailed analysis\nanalysis = company.to_context(detail='detailed')\n</code></pre>"},{"location":"ai-integration/#token-counting","title":"Token Counting","text":"<pre><code>from edgar.ai.core import TokenOptimizer\n\n# Estimate tokens before sending to LLM\ncontent = company.to_context()\ntoken_count = TokenOptimizer.estimate_tokens(content)\nprint(f\"Estimated tokens: {token_count}\")\n\n# Optimize for specific token limit\noptimized = TokenOptimizer.optimize_for_tokens(\n    content,\n    max_tokens=1000\n)\n</code></pre>"},{"location":"ai-integration/#examples","title":"Examples","text":""},{"location":"ai-integration/#example-1-building-llm-context","title":"Example 1: Building LLM Context","text":"<pre><code>from edgar import Company\n\n# Get company\ncompany = Company(\"AAPL\")\n\n# Build multi-level context\ncontext_parts = []\n\n# 1. Company overview\ncontext_parts.append(\"# Company Overview\")\ncontext_parts.append(company.to_context(detail='minimal', max_tokens=200))\n\n# 2. Latest filing\nfiling = company.get_filings(form=\"10-K\").latest()\ncontext_parts.append(\"\\n# Latest 10-K Filing\")\ncontext_parts.append(filing.text(detail='standard', max_tokens=300))\n\n# 3. Financial statements\nxbrl = filing.xbrl()\nincome = xbrl.statements.income_statement()\ncontext_parts.append(\"\\n# Income Statement\")\ncontext_parts.append(income.text(max_tokens=500))\n\n# Combine for LLM\nllm_context = \"\\n\".join(context_parts)\nprint(f\"Total context: ~{len(llm_context.split())*1.3:.0f} tokens\")\n</code></pre>"},{"location":"ai-integration/#example-2-interactive-documentation-assistant","title":"Example 2: Interactive Documentation Assistant","text":"<pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\n\n# Search for relevant documentation\nquery = \"how do I get historical financials\"\nresults = company.docs.search(query)\n\n# Display top results\nprint(f\"Search results for: {query}\\n\")\nfor i, result in enumerate(results[:3], 1):\n    print(f\"{i}. {result}\")\n</code></pre>"},{"location":"ai-integration/#example-3-batch-processing-with-token-budget","title":"Example 3: Batch Processing with Token Budget","text":"<pre><code>from edgar import get_filings\n\n# Get filings\nfilings = get_filings(2023, 1, form=\"10-K\")\n\n# Process with token budget\ntoken_budget = 5000\ntokens_used = 0\n\nresults = []\nfor filing in filings:\n    # Check token budget\n    filing_text = filing.text(detail='minimal')\n    estimated_tokens = len(filing_text.split()) * 1.3\n\n    if tokens_used + estimated_tokens &gt; token_budget:\n        break\n\n    results.append(filing_text)\n    tokens_used += estimated_tokens\n\nprint(f\"Processed {len(results)} filings using ~{tokens_used:.0f} tokens\")\n</code></pre>"},{"location":"ai-integration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"ai-integration/#issue-ai-features-not-available","title":"Issue: \"AI features not available\"","text":"<p>Solution: Install AI dependencies:</p> <pre><code>pip install edgartools[ai]\n</code></pre>"},{"location":"ai-integration/#issue-mcp-server-wont-start","title":"Issue: MCP server won't start","text":"<p>Solution: Check that EDGAR_IDENTITY is set:</p> <pre><code>export EDGAR_IDENTITY=\"Your Name your.email@example.com\"\npython -m edgar.ai\n</code></pre>"},{"location":"ai-integration/#issue-documentation-not-displaying","title":"Issue: Documentation not displaying","text":"<p>Solution: Documentation requires optional AI dependencies. Install with:</p> <pre><code>pip install edgartools[ai]\n</code></pre>"},{"location":"ai-integration/#issue-token-counts-seem-high","title":"Issue: Token counts seem high","text":"<p>Solution: Use lower detail levels or max_tokens:</p> <pre><code># Instead of:\ntext = company.to_context(detail='detailed')\n\n# Try:\ntext = company.to_context(detail='standard', max_tokens=500)\n</code></pre>"},{"location":"ai-integration/#additional-resources","title":"Additional Resources","text":"<ul> <li>EdgarTools Documentation</li> <li>MCP Quickstart Guide</li> <li>AI Skills README</li> <li>GitHub Issues</li> <li>GitHub Discussions</li> </ul>"},{"location":"ai-integration/#contributing","title":"Contributing","text":"<p>We welcome contributions to improve AI integration:</p> <ul> <li>Suggest new helper functions</li> <li>Create specialized skills for external packages</li> <li>Improve documentation</li> <li>Report integration issues</li> </ul> <p>See Contributing Guide for details.</p> <p>Need Help? Open an issue on GitHub or start a discussion.</p>"},{"location":"architecture-diagram/","title":"EdgarTools Architecture Diagram","text":""},{"location":"architecture-diagram/#system-architecture","title":"System Architecture","text":"<pre><code>%%{init: {'theme':'base', 'themeVariables': { 'primaryColor':'#FFD700', 'primaryTextColor':'#3d5875', 'primaryBorderColor':'#3d5875', 'lineColor':'#3d5875', 'secondaryColor':'#f8f9fa', 'tertiaryColor':'#ffffff', 'background':'#ffffff', 'mainBkg':'#f8f9fa', 'secondBkg':'#FFD700', 'tertiaryBkg':'#3d5875'}}}%%\n\ngraph TB\n    subgraph Users[\"\ud83e\uddd1\u200d\ud83d\udcbb Users &amp; Applications\"]\n        A1[Python Developers]\n        A2[AI Agents / LLMs]\n        A3[Data Scientists]\n        A4[Financial Analysts]\n    end\n\n    subgraph EdgarTools[\"EdgarTools Library\"]\n        direction TB\n        B1[Core API Layer]\n        B2[Filing Parser]\n        B3[XBRL Processor]\n        B4[Text Extractor]\n        B5[MCP Server]\n\n        B1 --&gt; B2\n        B1 --&gt; B3\n        B1 --&gt; B4\n        B1 --&gt; B5\n    end\n\n    subgraph DataLayer[\"\ud83d\udcca Data Objects\"]\n        C1[Company]\n        C2[Filings]\n        C3[Financials]\n        C4[Ownership]\n        C5[Funds]\n    end\n\n    subgraph Output[\"\ud83d\udcbe Output Formats\"]\n        D1[DataFrames]\n        D2[Python Objects]\n        D3[Markdown/Text]\n        D4[JSON/Dict]\n        D5[Rich Tables]\n    end\n\n    subgraph SEC[\"\ud83c\udfdb\ufe0f SEC EDGAR Database\"]\n        E1[Filing Archive]\n        E2[Company Data]\n        E3[XBRL Datasets]\n        E4[RSS Feeds]\n    end\n\n    A1 --&gt; B1\n    A2 --&gt; B5\n    A3 --&gt; B1\n    A4 --&gt; B1\n\n    B2 --&gt; C1\n    B2 --&gt; C2\n    B3 --&gt; C3\n    B2 --&gt; C4\n    B2 --&gt; C5\n\n    C1 --&gt; D1\n    C2 --&gt; D2\n    C3 --&gt; D1\n    C4 --&gt; D2\n    C5 --&gt; D1\n    C1 --&gt; D3\n    C2 --&gt; D3\n    C1 --&gt; D4\n    C1 --&gt; D5\n\n    B1 &lt;--&gt; SEC\n    B2 &lt;--&gt; E1\n    B3 &lt;--&gt; E3\n    B1 &lt;--&gt; E2\n    B1 &lt;--&gt; E4\n\n    classDef userClass fill:#FFD700,stroke:#3d5875,stroke-width:2px,color:#3d5875\n    classDef coreClass fill:#3d5875,stroke:#FFD700,stroke-width:2px,color:#FFD700\n    classDef dataClass fill:#f8f9fa,stroke:#3d5875,stroke-width:2px,color:#3d5875\n    classDef outputClass fill:#ffffff,stroke:#FFD700,stroke-width:2px,color:#3d5875\n    classDef secClass fill:#3d5875,stroke:#3d5875,stroke-width:2px,color:#FFD700\n\n    class A1,A2,A3,A4 userClass\n    class B1,B2,B3,B4,B5 coreClass\n    class C1,C2,C3,C4,C5 dataClass\n    class D1,D2,D3,D4,D5 outputClass\n    class E1,E2,E3,E4 secClass\n</code></pre>"},{"location":"architecture-diagram/#component-details","title":"Component Details","text":""},{"location":"architecture-diagram/#core-api-layer","title":"Core API Layer","text":"<ul> <li>Company: Entry point for company-specific data</li> <li>get_filings(): Retrieve and filter filings</li> <li>set_identity(): SEC-required user identification</li> <li>get_funds(): Access fund holdings data</li> </ul>"},{"location":"architecture-diagram/#filing-parser","title":"Filing Parser","text":"<ul> <li>HTML Parsing: lxml-based high-performance parsing</li> <li>Form Recognition: Automatic detection of form types</li> <li>Data Extraction: Structured data from forms (10-K, 10-Q, 8-K, Form 4, 13F, etc.)</li> <li>Attachment Handling: Access exhibits and attachments</li> </ul>"},{"location":"architecture-diagram/#xbrl-processor","title":"XBRL Processor","text":"<ul> <li>Financial Statements: Balance sheets, income statements, cash flows</li> <li>Standardization: Cross-company comparable data</li> <li>Tag Mapping: XBRL tag to human-readable names</li> <li>Validation: Data quality checks</li> </ul>"},{"location":"architecture-diagram/#text-extractor","title":"Text Extractor","text":"<ul> <li>Clean Text: HTML to clean text conversion</li> <li>Section Extraction: Item 1A (Risk Factors), Item 7 (MD&amp;A), etc.</li> <li>Markdown Conversion: Formatted for LLMs</li> <li>Chunking Support: Large document handling</li> </ul>"},{"location":"architecture-diagram/#mcp-server","title":"MCP Server","text":"<ul> <li>Company Research: AI-driven company analysis</li> <li>Financial Analysis: Automated financial metric extraction</li> <li>Filing Search: Natural language filing queries</li> <li>Zero Configuration: No API keys required</li> </ul>"},{"location":"architecture-diagram/#data-flow","title":"Data Flow","text":"<ol> <li>User Request \u2192 Core API Layer</li> <li>API \u2192 SEC EDGAR Database</li> <li>Raw Data \u2192 Filing Parser</li> <li>Parsed Data \u2192 Data Objects (Company, Filings, Financials)</li> <li>Data Objects \u2192 Output Formats (DataFrame, Text, JSON)</li> <li>Output \u2192 User Application</li> </ol>"},{"location":"architecture-diagram/#integration-points","title":"Integration Points","text":""},{"location":"architecture-diagram/#for-python-developers","title":"For Python Developers","text":"<pre><code>from edgar import Company\ncompany = Company(\"AAPL\")\nfinancials = company.get_financials()\n</code></pre>"},{"location":"architecture-diagram/#for-ai-agents-via-mcp","title":"For AI Agents (via MCP)","text":"<pre><code># Automatic via Claude Desktop or other MCP clients\n# No code needed - configure once, use forever\n</code></pre>"},{"location":"architecture-diagram/#for-data-scientists","title":"For Data Scientists","text":"<pre><code>import pandas as pd\nfilings = Company(\"MSFT\").get_filings()\ndf = filings.to_pandas()\n</code></pre> <p>Diagram Usage in README:</p> <p>Add to README.md under an \"Architecture\" or \"How It Works\" section:</p> <pre><code>## How It Works\n\nEdgarTools provides a clean abstraction layer over the SEC EDGAR database:\n\n[Include Mermaid diagram here]\n\nThe library handles all the complexity of SEC data access, parsing, and transformation, exposing a simple, intuitive API for financial data analysis.\n</code></pre>"},{"location":"company-group-testing/","title":"Company Group Testing Framework","text":"<p>A simple and elegant approach to test EdgarTools features across curated groups of companies using the <code>edgar.reference.company_subsets</code> API as the foundation.</p>"},{"location":"company-group-testing/#overview","title":"Overview","text":"<p>Traditional testing often focuses on individual companies or small hardcoded sets. The Company Group Testing framework enables systematic testing across diverse, curated company groups to ensure features work robustly across different:</p> <ul> <li>Company sizes (mega-cap, mid-cap, small-cap)</li> <li>Industries (tech, finance, healthcare, retail)</li> <li>Exchanges (NYSE, NASDAQ, OTC)</li> <li>Data quality levels (comprehensive vs. sparse filings)</li> </ul>"},{"location":"company-group-testing/#key-benefits","title":"Key Benefits","text":"<p>\u2705 Representative Testing: Test across statistically meaningful company samples \u2705 Edge Case Discovery: Identify compatibility issues with different company types \u2705 Success Rate Metrics: Measure feature robustness with quantified success rates \u2705 Maintainable: Leverage existing company-subsets infrastructure \u2705 Flexible: Easy to create custom groups for specific testing needs</p>"},{"location":"company-group-testing/#basic-usage","title":"Basic Usage","text":""},{"location":"company-group-testing/#quick-example","title":"Quick Example","text":"<pre><code>from edgar.reference.company_subsets import get_tech_giants\n\ndef test_standardized_concepts_on_tech_giants():\n    \"\"\"Test new standardized API on major tech companies.\"\"\"\n    tech_companies = get_tech_giants().head(10)\n\n    passed = 0\n    for _, company_info in tech_companies.iterrows():\n        try:\n            company = Company(company_info['ticker'])\n            facts = company.get_facts()\n\n            # Test the feature\n            revenue = facts.get_revenue()\n            assert revenue is not None\n            assert revenue &gt; 1_000_000_000  # Tech giants should have &gt;$1B revenue\n\n            passed += 1\n            print(f\"\u2705 {company_info['ticker']}: ${revenue/1e9:.1f}B\")\n\n        except Exception as e:\n            print(f\"\u274c {company_info['ticker']}: {str(e)[:50]}\")\n\n    success_rate = (passed / len(tech_companies)) * 100\n    print(f\"Success Rate: {passed}/{len(tech_companies)} ({success_rate:.1f}%)\")\n\n    assert success_rate &gt;= 80, \"Feature should work on 80%+ of tech giants\"\n</code></pre>"},{"location":"company-group-testing/#available-company-groups","title":"Available Company Groups","text":"<p>The framework provides pre-defined groups via <code>company_subsets</code>:</p> <pre><code>from edgar.reference.company_subsets import (\n    get_faang_companies,      # Meta, Apple, Amazon, Netflix, Google\n    get_tech_giants,          # Major technology companies\n    get_dow_jones_sample,     # Dow Jones Industrial Average sample\n    get_popular_companies,    # Popular stocks by tier\n    CompanySubset             # Fluent interface for custom groups\n)\n\n# Pre-defined groups\nfaang = get_faang_companies()                    # 5 companies\ntech_giants = get_tech_giants()                  # ~13 companies\nmega_cap = get_popular_companies(PopularityTier.MEGA_CAP)  # Top 10\n\n# Custom groups using fluent interface\nnasdaq_sample = (CompanySubset()\n                .from_exchange(\"Nasdaq\")\n                .from_popular(PopularityTier.POPULAR)\n                .sample(20, random_state=42)\n                .get())\n</code></pre>"},{"location":"company-group-testing/#testing-patterns","title":"Testing Patterns","text":""},{"location":"company-group-testing/#pattern-1-systematic-feature-validation","title":"Pattern 1: Systematic Feature Validation","text":"<p>Test a new feature across multiple company groups:</p> <pre><code>def validate_standardized_concepts():\n    \"\"\"Validate FEAT-411 standardized concepts across company groups.\"\"\"\n\n    groups_to_test = [\n        (\"FAANG\", get_faang_companies()),\n        (\"Tech Giants\", get_tech_giants().head(10)),\n        (\"Mega Cap\", get_popular_companies(PopularityTier.MEGA_CAP)),\n        (\"NYSE Sample\", CompanySubset().from_exchange(\"NYSE\").sample(15).get())\n    ]\n\n    overall_results = []\n\n    for group_name, companies in groups_to_test:\n        print(f\"\\n\ud83e\uddea Testing {group_name} ({len(companies)} companies)\")\n\n        group_passed = 0\n        for _, company_info in companies.iterrows():\n            try:\n                company = Company(company_info['ticker'])\n                facts = company.get_facts()\n\n                # Test core standardized methods\n                revenue = facts.get_revenue()\n                net_income = facts.get_net_income()\n                assets = facts.get_total_assets()\n\n                # Validation logic\n                assert revenue is not None, \"Revenue should be available\"\n                if net_income: assert isinstance(net_income, (int, float))\n                if assets: assert assets &gt; 0\n\n                group_passed += 1\n                print(f\"  \u2705 {company_info['ticker']}\")\n\n            except Exception as e:\n                print(f\"  \u274c {company_info['ticker']}: {str(e)[:60]}\")\n\n        success_rate = (group_passed / len(companies)) * 100\n        overall_results.append((group_name, group_passed, len(companies), success_rate))\n        print(f\"  \ud83d\udcca {group_name}: {group_passed}/{len(companies)} ({success_rate:.1f}%)\")\n\n    # Overall assessment\n    total_passed = sum(r[1] for r in overall_results)\n    total_tested = sum(r[2] for r in overall_results)\n    overall_rate = (total_passed / total_tested) * 100\n\n    print(f\"\\n\ud83c\udfc6 Overall: {total_passed}/{total_tested} ({overall_rate:.1f}%)\")\n    return overall_rate &gt;= 75  # Require 75% overall success\n</code></pre>"},{"location":"company-group-testing/#pattern-2-method-specific-testing","title":"Pattern 2: Method-Specific Testing","text":"<p>Test individual methods across company diversity:</p> <pre><code>def test_revenue_method_robustness():\n    \"\"\"Test get_revenue() method across diverse company types.\"\"\"\n\n    # Create diverse test set\n    diverse_companies = (CompanySubset()\n                        .from_exchange([\"NYSE\", \"Nasdaq\"])\n                        .sample(50, random_state=42)\n                        .get())\n\n    results = {\n        'has_revenue': 0,\n        'positive_revenue': 0,\n        'reasonable_values': 0,\n        'concept_mapping_works': 0\n    }\n\n    for _, company_info in diverse_companies.iterrows():\n        ticker = company_info['ticker']\n\n        try:\n            company = Company(ticker)\n            facts = company.get_facts()\n\n            # Test revenue method\n            revenue = facts.get_revenue()\n\n            if revenue is not None:\n                results['has_revenue'] += 1\n\n                if revenue &gt; 0:\n                    results['positive_revenue'] += 1\n\n                    # Test reasonable value ranges (avoid unit issues)\n                    if 1_000_000 &lt; revenue &lt; 1_000_000_000_000:  # $1M to $1T\n                        results['reasonable_values'] += 1\n\n            # Test concept mapping functionality\n            revenue_concepts = ['Revenue', 'Revenues', 'NetSales']\n            mapping_info = facts.get_concept_mapping_info(revenue_concepts)\n            if isinstance(mapping_info, dict) and 'available' in mapping_info:\n                results['concept_mapping_works'] += 1\n\n        except Exception as e:\n            print(f\"Error with {ticker}: {str(e)[:50]}\")\n\n    total = len(diverse_companies)\n\n    print(\"Revenue Method Robustness Results:\")\n    print(f\"  \ud83d\udcca Has revenue data: {results['has_revenue']}/{total} ({results['has_revenue']/total*100:.1f}%)\")\n    print(f\"  \u2705 Positive values: {results['positive_revenue']}/{total} ({results['positive_revenue']/total*100:.1f}%)\")\n    print(f\"  \ud83c\udfaf Reasonable ranges: {results['reasonable_values']}/{total} ({results['reasonable_values']/total*100:.1f}%)\")\n    print(f\"  \ud83d\udd0d Mapping info works: {results['concept_mapping_works']}/{total} ({results['concept_mapping_works']/total*100:.1f}%)\")\n\n    return results\n</code></pre>"},{"location":"company-group-testing/#pattern-3-performance-testing","title":"Pattern 3: Performance Testing","text":"<p>Measure performance across company groups:</p> <pre><code>import time\n\ndef performance_test_across_groups():\n    \"\"\"Measure standardized concept performance across company groups.\"\"\"\n\n    groups = [\n        (\"Small Set\", get_faang_companies()),\n        (\"Medium Set\", get_tech_giants()),\n        (\"Large Set\", CompanySubset().from_popular().sample(30).get())\n    ]\n\n    for group_name, companies in groups:\n        print(f\"\\n\u23f1\ufe0f Performance Test: {group_name}\")\n\n        start_time = time.time()\n        successful_calls = 0\n\n        for _, company_info in companies.iterrows():\n            try:\n                company = Company(company_info['ticker'])\n                facts = company.get_facts()\n\n                # Time the standardized method calls\n                method_start = time.time()\n                revenue = facts.get_revenue()\n                net_income = facts.get_net_income()\n                assets = facts.get_total_assets()\n                method_time = time.time() - method_start\n\n                if revenue is not None:\n                    successful_calls += 1\n\n                print(f\"  {company_info['ticker']}: {method_time:.2f}s\")\n\n            except Exception as e:\n                print(f\"  {company_info['ticker']}: ERROR\")\n\n        total_time = time.time() - start_time\n        avg_time = total_time / len(companies)\n\n        print(f\"  \ud83d\udcc8 Total: {total_time:.1f}s, Avg: {avg_time:.2f}s/company\")\n        print(f\"  \u2705 Success: {successful_calls}/{len(companies)}\")\n</code></pre>"},{"location":"company-group-testing/#custom-company-groups","title":"Custom Company Groups","text":"<p>Create custom groups for specific testing scenarios:</p>"},{"location":"company-group-testing/#industry-specific-groups","title":"Industry-Specific Groups","text":"<pre><code># Healthcare companies\nhealthcare_companies = (CompanySubset()\n                       .from_exchange([\"NYSE\", \"Nasdaq\"])\n                       .filter_by(lambda df: df['name'].str.contains(\n                           'health|medical|pharma|bio', case=False))\n                       .sample(20, random_state=42)\n                       .get())\n\n# Financial services\nfinancial_companies = (CompanySubset()\n                      .from_exchange(\"NYSE\")\n                      .filter_by(lambda df: df['name'].str.contains(\n                          'bank|financial|insurance', case=False))\n                      .top(15, by='ticker')\n                      .get())\n</code></pre>"},{"location":"company-group-testing/#size-stratified-groups","title":"Size-Stratified Groups","text":"<pre><code># Multi-tier sample\ndef create_size_stratified_group():\n    mega_cap = get_popular_companies(PopularityTier.MEGA_CAP).head(5)\n    mid_cap = (CompanySubset()\n              .from_popular(PopularityTier.POPULAR)\n              .exclude_tickers(mega_cap['ticker'].tolist())\n              .sample(10, random_state=42)\n              .get())\n    small_cap = (CompanySubset()\n                .from_exchange([\"NYSE\", \"Nasdaq\"])\n                .exclude_tickers(mega_cap['ticker'].tolist() + mid_cap['ticker'].tolist())\n                .sample(15, random_state=42)\n                .get())\n\n    from edgar.reference.company_subsets import combine_company_sets\n    return combine_company_sets([mega_cap, mid_cap, small_cap])\n</code></pre>"},{"location":"company-group-testing/#geographicexchange-groups","title":"Geographic/Exchange Groups","text":"<pre><code># Exchange comparison\nexchange_groups = {\n    'NYSE': CompanySubset().from_exchange(\"NYSE\").sample(25).get(),\n    'NASDAQ': CompanySubset().from_exchange(\"Nasdaq\").sample(25).get(),\n    'Mixed': CompanySubset().from_exchange([\"NYSE\", \"Nasdaq\"]).sample(25).get()\n}\n</code></pre>"},{"location":"company-group-testing/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"company-group-testing/#pytest-integration","title":"Pytest Integration","text":"<pre><code>import pytest\nfrom edgar.reference.company_subsets import get_tech_giants\n\n@pytest.mark.parametrize(\"company_info\", get_tech_giants().head(5).to_dict('records'))\ndef test_standardized_concepts_parametrized(company_info):\n    \"\"\"Pytest parametrized test using company groups.\"\"\"\n    company = Company(company_info['ticker'])\n    facts = company.get_facts()\n\n    revenue = facts.get_revenue()\n    assert revenue is not None, f\"{company_info['ticker']} should have revenue\"\n    assert revenue &gt; 0, \"Revenue should be positive\"\n\ndef test_feature_success_rate():\n    \"\"\"Test that feature works on majority of companies.\"\"\"\n    tech_companies = get_tech_giants()\n\n    passed = 0\n    for _, company_info in tech_companies.iterrows():\n        try:\n            company = Company(company_info['ticker'])\n            facts = company.get_facts()\n\n            if facts.get_revenue() is not None:\n                passed += 1\n        except:\n            continue\n\n    success_rate = (passed / len(tech_companies)) * 100\n    assert success_rate &gt;= 70, f\"Success rate {success_rate:.1f}% below 70% threshold\"\n</code></pre>"},{"location":"company-group-testing/#performance-benchmarks","title":"Performance Benchmarks","text":"<pre><code>def benchmark_standardized_methods():\n    \"\"\"Benchmark standardized methods for performance regression.\"\"\"\n    import time\n\n    companies = get_popular_companies(PopularityTier.POPULAR).head(20)\n\n    times = []\n    for _, company_info in companies.iterrows():\n        try:\n            start = time.time()\n\n            company = Company(company_info['ticker'])\n            facts = company.get_facts()\n\n            # Test all standardized methods\n            facts.get_revenue()\n            facts.get_net_income()\n            facts.get_total_assets()\n\n            elapsed = time.time() - start\n            times.append(elapsed)\n\n        except:\n            continue\n\n    if times:\n        avg_time = sum(times) / len(times)\n        max_time = max(times)\n\n        print(f\"Avg time: {avg_time:.2f}s, Max time: {max_time:.2f}s\")\n\n        # Performance regression checks\n        assert avg_time &lt; 3.0, f\"Average time {avg_time:.2f}s too slow\"\n        assert max_time &lt; 10.0, f\"Max time {max_time:.2f}s too slow\"\n</code></pre>"},{"location":"company-group-testing/#best-practices","title":"Best Practices","text":""},{"location":"company-group-testing/#1-choose-representative-groups","title":"1. Choose Representative Groups","text":"<pre><code># Good: Diverse, representative sample\ntest_companies = (CompanySubset()\n                 .from_exchange([\"NYSE\", \"Nasdaq\"])\n                 .from_popular(PopularityTier.POPULAR)\n                 .sample(30, random_state=42)  # Reproducible\n                 .get())\n\n# Avoid: Overly narrow or biased samples\n# tech_only = get_tech_giants()  # Too narrow for general feature testing\n</code></pre>"},{"location":"company-group-testing/#2-set-appropriate-success-thresholds","title":"2. Set Appropriate Success Thresholds","text":"<pre><code># Adjust thresholds based on feature maturity and company diversity\nthresholds = {\n    'mega_cap': 95,      # Should work on almost all mega-cap companies\n    'tech_giants': 90,   # Tech companies usually have good data\n    'popular': 80,       # Popular companies generally reliable\n    'diverse_sample': 70,# Diverse samples include edge cases\n    'random_sample': 60  # Random samples include low-quality data\n}\n</code></pre>"},{"location":"company-group-testing/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code>def robust_group_testing(companies, test_func, max_failures=5):\n    \"\"\"Test with graceful error handling.\"\"\"\n    results = {'passed': 0, 'failed': 0, 'errors': []}\n\n    for _, company_info in companies.iterrows():\n        try:\n            test_func(company_info)\n            results['passed'] += 1\n        except Exception as e:\n            results['failed'] += 1\n            results['errors'].append(f\"{company_info['ticker']}: {str(e)[:50]}\")\n\n            # Stop if too many failures\n            if results['failed'] &gt;= max_failures:\n                break\n\n    return results\n</code></pre>"},{"location":"company-group-testing/#4-document-group-characteristics","title":"4. Document Group Characteristics","text":"<pre><code>def analyze_group_characteristics(companies):\n    \"\"\"Analyze the characteristics of a company group.\"\"\"\n    print(f\"Group Analysis ({len(companies)} companies):\")\n    print(f\"  Exchanges: {companies['exchange'].value_counts().to_dict()}\")\n    print(f\"  Name lengths: {companies['name'].str.len().describe()}\")\n\n    # Can help understand why certain tests pass/fail\n    return companies.describe()\n</code></pre>"},{"location":"company-group-testing/#real-world-examples","title":"Real-World Examples","text":""},{"location":"company-group-testing/#example-1-feat-411-validation","title":"Example 1: FEAT-411 Validation","text":"<p>The standardized financial concepts feature was validated using this framework:</p> <pre><code>def validate_feat_411():\n    \"\"\"Complete validation of FEAT-411 standardized concepts.\"\"\"\n\n    test_groups = [\n        (\"FAANG\", get_faang_companies(), 0),        # Should be 100%\n        (\"Tech Giants\", get_tech_giants().head(10), 1),  # Allow 1 failure\n        (\"Mega Cap\", get_popular_companies(PopularityTier.MEGA_CAP), 1),\n        (\"Diverse\", CompanySubset().from_popular().sample(25).get(), 5)\n    ]\n\n    overall_success = True\n\n    for group_name, companies, max_failures in test_groups:\n        passed = test_standardized_concepts_on_group(companies, max_failures)\n        success_rate = (passed / len(companies)) * 100\n\n        min_rate = 100 if max_failures == 0 else 80\n        if success_rate &lt; min_rate:\n            print(f\"\u274c {group_name} failed: {success_rate:.1f}% &lt; {min_rate}%\")\n            overall_success = False\n        else:\n            print(f\"\u2705 {group_name} passed: {success_rate:.1f}%\")\n\n    return overall_success\n</code></pre>"},{"location":"company-group-testing/#example-2-cross-exchange-compatibility","title":"Example 2: Cross-Exchange Compatibility","text":"<pre><code>def test_cross_exchange_compatibility():\n    \"\"\"Test feature compatibility across different exchanges.\"\"\"\n\n    exchanges = ['NYSE', 'Nasdaq', 'OTC']\n    results = {}\n\n    for exchange in exchanges:\n        companies = (CompanySubset()\n                    .from_exchange(exchange)\n                    .sample(20, random_state=42)\n                    .get())\n\n        passed = 0\n        for _, company_info in companies.iterrows():\n            try:\n                # Test your feature here\n                company = Company(company_info['ticker'])\n                facts = company.get_facts()\n\n                if facts.get_revenue() is not None:\n                    passed += 1\n            except:\n                continue\n\n        success_rate = (passed / len(companies)) * 100\n        results[exchange] = success_rate\n        print(f\"{exchange}: {passed}/{len(companies)} ({success_rate:.1f}%)\")\n\n    return results\n</code></pre>"},{"location":"company-group-testing/#conclusion","title":"Conclusion","text":"<p>The Company Group Testing framework transforms feature validation from ad-hoc testing to systematic, quantified validation across representative company samples. By leveraging the existing company-subsets infrastructure, it provides:</p> <ul> <li>Comprehensive coverage across company types and characteristics</li> <li>Quantified success metrics for feature robustness assessment</li> <li>Maintainable test code using existing, well-tested infrastructure</li> <li>Flexible customization for specific testing scenarios</li> </ul> <p>This approach ensures EdgarTools features work reliably across the diverse landscape of SEC filers, from mega-cap tech companies to small regional businesses.</p>"},{"location":"company-subsets/","title":"Company Subsets","text":"<p>The <code>edgar.reference.company_subsets</code> module provides powerful and flexible tools for creating subsets of companies from SEC reference data. This is especially useful for research, analysis, educational purposes, and machine learning tasks where you need specific groups of companies.</p>"},{"location":"company-subsets/#key-features","title":"Key Features","text":"<ul> <li>Exchange-based selection: Filter by NYSE, NASDAQ, OTC, CBOE</li> <li>Popularity-based selection: Get popular stocks, mega-cap companies, etc.</li> <li>Sampling capabilities: Random sampling, stratified sampling, top N selection</li> <li>Filtering and combination utilities: Include/exclude specific companies, combine sets</li> <li>Fluent interface: Chain operations for readable, flexible subset creation</li> <li>Consistent output: All functions return standardized DataFrames with <code>['cik', 'ticker', 'name', 'exchange']</code> columns</li> </ul>"},{"location":"company-subsets/#quick-start","title":"Quick Start","text":"<pre><code>from edgar.reference.company_subsets import (\n    CompanySubset, \n    get_companies_by_exchanges,\n    get_popular_companies,\n    get_random_sample\n)\n\n# Simple exchange-based selection\nnyse_companies = get_companies_by_exchanges('NYSE')\nprint(f\"Found {len(nyse_companies)} NYSE companies\")\n\n# Get popular companies\npopular = get_popular_companies()\nprint(f\"Found {len(popular)} popular companies\")\n\n# Random sampling\nrandom_100 = get_random_sample(n=100, random_state=42)\nprint(f\"Sampled {len(random_100)} random companies\")\n</code></pre>"},{"location":"company-subsets/#fluent-interface-with-companysubset","title":"Fluent Interface with CompanySubset","text":"<p>The <code>CompanySubset</code> class provides a powerful fluent interface for building complex company selections:</p> <pre><code>from edgar.reference.company_subsets import CompanySubset, PopularityTier\n\n# Complex selection with method chaining\ncompanies = (CompanySubset()\n             .from_exchange(['NYSE', 'Nasdaq'])        # Major exchanges only\n             .exclude_tickers(['JPM', 'GS', 'C'])      # Exclude some financials\n             .sample(50, random_state=42)              # Take random sample\n             .get())                                   # Get the DataFrame\n\nprint(f\"Selected {len(companies)} companies\")\nprint(companies.head())\n\n# Popular tech companies\ntech_subset = (CompanySubset()\n               .from_popular(PopularityTier.POPULAR)   # Popular companies\n               .filter_by(lambda df: df['name'].str.contains('tech|software|computer', case=False))\n               .top(20, by='ticker')                   # Top 20 alphabetically\n               .get())\n</code></pre>"},{"location":"company-subsets/#core-functions","title":"Core Functions","text":""},{"location":"company-subsets/#exchange-based-selection","title":"Exchange-Based Selection","text":"<p>Filter companies by stock exchange:</p> <pre><code>from edgar.reference.company_subsets import get_companies_by_exchanges\n\n# Single exchange\nnyse_companies = get_companies_by_exchanges('NYSE')\nnasdaq_companies = get_companies_by_exchanges('Nasdaq')\n\n# Multiple exchanges\nmajor_exchanges = get_companies_by_exchanges(['NYSE', 'Nasdaq'])\nall_exchanges = get_companies_by_exchanges(['NYSE', 'Nasdaq', 'OTC', 'CBOE'])\n\nprint(f\"NYSE: {len(nyse_companies)} companies\")\nprint(f\"NASDAQ: {len(nasdaq_companies)} companies\") \nprint(f\"Major exchanges: {len(major_exchanges)} companies\")\n</code></pre>"},{"location":"company-subsets/#popular-companies","title":"Popular Companies","text":"<p>Access curated lists of popular and well-known companies:</p> <pre><code>from edgar.reference.company_subsets import get_popular_companies, PopularityTier\n\n# All popular companies\nall_popular = get_popular_companies()\n\n# By popularity tier\nmega_cap = get_popular_companies(PopularityTier.MEGA_CAP)      # Top 10\npopular = get_popular_companies(PopularityTier.POPULAR)        # Top 50\nmainstream = get_popular_companies(PopularityTier.MAINSTREAM)  # Top 100\nemerging = get_popular_companies(PopularityTier.EMERGING)      # All available\n\nprint(f\"Mega cap: {len(mega_cap)} companies\")\nprint(f\"Popular: {len(popular)} companies\")\nprint(f\"All popular: {len(all_popular)} companies\")\n</code></pre>"},{"location":"company-subsets/#sampling-methods","title":"Sampling Methods","text":"<p>Create representative samples from larger datasets:</p> <pre><code>from edgar.reference.company_subsets import (\n    get_random_sample, \n    get_stratified_sample,\n    get_top_companies_by_metric\n)\n\n# Random sampling\nrandom_sample = get_random_sample(n=200, random_state=42)\n\n# Stratified sampling (maintains exchange proportions)\nstratified_sample = get_stratified_sample(\n    n=100, \n    stratify_by='exchange', \n    random_state=42\n)\n\n# Top companies by name (alphabetical)\ntop_alphabetical = get_top_companies_by_metric(\n    n=50, \n    metric='name', \n    ascending=True\n)\n\n# Sample from a specific subset\nnyse_random = get_random_sample(\n    get_companies_by_exchanges('NYSE'), \n    n=100, \n    random_state=42\n)\n</code></pre>"},{"location":"company-subsets/#filtering-and-combining","title":"Filtering and Combining","text":""},{"location":"company-subsets/#includeexclude-specific-companies","title":"Include/Exclude Specific Companies","text":"<pre><code>from edgar.reference.company_subsets import filter_companies, exclude_companies\n\nall_companies = get_all_companies()\n\n# Include specific tickers (FAANG companies)\nfaang = filter_companies(\n    all_companies,\n    ticker_list=['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL']\n)\n\n# Include companies with names containing specific text\ntech_companies = filter_companies(\n    all_companies,\n    name_contains='Technology'\n)\n\n# Include specific CIKs\nspecific_companies = filter_companies(\n    all_companies,\n    cik_list=[320193, 1018724, 1652044]  # AAPL, AMZN, GOOGL\n)\n\n# Exclude financial companies (simplified example)\nnon_financial = exclude_companies(\n    all_companies,\n    ticker_list=['JPM', 'GS', 'C', 'BAC', 'WFC']\n)\n\n# Exclude companies with 'Corp' in name  \nnon_corp = exclude_companies(\n    all_companies,\n    name_contains='Corp'\n)\n</code></pre>"},{"location":"company-subsets/#custom-filtering","title":"Custom Filtering","text":"<p>Apply custom filtering logic:</p> <pre><code>from edgar.reference.company_subsets import filter_companies\n\n# Custom filter function\ndef large_company_filter(df):\n    \"\"\"Filter to companies with longer names (proxy for larger companies).\"\"\"\n    return df[df['name'].str.len() &gt; 20]\n\n# Apply custom filter\nlarge_companies = filter_companies(\n    get_companies_by_exchanges('NYSE'),\n    custom_filter=large_company_filter\n)\n\n# Using lambda for simple filters\nshort_tickers = filter_companies(\n    get_popular_companies(),\n    custom_filter=lambda df: df[df['ticker'].str.len() &lt;= 4]\n)\n</code></pre>"},{"location":"company-subsets/#combining-and-intersecting-sets","title":"Combining and Intersecting Sets","text":"<pre><code>from edgar.reference.company_subsets import combine_company_sets, intersect_company_sets\n\n# Get different company sets\nnyse_companies = get_companies_by_exchanges('NYSE')\npopular_companies = get_popular_companies()\ntech_companies = filter_companies(get_all_companies(), name_contains='Tech')\n\n# Union: Combine multiple sets (removes duplicates)\ncombined = combine_company_sets([nyse_companies, popular_companies, tech_companies])\n\n# Intersection: Find companies present in all sets\nnyse_popular = intersect_company_sets([nyse_companies, popular_companies])\npopular_tech = intersect_company_sets([popular_companies, tech_companies])\n\nprint(f\"Combined: {len(combined)} companies\")\nprint(f\"NYSE + Popular intersection: {len(nyse_popular)} companies\")\nprint(f\"Popular + Tech intersection: {len(popular_tech)} companies\")\n</code></pre>"},{"location":"company-subsets/#convenience-functions","title":"Convenience Functions","text":"<p>Pre-defined functions for common company groupings:</p> <pre><code>from edgar.reference.company_subsets import (\n    get_faang_companies,\n    get_tech_giants, \n    get_dow_jones_sample\n)\n\n# FAANG companies (Meta, Apple, Amazon, Netflix, Google)\nfaang = get_faang_companies()\n\n# Major tech companies\ntech_giants = get_tech_giants()\n\n# Dow Jones Industrial Average sample\ndow_sample = get_dow_jones_sample()\n\nprint(f\"FAANG: {len(faang)} companies\")\nprint(f\"Tech Giants: {len(tech_giants)} companies\") \nprint(f\"Dow Sample: {len(dow_sample)} companies\")\n\n# Display the companies\nprint(\"\\nFAANG Companies:\")\nfor _, company in faang.iterrows():\n    print(f\"  {company['ticker']}: {company['name']}\")\n</code></pre>"},{"location":"company-subsets/#advanced-examples","title":"Advanced Examples","text":""},{"location":"company-subsets/#research-dataset-creation","title":"Research Dataset Creation","text":"<p>Create a balanced research dataset:</p> <pre><code>from edgar.reference.company_subsets import CompanySubset, PopularityTier\n\n# Create a research dataset with companies from different tiers\nresearch_dataset = []\n\n# Get 20 mega-cap companies\nmega_cap = (CompanySubset()\n           .from_popular(PopularityTier.MEGA_CAP)\n           .sample(20, random_state=42)\n           .get())\n\n# Get 30 popular mid-tier companies  \nmid_tier = (CompanySubset()\n           .from_popular(PopularityTier.POPULAR)\n           .exclude_tickers(mega_cap['ticker'].tolist())  # Don't overlap\n           .sample(30, random_state=42)\n           .get())\n\n# Get 50 random companies from major exchanges\nrandom_companies = (CompanySubset()\n                    .from_exchange(['NYSE', 'Nasdaq'])\n                    .exclude_tickers(mega_cap['ticker'].tolist() + mid_tier['ticker'].tolist())\n                    .sample(50, random_state=42)\n                    .get())\n\n# Combine all for final research set\nresearch_companies = combine_company_sets([mega_cap, mid_tier, random_companies])\nprint(f\"Research dataset: {len(research_companies)} companies\")\n\n# Analyze composition\nexchange_dist = research_companies['exchange'].value_counts()\nprint(\"\\nExchange distribution:\")\nprint(exchange_dist)\n</code></pre>"},{"location":"company-subsets/#sector-based-analysis","title":"Sector-Based Analysis","text":"<p>Create industry-focused subsets:</p> <pre><code># Create sector-based subsets (simplified approach using name patterns)\nsectors = {\n    'technology': ['tech', 'software', 'computer', 'digital'],\n    'financial': ['bank', 'financial', 'insurance', 'capital'],\n    'healthcare': ['health', 'medical', 'pharma', 'bio'],\n    'energy': ['energy', 'oil', 'gas', 'power'],\n    'retail': ['retail', 'store', 'market', 'shop']\n}\n\nsector_companies = {}\nall_companies = get_companies_by_exchanges(['NYSE', 'Nasdaq'])\n\nfor sector, keywords in sectors.items():\n    # Create pattern for all keywords\n    pattern = '|'.join(keywords)\n\n    sector_subset = filter_companies(\n        all_companies,\n        custom_filter=lambda df, p=pattern: df[df['name'].str.contains(p, case=False)]\n    )\n\n    sector_companies[sector] = sector_subset\n    print(f\"{sector.title()}: {len(sector_subset)} companies\")\n\n# Get top 10 from each sector for analysis\nanalysis_set = []\nfor sector, companies in sector_companies.items():\n    top_10 = get_top_companies_by_metric(companies, n=10, metric='ticker')\n    analysis_set.append(top_10)\n\nfinal_analysis_set = combine_company_sets(analysis_set)\nprint(f\"\\nFinal analysis set: {len(final_analysis_set)} companies across sectors\")\n</code></pre>"},{"location":"company-subsets/#machine-learning-dataset-preparation","title":"Machine Learning Dataset Preparation","text":"<p>Prepare balanced datasets for ML training:</p> <pre><code>from edgar.reference.company_subsets import get_stratified_sample\n\n# Create training/test split with stratification\nall_popular = get_popular_companies()\n\n# Training set (70% of data, stratified by exchange)\ntraining_companies = get_stratified_sample(\n    all_popular,\n    n=int(len(all_popular) * 0.7),\n    stratify_by='exchange',\n    random_state=42\n)\n\n# Test set (remaining companies)  \ntest_companies = all_popular[~all_popular['cik'].isin(training_companies['cik'])]\n\nprint(f\"Training set: {len(training_companies)} companies\")\nprint(f\"Test set: {len(test_companies)} companies\")\n\n# Verify stratification worked\nprint(\"\\nTraining exchange distribution:\")\nprint(training_companies['exchange'].value_counts(normalize=True))\n\nprint(\"\\nTest exchange distribution:\")  \nprint(test_companies['exchange'].value_counts(normalize=True))\n</code></pre>"},{"location":"company-subsets/#data-structure","title":"Data Structure","text":"<p>All functions return a standardized pandas DataFrame with these columns:</p> <ul> <li><code>cik</code> (int): SEC Central Index Key - unique company identifier</li> <li><code>ticker</code> (str): Stock ticker symbol (e.g., 'AAPL', 'MSFT')  </li> <li><code>name</code> (str): Official company name</li> <li><code>exchange</code> (str): Stock exchange ('NYSE', 'Nasdaq', 'OTC', 'CBOE', etc.)</li> </ul> <pre><code># Example output structure\ncompanies = get_random_sample(5)\nprint(companies)\n\n#        cik ticker                     name exchange\n# 0   320193   AAPL             Apple Inc.   Nasdaq\n# 1  1018724   AMZN        Amazon.com, Inc.   Nasdaq  \n# 2  1652044  GOOGL          Alphabet Inc.   Nasdaq\n# 3   789019   MSFT  Microsoft Corporation   Nasdaq\n# 4  1326801   META     Meta Platforms, Inc   Nasdaq\n</code></pre>"},{"location":"company-subsets/#error-handling","title":"Error Handling","text":"<p>The module includes robust error handling and logging:</p> <pre><code># Functions gracefully handle errors and return empty DataFrames\nempty_result = get_companies_by_exchanges('INVALID_EXCHANGE')\nprint(f\"Invalid exchange result: {len(empty_result)} companies\")\n\n# Check for empty results\ncompanies = get_random_sample(n=10)\nif companies.empty:\n    print(\"No companies found\")\nelse:\n    print(f\"Found {len(companies)} companies\")\n\n# All functions include logging for debugging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Now function calls will show debug information\ncompanies = get_popular_companies()\n</code></pre>"},{"location":"company-subsets/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Caching: <code>get_all_companies()</code> uses LRU cache for performance</li> <li>Lazy evaluation: CompanySubset operations are efficient and don't duplicate data unnecessarily</li> <li>Memory efficient: Functions work with DataFrame views when possible</li> <li>Batch operations: Use combine/intersect functions instead of loops for better performance</li> </ul> <pre><code># Efficient: Use batch operations\ncompany_sets = [\n    get_companies_by_exchanges('NYSE'),\n    get_companies_by_exchanges('Nasdaq'),\n    get_popular_companies()\n]\ncombined = combine_company_sets(company_sets)\n\n# Less efficient: Multiple individual operations in loops\n# combined = pd.DataFrame()\n# for exchange in ['NYSE', 'Nasdaq']:\n#     exchange_companies = get_companies_by_exchanges(exchange)\n#     combined = pd.concat([combined, exchange_companies])  # Avoid this pattern\n</code></pre>"},{"location":"company-subsets/#integration-with-edgar-tools","title":"Integration with Edgar Tools","text":"<p>Company subsets integrate seamlessly with other Edgar tools:</p> <pre><code>from edgar import Company\nfrom edgar.reference.company_subsets import get_tech_giants\n\n# Get tech companies and analyze their latest filings\ntech_companies = get_tech_giants()\n\nfor _, company_info in tech_companies.head(5).iterrows():\n    try:\n        company = Company(company_info['ticker'])\n        latest_filing = company.get_filings(form='10-K').latest()\n        print(f\"{company_info['ticker']}: Latest 10-K filed {latest_filing.filing_date}\")\n    except:\n        print(f\"{company_info['ticker']}: No recent 10-K found\")\n</code></pre>"},{"location":"company-subsets/#best-practices","title":"Best Practices","text":"<ol> <li>Use appropriate sample sizes: Don't sample more companies than you need for analysis</li> <li>Set random seeds: Use <code>random_state</code> parameter for reproducible results  </li> <li>Handle empty results: Always check if returned DataFrames are empty</li> <li>Combine operations efficiently: Use method chaining with CompanySubset for readable code</li> <li>Cache results: Store company subsets if you'll reuse them multiple times</li> <li>Validate data: Check that your filters return expected results</li> </ol> <pre><code># Good: Reproducible and efficient\ncompanies = (CompanySubset()\n            .from_exchange('NYSE') \n            .sample(100, random_state=42)\n            .get())\n\n# Store for reuse\ncached_companies = companies.copy()\n\n# Good: Check for empty results\nif not companies.empty:\n    print(f\"Analysis ready with {len(companies)} companies\")\nelse:\n    print(\"No companies found matching criteria\")\n</code></pre> <p>This module provides a comprehensive toolkit for creating company subsets tailored to your specific research, analysis, or educational needs. The combination of simple functions and the powerful fluent interface makes it easy to create both simple selections and complex, multi-criteria company datasets.</p>"},{"location":"company/","title":"Company API","text":"<p>With the company API you find a company using the cik or ticker.  From the company you can access all their historical filings, and a dataset of the company facts. The SEC's company API also supplies a lot more details about a company including industry, the SEC filer type, the mailing and business address and much more.</p>"},{"location":"company/#find-by-ticker","title":"Find by Ticker","text":"<pre><code>c = Company(\"AAPL\")\n</code></pre> <p>Tickers are case-insensitive so you can use <code>Company(\"aapl\")</code> or <code>Company(\"AAPL\")</code></p>"},{"location":"company/#find-by-cik","title":"Find by CIK","text":"<p>The cik uniquely identifies a company or entity at the SEC.</p> <pre><code>c = Company(320193)\n</code></pre> <p>CIKS can also be strings which may or may not be zero padded to 10 places.</p> <pre><code>c = Company(\"0000320193\") \n# OR \nc = Company(\"320193\")\n</code></pre>"},{"location":"company/#find-a-company-using-the-cik","title":"Find a company using the cik","text":"<p>The cik is the id that uniquely identifies a company at the SEC. It is a number, but is sometimes shown in SEC Edgar resources as a string padded with leading zero's. For the edgar client API, just use the numbers and omit the leading zeroes.</p> <pre><code>company = Company(1318605)\n</code></pre> <p></p>"},{"location":"company/#find-a-company-using-ticker","title":"Find a company using ticker","text":"<p>You can get a company using a ticker e.g. SNOW. This will do a lookup for the company cik using the ticker, then load the company using the cik. This makes it two calls versus one for the cik company lookup, but is sometimes more convenient since tickers are easier to remember that ciks.</p> <p>Note that some companies have multiple tickers, so you technically cannot get SEC filings for a ticker. You instead get the SEC filings for the company to which the ticker belongs.</p> <p>The ticker is case-insensitive so you can use <code>Company(\"snow\")</code> or <code>Company(\"SNOW\")</code></p> <pre><code>snow = Company(\"snow\")\n</code></pre> <p></p> <pre><code>Company(1832950)\n</code></pre>"},{"location":"company/#get-filings-for-a-company","title":"Get filings for a company","text":"<p>To get the company's filings use <code>get_filings()</code>. This gets all the company's filings that are available from the Edgar submissions endpoint.</p> <pre><code>company.get_filings()\n</code></pre>"},{"location":"company/#filtering-filings","title":"Filtering filings","text":"<p>You can filter the company filings using a number of different parameters.</p> <pre><code>class CompanyFilings:\n\n    ...\n\n    def get_filings(self,\n                    *,\n                    form: str | List = None,\n                    accession_number: str | List = None,\n                    file_number: str | List = None,\n                    is_xbrl: bool = None,\n                    is_inline_xbrl: bool = None\n                    ):\n        \"\"\"\n        Get the company's filings and optionally filter by multiple criteria\n        :param form: The form as a string e.g. '10-K' or List of strings ['10-Q', '10-K']\n        :param accession_number: The accession number that uniquely identifies an SEC filing e.g. 0001640147-22-000100\n        :param file_number: The file number e.g. 001-39504\n        :param is_xbrl: Whether the filing is xbrl\n        :param is_inline_xbrl: Whether the filing is inline_xbrl\n        :return: The CompanyFiling instance with the filings that match the filters\n        \"\"\"\n</code></pre>"},{"location":"company/#the-companyfilings-class","title":"The CompanyFilings class","text":"<p>The result of <code>get_filings()</code> is a <code>CompanyFilings</code> class. This class contains a pyarrow table with the filings and provides convenient functions for working with filings. You can access the underlying pyarrow <code>Table</code> using the <code>.data</code> property</p> <pre><code>filings = company.get_filings()\n\n# Get the underlying Table\ndata: pa.Table = filings.data\n</code></pre>"},{"location":"company/#get-a-filing-by-index","title":"Get a filing by index","text":"<p>To access a filing in the CompanyFilings use the bracket <code>[]</code> notation e.g. <code>filings[2]</code></p> <pre><code>filings[2]\n</code></pre>"},{"location":"company/#get-the-latest-filing","title":"Get the latest filing","text":"<p>The <code>CompanyFilings</code> class has a <code>latest</code> function that will return the latest <code>Filing</code>.  So, to get the latest 10-Q filing, you do the following</p> <pre><code># Latest filing makes sense if you filter by form  type e.g. 10-Q\nsnow_10Qs = snow.get_filings(form='10-Q')\nlatest_10Q = snow_10Qs.latest()\n\n# Or chain the function calls\nsnow.get_filings(form='10-Q').latest()\n</code></pre>"},{"location":"company/#get-company-facts","title":"Get company facts","text":"<p>Facts are an interesting and important dataset about a company accumlated from data the company provides to the SEC. Company facts are available for a company on the Company Facts<code>f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik:010}.json\"</code> It is a JSON endpoint and <code>edgartools</code> parses the JSON into a structured dataset - a <code>pyarrow.Table</code>.</p>"},{"location":"company/#getting-facts-for-a-company","title":"Getting facts for a company","text":"<p>To get company facts, first get the company, then call <code>company.get_facts()</code></p> <pre><code>company = Company(\"SNOW\")\ncompany_facts = company.get_facts_for_namespace()\n</code></pre> <p>The result is a <code>CompanyFacts</code> object which wraps the underlying facts and provides convenient ways of working with the facts data. To get access to the underyling data use the <code>facts</code> property.</p> <p>You can get the facts as a pandas dataframe by calling <code>to_pandas</code></p> <pre><code>df = company_facts.to_pandas()\n</code></pre> <p>Facts differ among companies. To see what facts are available you can use the <code>facts_meta</code> property.</p>"},{"location":"concept-level-standardization-plan/","title":"Plan for Concept-Level Standardization in EdgarTools","text":""},{"location":"concept-level-standardization-plan/#current-state-analysis","title":"Current State Analysis","text":"<p>EdgarTools already has sophisticated standardization infrastructure:</p> <ol> <li>XBRL Standardization Package (<code>edgar.xbrl.standardization</code>):</li> <li><code>StandardConcept</code> enum with 100+ predefined concepts</li> <li><code>ConceptMapper</code> with ML-based inference (similarity matching)</li> <li><code>MappingStore</code> with 352 lines of concept mappings</li> <li>Company-specific mapping support</li> <li> <p>Automatic learning from filing patterns</p> </li> <li> <p>Facts API Integration (<code>edgar.entity.entity_facts</code>):</p> </li> <li>Raw SEC CompanyFacts API data</li> <li>Unit standardization (<code>_clean_unit()</code>)</li> <li> <p>No concept standardization currently</p> </li> <li> <p>Financials Module (<code>edgar.financials</code>):</p> </li> <li>Uses <code>_get_standardized_concept_value()</code> </li> <li>Pattern-based label matching for key metrics</li> <li>Limited to specific financial ratios</li> </ol>"},{"location":"concept-level-standardization-plan/#gap-analysis","title":"Gap Analysis","text":"<p>\u2705 What Works Well: - XBRL package has comprehensive concept standardization - Company-specific mappings with priority system - ML-based concept inference with confidence scoring - Extensive mapping database (352 lines)</p> <p>\u274c What's Missing: - Facts API doesn't use XBRL standardization - No unified standardization across data sources - Limited integration between packages - No user-facing standardization controls</p>"},{"location":"concept-level-standardization-plan/#proposed-implementation-plan","title":"Proposed Implementation Plan","text":""},{"location":"concept-level-standardization-plan/#phase-1-bridge-xbrl-standardization-to-facts-api","title":"Phase 1: Bridge XBRL Standardization to Facts API","text":"<p>1.1 Enhance EntityFacts with Standardization</p> <pre><code># edgar/entity/entity_facts.py - Add standardization support\nclass EntityFacts:\n    def __init__(self, cik: int, name: str, facts: List[FinancialFact], enable_standardization: bool = True):\n        self._standardization_enabled = enable_standardization\n        if enable_standardization:\n            from edgar.xbrl.standardization import initialize_default_mappings, ConceptMapper\n            self._mapping_store = initialize_default_mappings()\n            self._concept_mapper = ConceptMapper(self._mapping_store)\n\n    def get_standardized_fact(self, standard_concept: str, period: Optional[str] = None) -&gt; Optional[FinancialFact]:\n        \"\"\"Get fact using standardized concept names.\"\"\"\n        if not self._standardization_enabled:\n            return self.get_fact(standard_concept, period)\n\n        # Map standard concept to company concepts\n        company_concepts = self._mapping_store.get_company_concepts(standard_concept)\n\n        for concept in company_concepts:\n            fact = self.get_fact(concept, period)\n            if fact:\n                # Create standardized copy\n                std_fact = fact.copy()\n                std_fact.concept = standard_concept\n                std_fact.label = standard_concept\n                return std_fact\n\n        return None\n</code></pre> <p>1.2 Add Standardized Query Interface</p> <pre><code># edgar/entity/query.py - Enhance FactQuery\nclass FactQuery:\n    def by_standard_concept(self, standard_concept: str, exact: bool = True) -&gt; 'FactQuery':\n        \"\"\"Filter by standardized concept name.\"\"\"\n        if hasattr(self._entity_facts, '_concept_mapper'):\n            # Get all company concepts that map to this standard concept\n            company_concepts = self._entity_facts._mapping_store.get_company_concepts(standard_concept)\n            # Filter by any of these concepts\n            return self.by_concept_list(list(company_concepts), exact=exact)\n        else:\n            # Fallback to direct concept matching\n            return self.by_concept(standard_concept, exact=exact)\n</code></pre>"},{"location":"concept-level-standardization-plan/#phase-2-unified-standardization-configuration","title":"Phase 2: Unified Standardization Configuration","text":"<p>2.1 Global Standardization Settings</p> <pre><code># edgar/core.py - Add standardization controls\n_standardization_enabled = True\n_standardization_mode = \"aggressive\"  # \"conservative\", \"aggressive\", \"strict\"\n\ndef enable_standardization(mode: str = \"aggressive\"):\n    \"\"\"Enable concept standardization globally.\"\"\"\n    global _standardization_enabled, _standardization_mode\n    _standardization_enabled = True\n    _standardization_mode = mode\n\ndef disable_standardization():\n    \"\"\"Disable concept standardization globally.\"\"\"\n    global _standardization_enabled\n    _standardization_enabled = False\n\ndef get_standardization_config():\n    return {\n        'enabled': _standardization_enabled,\n        'mode': _standardization_mode\n    }\n</code></pre> <p>2.2 Enhanced Concept Mapping</p> <pre><code># edgar/xbrl/standardization/core.py - Extend mapping capabilities\nclass ConceptMapper:\n    def get_all_standard_concepts_for_company(self, cik: int) -&gt; Dict[str, List[str]]:\n        \"\"\"Get all standardized concepts available for a specific company.\"\"\"\n        # Analyze company's actual concepts and return mappings\n\n    def suggest_mappings(self, unknown_concepts: List[str], context: Dict = None) -&gt; Dict[str, List[Tuple[str, float]]]:\n        \"\"\"Suggest standard concept mappings for unknown concepts.\"\"\"\n        # ML-based suggestions with confidence scores\n\n    def validate_mapping_quality(self, cik: int) -&gt; Dict[str, Any]:\n        \"\"\"Assess mapping quality and coverage for a company.\"\"\"\n        # Return coverage stats, confidence scores, missing concepts\n</code></pre>"},{"location":"concept-level-standardization-plan/#phase-3-user-facing-standardization-api","title":"Phase 3: User-Facing Standardization API","text":"<p>3.1 Standardized Facts Interface</p> <pre><code># edgar/standardization/__init__.py - New top-level module\nfrom edgar.xbrl.standardization import StandardConcept, ConceptMapper, MappingStore\n\nclass StandardizedEntityFacts:\n    \"\"\"Wrapper for EntityFacts with standardization as first-class feature.\"\"\"\n\n    def __init__(self, entity_facts: EntityFacts):\n        self.raw_facts = entity_facts\n        self._mapper = ConceptMapper(initialize_default_mappings())\n\n    def revenue(self, period: str = None) -&gt; Optional[FinancialFact]:\n        \"\"\"Get revenue using standardized concept mapping.\"\"\"\n        return self.get_fact(StandardConcept.REVENUE, period)\n\n    def net_income(self, period: str = None) -&gt; Optional[FinancialFact]:\n        \"\"\"Get net income using standardized concept mapping.\"\"\"\n        return self.get_fact(StandardConcept.NET_INCOME, period)\n\n    def get_fact(self, standard_concept: StandardConcept, period: str = None) -&gt; Optional[FinancialFact]:\n        \"\"\"Get fact by standard concept enum.\"\"\"\n        return self.raw_facts.get_standardized_fact(standard_concept.value, period)\n\n    def available_concepts(self) -&gt; List[StandardConcept]:\n        \"\"\"Get all standard concepts available for this company.\"\"\"\n        # Return intersection of company concepts and standard mappings\n</code></pre> <p>3.2 Comparison-Friendly Interface</p> <pre><code># Cross-company standardized comparison\ndef compare_companies(tickers: List[str], concepts: List[StandardConcept], periods: int = 4) -&gt; pd.DataFrame:\n    \"\"\"Compare standardized concepts across multiple companies.\"\"\"\n    data = []\n    for ticker in tickers:\n        company = Company(ticker)\n        std_facts = StandardizedEntityFacts(company.facts)\n\n        for concept in concepts:\n            for i in range(periods):\n                fact = std_facts.get_fact(concept, period_offset=i)\n                if fact:\n                    data.append({\n                        'company': ticker,\n                        'concept': concept.value,\n                        'period': f\"{fact.fiscal_year}-{fact.fiscal_period}\",\n                        'value': fact.numeric_value,\n                        'unit': fact.unit\n                    })\n\n    return pd.DataFrame(data).pivot_table(\n        index=['concept', 'period'],\n        columns='company',\n        values='value'\n    )\n</code></pre>"},{"location":"concept-level-standardization-plan/#phase-4-enhanced-learning-and-quality","title":"Phase 4: Enhanced Learning and Quality","text":"<p>4.1 Automated Concept Discovery</p> <pre><code># edgar/xbrl/standardization/learning.py\nclass ConceptLearner:\n    def discover_new_concepts(self, companies: List[str]) -&gt; Dict[str, List[str]]:\n        \"\"\"Discover frequently used concepts not in standard mappings.\"\"\"\n\n    def validate_existing_mappings(self) -&gt; Dict[str, float]:\n        \"\"\"Validate mapping accuracy across sample companies.\"\"\"\n\n    def suggest_new_standard_concepts(self, threshold: float = 0.1) -&gt; List[str]:\n        \"\"\"Suggest new standard concepts based on usage frequency.\"\"\"\n</code></pre> <p>4.2 Quality Metrics</p> <pre><code># Standardization quality metrics\nclass StandardizationQuality:\n    def coverage_score(self, cik: int) -&gt; float:\n        \"\"\"Percentage of company concepts that have standard mappings.\"\"\"\n\n    def confidence_score(self, cik: int) -&gt; float:\n        \"\"\"Average confidence of applied mappings.\"\"\"\n\n    def consistency_score(self, concept: str, companies: List[int]) -&gt; float:\n        \"\"\"How consistently a concept is mapped across companies.\"\"\"\n</code></pre>"},{"location":"concept-level-standardization-plan/#integration-plan","title":"Integration Plan","text":""},{"location":"concept-level-standardization-plan/#step-1-minimal-integration-week-1","title":"Step 1: Minimal Integration (Week 1)","text":"<ul> <li>Add <code>enable_standardization=True</code> parameter to <code>EntityFacts</code></li> <li>Implement <code>get_standardized_fact()</code> method</li> <li>Basic testing with AAPL, MSFT, TSLA</li> </ul>"},{"location":"concept-level-standardization-plan/#step-2-enhanced-query-interface-week-2","title":"Step 2: Enhanced Query Interface (Week 2)","text":"<ul> <li>Extend <code>FactQuery</code> with <code>by_standard_concept()</code></li> <li>Add standardization to income/balance/cashflow statement methods</li> <li>Documentation and examples</li> </ul>"},{"location":"concept-level-standardization-plan/#step-3-user-facing-api-week-3","title":"Step 3: User-Facing API (Week 3)","text":"<ul> <li>Create <code>StandardizedEntityFacts</code> wrapper</li> <li>Implement cross-company comparison tools</li> <li>Add standardization controls to <code>edgar.core</code></li> </ul>"},{"location":"concept-level-standardization-plan/#step-4-advanced-features-week-4","title":"Step 4: Advanced Features (Week 4)","text":"<ul> <li>Learning pipeline integration</li> <li>Quality metrics and validation</li> <li>Performance optimization and caching</li> </ul>"},{"location":"concept-level-standardization-plan/#usage-examples","title":"Usage Examples","text":"<pre><code># Enable standardization globally\nimport edgar\nedgar.enable_standardization(mode=\"aggressive\")\n\n# Standard concept access\ncompany = edgar.Company(\"AAPL\")\nfacts = company.facts\n\n# Access by standard concept\nrevenue = facts.get_standardized_fact(\"Revenue\")\nnet_income = facts.get_standardized_fact(\"Net Income\")\n\n# Enhanced query with standardization\nrevenue_series = facts.query().by_standard_concept(\"Revenue\").latest(4).to_dataframe()\n\n# Cross-company comparison\ncomparison = edgar.compare_companies(\n    tickers=[\"AAPL\", \"MSFT\", \"GOOGL\"],\n    concepts=[StandardConcept.REVENUE, StandardConcept.NET_INCOME],\n    periods=4\n)\n\n# Quality assessment\nquality = edgar.assess_standardization_quality(\"AAPL\")\nprint(f\"Coverage: {quality['coverage']:.1%}\")\nprint(f\"Confidence: {quality['confidence']:.1%}\")\n</code></pre>"},{"location":"concept-level-standardization-plan/#benefits-of-this-approach","title":"Benefits of This Approach","text":"<ol> <li>Leverages Existing Infrastructure: Uses the comprehensive XBRL standardization already built</li> <li>Backward Compatible: Existing code continues to work unchanged</li> <li>Opt-in Standardization: Users can enable/disable as needed</li> <li>Cross-Package Integration: Unifies XBRL and Facts API standardization</li> <li>Extensible: Easy to add new standard concepts and mappings</li> <li>Quality-Focused: Built-in validation and confidence scoring</li> </ol> <p>This plan provides a pathway to bring EdgarTools' existing sophisticated standardization capabilities to the concept level while maintaining the library's core principles of simplicity and user-friendliness.</p>"},{"location":"concept-level-standardization-plan/#implementation-context","title":"Implementation Context","text":"<p>This plan was developed based on analysis of EdgarTools' existing standardization infrastructure:</p> <ul> <li>XBRL Package: Comprehensive <code>StandardConcept</code> enum, <code>ConceptMapper</code> with ML inference, extensive mapping database (352 lines)</li> <li>Facts API: Raw SEC data with unit standardization but no concept standardization</li> <li>Financials Module: Limited pattern-based label matching for key metrics</li> <li>Gap: No unified standardization across data sources or user-facing controls</li> </ul> <p>The proposed approach bridges these systems to provide concept-level standardization while maintaining EdgarTools' design principles.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>EdgarTools provides extensive configuration options through environment variables and programmatic settings to customize behavior, optimize performance, and ensure SEC compliance.</p>"},{"location":"configuration/#quick-setup","title":"Quick Setup","text":"<p>For most users, you only need to set your identity:</p> <pre><code>export EDGAR_IDENTITY=\"Your Name your.email@company.com\"\n</code></pre> <p>Or in Python:</p> <pre><code>from edgar import set_identity\nset_identity(\"Your Name your.email@company.com\")\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"configuration/#required-configuration","title":"Required Configuration","text":""},{"location":"configuration/#edgar_identity","title":"EDGAR_IDENTITY","text":"<p>Required for all SEC requests</p> <p>Sets the User-Agent string for SEC EDGAR requests. Required by SEC to identify your application.</p> <pre><code>export EDGAR_IDENTITY=\"John Doe john.doe@company.com\"\n</code></pre> <p>Format Options: - <code>\"Name email@domain.com\"</code> - Full name and email (recommended) - <code>\"email@domain.com\"</code> - Email only (acceptable) - <code>\"Company Name contact@company.com\"</code> - Company identification</p> <p>Python Alternative:</p> <pre><code>from edgar import set_identity\nset_identity(\"John Doe john.doe@company.com\")\n</code></pre>"},{"location":"configuration/#performance-and-access-control","title":"Performance and Access Control","text":""},{"location":"configuration/#edgar_access_mode","title":"EDGAR_ACCESS_MODE","text":"<p>Controls HTTP request behavior and connection limits to manage SEC server load.</p> <pre><code>export EDGAR_ACCESS_MODE=\"NORMAL\"\n</code></pre> <p>Available Modes:</p> Mode Timeout Max Connections Retries Use Case <code>NORMAL</code> 15s 10 3 Default - balanced performance <code>CAUTION</code> 20s 5 3 Conservative - reduces server load <code>CRAWL</code> 25s 2 2 Minimal impact - bulk processing <p>Examples:</p> <pre><code># High-performance research (default)\nexport EDGAR_ACCESS_MODE=\"NORMAL\"\n\n# Conservative access for production\nexport EDGAR_ACCESS_MODE=\"CAUTION\"\n\n# Bulk data processing with minimal server impact\nexport EDGAR_ACCESS_MODE=\"CRAWL\"\n</code></pre>"},{"location":"configuration/#local-data-storage","title":"Local Data Storage","text":""},{"location":"configuration/#edgar_use_local_data","title":"EDGAR_USE_LOCAL_DATA","text":"<p>Enables local caching of SEC data for improved performance and reduced API calls.</p> <pre><code>export EDGAR_USE_LOCAL_DATA=\"True\"\n</code></pre> <p>Values: - <code>\"True\"</code>, <code>\"true\"</code>, <code>\"1\"</code> - Enable local storage - <code>\"False\"</code>, <code>\"false\"</code>, <code>\"0\"</code> - Disable local storage (default)</p> <p>Benefits of Local Storage: - Faster repeated access to same data - Reduced SEC API calls - Offline access to cached data - Better performance for bulk operations</p> <p>Python Alternative:</p> <pre><code>from edgar import use_local_storage\nuse_local_storage(True)\n</code></pre>"},{"location":"configuration/#edgar_local_data_dir","title":"EDGAR_LOCAL_DATA_DIR","text":"<p>Sets the directory for local data storage.</p> <pre><code>export EDGAR_LOCAL_DATA_DIR=\"/path/to/your/edgar/data\"\n</code></pre> <p>Default: <code>~/.edgar</code> (user's home directory)</p> <p>Directory Structure:</p> <pre><code>~/.edgar/                    # Root data directory\n\u251c\u2500\u2500 requestcache/            # HTTP response cache\n\u251c\u2500\u2500 filings/                 # Downloaded filing data\n\u2502   \u2514\u2500\u2500 YYYYMMDD/            # Organized by date\n\u251c\u2500\u2500 submissions/             # Company submissions data\n\u251c\u2500\u2500 companyfacts/            # Company facts data\n\u2514\u2500\u2500 reference/               # Reference data (tickers, etc.)\n</code></pre> <p>Example Setup:</p> <pre><code># Custom data directory for project\nexport EDGAR_LOCAL_DATA_DIR=\"/project/edgar_data\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\n</code></pre>"},{"location":"configuration/#security-and-ssl","title":"Security and SSL","text":""},{"location":"configuration/#edgar_verify_ssl","title":"EDGAR_VERIFY_SSL","text":"<p>Controls SSL certificate verification for HTTPS requests.</p> <pre><code>export EDGAR_VERIFY_SSL=\"true\"\n</code></pre> <p>Values: - <code>\"true\"</code> (default) - Verify SSL certificates (recommended) - <code>\"false\"</code>, <code>\"0\"</code>, <code>\"no\"</code>, <code>\"n\"</code>, <code>\"off\"</code> - Disable SSL verification</p> <p>\u26a0\ufe0f Security Warning: Only disable SSL verification in controlled environments. This reduces security by allowing man-in-the-middle attacks.</p> <p>Use Cases for Disabling: - Corporate proxy environments with custom certificates - Development environments with self-signed certificates - Network environments with SSL inspection</p>"},{"location":"configuration/#http-rate-limiting","title":"HTTP Rate Limiting","text":"<p>Rate limiting is implemented in <code>httpclient_ratelimiting</code>. </p> <p>The default rate limit is 9 requests per second. SEC has a maximum of 10 requests per second. To change the rate limit, call: <code>httpclient.update_rate_limiter(requests_per_second: int)</code>.</p>"},{"location":"configuration/#advanced-distributed-rate-limiting","title":"Advanced: Distributed Rate Limiting","text":"<p>Distributed Rate Limiting: rate limiting is implemented using pyrate_limiter. To use a distributed rate limiter, such as for multiprocessing, define an httpclient._RATE_LIMITER. See the pyrate_limiter documentation and examples for details.</p>"},{"location":"configuration/#enterprise-configuration","title":"Enterprise Configuration","text":"<p>EdgarTools v4.28.0+ supports enterprise-grade configuration for custom SEC data sources and flexible rate limiting, enabling deployment with private mirrors, academic institutions, and high-volume applications.</p>"},{"location":"configuration/#configurable-rate-limiting","title":"Configurable Rate Limiting","text":""},{"location":"configuration/#edgar_rate_limit_per_sec","title":"EDGAR_RATE_LIMIT_PER_SEC","text":"<p>Control the maximum number of requests per second to SEC servers or custom mirrors.</p> <pre><code>export EDGAR_RATE_LIMIT_PER_SEC=\"9\"\n</code></pre> <p>Default: <code>9</code> requests/second (SEC's official limit)</p> <p>Typical Values: - <code>9</code> - SEC's standard limit (default, recommended for official SEC servers) - <code>10</code> - SEC's maximum allowed limit - Higher values (e.g., <code>20</code>, <code>50</code>) - Only for authorized custom mirrors with relaxed rate restrictions</p> <p>Use Cases: - Custom mirrors: Higher rate limits for private infrastructure with different restrictions - Authorized applications: High-volume applications with special SEC authorization - Testing environments: Flexible rate limits for development and testing - International mirrors: Optimized rates for regional mirrors</p> <p>Example:</p> <pre><code># Standard SEC access (default)\nexport EDGAR_RATE_LIMIT_PER_SEC=\"9\"\n\n# Custom mirror with relaxed limits\nexport EDGAR_RATE_LIMIT_PER_SEC=\"50\"\nexport EDGAR_BASE_URL=\"https://sec-mirror.company.com\"\n</code></pre> <p>Python Alternative:</p> <pre><code>from edgar import httpclient\n\n# Update rate limiter programmatically\nhttpclient.update_rate_limiter(requests_per_second=20)\n</code></pre> <p>\u26a0\ufe0f Important: Only use rate limits higher than 10 req/sec with custom mirrors or when authorized by SEC. Exceeding SEC's 10 req/sec limit may result in IP blocking.</p>"},{"location":"configuration/#custom-sec-data-sources","title":"Custom SEC Data Sources","text":"<p>Configure EdgarTools to use custom SEC mirrors, private data sources, or testing servers instead of the official SEC website.</p>"},{"location":"configuration/#edgar_base_url","title":"EDGAR_BASE_URL","text":"<p>Sets the base URL for SEC EDGAR website access.</p> <pre><code>export EDGAR_BASE_URL=\"https://www.sec.gov\"\n</code></pre> <p>Default: <code>https://www.sec.gov</code></p> <p>Use Cases: - Corporate SEC mirrors for compliance workflows - Academic research institutions with local mirrors - Regional mirrors for reduced latency (international users) - Testing environments with mock servers</p> <p>Example:</p> <pre><code># Corporate mirror\nexport EDGAR_BASE_URL=\"https://sec-mirror.company.com\"\n\n# Academic institution mirror\nexport EDGAR_BASE_URL=\"https://sec.university.edu\"\n\n# Regional mirror (example)\nexport EDGAR_BASE_URL=\"https://sec-eu.example.com\"\n</code></pre>"},{"location":"configuration/#edgar_data_url","title":"EDGAR_DATA_URL","text":"<p>Sets the base URL for SEC data archives (filing documents, submissions, company facts).</p> <pre><code>export EDGAR_DATA_URL=\"https://data.sec.gov\"\n</code></pre> <p>Default: <code>https://data.sec.gov</code></p> <p>Use Cases: - Separate data server from website server - CDN acceleration for filing downloads - Private data repositories - Bandwidth optimization</p> <p>Example:</p> <pre><code># Use CDN for data downloads\nexport EDGAR_DATA_URL=\"https://cdn.sec-data.company.com\"\n\n# Corporate data repository\nexport EDGAR_DATA_URL=\"https://sec-data.company.com\"\n</code></pre>"},{"location":"configuration/#edgar_xbrl_url","title":"EDGAR_XBRL_URL","text":"<p>Sets the base URL for XBRL-specific data and services.</p> <pre><code>export EDGAR_XBRL_URL=\"https://www.sec.gov\"\n</code></pre> <p>Default: <code>https://www.sec.gov</code></p> <p>Use Cases: - Specialized XBRL processing servers - XBRL validation and parsing services - Enhanced XBRL data repositories</p> <p>Example:</p> <pre><code># Dedicated XBRL server\nexport EDGAR_XBRL_URL=\"https://xbrl.sec-mirror.company.com\"\n</code></pre>"},{"location":"configuration/#complete-enterprise-configuration-example","title":"Complete Enterprise Configuration Example","text":""},{"location":"configuration/#corporate-mirror-setup","title":"Corporate Mirror Setup","text":"<pre><code># Corporate SEC mirror with higher rate limits\nexport EDGAR_IDENTITY=\"Corporate Compliance compliance@company.com\"\nexport EDGAR_BASE_URL=\"https://sec-mirror.company.com\"\nexport EDGAR_DATA_URL=\"https://sec-data.company.com\"\nexport EDGAR_XBRL_URL=\"https://sec-xbrl.company.com\"\nexport EDGAR_RATE_LIMIT_PER_SEC=\"50\"\nexport EDGAR_ACCESS_MODE=\"NORMAL\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_LOCAL_DATA_DIR=\"/var/lib/edgar\"\n</code></pre>"},{"location":"configuration/#academic-research-institution","title":"Academic Research Institution","text":"<pre><code># University research mirror with custom rate limits\nexport EDGAR_IDENTITY=\"Research Lab research@university.edu\"\nexport EDGAR_BASE_URL=\"https://sec.university.edu\"\nexport EDGAR_DATA_URL=\"https://sec-data.university.edu\"\nexport EDGAR_RATE_LIMIT_PER_SEC=\"25\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_LOCAL_DATA_DIR=\"/research/edgar_data\"\n</code></pre>"},{"location":"configuration/#regional-mirror-international-users","title":"Regional Mirror (International Users)","text":"<pre><code># Regional mirror for reduced latency\nexport EDGAR_IDENTITY=\"International Analyst analyst@company.com\"\nexport EDGAR_BASE_URL=\"https://sec-eu.example.com\"\nexport EDGAR_DATA_URL=\"https://sec-data-eu.example.com\"\nexport EDGAR_RATE_LIMIT_PER_SEC=\"15\"\nexport EDGAR_ACCESS_MODE=\"NORMAL\"\n</code></pre>"},{"location":"configuration/#developmenttesting-environment","title":"Development/Testing Environment","text":"<pre><code># Mock SEC server for testing\nexport EDGAR_IDENTITY=\"Developer dev@company.com\"\nexport EDGAR_BASE_URL=\"http://localhost:8080\"\nexport EDGAR_DATA_URL=\"http://localhost:8080/data\"\nexport EDGAR_XBRL_URL=\"http://localhost:8080/xbrl\"\nexport EDGAR_RATE_LIMIT_PER_SEC=\"100\"  # No limits for testing\nexport EDGAR_VERIFY_SSL=\"false\"  # Self-signed certificates in dev\nexport EDGAR_USE_RICH_LOGGING=\"1\"\n</code></pre>"},{"location":"configuration/#python-configuration-api","title":"Python Configuration API","text":"<p>Configure enterprise settings programmatically:</p> <pre><code>import os\n\n# Set custom SEC mirror\nos.environ['EDGAR_BASE_URL'] = \"https://sec-mirror.company.com\"\nos.environ['EDGAR_DATA_URL'] = \"https://sec-data.company.com\"\nos.environ['EDGAR_RATE_LIMIT_PER_SEC'] = \"50\"\n\n# Now import and use EdgarTools\nfrom edgar import Company\n\ncompany = Company(\"AAPL\")  # Uses custom mirror\nfilings = company.get_filings(form=\"10-K\")\n</code></pre> <p>Note: Environment variables must be set before importing EdgarTools modules, as configuration is evaluated at import time.</p>"},{"location":"configuration/#dockercontainer-configuration","title":"Docker/Container Configuration","text":"<p>For containerized deployments with custom SEC mirrors:</p> <pre><code># Dockerfile\nFROM python:3.11-slim\n\n# Install EdgarTools\nRUN pip install edgartools\n\n# Configure enterprise SEC access\nENV EDGAR_IDENTITY=\"Container App app@company.com\"\nENV EDGAR_BASE_URL=\"https://sec-mirror.company.com\"\nENV EDGAR_DATA_URL=\"https://sec-data.company.com\"\nENV EDGAR_RATE_LIMIT_PER_SEC=\"50\"\nENV EDGAR_ACCESS_MODE=\"CAUTION\"\nENV EDGAR_USE_LOCAL_DATA=\"True\"\nENV EDGAR_LOCAL_DATA_DIR=\"/app/edgar_data\"\n\n# Create data directory\nRUN mkdir -p /app/edgar_data\nVOLUME /app/edgar_data\n\nWORKDIR /app\n</code></pre> <p>Docker Compose Example:</p> <pre><code>version: '3.8'\nservices:\n  edgar-app:\n    image: your-edgar-app:latest\n    environment:\n      - EDGAR_IDENTITY=Service app@company.com\n      - EDGAR_BASE_URL=https://sec-mirror.company.com\n      - EDGAR_DATA_URL=https://sec-data.company.com\n      - EDGAR_RATE_LIMIT_PER_SEC=50\n      - EDGAR_USE_LOCAL_DATA=True\n      - EDGAR_LOCAL_DATA_DIR=/data\n    volumes:\n      - edgar-data:/data\n\nvolumes:\n  edgar-data:\n</code></pre>"},{"location":"configuration/#validation-and-testing","title":"Validation and Testing","text":"<p>Verify your enterprise configuration:</p> <pre><code>import os\nfrom edgar import Company\n\ndef validate_enterprise_config():\n    \"\"\"Validate enterprise EdgarTools configuration.\"\"\"\n    print(\"Enterprise Configuration:\")\n    print(f\"  Base URL: {os.getenv('EDGAR_BASE_URL', 'https://www.sec.gov')}\")\n    print(f\"  Data URL: {os.getenv('EDGAR_DATA_URL', 'https://data.sec.gov')}\")\n    print(f\"  XBRL URL: {os.getenv('EDGAR_XBRL_URL', 'https://www.sec.gov')}\")\n    print(f\"  Rate Limit: {os.getenv('EDGAR_RATE_LIMIT_PER_SEC', '9')} req/sec\")\n\n    # Test basic functionality\n    try:\n        company = Company(\"AAPL\")\n        print(f\"\\n\u2713 Successfully connected: {company.name}\")\n\n        # Test filing access\n        filings = company.get_filings(form=\"10-K\").head(1)\n        if filings:\n            print(f\"\u2713 Successfully retrieved filings from: {filings[0].accession_number}\")\n\n        return True\n    except Exception as e:\n        print(f\"\\n\u274c Configuration test failed: {e}\")\n        return False\n\n# Run validation\nvalidate_enterprise_config()\n</code></pre>"},{"location":"configuration/#troubleshooting-enterprise-configuration","title":"Troubleshooting Enterprise Configuration","text":""},{"location":"configuration/#custom-mirror-connection-issues","title":"Custom Mirror Connection Issues","text":"<pre><code># Test connectivity to custom mirror\nimport requests\n\nbase_url = os.getenv('EDGAR_BASE_URL')\ntry:\n    response = requests.get(f\"{base_url}/cgi-bin/browse-edgar\")\n    print(f\"\u2713 Mirror accessible: {response.status_code}\")\nexcept Exception as e:\n    print(f\"\u274c Mirror connection failed: {e}\")\n</code></pre>"},{"location":"configuration/#rate-limit-verification","title":"Rate Limit Verification","text":"<pre><code># Verify rate limiter is using correct setting\nfrom edgar import httpclient\n\nprint(f\"Current rate limit: {os.getenv('EDGAR_RATE_LIMIT_PER_SEC', '9')} req/sec\")\n\n# Monitor rate limiting in action\nimport time\nstart = time.time()\nfor i in range(20):\n    # Make 20 requests\n    company = Company(\"AAPL\")\nelapsed = time.time() - start\nactual_rate = 20 / elapsed\nprint(f\"Actual request rate: {actual_rate:.2f} req/sec\")\n</code></pre>"},{"location":"configuration/#ssl-certificate-issues-with-custom-mirrors","title":"SSL Certificate Issues with Custom Mirrors","text":"<pre><code># If custom mirror uses self-signed certificates\nexport EDGAR_VERIFY_SSL=\"false\"\n\n# Or configure SSL certificate bundle\nexport REQUESTS_CA_BUNDLE=\"/path/to/company-ca-bundle.crt\"\n</code></pre>"},{"location":"configuration/#best-practices-for-enterprise-deployment","title":"Best Practices for Enterprise Deployment","text":"<ol> <li>Always set EDGAR_IDENTITY - Include company/team identification</li> <li>Test mirror connectivity - Validate URLs before production deployment</li> <li>Monitor rate limits - Ensure compliance with mirror's rate restrictions</li> <li>Use local data storage - Enable caching for improved performance</li> <li>Secure credentials - Use environment variables, not hardcoded values</li> <li>Document configuration - Maintain configuration profiles for different environments</li> <li>Version control - Use <code>.env.example</code> files to document required variables</li> <li>Health checks - Implement validation functions to verify configuration</li> </ol>"},{"location":"configuration/#environment-variables-summary","title":"Environment Variables Summary","text":"Variable Default Purpose Enterprise Use Case <code>EDGAR_RATE_LIMIT_PER_SEC</code> <code>9</code> Request rate limit Custom mirrors, authorized high-volume apps <code>EDGAR_BASE_URL</code> <code>https://www.sec.gov</code> SEC website base URL Corporate mirrors, regional mirrors <code>EDGAR_DATA_URL</code> <code>https://data.sec.gov</code> Data archives URL CDN acceleration, private repositories <code>EDGAR_XBRL_URL</code> <code>https://www.sec.gov</code> XBRL services URL Specialized XBRL servers"},{"location":"configuration/#backward-compatibility","title":"Backward Compatibility","text":"<p>All enterprise configuration features are fully backward compatible: - Default values point to official SEC servers - Zero configuration needed for standard users - Existing code continues to work without changes - Environment variables are optional</p>"},{"location":"configuration/#http-caching","title":"HTTP Caching","text":"<p>Web requests are cached by default, according to the rules defined in httpclient_cache. </p>"},{"location":"configuration/#cache-directory","title":"Cache Directory","text":"<p>The cache directory is set in <code>httpclient.CACHE_DIRECTORY</code>, set to <code>_cache</code> by default. Set CACHE_DIRECTORY=None to disable cache. Call <code>httpclient.close_client()</code> after any changes to the CACHE_DIRECTORY variable. </p>"},{"location":"configuration/#caching-rules","title":"Caching Rules","text":"<p>The SEC marks all requests as either NO-STORE or NO-CACHE, therefore a custom cache controller was implemented with the following rules:  - <code>/submissions</code> URLs for up to 10 minutes by default, set in <code>MAX_SUBMISSIONS_AGE_SECONDS</code> - <code>.*index/.*</code> URLs for up to 30 minutes by default, set in <code>MAX_INDEX_AGE_SECONDS</code> - <code>/Archives/edgar/data</code> URLs indefinitely (forever)</p> <p>See <code>httpclient_cache</code> for implementation. </p>"},{"location":"configuration/#advanced-alternative-storage-caches","title":"Advanced: Alternative Storage Caches","text":"<ul> <li>The underlying cache is a FileStorage cache. While not implemented, it's feasible to replace this with a S3Storage cache by overriding get_transport and get_async_storage. See S3Storage and AsyncS3Storage at https://hishel.com/ for details.</li> </ul>"},{"location":"configuration/#edgar_use_rich_logging","title":"EDGAR_USE_RICH_LOGGING","text":"<p>Enables enhanced console logging with rich formatting.</p> <pre><code>export EDGAR_USE_RICH_LOGGING=\"1\"\n</code></pre> <p>Values: - <code>\"1\"</code> - Enable rich logging with colors and formatting - <code>\"0\"</code> (default) - Standard logging</p> <p>Benefits: - Color-coded log levels - Enhanced readability - Progress bars and status indicators - Better debugging information</p>"},{"location":"configuration/#programmatic-configuration","title":"Programmatic Configuration","text":""},{"location":"configuration/#setting-identity","title":"Setting Identity","text":"<pre><code>from edgar import set_identity\n\n# Set identity programmatically\nset_identity(\"Research Team research@university.edu\")\n\n# Verify identity is set\nfrom edgar.core import get_identity\nprint(f\"Current identity: {get_identity()}\")\n</code></pre>"},{"location":"configuration/#local-storage-control","title":"Local Storage Control","text":"<pre><code>from edgar import use_local_storage\n\n# Enable local storage\nuse_local_storage(True)\n\n# Disable local storage\nuse_local_storage(False)\n\n# Check current setting\nfrom edgar.storage import using_local_storage\nprint(f\"Using local storage: {using_local_storage()}\")\n</code></pre>"},{"location":"configuration/#http-client-configuration","title":"HTTP Client Configuration","text":"<pre><code>from edgar.core import EdgarSettings\n\n# Custom access mode\ncustom_settings = EdgarSettings(\n    http_timeout=30,        # 30 second timeout\n    max_connections=3,      # Maximum 3 concurrent connections\n    retries=5              # 5 retry attempts\n)\n\n# Apply custom settings (requires restarting client)\n</code></pre>"},{"location":"configuration/#configuration-profiles","title":"Configuration Profiles","text":""},{"location":"configuration/#research-profile","title":"Research Profile","text":"<p>Optimized for interactive research and analysis:</p> <pre><code>export EDGAR_IDENTITY=\"Researcher researcher@university.edu\"\nexport EDGAR_ACCESS_MODE=\"NORMAL\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_USE_RICH_LOGGING=\"1\"\n</code></pre>"},{"location":"configuration/#production-profile","title":"Production Profile","text":"<p>Conservative settings for production environments:</p> <pre><code>export EDGAR_IDENTITY=\"Production System api@company.com\"\nexport EDGAR_ACCESS_MODE=\"CAUTION\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_LOCAL_DATA_DIR=\"/var/lib/edgar\"\nexport EDGAR_VERIFY_SSL=\"true\"\n</code></pre>"},{"location":"configuration/#bulk-processing-profile","title":"Bulk Processing Profile","text":"<p>Minimal server impact for large-scale data processing:</p> <pre><code>export EDGAR_IDENTITY=\"Bulk Processor batch@company.com\"\nexport EDGAR_ACCESS_MODE=\"CRAWL\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_LOCAL_DATA_DIR=\"/data/edgar\"\n</code></pre>"},{"location":"configuration/#development-profile","title":"Development Profile","text":"<p>Flexible settings for development and testing:</p> <pre><code>export EDGAR_IDENTITY=\"Developer dev@company.com\"\nexport EDGAR_ACCESS_MODE=\"NORMAL\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_USE_RICH_LOGGING=\"1\"\nexport EDGAR_VERIFY_SSL=\"false\"  # Only if needed for proxy\n</code></pre>"},{"location":"configuration/#enterprise-mirror-profile","title":"Enterprise Mirror Profile","text":"<p>For custom SEC mirrors with higher rate limits (see Enterprise Configuration):</p> <pre><code>export EDGAR_IDENTITY=\"Corporate Compliance compliance@company.com\"\nexport EDGAR_BASE_URL=\"https://sec-mirror.company.com\"\nexport EDGAR_DATA_URL=\"https://sec-data.company.com\"\nexport EDGAR_RATE_LIMIT_PER_SEC=\"50\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_LOCAL_DATA_DIR=\"/var/lib/edgar\"\n</code></pre>"},{"location":"configuration/#configuration-file-setup","title":"Configuration File Setup","text":""},{"location":"configuration/#env-file","title":".env File","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># .env file\nEDGAR_IDENTITY=John Doe john.doe@company.com\nEDGAR_ACCESS_MODE=NORMAL\nEDGAR_USE_LOCAL_DATA=True\nEDGAR_LOCAL_DATA_DIR=./edgar_data\nEDGAR_USE_RICH_LOGGING=1\n</code></pre> <p>Load with python-dotenv:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\n\n# Now EdgarTools will use the environment variables\nfrom edgar import Company\ncompany = Company(\"AAPL\")\n</code></pre>"},{"location":"configuration/#shell-configuration","title":"Shell Configuration","text":"<p>Add to your shell profile (<code>.bashrc</code>, <code>.zshrc</code>, etc.):</p> <pre><code># Edgar Tools Configuration\nexport EDGAR_IDENTITY=\"Your Name your.email@company.com\"\nexport EDGAR_ACCESS_MODE=\"NORMAL\"\nexport EDGAR_USE_LOCAL_DATA=\"True\"\nexport EDGAR_LOCAL_DATA_DIR=\"$HOME/.edgar\"\n</code></pre>"},{"location":"configuration/#data-management","title":"Data Management","text":""},{"location":"configuration/#local-storage-benefits","title":"Local Storage Benefits","text":"<p>When <code>EDGAR_USE_LOCAL_DATA=\"True\"</code>:</p> <ol> <li>Caching: HTTP responses cached locally</li> <li>Offline Access: Previously accessed data available offline</li> <li>Performance: Faster subsequent access to same data</li> <li>Reduced API Calls: Less load on SEC servers</li> </ol>"},{"location":"configuration/#storage-space-considerations","title":"Storage Space Considerations","text":"<p>Typical storage usage: - Company submissions: ~100MB for major companies - Company facts: ~50MB for major companies - HTTP cache: Varies based on usage - Individual filings: 1-10MB each</p>"},{"location":"configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"configuration/#check-current-configuration","title":"Check Current Configuration","text":"<pre><code>import os\nfrom edgar.core import get_identity\n\n# Check identity\nprint(f\"Identity: {get_identity()}\")\n\n# Check access mode\nprint(f\"Access Mode: {os.getenv('EDGAR_ACCESS_MODE', 'NORMAL')}\")\n\n# Check local data settings\nprint(f\"Use Local Data: {os.getenv('EDGAR_USE_LOCAL_DATA', 'False')}\")\nprint(f\"Data Directory: {os.getenv('EDGAR_LOCAL_DATA_DIR', '~/.edgar')}\")\n\n# Check SSL verification\nprint(f\"Verify SSL: {os.getenv('EDGAR_VERIFY_SSL', 'true')}\")\n</code></pre>"},{"location":"configuration/#common-issues","title":"Common Issues","text":""},{"location":"configuration/#identity-not-set","title":"Identity Not Set","text":"<pre><code># Error: No identity set\n# Solution:\nset_identity(\"Your Name your.email@company.com\")\n</code></pre>"},{"location":"configuration/#permission-errors","title":"Permission Errors","text":"<pre><code># Error: Permission denied writing to ~/.edgar\n# Solution: Check directory permissions or use custom directory\nexport EDGAR_LOCAL_DATA_DIR=\"/tmp/edgar\"\n</code></pre>"},{"location":"configuration/#ssl-verification-errors","title":"SSL Verification Errors","text":"<pre><code># Error: SSL certificate verification failed\n# Solution: Disable SSL verification (only if safe)\nexport EDGAR_VERIFY_SSL=\"false\"\n</code></pre>"},{"location":"configuration/#connection-timeouts","title":"Connection Timeouts","text":"<pre><code># Error: Connection timeouts in slow network\n# Solution: Use more conservative settings\nexport EDGAR_ACCESS_MODE=\"CAUTION\"\n</code></pre>"},{"location":"configuration/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Always set EDGAR_IDENTITY - Required for SEC compliance</li> <li>Keep SSL verification enabled - Only disable in controlled environments</li> <li>Secure data directory - Ensure appropriate file permissions</li> <li>Use least-privilege access - Don't run with unnecessary elevated permissions</li> <li>Monitor data usage - Be aware of local storage space consumption</li> </ol>"},{"location":"configuration/#docker-configuration","title":"Docker Configuration","text":"<p>For containerized deployments:</p> <pre><code># Dockerfile\nENV EDGAR_IDENTITY=\"Container App app@company.com\"\nENV EDGAR_ACCESS_MODE=\"CAUTION\"\nENV EDGAR_USE_LOCAL_DATA=\"True\"\nENV EDGAR_LOCAL_DATA_DIR=\"/app/edgar_data\"\n\n# Create data directory\nRUN mkdir -p /app/edgar_data\nVOLUME /app/edgar_data\n</code></pre>"},{"location":"configuration/#configuration-validation","title":"Configuration Validation","text":"<p>Validate your configuration before running analysis:</p> <pre><code>from edgar import Company\nimport os\n\ndef validate_config():\n    \"\"\"Validate EdgarTools configuration.\"\"\"\n    issues = []\n\n    # Check identity\n    try:\n        from edgar.core import get_identity\n        identity = get_identity()\n        if not identity:\n            issues.append(\"EDGAR_IDENTITY not set\")\n        elif \"@\" not in identity:\n            issues.append(\"EDGAR_IDENTITY should include email\")\n    except:\n        issues.append(\"Cannot retrieve EDGAR_IDENTITY\")\n\n    # Check data directory\n    if os.getenv('EDGAR_USE_LOCAL_DATA', 'False').lower() in ['true', '1']:\n        data_dir = os.getenv('EDGAR_LOCAL_DATA_DIR', '~/.edgar')\n        expanded_dir = os.path.expanduser(data_dir)\n        if not os.path.exists(expanded_dir):\n            try:\n                os.makedirs(expanded_dir, exist_ok=True)\n            except:\n                issues.append(f\"Cannot create data directory: {data_dir}\")\n\n    # Test basic functionality\n    try:\n        company = Company(\"AAPL\")\n        print(f\"\u2713 Successfully created company: {company.name}\")\n    except Exception as e:\n        issues.append(f\"Basic functionality test failed: {e}\")\n\n    if issues:\n        print(\"Configuration Issues:\")\n        for issue in issues:\n            print(f\"  \u274c {issue}\")\n        return False\n    else:\n        print(\"\u2713 Configuration validated successfully\")\n        return True\n\n# Run validation\nvalidate_config()\n</code></pre>"},{"location":"configuration/#see-also","title":"See Also","text":"<ul> <li>Installation Guide - Getting started with EdgarTools</li> <li>Quick Start - Your first analysis</li> <li>Performance Best Practices - Optimization tips</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"contributing/","title":"Contributing to EdgarTools","text":"<p>Thank you for your interest in contributing to EdgarTools! This open-source project thrives on community contributions, and we appreciate any help you can provide. \ud83c\udf89</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":""},{"location":"contributing/#support-the-project","title":"\ud83d\udc9d Support the Project","text":"<p>If you find EdgarTools useful, consider supporting its development:</p> <p> </p> <p>Your support helps maintain and improve EdgarTools, ensuring it remains free and open-source for everyone.</p>"},{"location":"contributing/#report-bugs","title":"\ud83d\udc1b Report Bugs","text":"<p>If you encounter a bug:</p> <ol> <li>Check if it's already reported in GitHub Issues</li> <li>If not, open a new issue</li> </ol> <p>Include:</p> <ol> <li>Clear title and description</li> <li>Steps to reproduce</li> <li>Expected vs actual behavior</li> <li>Environment details (OS, Python version, EdgarTools version)</li> </ol>"},{"location":"contributing/#suggest-features","title":"\ud83d\udca1 Suggest Features","text":"<p>Have an idea for improvement? - Open an issue using the \"Feature request\" template - Describe your idea clearly - Explain why it would be beneficial - Include any implementation ideas</p>"},{"location":"contributing/#improve-documentation","title":"\ud83d\udcdd Improve Documentation","text":"<p>Help make our docs better: - Fix typos or unclear explanations - Add examples and use cases - Improve API documentation - Translate documentation</p>"},{"location":"contributing/#write-code","title":"\ud83d\udd27 Write Code","text":"<p>Ready to code? Here's how:</p> <ol> <li>Find an issue to work on (or create one)</li> <li>Discuss significant changes in issue comments</li> <li>Follow the development workflow below</li> </ol>"},{"location":"contributing/#share-expertise","title":"\ud83c\udf93 Share Expertise","text":"<p>Your domain knowledge is valuable! - Share insights on SEC filings, XBRL, or financial analysis - Help answer questions in issues - Review pull requests - Write tutorials or blog posts</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>EdgarTools uses Hatch for project management.</p>"},{"location":"contributing/#1-fork-clone","title":"1. Fork &amp; Clone","text":"<pre><code># Fork on GitHub, then:\ngit clone https://github.com/&lt;YOUR_USERNAME&gt;/edgartools.git\ncd edgartools\n</code></pre>"},{"location":"contributing/#2-install-hatch","title":"2. Install Hatch","text":"<p>Follow the official installation guide if you don't have Hatch.</p>"},{"location":"contributing/#3-set-up-environment","title":"3. Set Up Environment","text":"<pre><code># Activate development environment\nhatch shell\n</code></pre> <p>This installs all dependencies including development tools.</p>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#1-create-a-branch","title":"1. Create a Branch","text":"<pre><code>git checkout main\ngit pull origin main\ngit checkout -b feature/your-feature-name\n</code></pre> <p>Use descriptive branch names like: - <code>fix/filing-parsing-error</code> - <code>feature/insider-transaction-api</code> - <code>docs/improve-xbrl-examples</code></p>"},{"location":"contributing/#2-make-changes","title":"2. Make Changes","text":"<ul> <li>Max line length: 150 characters</li> <li>Use type annotations</li> <li>Include docstrings for public functions</li> <li>Write tests for new features</li> </ul>"},{"location":"contributing/#3-format-lint","title":"3. Format &amp; Lint","text":"<pre><code># Format code\nhatch run ruff format .\n\n# Check linting\nhatch run lint\n\n# Type check\nhatch run pyright\n</code></pre>"},{"location":"contributing/#4-test","title":"4. Test","text":"<pre><code># Run tests with coverage\nhatch run cov\n\n# Run specific tests\nhatch run pytest tests/test_file.py::test_function\n</code></pre> <p>Ensure: - All tests pass - Coverage doesn't decrease - New features have tests</p>"},{"location":"contributing/#5-commit","title":"5. Commit","text":"<p>Use clear, conventional commit messages:</p> <pre><code>git add .\ngit commit -m \"feat: add support for Form 13F parsing\"\n</code></pre> <p>Commit message prefixes: - <code>feat:</code> - New feature - <code>fix:</code> - Bug fix - <code>docs:</code> - Documentation changes - <code>test:</code> - Test additions/changes - <code>refactor:</code> - Code refactoring - <code>style:</code> - Code style changes - <code>chore:</code> - Maintenance tasks</p>"},{"location":"contributing/#6-push-pull-request","title":"6. Push &amp; Pull Request","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then on GitHub:</p> <ol> <li>Open a pull request to <code>main</code> branch</li> <li>Provide clear title and description</li> <li>Reference relevant issues (e.g., \"Closes #123\")</li> <li>Explain what and why</li> </ol>"},{"location":"contributing/#7-review-process","title":"7. Review Process","text":"<ul> <li>A maintainer will review your PR</li> <li>Address feedback constructively</li> <li>Make requested changes</li> <li>Tests must pass before merging</li> </ul>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":"<p>Preview documentation locally:</p> <pre><code># Start local docs server\nhatch run mkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000</code> to see your changes.</p>"},{"location":"contributing/#code-style-guide","title":"Code Style Guide","text":""},{"location":"contributing/#python-code","title":"Python Code","text":"<ul> <li>Line length: 150 chars max</li> <li>Use type hints</li> <li>Snake_case for functions/variables</li> <li>PascalCase for classes</li> <li>Descriptive docstrings</li> </ul>"},{"location":"contributing/#example","title":"Example:","text":"<pre><code>def get_filing_documents(\n    filing: Filing,\n    document_type: Optional[str] = None\n) -&gt; List[Document]:\n    \"\"\"\n    Retrieve documents from an SEC filing.\n\n    Args:\n        filing: The Filing object to extract documents from\n        document_type: Optional filter for specific document types\n\n    Returns:\n        List of Document objects matching the criteria\n    \"\"\"\n    # Implementation\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Use clear, concise language</li> <li>Include code examples</li> <li>Link to related topics</li> <li>Keep formatting consistent</li> </ul>"},{"location":"contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<ul> <li>Test files mirror source structure</li> <li>Use descriptive test names</li> <li>Cover edge cases</li> <li>Mock external dependencies</li> </ul>"},{"location":"contributing/#example_1","title":"Example:","text":"<pre><code>def test_company_retrieval_by_ticker():\n    \"\"\"Test that companies can be retrieved by ticker symbol.\"\"\"\n    company = Company(\"AAPL\")\n    assert company.name == \"Apple Inc.\"\n    assert company.cik == 320193\n</code></pre>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcac GitHub Discussions - Ask questions</li> <li>\ud83d\udce7 Email - Direct contact</li> <li>\ud83d\udcda Documentation - Usage guides</li> </ul>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in: - GitHub Contributors - Release notes - Documentation credits</p>"},{"location":"contributing/#support-the-project_1","title":"Support the Project","text":"<p>If you find EdgarTools valuable, please consider:</p> <p> </p> <p>Your support helps:</p> <ul> <li>\ud83d\ude80 Maintain and improve the library</li> <li>\ud83d\udcda Keep documentation up-to-date</li> <li>\ud83d\udc1b Fix bugs quickly</li> <li>\u2728 Add new features</li> <li>\ud83d\udcbb Keep the project free and open-source</li> </ul> <p>Thank you for contributing to EdgarTools! \ud83d\ude4f</p>"},{"location":"data-objects/","title":"Data Objects","text":"<p>Data Objects in EdgarTools provide structured access to filing content in a format specific to each filing type. These specialized objects extract, organize, and expose the relevant data from SEC filings, making it much easier to work with different filing types programmatically.</p>"},{"location":"data-objects/#overview","title":"Overview","text":"<p>Data Objects represent parsed SEC filings with type-specific properties and methods. They automatically handle the complex parsing of raw filing data (HTML, XML, XBRL) and present a clean, intuitive interface tailored to each filing type.</p> <p>For example, a <code>TenK</code> object provides structured access to an annual report's business description, risk factors, and financial data, while a <code>ThirteenF</code> object organizes investment holdings into tabular data.</p>"},{"location":"data-objects/#supported-filing-types","title":"Supported Filing Types","text":"<p>EdgarTools provides specialized Data Objects for the most common SEC filing types:</p> Form Data Object Description Key Features 10-K <code>TenK</code> Annual report Section access, financial statements, XBRL data 10-Q <code>TenQ</code> Quarterly report Section access, financial statements, XBRL data 8-K <code>EightK</code> Current report Item access, press releases, event categorization 3, 4, 5 <code>Ownership</code> Ownership reports Transaction details, insider information 13F-HR <code>ThirteenF</code> 13F Holdings Report Portfolio holdings, securities information NPORT-P <code>FundReport</code> Fund Report Fund portfolio data, investments D <code>FormD</code> Form D Offering Exempt offering details C, C-U, C-AR, C-TR <code>FormC</code> Form C Crowdfunding Offering Crowdfunding details, issuer information MA-I <code>MunicipalAdvisorForm</code> Municipal advisor initial filing Municipal advisor information Form 144 <code>Form144</code> Notice of proposed sale of securities Proposed sale details EFFECT <code>Effect</code> Notice of Effectiveness Registration statement effectiveness Any filing with XBRL <code>FilingXbrl</code> XBRL-enabled filing Access to structured XBRL data"},{"location":"data-objects/#converting-filings-to-data-objects","title":"Converting Filings to Data Objects","text":"<p>To get a Data Object from a <code>Filing</code>, use the <code>obj()</code> method:</p> <pre><code>from edgar import Company, get_filings\n\n# Method 1: From a company object\napple = Company(\"AAPL\")\nfilings = apple.get_filings(form=\"10-K\")\nlatest_10k = filings.latest()\ntenk = latest_10k.obj()\n\n# Method 2: From filings search\nform4_filings = get_filings(form=\"4\", limit=10)\nform4 = form4_filings[0].obj()\n\n# Method 3: Direct from a filing accessor\nfiling = apple.get_latest_filing(\"10-K\")\ntenk = filing.obj()\n</code></pre>"},{"location":"data-objects/#working-with-data-objects","title":"Working with Data Objects","text":""},{"location":"data-objects/#company-reports-10-k-10-q","title":"Company Reports (10-K, 10-Q)","text":"<pre><code># Get a 10-K data object\ntenk = filing.obj()\n\n# Access document sections by name\nbusiness_description = tenk.business\nrisk_factors = tenk.risk_factors\nmd_and_a = tenk.management_discussion\nlegal_proceedings = tenk.legal_proceedings\n\n# Access financial statements\nbalance_sheet = tenk.balance_sheet\nincome_stmt = tenk.income_statement\ncash_flow = tenk.cashflow_statement\n\n# Get specific financial values\nrevenue = income_stmt.get_value(\"Revenues\")\nnet_income = income_stmt.get_value(\"NetIncomeLoss\")\nassets = balance_sheet.get_value(\"Assets\")\n\n# Convert to DataFrame for analysis\nincome_df = income_stmt.to_dataframe()\nbalance_df = balance_sheet.to_dataframe()\n\n# Access raw text of a section\nrisk_text = tenk.get_section_text(\"Risk Factors\")\n</code></pre>"},{"location":"data-objects/#current-reports-8-k","title":"Current Reports (8-K)","text":"<pre><code>eightk = filing.obj()\n\n# Get basic information\nreport_date = eightk.date_of_report\nitems_reported = eightk.items\n\n# Check for specific events\nhas_acquisition = eightk.has_item(\"2.01\")  # Acquisition/disposition\nhas_officer_change = eightk.has_item(\"5.02\")  # Officer changes\n\n# Access specific items by number\nif \"Item 2.01\" in eightk:\n    acquisition_info = eightk[\"Item 2.01\"]\n\n# Get press releases\nif eightk.has_press_release:\n    press_releases = eightk.press_releases\n    for pr in press_releases:\n        print(f\"Title: {pr.title}\")\n        print(f\"Content: {pr.content[:100]}...\")\n</code></pre>"},{"location":"data-objects/#insider-trading-forms-3-4-5","title":"Insider Trading (Forms 3, 4, 5)","text":"<pre><code>form4 = filing.obj()\n\n# Get basic information\ninsider_name = form4.reporting_owner\ncompany_name = form4.issuer\nfiling_date = form4.filing_date\n\n# Access transaction data\nfor transaction in form4.transactions:\n    print(f\"Date: {transaction.transaction_date}\")\n    print(f\"Type: {transaction.transaction_code}\")  # P for purchase, S for sale\n    print(f\"Shares: {transaction.shares}\")\n    print(f\"Price: ${transaction.price_per_share}\")\n    print(f\"Value: ${transaction.value}\")\n\n# Get summary of market trades\nbuy_count, sell_count = form4.get_buy_sell_counts()\nnet_shares = form4.get_net_shares_traded()\n</code></pre>"},{"location":"data-objects/#investment-fund-holdings-13f","title":"Investment Fund Holdings (13F)","text":"<pre><code>thirteen_f = filing.obj()\n\n# Get fund information\nfund_name = thirteen_f.manager_name\nreport_date = thirteen_f.report_date\n\n# Get holdings summary\ntotal_value = thirteen_f.total_value\nholdings_count = thirteen_f.total_holdings\n\n# Access all holdings\nholdings = thirteen_f.infotable\nfor holding in holdings:\n    print(f\"Company: {holding.name}\")\n    print(f\"Value: ${holding.value:,.2f}\")\n    print(f\"Shares: {holding.shares:,}\")\n    print(f\"Security Type: {holding.security_type}\")\n\n# Convert to DataFrame for analysis\nholdings_df = holdings.to_dataframe()\ntop_holdings = holdings_df.sort_values('value', ascending=False).head(10)\n</code></pre>"},{"location":"data-objects/#rich-display","title":"Rich Display","text":"<p>Most Data Objects include rich display formatting for use in terminals or notebooks:</p> <pre><code># Display formatted information in a terminal or notebook\nprint(tenk)  # Shows a summary of the 10-K filing\nprint(form4)  # Shows insider transaction details\nprint(thirteen_f)  # Shows fund holdings summary\n\n# In Jupyter notebooks, objects render as HTML tables automatically\ntenk.balance_sheet  # Displays as formatted table\nthirteen_f.infotable  # Displays as holdings table\n</code></pre>"},{"location":"data-objects/#error-handling","title":"Error Handling","text":"<p>Data Objects handle common parsing errors gracefully:</p> <pre><code>try:\n    data_obj = filing.obj()\nexcept UnsupportedFilingTypeError:\n    print(\"This filing type doesn't have a specialized data object\")\nexcept ParsingError as e:\n    print(f\"Error parsing filing: {e}\")\n    # Fall back to generic access\n    text = filing.text\n</code></pre>"},{"location":"data-objects/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Data Objects parse filing content on-demand</li> <li>Large filings (like 10-Ks) may take a few seconds to parse</li> <li>Consider using local storage for batch processing</li> </ul>"},{"location":"data-objects/#implementation-details","title":"Implementation Details","text":"<p>Data Objects are implemented using a mix of regular classes, dataclasses, and Pydantic models, depending on the complexity of the filing type. They handle parsing of HTML, XML, and XBRL content automatically, providing a clean interface to work with filing data.</p>"},{"location":"eightk-filings/","title":"Eight-K Filings","text":"<p>Imagine having instant access to a company's most critical corporate updates the moment they happen!</p> <p>8-K filings are real-time windows into significant corporate events, revealing everything from  leadership changes to major business transformations.</p> <p>With edgartools, you can effortlessly retrieve and analyze these crucial SEC documents in just a few lines of Python code. </p>"},{"location":"eightk-filings/#getting-8-k-filings-for-a-company","title":"Getting 8-K filings for a company","text":"<p>The easiest way to get 8-K filings is to get access to a company object and use the <code>latest</code> function. You can restrict to the latest 5 filings by passing <code>n</code> as a parameter.</p> <p>This returns a <code>Filings</code> object with multiple filings so to get a single filing use the bracket <code>[]</code> operator e.g. <code>filings[1]</code>.</p> <pre><code>c = Company(\"AAPL\")\n\nfilings = filings.latest(\"8-K\", 5)\n</code></pre> <p></p> <p>To get the last filing use <code>latest</code> without <code>n</code>. This returns a single <code>Filing</code> object.</p> <pre><code>filing = filings.latest(\"8-K\")\n</code></pre> <p></p>"},{"location":"eightk-filings/#getting-all-8-k-filings","title":"Getting all 8-K filings","text":"<p>Another way to get 8-K filings is to use <code>get_filings(form=\"8-K\")</code>. This gets all the filings for a company, but also allow for filtering by date</p> <pre><code>filings = c.get_filings(form='8-K')\n</code></pre>"},{"location":"eightk-filings/#filtering-by-date","title":"Filtering by date","text":"<p>You can also filter the filings by date using a range 'YYYY-MM-DD:YYYY-MM-DD' or from a specific date 'YYYY-MM-DD:' or before a specific date ':YYYY-MM-DD'.</p> <pre><code>filings = c.get_filings(form='8-K', date='2022-01-01:')\n</code></pre> <p></p>"},{"location":"eightk-filings/#viewing-the-8-k-filing","title":"Viewing the 8-K filing","text":"<p>Once you have the 8-K filing you can view it in the browser using <code>filing.open()</code></p> <pre><code>filing.open()\n</code></pre> <p>You can also view it in the console using <code>filing.view()</code></p> <pre><code>filing.view()\n</code></pre> <p></p>"},{"location":"eightk-filings/#viewing-the-filing-exhibits","title":"Viewing the filing exhibits","text":"<p>8-K filings often gave attached exhibits which contain the informnation the company is releasing in the filing.  You can view the list of exhibits using <code>filing.exhibits</code></p> <pre><code>filing.exhibits \n</code></pre> <p></p>"},{"location":"eightk-filings/#viewing-a-specific-exhibit","title":"Viewing a specific exhibit","text":"<p>To select a specific exhibit use the bracket <code>[]</code> operator e.g. <code>filing.exhibits[0]</code>. This selects the first exhibit, so <code>filing.exhibits[1]</code> selects the second exhibit.</p> <p>To view the exhibit <code>filing.exhibits[1].view()</code></p> <pre><code>filing.exhibits[1].view()\n</code></pre> <p></p>"},{"location":"eightk-filings/#downloading-the-exhibit","title":"Downloading the exhibit","text":"<p>To download the exhibit use <code>filing.exhibits[1].download()</code>. Note that this downloads the file into memory, while you may want to download to a path. To download to a path use <code>filing.exhibits[1].download(path=\"path/to/save\")</code></p> <pre><code>filing.exhibits[1].download()\n</code></pre>"},{"location":"examples/","title":"Solve Real Problems with EdgarTools","text":"<p>This document showcases common workflows and tasks that financial professionals, developers, and researchers can accomplish using EdgarTools. Each journey addresses a specific problem and provides a concise code example.</p>"},{"location":"examples/#example-resources","title":"Example Resources","text":"<p>All examples are in the <code>examples/</code> directory:</p>"},{"location":"examples/#interactive-notebooks","title":"\ud83d\udcd3 Interactive Notebooks","text":"<p>Explore 28 Jupyter notebooks organized by topic in <code>examples/notebooks/</code>: - Beginner - Getting started guides - XBRL - Financial statement analysis (18 notebooks) - Filings - Working with SEC filings - Funds - Investment fund analysis - Insiders - Insider trading data - See all notebooks</p>"},{"location":"examples/#python-scripts","title":"\ud83d\udcbb Python Scripts","text":"<p>Browse 8 ready-to-use Python scripts in <code>examples/scripts/</code>: - Basic - Simple examples for common tasks - Advanced - Complex use cases - AI Integration - AI/LLM workflows - See all scripts</p>"},{"location":"examples/#use-case-examples","title":"Use Case Examples","text":""},{"location":"examples/#1-company-financial-analysis","title":"1. Company Financial Analysis","text":"<p>Problem: Need to analyze a company's financial health across multiple periods.</p> <p></p> <pre><code>\ndef get_income_dataframe(ticker:str):\n    c = Company(ticker)\n    filings = c.get_filings(form=\"10-K\").latest(5)\n    xbs = XBRLS.from_filings(filings)\n    income_statement = xbs.statements.income_statement()\n    income_df = income_statement.to_dataframe()\n    return income_df\n\n\ndef plot_revenue(ticker:str):\n    income_df = get_income_dataframe(ticker)\n\n    # Extract financial metrics\n    net_income = income_df[income_df.concept == \"us-gaap_NetIncomeLoss\"][income_statement.periods].iloc[0]\n    gross_profit = income_df[income_df.concept == \"us-gaap_GrossProfit\"][income_statement.periods].iloc[0]\n    revenue = income_df[income_df.label == \"Revenue\"][income_statement.periods].iloc[0]\n\n    # Convert periods to fiscal years for better readability\n    periods = [pd.to_datetime(period).strftime('FY%y') for period in income_statement.periods]\n\n    # Reverse the order so most recent years are last (oldest to newest)\n    periods = periods[::-1]\n    revenue_values = revenue.values[::-1]\n    gross_profit_values = gross_profit.values[::-1]\n    net_income_values = net_income.values[::-1]\n\n    # Create a DataFrame for plotting\n    plot_data = pd.DataFrame({\n        'Revenue': revenue_values,\n        'Gross Profit': gross_profit_values,\n        'Net Income': net_income_values\n    }, index=periods)\n\n    # Convert to billions for better readability\n    plot_data = plot_data / 1e9\n\n    # Create the figure\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    # Plot the data as lines with markers\n    plot_data.plot(kind='line', marker='o', ax=ax, linewidth=2.5)\n\n    # Format the y-axis to show billions with 1 decimal place\n    ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f'${x:.1f}B'))\n\n    # Add labels and title\n    ax.set_xlabel('Fiscal Year')\n    ax.set_ylabel('Billions USD')\n    ax.set_title(f'{c.name} ({ticker}) Financial Performance')\n\n    # Add a grid for better readability\n    ax.grid(True, linestyle='--', alpha=0.7)\n\n    # Add a source note\n    plt.figtext(0.5, 0.01, 'Source: SEC EDGAR via edgartools', ha='center', fontsize=9)\n\n    # Improve layout\n    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n\n    return fig\n</code></pre>"},{"location":"examples/#2-investment-fund-research","title":"2. Investment Fund Research","text":"<p>Problem: Need to analyze fund holdings and compare share classes.</p> <pre><code>from edgar import find\n\n# Find a fund by ticker\nfund = find(\"VFIAX\")  # Vanguard 500 Index Fund\n\n# Get the fund's structure\nclasses = fund.get_classes()\nprint(f\"Fund has {len(classes)} share classes\")\n\n# Get the latest portfolio holdings\nportfolio = fund.get_portfolio()\n\n# Show top 10 holdings by value\ntop_holdings = portfolio.sort_values('value', ascending=False).head(10)\ntop_holdings\n</code></pre>"},{"location":"getting-started/","title":"Edgartools","text":"<p>Welcome to edgartools, the easiest way to work with SEC filings in Python</p>"},{"location":"getting-started/#getting-started","title":"Getting Started","text":""},{"location":"getting-started/#1-install","title":"1. Install","text":"<pre><code>pip install edgartools\n</code></pre> <p>There are frequent releases so it is a good idea to use <code>pip install -U edgartools</code> to get new features and bug fixes. That being said we try to keep the API stable and backwards compatible.</p> <p>If you prefer uv instead of pip you can use the following command:</p> <pre><code>uv pip install edgartools\n</code></pre>"},{"location":"getting-started/#2-import-edgar","title":"2. Import edgar","text":"<p>The main way to use the library is to import everything with <code>from edgar import *</code>. This will give you access to most of the functions and classes you need.</p> <pre><code>from edgar import *\n</code></pre> <p>If you prefer a minimal import you can use the following:</p>"},{"location":"getting-started/#3-set-your-identity","title":"3. Set your identity","text":"<p>Before you can access the SEC Edgar API you need to set the identity that you will use to access Edgar. This is usually your name and email, but you can also just use an email.</p> <p>You can set your identity in Python before you start using the library. </p>"},{"location":"getting-started/#setting-your-identity-in-python","title":"Setting your identity in Python","text":"<pre><code>from edgar import *\nset_identity(\"mike.mccalum@indigo.com\")\n</code></pre>"},{"location":"getting-started/#setting-your-identity-using-an-environment-variable","title":"Setting your identity using an environment variable","text":"<p>You can also set your identity using an environment variable. This is useful if you are using the library in a script or notebook.</p> <pre><code>export EDGAR_IDENTITY=\"mike.mccalum@indigo.com\"\n</code></pre>"},{"location":"getting-xbrl/","title":"Getting XBRL from Filings","text":""},{"location":"getting-xbrl/#overview","title":"Overview","text":"<p>The <code>edgar.xbrl</code> module provides a powerful yet user-friendly API for processing XBRL (eXtensible Business Reporting Language) financial data from SEC filings. </p>"},{"location":"getting-xbrl/#key-features","title":"Key Features","text":"<ul> <li>Intuitive API: Access financial statements with simple, readable method calls</li> <li>Multi-period Analysis: Compare financial data across quarters and years with statement stitching</li> <li>Standardized Concepts: View company-specific terms or standardized labels for cross-company comparison</li> <li>Rich Rendering: Display beautifully formatted financial statements in console or notebooks</li> <li>Smart Period Selection: Automatically identify and select relevant periods for meaningful comparisons</li> <li>DataFrame Export: Convert any statement to pandas DataFrames for further analysis</li> </ul>"},{"location":"getting-xbrl/#getting-started","title":"Getting Started","text":"<p>You can get the XBRL from a single filing, or stitch together multiple filings.</p>"},{"location":"getting-xbrl/#getting-xbrl-from-a-single-filing","title":"Getting XBRL from a single filing","text":"<p>For a single filing you can use <code>filing.xbrl()</code> to get the XBRL data, and then access the financial and other statements.</p> <pre><code>from edgar import Company\nfrom edgar.xbrl.xbrl import XBRL\n\n# Get a company's latest 10-K filing\ncompany = Company('AAPL')\nfiling = company.latest(\"10-K\")\n\n# Parse XBRL data\nxb = filing.xbrl()\n\n# Access statements through the user-friendly API\nstatements = xb.statements\n\n# Display financial statements\nbalance_sheet = statements.balance_sheet()\nincome_statement = statements.income_statement()\ncash_flow = statements.cashflow_statement()\n</code></pre>"},{"location":"getting-xbrl/#getting-xbrl-from-multiple-filings","title":"Getting XBRL from multiple filings","text":"<p>You can also stitch together multiple filings to create a multi-period view of financial statements. This uses the <code>edgar.XBRLS</code> class to combine data across multiple filings. Each filing should be of the same type (e.g., all 10-Ks or all 10-Qs) and from the same company.</p> <pre><code>from edgar import Company\nfrom edgar.xbrl import XBRLS\n\n# Get multiple filings for trend analysis\ncompany = Company('AAPL')\nfilings = company.get_filings(form=\"10-K\").head(3)  # Get the last 3 annual reports\n\n# Create a stitched view across multiple filings\nxbrls = XBRLS.from_filings(filings)\n\n# Access stitched statements\nstitched_statements = xbrls.statements\n\n# Display multi-period statements\nincome_trend = stitched_statements.income_statement()\nbalance_sheet_trend = stitched_statements.balance_sheet()\ncashflow_trend = stitched_statements.cashflow_statement()\n</code></pre>"},{"location":"getting-xbrl/#user-friendly-features","title":"User-Friendly Features","text":""},{"location":"getting-xbrl/#simple-statement-access","title":"Simple Statement Access","text":"<p>Access common financial statements with intuitive methods:</p> <pre><code># Get basic statements\nbalance_sheet = statements.balance_sheet()\nincome_statement = statements.income_statement()\ncash_flow = statements.cashflow_statement()\nstatement_of_equity = statements.statement_of_equity()\n\n# Access any statement by type\ncomprehensive_income = statements[\"ComprehensiveIncome\"]\n</code></pre>"},{"location":"getting-xbrl/#smart-period-views","title":"Smart Period Views","text":"<p>Choose from intelligent period selection views:</p> <pre><code># See available period views\nperiod_views = statements.get_period_views(\"IncomeStatement\")\nfor view in period_views:\n    print(f\"- {view['name']}: {view['description']}\")\n\n# Render with specific view\nannual_comparison = statements.income_statement(period_view=\"Annual Comparison\")\nquarter_comparison = statements.income_statement(period_view=\"Quarterly Comparison\")\n</code></pre>"},{"location":"getting-xbrl/#easy-conversion-to-dataframes","title":"Easy Conversion to DataFrames","text":"<p>Transform any statement into a pandas DataFrame for further analysis:</p> <pre><code># Get DataFrame of income statement\ndf = income_statement.to_dataframe()\n</code></pre>"},{"location":"getting-xbrl/#statement-stitching-for-trend-analysis","title":"Statement Stitching for Trend Analysis","text":"<p>The XBRLS class combines data from multiple periods with intelligent handling of concept changes:</p> <pre><code># Create stitched statements across multiple filings\nxbrls = XBRLS.from_filings(filings)\nstitched = xbrls.statements\n\n# Get a three-year comparison of income statements\nincome_trend = stitched.income_statement(max_periods=3)\n\n# Convert to DataFrame for time series analysis\ntrend_df = income_trend.to_dataframe()\n</code></pre>"},{"location":"getting-xbrl/#rendering-options","title":"Rendering Options","text":"<p>The XBRL2 module provides flexible output options for financial statements:</p> <pre><code># Display with default styling as Rich tables in console/notebooks\nprint(statements.balance_sheet())\n\n# Show full date ranges for duration periods\nprint(statements.income_statement(show_date_range=True))\n\n# Customize period view\nprint(statements.income_statement(period_view=\"Annual Comparison\"))\n\n# Convert to pandas DataFrame for analysis\ndf = statements.to_dataframe(\"BalanceSheet\")\n\n# Export the statement to markdown\nincome_statement = statements.income_statement()\nmarkdown_text = income_statement.render().to_markdown()\n</code></pre>"},{"location":"getting-xbrl/#statement-display-options","title":"Statement Display Options","text":"<p>The rendering system offers several customization options:</p> Option Description <code>standard=True</code> Use standardized labels for cross-company comparison (default) <code>standard=False</code> Use company-specific labels as reported in the filing <code>show_date_range=True</code> Show complete date ranges for duration periods (e.g., \"Jan 1 - Mar 31, 2023\") <code>show_date_range=False</code> Show only end dates for cleaner presentation (default) <code>period_view=\"Name\"</code> Select a predefined period view (\"Annual Comparison\", \"Quarterly Comparison\", etc.) <code>period_filter=\"duration_...\"</code> Filter to a specific period by period key"},{"location":"getting-xbrl/#the-renderedstatement-class","title":"The <code>RenderedStatement</code> Class","text":"<p>The <code>render_statement()</code> function returns a <code>RenderedStatement</code> object, which provides multiple output formats:</p> <pre><code># Get a rendered statement\nstatement = xbrl.render_statement(\"BalanceSheet\")\n\n# Display as Rich table (default)\nprint(statement)\n\n# Convert to pandas DataFrame \ndf = statement.to_dataframe()\n\n# Export to markdown\nmarkdown = statement.to_markdown()\n</code></pre>"},{"location":"getting-xbrl/#customizing-statement-appearance","title":"Customizing Statement Appearance","text":"<p>The rendering engine automatically handles:</p> <ul> <li>Proper monetary formatting with scale indicators (thousands, millions, billions)</li> <li>Appropriate indentation for statement hierarchy</li> <li>Formatting of section headers and dimension items</li> <li>Correct display of share counts and per-share values</li> <li>Fiscal period indicators in statement titles</li> <li>Unit notes (e.g., \"In millions, except per share data\")</li> </ul> <p>For stitched multi-period statements, you can control the number of periods and date formatting:</p> <pre><code># Get 3-year comparison with full date ranges\nannual_trend = stitched_statements.income_statement(\n    max_periods=3, \n    show_date_range=True\n)\n</code></pre>"},{"location":"getting-xbrl/#advanced-features","title":"Advanced Features","text":""},{"location":"getting-xbrl/#custom-period-selection","title":"Custom Period Selection","text":"<pre><code># Get specific periods from available options\navailable_periods = xbrl.reporting_periods\nlatest_period = available_periods[0]\n\n# Render with specific period\nif latest_period['type'] == 'instant':\n    period_filter = f\"instant_{latest_period['date']}\"\n    latest_balance_sheet = statements.balance_sheet().render(period_filter=period_filter)\n</code></pre>"},{"location":"getting-xbrl/#statement-data-exploration","title":"Statement Data Exploration","text":"<pre><code># Get raw statement data for custom processing\nraw_data = statements.balance_sheet().get_raw_data()\n\n# Extract specific information\nassets = [item for item in raw_data if 'assets' in item['label'].lower()]\n</code></pre>"},{"location":"getting-xbrl/#design-philosophy","title":"Design Philosophy","text":"<p>The XBRL2 module is designed with these principles:</p> <ol> <li>User-First API: Simple methods that match how financial analysts think about statements</li> <li>Intelligent Defaults: Smart period selection and formatting that \"just works\" out of the box</li> <li>Flexible Output Options: Rich tables for display, DataFrames for analysis, and raw data for custom processing</li> <li>Consistency Across Companies: Standardized concepts that enable cross-company comparison</li> </ol>"},{"location":"getting-xbrl/#period-selection-logic","title":"Period Selection Logic","text":"<p>The XBRL2 module implements sophisticated period selection logic to ensure appropriate periods are displayed for financial statements:</p>"},{"location":"getting-xbrl/#quarterly-statement-period-selection","title":"Quarterly Statement Period Selection","text":"<p>When rendering quarterly statements (when fiscal_period_focus is Q1, Q2, Q3, or Q4):</p> <ol> <li>The system identifies true quarterly periods by filtering duration periods to those with 80-100 day durations</li> <li>If quarterly periods are found, the most recent one is selected as the current quarter</li> <li>For comparison, the system looks for periods with similar duration from approximately 1-2 years prior</li> <li>If no quarterly periods are found, it falls back to the most recent period with a warning</li> </ol>"},{"location":"getting-xbrl/#annual-statement-period-selection","title":"Annual Statement Period Selection","text":"<p>For annual reports (when fiscal_period_focus is FY):</p> <ol> <li>Annual periods are identified by looking for ~365 day durations or fiscal year markers</li> <li>The system prioritizes periods that align with the entity's fiscal year end</li> <li>Up to three most recent fiscal years are displayed in chronological order</li> </ol> <p>This intelligent period selection ensures appropriate periods are displayed for statements, with robust fallbacks when ideal periods aren't available.</p>"},{"location":"getting-xbrl/#enhanced-facts-api","title":"Enhanced Facts API","text":"<p>The XBRL2 module includes a powerful facts query interface for direct access to individual XBRL facts:</p> <pre><code>from edgar import Company\nfrom edgar.xbrl import XBRL\n\n# Parse XBRL data\ncompany = Company('AAPL')\nfiling = company.get_filings(form='10-K').latest()\n\nxbrl = XBRL.from_filing(filing)\n\n# Access the facts view\nfacts = xbrl.facts\n\n# Query facts by various attributes\nrevenue = facts.query().by_concept('Revenue').to_dataframe()\nbalance_sheet_facts = facts.query().by_statement_type('BalanceSheet').to_dataframe()\n\n# Use predefined period views - returns important metadata including available periods\nincome_views = facts.get_available_period_views('IncomeStatement')\nfor view in income_views:\n    print(f\"- {view['name']}: {view['description']} ({view['facts_count']} facts)\")\n\n# Get facts filtered by period view\nannual_comparison = facts.get_facts_by_period_view('IncomeStatement', 'Annual Comparison')\n\n# Flexible text search across all text fields (concept, label, element name)\nearnings_facts = facts.search_facts(\"Earnings Per Share\")\n\n# Filter by period keys - useful for custom period selection\nfacts.query().by_period_keys(['duration_2023-01-01_2023-12-31',\n                              'duration_2022-01-01_2022-12-31']).to_dataframe()\n\n# Query dimensional data\nfacts_by_segment = facts.query().by_dimension('Segment').to_dataframe()\n\n# Safe numeric value filtering with proper None handling\nlarge_income_items = (facts.query()\n    .by_statement_type('IncomeStatement')\n    .by_value(lambda v: v &gt; 1_000_000_000)\n    .sort_by('numeric_value', ascending=False)\n    .to_dataframe())\n\n# Time series analysis\nrevenue_over_time = facts.time_series('Revenue')\n</code></pre>"},{"location":"getting-xbrl/#xbrl-calculation-support","title":"XBRL Calculation Support","text":"<p>The XBRL2 module properly handles calculation relationships from XBRL calculation linkbases:</p> <pre><code># Values are automatically adjusted according to calculation weights\n# For example, elements with negative weights (-1.0) like \"IncreaseDecreaseInInventories\"\n# are automatically negated to maintain proper calculation relationships\ncash_flow_statement = statements.cashflow_statement()\n\n# The calculation trees are accessible for inspection\nfor role_uri, calc_tree in xbrl.calculation_trees.items():\n    print(f\"Calculation tree: {calc_tree.definition}\")\n    for element_id, node in calc_tree.all_nodes.items():\n        if node.weight != 1.0:\n            print(f\"- {element_id}: weight={node.weight}\")\n</code></pre> <p>The parser intelligently applies calculation weights to ensure consistent financial data presentation:</p> <ol> <li>Expense Concept Consistency: Major expense categories (R&amp;D, SG&amp;A, Marketing, etc.) are consistently positive across companies, matching SEC CompanyFacts API behavior</li> <li>Cash Flow Integrity: Elements with negative weights (-1.0) in cash flow statements maintain proper sign relationships for accurate calculations</li> <li>Legitimate Negatives Preserved: Concepts that should be negative (tax benefits, foreign exchange gains/losses) retain their intended signs</li> <li>Cross-Company Comparability: Eliminates inconsistencies where MSFT showed R&amp;D as negative while AAPL showed positive values</li> </ol> <pre><code># Example: R&amp;D expenses are now consistently positive across companies\nmsft_statements = msft_xbrl.statements.income_statement()\naapl_statements = aapl_xbrl.statements.income_statement()\n\n# Both show R&amp;D as positive values for proper comparison\nmsft_rnd = msft_statements.get_concept_value(\"ResearchAndDevelopmentExpense\")  # $32.5B (positive)\naapl_rnd = aapl_statements.get_concept_value(\"ResearchAndDevelopmentExpense\")  # $31.4B (positive)\n</code></pre>"},{"location":"getting-xbrl/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Enhanced support for non-standard financial statements</li> <li>Interactive visualization options</li> <li>Expanded dimensional analysis capabilities</li> <li>Automatic footnote association</li> <li>Financial ratio calculations</li> <li>Advanced calculation validation and reconciliation</li> </ul>"},{"location":"initial-steps/","title":"Initial Steps","text":""},{"location":"initial-steps/#getting-filings","title":"Getting Filings","text":"<p>The library is designed to be easy to use and flexible. You can start by getting all filings for the current year and quarter with <code>get_filings()</code>.</p> <pre><code>filings = get_filings()\n</code></pre> <p></p> <p>You can expand beyond the current year and quarter by using the parameters of the <code>get_filings</code> function.</p> <p>For example you can specify the year you want to get filings for:</p> <pre><code>filings = get_filings(year=2021)\n</code></pre> <p>For more details on filtering filings see the Filtering Filings docs</p>"},{"location":"initial-steps/#selecting-a-filing","title":"Selecting a filing","text":"<p>You can select a filing using the <code>[]</code> operator. For example to get the third filing in the list:</p> <pre><code>filing = filings[3]\n</code></pre>"},{"location":"initial-steps/#paginating-filings","title":"Paginating filings","text":"<p>The <code>Filings</code> object is a container for a list of filings. The list of filings can  be large but by default you can only see the first page of filings. </p> <p>To change the page, you can paginate filings using the <code>next</code> and <code>prev</code> methods. For example:</p> <pre><code>filings = get_filings()\nfilings.next()\nfilings.previous()\n</code></pre>"},{"location":"initial-steps/#looping-through-filings","title":"Looping through filings","text":"<p>You can loop through filings using the <code>for</code> loop. For example:</p> <pre><code>\nfilings = get_filings()\nfor filing in filings:\n    # Do something with the filing\n    ...\n</code></pre>"},{"location":"initial-steps/#getting-related-filings","title":"Getting Related Filings","text":"<p>Filings can be related to other filings using the file number. In some cases this relationship can be meaningful, as in they represent a group of filings for a specific securities offering. The link between the filing is via the <code>file_number</code> attribute of the filing, which is an identifier that the SEC uses to group filings.</p> <p>You can get related filings using the <code>get_related_filings</code> method. For example:</p> <pre><code>filing = get_filing('0000320193-22-000002')\nfilings = filing.related_filings()\n</code></pre>"},{"location":"initial-steps/#getting-a-company","title":"Getting a Company","text":"<p>You can start by getting a company by CIK or Ticker with <code>Company()</code>. For example:</p> <pre><code>c = Company(\"AAPL\")\n</code></pre> <p>You can also get a company by CIK. For example:</p> <pre><code>c = Company(\"0000320193\")\n</code></pre> <p>To get a Company by ticker, the library first does a lookup of the CIK for the ticker and then gets filings for the CIK. So if you know the CIK, it is faster to use that directly.</p>"},{"location":"initial-steps/#company-filings","title":"Company Filings","text":"<p>You can get the filings for a company by using the <code>get_filings()</code> function. For example:</p> <pre><code>filings = c.get_filings()\n</code></pre>"},{"location":"initial-steps/#getting-company-facts","title":"Getting Company Facts","text":"<p>You can get facts for a company using the <code>get_facts()</code> method. For example:</p> <pre><code>facts = c.get_facts()\n</code></pre> <p>The result is an <code>EntityFacts</code> object that wraps the data returned from the SEC API. To get the data as a dataframe use the <code>to_pandas()</code> method. For example:</p> <pre><code>facts_df = facts.to_pandas()\n</code></pre>"},{"location":"initial-steps/#getting-company-financials","title":"Getting Company Financials","text":"<p>You can get financials for a company using the <code>get_financials</code> function. For example:</p> <pre><code>financials = c.get_financials()\nfinancials.income_statement()\n</code></pre>"},{"location":"initial-steps/#viewing-unpublished-filings","title":"Viewing unpublished filings","text":"<p>The SEC publishes the filing indexes week nights by 10:30 PM EST. To get the latest filings not yet in the index use the <code>get_latest_filings</code> function. For example:</p> <pre><code>filings = get_latest_filings()\n</code></pre>"},{"location":"insider-filings/","title":"Insider Filings","text":"<p>Insider filings are reports filed by company insiders (such as officers, directors, and employees) when they buy or sell shares in their own companies. </p> <p>There are several types of insider filings that investors should be aware of:</p> <ol> <li>Form 3: Filed by insiders to report their initial ownership of company stock - typically filed when an insider joins a company or becomes an officer or director.</li> <li>Form 4: Filed to report any changes in ownership of company stock - typically filed when an insider buys or sells company stock.</li> <li>Form 5: Includes any transactions that were not reported on Form 4 - typically filed at the end of the fiscal year.</li> </ol>"},{"location":"insider-filings/#getting-insider-filings","title":"Getting Insider Filings","text":"<p>You can access insider filings using the <code>get_filings</code> method of the <code>Company</code> class.</p> <pre><code>c = Company(\"VRTX\")\nfilings = c.get_filings(form=[3,4,5])\n</code></pre> <p>You can use either the string or numeric value for the form e.g. \"3\" or 3.</p> <pre><code>filings = c.get_filings(form=4)\n</code></pre> <p>If you are more interested in insider filings non-specific to a particular company, you can use the <code>get_insider_filings</code> method of the <code>Filing</code> class.</p> <pre><code>filings = get_filings(form=[3,4,5])\n</code></pre>"},{"location":"insider-filings/#the-ownership-data-object","title":"The Ownership data object","text":"<p>The <code>Ownership</code> object is a data object that represents the basic information contained in an insider filing. It is created by parsing the  XML attachment with the data about the insider transactions in the filing. </p> <p>The <code>Ownership</code> is subclassed into <code>Form3</code>, <code>Form4</code>, and <code>Form5</code> objects that contain additional information specific to the type of filing. So if you have a Form 3 filing you can convert the <code>Ownership</code> object to a <code>Form3</code> object to get the additional information.</p> <pre><code>form3 = filing.obj()\n</code></pre>"},{"location":"insider-filings/#converting-ownership-to-a-dataframe","title":"Converting Ownership to a dataframe","text":"<p>You can convert the <code>Ownership</code> object to a pandas dataframe using the <code>to_dataframe()</code> method.</p> <pre><code>df = form4.to_dataframe()\n</code></pre> <p></p> <p>By default this will show each of the trades made in that filing. If you want to see the aggregated summary of the trades you can set <code>detailed=False</code></p> <pre><code>df = form4.to_dataframe(detailed=False)\n</code></pre> <p></p> <p>By default the dataframe will include metadata about the filing. If you want to exclude the metadata you can set <code>include_metadata=False</code></p> <pre><code>df = form4.to_dataframe(include_metadata=False)\n</code></pre> <p></p> <p>The specifics of the data in the dataframe will depend on the type of filing and the information contained in the filing.</p>"},{"location":"insider-filings/#form-3-initial-beneficial-ownership","title":"Form 3 - Initial Beneficial Ownership","text":"<p>The <code>Form3</code> data object is created from a form 3 filing as follows</p> <pre><code>form3 = filing.obj()\n</code></pre> <p></p>"},{"location":"insider-filings/#form-4-changes-in-beneficial-ownership","title":"Form 4 - Changes in Beneficial Ownership","text":"<p>In November 2020 Bruce Sachs, an independent director of Vertex Pharmaceuticals, filed a Form 4 to report the purchase of 15,000 shares of Vertex Pharmaceuticals (VRTX) at an average price of $217.36 per share.</p> <p></p> <p>The filing object shows basic information but none of the details of the transaction. To get the details of the transaction you can use the <code>obj()</code> method to convert the filing to a <code>Form4</code> object.</p> <pre><code>form4 = filing.obj()\n</code></pre> <p></p> <p>The form 4 shows the individual transactions that make up the total transaction. In this case, the total transaction was the purchase of 15,000 shares of Vertex Pharmaceuticals.</p> <p>Additional information about the transaction can be found in the <code>TransactionSummary</code> object.</p> <pre><code>ownership_summary = form4.get_ownership_summary()\n</code></pre> <p></p>"},{"location":"insider-filings/#form-5-annual-changes-in-beneficial-ownership","title":"Form 5 - Annual Changes in Beneficial Ownership","text":"<p>Form 5 filings are essentially the same as Form 4 filings but are filed at the end of the fiscal year to report any transactions that were not reported on Form 4. So the data in a Form 5 filing will be similar to that in a Form 4 filing.</p>"},{"location":"insider-filings/#ownership-summary","title":"Ownership Summary","text":"<p>The <code>Ownership</code> object has a <code>get_ownership_summary()</code> method that returns either an <code>InitialOwnershipSummary</code> for Form 3 filings or a <code>TransactionSummary</code> object for Forms 4 and 5. These object contain more specific details about the ownership filing.</p> <pre><code>ownership_summary = form4.get_ownership_summary()\n</code></pre>"},{"location":"insider-filings/#initial-ownership-summary","title":"Initial Ownership Summary","text":"<p>The <code>InitialOwnershipSummary</code> object contains the following fields:</p> <ul> <li><code>total_shares</code> - the total number of shares owned by the insider</li> <li><code>has_derivatives</code> - a boolean indicating whether the insider owns any derivatives</li> <li><code>no_securities</code> - a boolean indicating whether the insider owns any securities</li> <li><code>holdings</code>: List[SecurityHolding] - a list of SecurityHolding objects representing the insider's holdings</li> </ul> <p>The <code>SecurityHolding</code> object is defined as follows:</p> <pre><code>@dataclass\nclass SecurityHolding:\n    \"\"\"Represents a security holding (for Form 3)\"\"\"\n    security_type: str  # \"non-derivative\" or \"derivative\"\n    security_title: str\n    shares: int\n    direct_ownership: bool\n    ownership_nature: str = \"\"\n    underlying_security: str = \"\"\n    underlying_shares: int = 0\n    exercise_price: Optional[float] = None\n    exercise_date: str = \"\"\n    expiration_date: str = \"\"\n</code></pre> <p><code>SecurityHolding</code> also has these properties</p> <ul> <li><code>ownership_description</code> - a human-readable description of the type of ownership \"Direct/Indirect\"</li> <li><code>is_derivative</code> - a boolean indicating whether the holding is a derivative</li> </ul>"},{"location":"insider-filings/#transaction-summary","title":"Transaction Summary","text":"<p>The <code>TransactionSummary</code> object is defined as follows:</p> <pre><code>@dataclass\nclass TransactionActivity:\n    \"\"\"Represents a specific transaction activity type\"\"\"\n    transaction_type: str\n    code: str\n    shares: Any = 0  # Handle footnote references\n    value: Any = 0\n    price_per_share: Any = None  # Add explicit price per share field\n    description: str = \"\"\n</code></pre> <p>It also has these properties as a convenience in case any of the expected numeric values are not in fact numeric.</p> <ul> <li><code>shares_numeric</code> - the number of shares involved in the transaction</li> <li><code>value_numeric</code> - the value of the transaction</li> <li><code>price_numeric</code> - the price per share of the transaction</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>Get started with edgartools in minutes. This guide covers all installation methods and system requirements.</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.8 or higher</li> </ul>"},{"location":"installation/#quick-installation","title":"Quick Installation","text":""},{"location":"installation/#using-pip-recommended","title":"Using pip (Recommended)","text":"<pre><code>pip install edgartools\n</code></pre> <p>For the latest features and bug fixes:</p> <pre><code>pip install -U edgartools\n</code></pre>"},{"location":"installation/#using-uv-fast-alternative","title":"Using uv (Fast Alternative)","text":"<pre><code>uv pip install edgartools\n</code></pre>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>If you want to contribute or use the latest development version:</p> <pre><code># Clone the repository\ngit clone https://github.com/dgunning/edgartools.git\ncd edgartools\n\n# Install in development mode\npip install -e .\n\n# Or with development dependencies\npip install -e \".[dev]\"\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>Test your installation by running this simple command:</p> <pre><code>from edgar import get_filings\nprint(\"EdgarTools installed successfully!\")\n</code></pre> <p>Expected output:</p> <pre><code>EdgarTools installed successfully!\n</code></pre> <p>If you see this message, your installation is successful. </p> <p>If you see <code>ImportError: cannot import name 'get_filings' from 'edgar'</code> then you have likely installed another package named edgar not edgartools. If you encounter this error, uninstall the conflicting package and reinstall edgartools:</p> <pre><code>pip uninstall edgar\npip install edgartools\n</code></pre>"},{"location":"installation/#setting-your-identity","title":"Setting Your Identity","text":"<p>Before using edgartools, you must set your identity to comply with SEC requirements:</p>"},{"location":"installation/#method-1-in-python-code","title":"Method 1: In Python Code","text":"<pre><code>from edgar import set_identity\n\n# Use your name and email\nset_identity(\"John Doe john.doe@company.com\")\n\n# Or just your email\nset_identity(\"john.doe@company.com\")\n</code></pre>"},{"location":"installation/#method-2-environment-variable","title":"Method 2: Environment Variable","text":"<p>Set the <code>EDGAR_IDENTITY</code> environment variable:</p> <p>Linux/macOS:</p> <pre><code>export EDGAR_IDENTITY=\"John Doe john.doe@company.com\"\n</code></pre> <p>Windows:</p> <pre><code>set EDGAR_IDENTITY=John Doe john.doe@company.com\n</code></pre> <p>Windows PowerShell:</p> <pre><code>$env:EDGAR_IDENTITY = \"John Doe john.doe@company.com\"\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For enhanced functionality, install these optional packages:</p>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#common-issues","title":"Common Issues","text":""},{"location":"installation/#importerror-no-module-named-edgar","title":"ImportError: No module named 'edgar'","text":"<p>Problem: Package not installed correctly Solution: </p> <pre><code>pip uninstall edgar\npip install --force-reinstall edgartools\n</code></pre>"},{"location":"installation/#sec-identity-error","title":"SEC Identity Error","text":"<p>Problem: Identity not set Solution: Follow the Setting Your Identity section above</p>"},{"location":"installation/#permission-errors-on-windows","title":"Permission Errors on Windows","text":"<p>Problem: Insufficient permissions Solution: Run as administrator or use <code>--user</code> flag:</p> <pre><code>pip install --user edgartools\n</code></pre>"},{"location":"installation/#ssl-certificate-errors","title":"SSL Certificate Errors","text":"<p>Problem: Corporate firewall or proxy Solution: Configure pip for your proxy:</p> <pre><code>pip install --trusted-host pypi.org --trusted-host pypi.python.org edgartools\n</code></pre>"},{"location":"installation/#memory-issues-with-large-datasets","title":"Memory Issues with Large Datasets","text":"<p>Problem: Out of memory errors Solution:  - Increase system memory - Use data chunking techniques - Process data in smaller batches</p>"},{"location":"installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Search existing issues: GitHub Issues</li> <li>Create a new issue: Include Python version, OS, and error messages</li> <li>Join the community: Discussions and support channels</li> </ol>"},{"location":"installation/#virtual-environment-setup","title":"Virtual Environment Setup","text":"<p>For isolated development, use virtual environments:</p>"},{"location":"installation/#using-venv-python-38","title":"Using venv (Python 3.8+)","text":"<pre><code># Create virtual environment\npython -m venv edgar-env\n\n# Activate (Linux/macOS)\nsource edgar-env/bin/activate\n\n# Activate (Windows)\nedgar-env\\Scripts\\activate\n\n# Install edgartools\npip install edgartools\n\n# Deactivate when done\ndeactivate\n</code></pre>"},{"location":"installation/#performance-optimization","title":"Performance Optimization","text":"<p>For optimal performance:</p> <ol> <li>Use Local Storage to download and work with SEC filings locally</li> <li>Set reasonable limits when querying large datasets</li> <li>Use filtering to reduce data transfer</li> </ol>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>After installation:</p> <ol> <li>Read the Quick Start Guide for your first analysis</li> <li>Check the API Reference for detailed documentation</li> </ol>"},{"location":"installation/#security-considerations","title":"Security Considerations","text":"<ul> <li>Never commit your identity to version control</li> <li>Use environment variables for production deployments</li> <li>Follow SEC rate limits to avoid being blocked</li> <li>Keep your installation updated for security patches</li> </ul>"},{"location":"installation/#license","title":"License","text":"<p>EdgarTools is released under the MIT License. See LICENSE for details.</p>"},{"location":"navigating-filings/","title":"Navigating Filings","text":""},{"location":"navigating-filings/#paginating-filings","title":"Paginating filings","text":"<p>The <code>Filings</code> object is a container for a list of filings. The list of filings can  be large but by default you can only see the first page of filings. </p> <p>To change the page, you can paginate filings using the <code>next</code> and <code>prev</code> methods. For example:</p> <pre><code>filings = get_filings()\nfilings.next()\nfilings.previous()\n</code></pre>"},{"location":"navigating-filings/#looping-through-filings","title":"Looping through filings","text":"<p>You can loop through filings using the <code>for</code> loop. For example:</p> <pre><code>\nfilings = get_filings()\nfor filing in filings:\n    ...\n    # Do something with the filing\n</code></pre>"},{"location":"navigating-filings/#getting-related-filings","title":"Getting Related Filings","text":"<p>Filings can be related to other filings using the file number. In some cases this relationship can be meaningful, as in they represent a group of filings for a specific securities offering. The link between the filing is via the <code>file_number</code> attribute of the filing, which is an identifier that the SEC uses to group filings.</p> <p>You can get related filings using the <code>get_related_filings</code> method. For example:</p> <pre><code>filing = get_filing('0000320193-22-000002')\nfilings = filing.related_filings()\n</code></pre>"},{"location":"parsing-filing-data/","title":"Parsing Filing Data","text":"<p>An SEC filing represents information a company wishes to make public. The information is sometimes contained in data files attached to the filing, such as XBRL, XML or JSON.</p> <p>In edgartools each Filing has a <code>.obj()</code> function that converts the filing to a parsed version of the data file.</p> <p>For example, the following code converts the filing for the 10-K for Apple Inc. to a <code>TenK</code> object containing the data from the filing:</p> <pre><code>from edgar import get_filings \nfilings = get_filings(form=\"10-K\")\nfiling = filings[0]\ntenk = filing.obj()\n</code></pre> <p>Under the hood, the <code>.obj()</code> function gets the data file for the filing, which is usually the filing's XML, parses it, and converts it to the approaptate data object.</p> <p>If a filing has no corresponding data object, the <code>.obj()</code> function returns <code>None</code></p>"},{"location":"parsing-filing-data/#filing-types-with-data-objects","title":"Filing types with data objects","text":"<p>The following table lists the filing types that have data objects:</p> Filing type Data object Description 10-K <code>TenK</code> Annual report 10-Q <code>TenQ</code> Quarterly report 8-K <code>EightK</code> Current report 144 <code>Form144</code> Insider trading report 3,4,5 <code>Ownership</code> Insider trading report D <code>Effect</code> Effect filing for the Form D NPORT <code>NPORT</code> Investment company report 13F-HR <code>ThirteenF</code> Institutional investment manager's report Any other filing with XBRL <code>XbrlFiling</code> XBRL filing object with the data"},{"location":"parsing-filing-data/#ownership-documents","title":"Ownership Documents","text":"<p>Ownership documents are SEC forms that contain information about ownership of securities.</p>"},{"location":"parsing-filing-data/#ownership-forms","title":"Ownership Forms","text":"Form Description 3 Initial statement of beneficial ownership of securities 4 Statement of changes of beneficial ownership of securities 5 Annual statement of changes in beneficial ownership of securities <p>The module <code>edgar.ownership</code> module parses XML into an <code>OwnershipDocument</code> instance,  containing data about transactions and holdings.</p>"},{"location":"parsing-filing-data/#getting-ownership-documents","title":"Getting Ownership Documents","text":"<ul> <li>get a form 3, 4, or 5 filing</li> <li>get the xml document</li> <li>call <code>OwnershipDocument.from_xml()</code></li> </ul> <pre><code>from edgar import CompanyData\nfrom edgar.ownership import Ownership\n\n# Get Snowflake\ncompany = CompanyData.for_ticker(\"SNOW\")\n\n# Get Form 4 filings for Snowflake\nfilings = company.get_filings(form=\"4\")\n\n# Get the first filing\nfiling = filings[0]\n\n# Get the filing xml\nxml = filing.xml()\n\n# Now get the OwnershipDocument\nownership = Ownership.from_xml(xml)\n</code></pre>"},{"location":"parsing-filing-data/#derivative-table","title":"Derivative Table","text":"<p>This contains data on derivative holdings and transactions. To access it call <code>ownership_document.derivatives</code>.</p>"},{"location":"parsing-filing-data/#derivative-holdings","title":"Derivative Holdings","text":"<p>To access derivative transactions use <code>ownership.derivatives.holdings</code></p>"},{"location":"parsing-filing-data/#derivative-transactions","title":"Derivative Transactions","text":"<p>To access derivative transactions use <code>ownership.derivatives.transactions</code></p> <p>You can access individual transaction using the <code>[]</code> notation.</p> <pre><code>ownership.derivative_table.transactions[0]\n</code></pre> <p></p>"},{"location":"parsing-filing-data/#non-derivative-table","title":"Non Derivative Table","text":"<p>This contains data on non-derivative holdings and transactions. To access it call <code>ownership_document.non_ derivatives</code>.</p>"},{"location":"parsing-filing-data/#non-derivative-holdings","title":"Non Derivative Holdings","text":"<p>To access derivative holdings use <code>ownership.non_derivatives.holdings</code></p> <p>You can access individual holdings using the <code>[]</code> notation.</p> <pre><code>holding = ownership.non_derivative_table.holdings[0]\nholding\n</code></pre> <p></p>"},{"location":"parsing-filing-data/#non-derivative-transactions","title":"Non Derivative Transactions","text":"<p>To access derivative transactions use <code>ownership.non_derivatives.transactions</code></p> <p>You can access individual transactions using the <code>[]</code> notation.</p> <pre><code>transaction = ownership.non_derivative_table.transactions[0]\ntransaction\n</code></pre>"},{"location":"quick-guide/","title":"Quick Guide","text":"Code Set your EDGAR identity in Linux/Mac <code>export EDGAR_IDENTITY=\"email@domain.com\"</code> Set your EDGAR identity in Windows <code>set EDGAR_IDENTITY=\"email@domain.com\"</code> Set identity in Windows Powershell <code>$env:EDGAR_IDENTITY=\"email@domain.com\"</code> Set identity in Python <code>set_identity(\"email@domain.com\")</code> Importing the library <code>from edgar import *</code>"},{"location":"quick-guide/#working-with-filings","title":"Working with filings \ud83d\udcc1","text":""},{"location":"quick-guide/#getting-filings","title":"\ud83d\udd0d Getting Filings","text":"Code \ud83d\udcc5 Get filings for the year to date <code>filings = get_filings()</code> \ud83d\udcca Get only XBRL filings <code>filings = get_filings(index=\"xbrl\")</code> \ud83d\udcc6 Get filings for a specific year <code>filings = get_filings(2020)</code> \ud83d\uddd3\ufe0f Get filings for a specific quarter <code>filings = get_filings(2020, 1)</code> \ud83d\udcda Get filings for multiple years <code>filings = get_filings([2020, 2021])</code> \ud83d\udcc8 Get filings for a range of years <code>filings = get_filings(year=range(2010, 2020))</code> \ud83d\udcc8 Get filings released just now <code>filings = get_latest_filings()</code>"},{"location":"quick-guide/#filtering-filings","title":"\ud83d\udcc4 Filtering Filings","text":"Code \ud83d\udcdd Filter by form type <code>filings.filter(form=\"10-K\")</code> \ud83d\udcd1 Filter by multiple forms <code>filings.filter(form=[\"10-K\", \"10-Q\"])</code> \ud83d\udd04 Include form amendments <code>filings.filter(form=\"10-K\", amendments=True)</code> \ud83c\udfe2 Filter by CIK <code>filings.filter(cik=\"0000320193\")</code> \ud83c\udfd9\ufe0f Filter by multiple CIKs <code>filings.filter(cik=[\"0000320193\", \"1018724\"])</code> \ud83c\udff7\ufe0f Filter by ticker <code>filings.filter(ticker=\"AAPL\")</code> \ud83c\udff7\ufe0f\ud83c\udff7\ufe0f Filter by multiple tickers <code>filings.filter(ticker=[\"AAPL\", \"MSFT\"])</code> \ud83d\udcc5 Filter on a specific date <code>filings.filter(date=\"2020-01-01\")</code> \ud83d\udcc5\u2194\ufe0f\ud83d\udcc5 Filter between dates <code>filings.filter(date=\"2020-01-01:2020-03-01\")</code> \ud83d\udcc5\u2b05\ufe0f Filter before a date <code>filings.filter(date=\":2020-03-01\")</code> \ud83d\udcc5\u27a1\ufe0f Filter after a date <code>filings.filter(date=\"2020-03-01:\")</code> \ud83d\udd00 Combine multiple filters <code>filings.filter(form=\"10-K\", date=\"2020-01-01:\", ticker=\"AAPL\")</code>"},{"location":"quick-guide/#viewing-and-manipulating-filings","title":"\ud83d\udcca Viewing and Manipulating Filings","text":"Code \u23ed\ufe0f Show the next page of filings <code>filings.next()</code> \u23ee\ufe0f Show the previous page of filings <code>filings.previous()</code> \ud83d\udd1d Get the first n filings <code>filings.head(20)</code> \ud83d\udd1a Get the last n filings <code>filings.tail(20)</code> \ud83d\udd52 Get the latest n filings by date <code>filings.latest(20)</code> \ud83c\udfb2 Get a random sample of filings <code>filings.sample(20)</code> \ud83d\udc3c Get filings as a pandas dataframe <code>filings.to_pandas()</code>"},{"location":"quick-guide/#working-with-a-filing","title":"Working with a filing \ud83d\udcc4","text":""},{"location":"quick-guide/#accessing-and-viewing-a-filing","title":"\ud83d\udd0d Accessing and viewing a Filing","text":"Code \ud83d\udccc Get a single filing <code>filing = filings[3]</code> \ud83d\udd22 Get a filing by accession number <code>filing = get_by_accession_number(\"0000320193-20-34576\")</code> \ud83c\udfe0 Get the filing homepage <code>filing.homepage</code> \ud83c\udf10 Open a filing in the browser <code>filing.open()</code> \ud83c\udfe0 Open homepage in the browser <code>filing.homepage.open()</code> \ud83d\udcbb View the filing in the terminal <code>filing.view()</code>"},{"location":"quick-guide/#extracting-filing-content","title":"\ud83d\udcca Extracting Filing Content","text":"Code \ud83c\udf10 Get the HTML of the filing <code>filing.html()</code> \ud83d\udcca Get the XBRL of the filing <code>filing.xbrl()</code> \ud83d\udcdd Get the filing as markdown <code>filing.markdown()</code> \ud83d\udcc4 Get the full submission text <code>filing.full_text_submission()</code> \ud83d\udd22 Get and parse filing data object <code>filing.obj()</code> \ud83d\udcd1 Get filing header <code>filing.header</code>"},{"location":"quick-guide/#searching-inside-a-filing","title":"\ud83d\udd0e Searching inside a Filing","text":"Code \ud83d\udd0d Search within the filing <code>filing.search(\"query\")</code> \ud83d\udd0d Search with regex <code>filing.search(\"pattern\", regex=True)</code> \ud83d\udcca Get filing sections <code>filing.sections()</code>"},{"location":"quick-guide/#working-with-attachments","title":"\ud83d\udcce Working with Attachments","text":"Code \ud83d\udcc1 Get all filing attachments <code>filing.attachments</code> \ud83d\udcc4 Get a single attachment <code>attachment = filing.attachments[0]</code> \ud83c\udf10 Open attachment in browser <code>attachment.open()</code> \u2b07\ufe0f Download an attachment <code>content = attachment.download()</code>"},{"location":"quick-guide/#working-with-a-company","title":"Working with a company","text":"Code Get a company by ticker <code>company = Company(\"AAPL\")</code> Get a company by CIK <code>company = Company(\"0000320193\")</code> Get company facts <code>company.get_facts()</code> Get company facts as a pandas dataframe <code>company.get_facts().to_pandas()</code> Get company filings <code>company.get_filings()</code> Get company filings by form <code>company.get_filings(form=\"10-K\")</code> Get the latest 10-Q <code>company.latest(\"10-Q\")</code> Get the last 5 10-Q's <code>company.get_filings(form=\"10-Q\", 5)</code> Get a company filing by accession_number <code>company.get_filing(accession_number=\"0000320193-21-000139\")</code> Get the company's financials <code>company.get_financials()</code> Get the company's balance sheet <code>company.financials.balance_sheet()</code> Get the company's income statement <code>company.financials.income_statement()</code> Get the company's cash flow statement <code>company.financials.cashflow_statement()</code>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>Get up and running with EdgarTools in 5 minutes. This guide will take you from installation to your first meaningful analysis.</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Internet connection</li> <li>Basic familiarity with Python</li> </ul>"},{"location":"quickstart/#step-1-install-edgartools","title":"Step 1: Install EdgarTools","text":"<pre><code>pip install edgartools\n</code></pre>"},{"location":"quickstart/#step-2-set-your-identity","title":"Step 2: Set Your Identity","text":"<p>The SEC requires all API users to identify themselves. Set your identity once:</p> <pre><code>from edgar import set_identity\n\n# Use your name and email (required by SEC)\nset_identity(\"John Doe john.doe@company.com\")\n</code></pre> <p>\ud83d\udca1 Tip: You can also set the <code>EDGAR_IDENTITY</code> environment variable to avoid doing this in every script.</p>"},{"location":"quickstart/#step-3-your-first-filings","title":"Step 3: Your first filings","text":"<p>Let's see available filings on the SEC Edgar</p> <pre><code>from edgar import *\n\nfilings = get_filings()\n</code></pre> <p></p>"},{"location":"quickstart/#step-4-filtering-for-insider-trading-filings","title":"Step 4: Filtering for insider trading filings","text":"<p>To focus on insider trading activity, filter for Form 4 filings:</p> <pre><code>insider_filings = filings.filter(form=\"4\")\n</code></pre> <p></p>"},{"location":"quickstart/#step-5-getting-a-company","title":"Step 5: Getting a Company","text":"<p>If you would like to focus on a specific company, you can use the <code>Company</code> class. For example, to analyze Apple Inc. (AAPL):</p> <pre><code>c = Company(\"AAPL\")  # Apple Inc.\n</code></pre> <p></p>"},{"location":"quickstart/#step-6-getting-filings-for-a-company","title":"Step 6: Getting filings for a Company","text":"<p>You can retrieve all filings for a company using the <code>company.get_filings</code> method:</p> <pre><code># Get Apple's recent SEC filings\naapl_filings = c.get_filings()\n</code></pre> <p></p>"},{"location":"quickstart/#step-7-insider-filings-for-apple-inc","title":"Step 7: Insider Filings for Apple Inc.","text":"<p>To analyze insider trading activity for Apple Inc., filter the filings for Form 4:</p> <pre><code>insider_filings = c.get_filings(form=\"4\")\n# Get the first insider filing\nf = insider_filings[0]\n\n# Convert to a Form4 object\nform4 = f.obj()\n</code></pre> <p></p>"},{"location":"quickstart/#what-you-just-learned","title":"What You Just Learned","text":"<p>In 5 minutes, you:</p> <ol> <li>\u2705 Installed and configured EdgarTools</li> <li>\u2705 Retrieved and filtered SEC filings</li> <li>\u2705 Focused on insider trading with Form 4</li> <li>\u2705 Analyzed a specific company (Apple Inc.)</li> <li>\u2705 Extracted structured data from filings</li> <li>\u2705 Converted filings to data objects for easy analysis</li> <li>\u2705 Explored company filings and insider activity</li> </ol>"},{"location":"quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Documentation: Browse our comprehensive guides</li> <li>\ud83d\udcac GitHub Discussions: Ask questions and share insights  </li> <li>\ud83d\udc1b Issues: Report bugs or request features</li> </ul>"},{"location":"quickstart/#support-edgartools","title":"Support EdgarTools","text":"<p>If you found this quickstart helpful, consider supporting EdgarTools development:</p> <p> </p> <p>Your support helps us maintain and improve EdgarTools!</p> <p>\ud83c\udf89 Congratulations! You're now ready to analyze SEC data with EdgarTools. </p> <p>What's your next analysis goal? Choose a path above and dive deeper into the world of financial data analysis.</p>"},{"location":"storage-management/","title":"Storage Management Guide","text":"<p>EdgarTools provides comprehensive tools to manage, analyze, and optimize your local SEC filing storage.</p>"},{"location":"storage-management/#overview","title":"Overview","text":"<p>The storage management module provides:</p> <ul> <li>\ud83d\udcca Storage Analytics: View size, file counts, compression ratios</li> <li>\ud83d\udd0d Filing Availability: Check which filings are available offline</li> <li>\ud83d\udca1 Smart Analysis: Get optimization recommendations</li> <li>\ud83d\udee0\ufe0f Optimization Tools: Compress files, clear caches, remove old data</li> </ul> <p>All functions are available from the main <code>edgar</code> package:</p> <pre><code>from edgar import (\n    storage_info,           # View storage statistics\n    check_filing,           # Check single filing availability\n    check_filings_batch,    # Check multiple filings\n    availability_summary,   # Get availability summary\n    analyze_storage,        # Analyze with recommendations\n    optimize_storage,       # Compress uncompressed files\n    cleanup_storage,        # Remove old filings\n    clear_cache,           # Clear HTTP caches\n)\n</code></pre>"},{"location":"storage-management/#storage-analytics","title":"Storage Analytics","text":""},{"location":"storage-management/#view-storage-information","title":"View Storage Information","text":"<p>Get an overview of your local EdgarTools storage:</p> <pre><code>from edgar import storage_info\n\n# Get storage statistics\ninfo = storage_info()\nprint(info)  # Beautiful Rich panel display\n</code></pre> <p>Output:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   EdgarTools Local Storage                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \ud83d\udcca Total Size:        179.23 GB (uncompressed)              \u2502\n\u2502 \ud83d\udcbe Disk Usage:        53.77 GB (compressed)                 \u2502\n\u2502 \ud83d\udddc\ufe0f Space Saved:       125.46 GB (70.0%)                     \u2502\n\u2502 \ud83d\udcc1 Total Files:       22,847                                \u2502\n\u2502 \ud83d\udcc4 Filings:           18,234                                \u2502\n\u2502 \ud83d\udccd Location:          /Users/you/.edgar                     \u2502\n\u2502                                                             \u2502\n\u2502   filings:            18,234 files                          \u2502\n\u2502   companyfacts:       3,456 files                           \u2502\n\u2502   submissions:        892 files                             \u2502\n\u2502   _cache:             265 files                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"storage-management/#access-storage-data-programmatically","title":"Access Storage Data Programmatically","text":"<pre><code>from edgar import storage_info\n\ninfo = storage_info()\n\n# Check size\nif info.total_size_compressed &gt; 50e9:  # More than 50 GB\n    print(f\"Storage is large: {info.total_size_compressed / 1e9:.1f} GB\")\n\n# Check compression ratio\nprint(f\"Compression savings: {info.compression_ratio:.1%}\")\n\n# Check file counts by type\nprint(f\"Filings: {info.by_type.get('filings', 0):,}\")\nprint(f\"Company facts: {info.by_type.get('companyfacts', 0):,}\")\n</code></pre>"},{"location":"storage-management/#force-refresh","title":"Force Refresh","text":"<p>Storage info is cached for 60 seconds for performance. To force a fresh scan:</p> <pre><code>info = storage_info(force_refresh=True)\n</code></pre>"},{"location":"storage-management/#filing-availability","title":"Filing Availability","text":""},{"location":"storage-management/#check-single-filing","title":"Check Single Filing","text":"<p>Check if a specific filing is available in local storage:</p> <pre><code>from edgar import Company, check_filing\n\n# Get a filing\ncompany = Company(\"AAPL\")\nfiling = company.latest(\"10-K\")\n\n# Check availability\nif check_filing(filing):\n    print(\"\u2713 Available offline\")\nelse:\n    print(\"\u2717 Need to download\")\n</code></pre>"},{"location":"storage-management/#check-multiple-filings","title":"Check Multiple Filings","text":"<p>Efficiently check availability for many filings:</p> <pre><code>from edgar import get_filings, check_filings_batch\n\n# Get some filings\nfilings = get_filings(form=\"10-K\", filing_date=\"2024-01-01\").sample(100)\n\n# Check availability\navailability = check_filings_batch(filings)\n\n# Filter to available filings\navailable_filings = [f for f in filings if availability[f.accession_no]]\nprint(f\"Found {len(available_filings)} filings offline\")\n</code></pre>"},{"location":"storage-management/#get-availability-summary","title":"Get Availability Summary","text":"<p>Get a quick summary string:</p> <pre><code>from edgar import get_filings, availability_summary\n\nfilings = get_filings(filing_date=\"2024-01-15\").head(100)\nprint(availability_summary(filings))\n# Output: \"45 of 100 filings available offline (45%)\"\n</code></pre>"},{"location":"storage-management/#storage-analysis","title":"Storage Analysis","text":""},{"location":"storage-management/#analyze-storage-with-recommendations","title":"Analyze Storage with Recommendations","text":"<p>Get intelligent analysis and optimization suggestions:</p> <pre><code>from edgar import analyze_storage\n\nanalysis = analyze_storage()\nprint(analysis)\n</code></pre> <p>Output:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Storage Analysis                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \ud83d\udcca Current Size:      53.77 GB                              \u2502\n\u2502 \ud83d\udcbe Total Files:       22,847                                \u2502\n\u2502 \ud83d\udcb0 Potential Savings: 12.34 GB                              \u2502\n\u2502                                                             \u2502\n\u2502 \u26a0\ufe0f  Issues Found:                                           \u2502\n\u2502   \u2022 Found 1,234 uncompressed files (17.63 GB)              \u2502\n\u2502   \u2022 Cache directories contain 265 files (2.15 GB)          \u2502\n\u2502                                                             \u2502\n\u2502 \ud83d\udca1 Recommendations:                                         \u2502\n\u2502   \u2022 Run optimize_storage() to compress files (~12.3 GB)    \u2502\n\u2502   \u2022 Run clear_cache() to free up 2.2 GB                    \u2502\n\u2502   \u2022 Consider cleanup_storage(days=365) to remove           \u2502\n\u2502     456 old filings (8.9 GB)                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"storage-management/#use-analysis-programmatically","title":"Use Analysis Programmatically","text":"<pre><code>from edgar import analyze_storage\n\nanalysis = analyze_storage()\n\n# Check for issues\nif analysis.issues:\n    print(\"Issues found:\")\n    for issue in analysis.issues:\n        print(f\"  - {issue}\")\n\n# Check potential savings\nif analysis.potential_savings_bytes &gt; 1e9:  # More than 1 GB\n    print(f\"Can save {analysis.potential_savings_bytes / 1e9:.1f} GB\")\n\n# Follow recommendations\nfor rec in analysis.recommendations:\n    print(f\"\u2713 {rec}\")\n</code></pre>"},{"location":"storage-management/#storage-optimization","title":"Storage Optimization","text":""},{"location":"storage-management/#compress-files","title":"Compress Files","text":"<p>Compress uncompressed files to save disk space:</p> <pre><code>from edgar import optimize_storage\n\n# First, see what would happen (dry run)\nresult = optimize_storage(dry_run=True)\nprint(f\"Would compress {result['files_compressed']} files\")\nprint(f\"Would save {result['bytes_saved'] / 1e9:.1f} GB\")\n\n# Then do it for real\nresult = optimize_storage(dry_run=False)\nprint(f\"Compressed {result['files_compressed']} files\")\nprint(f\"Saved {result['bytes_saved'] / 1e9:.1f} GB\")\n</code></pre> <p>Note: The library transparently handles compressed files, so <code>.json.gz</code> files are read exactly like <code>.json</code> files.</p>"},{"location":"storage-management/#clear-caches","title":"Clear Caches","text":"<p>Clear HTTP cache directories to free up space:</p> <pre><code>from edgar import clear_cache\n\n# Preview what would be cleared\nresult = clear_cache(dry_run=True)\nprint(f\"Would free {result['bytes_freed'] / 1e9:.1f} GB\")\n\n# Clear the cache\nresult = clear_cache(dry_run=False)\nprint(f\"Cleared {result['files_deleted']} cache files\")\nprint(f\"Freed {result['bytes_freed'] / 1e9:.1f} GB\")\n</code></pre> <p>Note: Cache is automatically rebuilt on demand, so this is safe to run anytime.</p>"},{"location":"storage-management/#remove-old-filings","title":"Remove Old Filings","text":"<p>Remove filings older than a specified number of days:</p> <pre><code>from edgar import cleanup_storage\n\n# Preview what would be deleted (1 year old)\nresult = cleanup_storage(days=365, dry_run=True)\nprint(f\"Would delete {result['files_deleted']} files\")\nprint(f\"Would free {result['bytes_freed'] / 1e9:.1f} GB\")\n\n# Remove filings older than 2 years\nresult = cleanup_storage(days=730, dry_run=False)\nprint(f\"Deleted {result['files_deleted']} old filings\")\nprint(f\"Freed {result['bytes_freed'] / 1e9:.1f} GB\")\n</code></pre> <p>Note: This only removes filings from the <code>filings/</code> directory. Company facts and submissions are not affected.</p>"},{"location":"storage-management/#complete-workflows","title":"Complete Workflows","text":""},{"location":"storage-management/#weekly-maintenance-routine","title":"Weekly Maintenance Routine","text":"<pre><code>from edgar import analyze_storage, optimize_storage, clear_cache\n\n# Analyze storage\nanalysis = analyze_storage()\nprint(analysis)\n\n# Optimize if savings are substantial\nif analysis.potential_savings_bytes &gt; 5e9:  # More than 5 GB\n    print(\"\\nOptimizing storage...\")\n    optimize_storage(dry_run=False)\n\n# Clear cache if it's large\ncache_info = analysis.storage_info.by_type.get('_cache', 0)\nif cache_info &gt; 1e9:  # More than 1 GB\n    print(\"\\nClearing cache...\")\n    clear_cache(dry_run=False)\n\nprint(\"\\n\u2713 Maintenance complete!\")\n</code></pre>"},{"location":"storage-management/#before-large-download","title":"Before Large Download","text":"<p>Check available space before downloading many filings:</p> <pre><code>from edgar import storage_info, get_filings, download_filings\n\n# Check current storage\ninfo = storage_info()\nprint(f\"Current usage: {info.total_size_compressed / 1e9:.1f} GB\")\n\n# Estimate download size (rough: 50 KB per filing)\nfilings = get_filings(form=\"10-K\", filing_date=\"2024-01-01\")\nestimated_size = len(filings) * 50_000  # 50 KB per filing\n\nprint(f\"Estimated download: {estimated_size / 1e9:.1f} GB\")\n\n# Download if there's space\nif estimated_size &lt; 10e9:  # Less than 10 GB\n    download_filings(filings)\nelse:\n    print(\"\u26a0\ufe0f  Large download - consider filtering filings\")\n</code></pre>"},{"location":"storage-management/#offline-research-workflow","title":"Offline Research Workflow","text":"<pre><code>from edgar import Company, check_filing, availability_summary\n\n# Research a company offline\ncompany = Company(\"TSLA\")\nfilings = company.get_filings(form=\"10-K\")\n\n# Check what's available offline\nprint(availability_summary(list(filings)))\n\n# Work with available filings only\navailable = [f for f in filings if check_filing(f)]\nfor filing in available:\n    print(f\"\u2713 {filing.form} - {filing.filing_date}\")\n    # Process filing...\n</code></pre>"},{"location":"storage-management/#automated-cleanup-script","title":"Automated Cleanup Script","text":"<pre><code>from edgar import analyze_storage, cleanup_storage, clear_cache\nfrom datetime import datetime\n\ndef auto_cleanup(max_age_days=365, max_cache_gb=2):\n    \"\"\"\n    Automatic cleanup based on policies.\n    \"\"\"\n    print(f\"Running storage cleanup - {datetime.now()}\")\n\n    # Analyze first\n    analysis = analyze_storage()\n    print(f\"Current size: {analysis.storage_info.total_size_compressed / 1e9:.1f} GB\")\n\n    # Clear large caches\n    cache_size = sum(\n        size for name, size in analysis.storage_info.by_type.items()\n        if name.startswith('_')\n    )\n    if cache_size &gt; max_cache_gb * 1e9:\n        print(f\"\\nClearing {cache_size / 1e9:.1f} GB cache...\")\n        result = clear_cache(dry_run=False)\n        print(f\"\u2713 Freed {result['bytes_freed'] / 1e9:.1f} GB\")\n\n    # Remove old filings\n    print(f\"\\nRemoving filings older than {max_age_days} days...\")\n    result = cleanup_storage(days=max_age_days, dry_run=False)\n    print(f\"\u2713 Deleted {result['files_deleted']} files\")\n    print(f\"\u2713 Freed {result['bytes_freed'] / 1e9:.1f} GB\")\n\n    # Final summary\n    info = storage_info(force_refresh=True)\n    print(f\"\\nFinal size: {info.total_size_compressed / 1e9:.1f} GB\")\n\n# Run weekly\nauto_cleanup(max_age_days=365, max_cache_gb=2)\n</code></pre>"},{"location":"storage-management/#safety-features","title":"Safety Features","text":"<p>All destructive operations default to dry-run mode for safety:</p> <pre><code># These are all safe by default (no changes made)\noptimize_storage()              # dry_run=True by default\ncleanup_storage()               # dry_run=True by default\nclear_cache()                   # dry_run=True by default\n\n# Explicitly enable changes\noptimize_storage(dry_run=False)\ncleanup_storage(dry_run=False)\nclear_cache(dry_run=False)\n</code></pre>"},{"location":"storage-management/#performance-notes","title":"Performance Notes","text":"<ul> <li>storage_info(): Results cached for 60 seconds to avoid repeated filesystem scans</li> <li>check_filings_batch(): Much faster than checking filings individually</li> <li>analyze_storage(): Can take a few seconds on large storage directories</li> </ul>"},{"location":"storage-management/#best-practices","title":"Best Practices","text":"<ol> <li>Always dry-run first: Preview changes before making them</li> <li>Regular analysis: Run <code>analyze_storage()</code> weekly to catch issues early</li> <li>Compress files: Run <code>optimize_storage()</code> after bulk downloads</li> <li>Clear caches: Safe to run anytime, cache rebuilds automatically</li> <li>Careful with cleanup: Set appropriate <code>days</code> parameter for your needs</li> <li>Monitor size: Check <code>storage_info()</code> regularly if doing bulk downloads</li> </ol>"},{"location":"storage-management/#faq","title":"FAQ","text":"<p>Q: Will compressed files still work with the library? A: Yes! EdgarTools transparently handles <code>.gz</code> files. You won't notice any difference.</p> <p>Q: How much space does compression save? A: Typically 70% savings on text-based files (.json, .xml, .txt, .nc).</p> <p>Q: Is it safe to clear the cache? A: Yes, cache rebuilds automatically on demand. No data loss.</p> <p>Q: What happens if I accidentally delete important filings? A: Filings can be re-downloaded from SEC. Use <code>dry_run=True</code> first to preview.</p> <p>Q: Can I undo cleanup_storage()? A: No, deleted files cannot be recovered. Use dry-run mode first!</p> <p>Q: How often should I run maintenance? A: Weekly <code>analyze_storage()</code> is sufficient for most users. Monthly optimization recommended.</p> <p>Q: Does this affect downloaded company facts or submissions? A: <code>cleanup_storage()</code> only affects filings. Company facts and submissions are preserved.</p>"},{"location":"storage-management/#api-reference","title":"API Reference","text":"<p>See individual function docstrings for complete API details:</p> <pre><code>help(storage_info)\nhelp(check_filing)\nhelp(check_filings_batch)\nhelp(availability_summary)\nhelp(analyze_storage)\nhelp(optimize_storage)\nhelp(cleanup_storage)\nhelp(clear_cache)\n</code></pre>"},{"location":"using-the-filings-api/","title":"Filings","text":"<p>To get started import from edgar and use the <code>get_filings</code> function.</p> <pre><code>from edgar import *\n\nfilings = get_filings()\n</code></pre> <p>This gets the list of filings for the current year and quarter into a <code>Filings</code> object. </p> <p></p> <p>If you need a different date range you can specify a year or years and a quarter or quarters. These are valid ways to specify the date range or filter by form or by filing date.</p> <pre><code>\n    &gt;&gt;&gt; filings = get_filings(2021) # Get filings for 2021\n\n    &gt;&gt;&gt; filings = get_filings(2021, 4) # Get filings for 2021 Q4\n\n    &gt;&gt;&gt; filings = get_filings(2021, [3,4]) # Get filings for 2021 Q3 and Q4\n\n    &gt;&gt;&gt; filings = get_filings([2020, 2021]) # Get filings for 2020 and 2021\n\n    &gt;&gt;&gt; filings = get_filings([2020, 2021], 4) # Get filings for Q4 of 2020 and 2021\n\n    &gt;&gt;&gt; filings = get_filings(range(2010, 2021)) # Get filings between 2010 and 2021 - does not include 2021\n\n    &gt;&gt;&gt; filings = get_filings(2021, 4, form=\"D\") # Get filings for 2021 Q4 for form D\n\n    &gt;&gt;&gt; filings = get_filings(2021, 4, filing_date=\"2021-10-01\") # Get filings for 2021 Q4 on \"2021-10-01\"\n\n    &gt;&gt;&gt; filings = get_filings(2021, 4, filing_date=\"2021-10-01:2021-10-10\") # Get filings for 2021 Q4 between\n                                                                            # \"2021-10-01\" and \"2021-10-10\"\n</code></pre>"},{"location":"using-the-filings-api/#convert-the-filings-to-a-pandas-dataframe","title":"Convert the filings to a pandas dataframe","text":"<p>The filings data is stored in the <code>Filings</code> class as a <code>pyarrow.Table</code>. You can get the data as a pandas dataframe using <code>to_pandas</code></p> <pre><code>df = filings.to_pandas()\n</code></pre>"},{"location":"using-the-filings-api/#navigating-filings","title":"Navigating filings","text":"<p>The Filings object allows you to navigate through filings using <code>filings.next()</code> and <code>filings.prev()</code>.  This shows you pages of the data - the page size is about 50.</p> <pre><code># To see the next page of data\nfilings.next()\n\n# To see the previous page\nfilings.previous()\n\n# To see the current page\nfilings.current()\n</code></pre> <p></p>"},{"location":"using-the-filings-api/#getting-the-latest-filings","title":"Getting the latest filings","text":"<p>You can get the latest n filings by filing_date from a filings using <code>filings.latest()</code>.</p> <p>If you provide the parameter <code>n</code> it will return the latest <code>n</code> filings.</p> <pre><code>filing = filings.latest(n=5)\nfiling\n</code></pre> <p></p> <p>If you omit this parameter, or set <code>n=1</code> it will return a single `Filings object.</p> <pre><code>filing = filings.latest()\nfiling\n</code></pre> <p></p>"},{"location":"using-the-filings-api/#filtering-filings","title":"Filtering filings","text":"<p>You can filter the filings object using te <code>filter()</code> function. This allows you to filter by filing date, or by form.</p>"},{"location":"using-the-filings-api/#filtering-filings-by-date","title":"Filtering filings by date","text":"<p>To filter by filing date specify the filing date in YYYY-MM-DD format e.g. 2022-01-24 (Note the parameters <code>date</code> and <code>filing_date</code> are equivalent aliases for each other)</p> <pre><code>filings.filter(date=\"2021-01-24\") # or filings.filter(filing_date=\"2021-01-24\")\n</code></pre> <p>You can specify a filing date range using the colon</p> <pre><code>filings.filter(date=\"2021-01-12:2021-02-28\") \n</code></pre> <p>To filter by dates before a specified date use `:YYYY-MM-DD'</p> <pre><code>filings.filter(date=\":2021-02-28\") \n</code></pre> <p>To filter by dates after a specified date use `YYYY-MM-DD:'</p> <pre><code>filings.filter(date=\"2021-02-28:\") \n</code></pre>"},{"location":"using-the-filings-api/#filtering-filings-by-form","title":"Filtering filings by form","text":"<p>You can filter filings by form using the <code>form</code> parameter. </p> <pre><code>filings.filter(form=\"10-K\") \n</code></pre> <p>To filter by form e.g. 10-K and include form amendments use <code>amendments = True</code>. </p> <pre><code>filings.filter(form=\"10-K\", amendments=True) \n</code></pre> <p></p>"},{"location":"using-the-filings-api/#getting-a-single-filing","title":"Getting a single filing","text":"<p>You can get a single filing from the filings using the bracket operator <code>[]</code>,  specifying the index of the filing. The index is the value displayed in the leftmost position in the filings table. For example, to get the 10-Q for Costco in the table above use <code>filings[3]</code></p> <pre><code>filing = filings[3]\n</code></pre> <p></p>"},{"location":"using-the-filings-api/#view-the-filing-homepage","title":"View the filing homepage","text":"<p>You can view the filing homepage in the terminal using <code>filing.homepage</code></p> <p>This gives you access to the <code>FilingHomepage</code> class that you can use to list all the documents and datafiles on the filing.</p> <pre><code>filing.homepage\n</code></pre> <p></p>"},{"location":"using-the-filings-api/#open-a-filing","title":"Open a filing","text":"<p>You can open the filing in your browser using <code>filing.open()</code>. This will work on environments with access to the browser,  will probably not work on a remote server.</p> <pre><code>filing.open()\n</code></pre>"},{"location":"using-the-filings-api/#open-the-filing-homepage","title":"Open the Filing Homepage","text":"<p>You can open the filing homepage in the browser using <code>filing.homepage.open()</code>.</p> <pre><code>filing.homepage.open()\n</code></pre>"},{"location":"using-the-filings-api/#view-the-filing-as-markdown","title":"View the filing as Markdown","text":"<p>You can view the filing's HTML content as markdown in the console using <code>view()</code>. It works for all filing types but can be a little slow for filings with large HTML files</p> <pre><code>filing.view()\n</code></pre>"},{"location":"using-the-filings-api/#get-the-filings-html","title":"Get the filing's html","text":"<p>You can get the html content of the filing using<code>.html()</code></p> <pre><code>filing.html()\n</code></pre>"},{"location":"using-the-filings-api/#get-the-filings-html-as-markdown","title":"Get the filing's html as Markdown","text":"<p>You can get the html content as markdown using<code>.markdown()</code></p> <pre><code>filing.markdown()\n</code></pre>"},{"location":"using-the-filings-api/#working-with-xbrl-filings","title":"Working with XBRL filings","text":"<p>Some filings are in XBRL (eXtensible Business Markup Language) format.  These are mainly the newer filings, as the SEC has started requiring this for newer filings.</p> <p>If a filing is in XBRL format then it opens up a lot more ways to get structured data about that specific filing and also  about the company referred to in that filing.</p> <p>The <code>Filing</code> class has an <code>xbrl</code> function that will download, parse and structure the filing's XBRL document if one exists. If it does not exist, then <code>filing.xbrl()</code> will return <code>None</code>.</p> <p>The function <code>filing.xbrl()</code> returns a <code>FilingXbrl</code> instance, which wraps the data, and provides convenient ways of working with the xbrl data.</p> <pre><code>filing_xbrl = filing.xbrl()\n</code></pre> <p></p>"},{"location":"why-edgartools/","title":"Why Choose EdgarTools?","text":"<p>If you're working with SEC data, you have several options. Here's why EdgarTools stands out as the best choice for Python developers, researchers, and financial professionals.</p>"},{"location":"why-edgartools/#the-sec-data-challenge","title":"The SEC Data Challenge","text":"<p>Working with SEC filings has traditionally been painful:</p> <ul> <li>Complex file formats: Raw XBRL is verbose and hard to parse</li> <li>Inconsistent data: Different companies use different concepts for the same items</li> <li>Poor tooling: Existing solutions are either too basic or overly complex</li> <li>Performance issues: Large datasets take forever to process</li> <li>Documentation gaps: Sparse examples and unclear APIs</li> </ul> <p>EdgarTools solves all of these problems.</p>"},{"location":"why-edgartools/#how-edgartools-is-different","title":"How EdgarTools is Different","text":""},{"location":"why-edgartools/#built-for-real-users","title":"\ud83c\udfaf Built for Real Users","text":"<p>Unlike academic projects or corporate tools, EdgarTools is designed by practitioners for practitioners. Every feature addresses real pain points from actual SEC data analysis workflows.</p> <p>Other tools:</p> <pre><code># Complex setup, raw data\nimport sec_api\napi = sec_api.QueryApi(api_key=\"your_key\")\nquery = {\n    \"query\": {\"field\": \"cik\", \"operator\": \"=\", \"value\": \"0000320193\"},\n    \"from\": \"2020-01-01\", \n    \"to\": \"2023-12-31\"\n}\nfilings = api.get_filings(query)\n# Now parse raw XBRL...\n</code></pre> <p>EdgarTools:</p> <pre><code># Simple, clean API\nfrom edgar import Company\napple = Company(\"AAPL\")\nfinancials = apple.get_financials()\nrevenue = financials.get_revenue()  # Done!\n</code></pre>"},{"location":"why-edgartools/#data-quality-first","title":"\ud83d\udcca Data Quality First","text":"<p>EdgarTools doesn't just give you data\u2014it gives you clean, standardized, analysis-ready data.</p>"},{"location":"why-edgartools/#before-edgartools","title":"Before EdgarTools:","text":"<ul> <li>Spend 80% of time cleaning and standardizing data</li> <li>Deal with inconsistent concept mappings across companies</li> <li>Handle missing values and edge cases manually</li> <li>Write custom parsers for each filing type</li> </ul>"},{"location":"why-edgartools/#with-edgartools","title":"With EdgarTools:","text":"<ul> <li>Get standardized financial concepts automatically</li> <li>Clean data with proper data types and formatting</li> <li>Consistent APIs across all filing types</li> <li>Built-in handling of edge cases and variations</li> </ul> <p>Example: Revenue standardization</p> <pre><code># Tesla uses \"AutomotiveRevenue\", Microsoft uses \"ProductRevenue\" \n# EdgarTools maps both to standardized \"Revenue\" concept\ntesla_revenue = Company(\"TSLA\").get_financials().get_revenue()\nmsft_revenue = Company(\"MSFT\").get_financials().get_revenue()\n\n# Both return the same format, ready for comparison\ncomparison = pd.concat([tesla_revenue, msft_revenue], axis=1)\n</code></pre>"},{"location":"why-edgartools/#performance-that-scales","title":"\u26a1 Performance That Scales","text":"<p>Built for analysts who need to process hundreds or thousands of filings efficiently.</p> Operation EdgarTools Alternative Solutions Get 5 years of financials 2-3 seconds 30-60 seconds Parse 100 10-K filings 2-5 minutes 30-60 minutes Extract all insider trades 10-15 seconds 5-10 minutes Query XBRL facts Instant (cached) 5-15 seconds each <p>Performance features: - Smart caching reduces redundant API calls - Parallel processing for bulk operations - Memory-efficient streaming for large datasets - Pre-computed indexes for common queries</p>"},{"location":"why-edgartools/#developer-experience","title":"\ud83d\udee0 Developer Experience","text":"<p>EdgarTools is built by developers, for developers.</p>"},{"location":"why-edgartools/#type-safety-intellisense","title":"Type Safety &amp; IntelliSense","text":"<pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")  # Type: Company\nfilings = company.get_filings()  # Type: Filings\nfiling = filings.latest()  # Type: Filing\nfinancials = filing.obj().financials  # Full autocomplete support\n</code></pre>"},{"location":"why-edgartools/#rich-display-in-jupyter","title":"Rich Display in Jupyter","text":"<pre><code># Automatic pretty-printing\ncompany  # Shows company card with key info\nfilings  # Shows interactive table\nfinancials.income_statement  # Rich formatted statements\n</code></pre>"},{"location":"why-edgartools/#comprehensive-error-handling","title":"Comprehensive Error Handling","text":"<pre><code>try:\n    company = Company(\"INVALID\")\nexcept CompanyNotFoundError as e:\n    print(f\"Company not found: {e}\")\n    suggestions = search_companies(\"Invalid Corp\")\n</code></pre>"},{"location":"why-edgartools/#complete-feature-set","title":"\ud83d\udd0d Complete Feature Set","text":"<p>EdgarTools covers the entire SEC ecosystem, not just basic filings.</p> Feature EdgarTools EDGAR-Tool sec-api python-edgar 10-K/10-Q Analysis \u2705 Full support \u2705 Basic \u2705 Raw data \u274c Limited XBRL Financial Data \u2705 Standardized \u26a0\ufe0f Raw only \u26a0\ufe0f Raw only \u274c No Insider Trading (Forms 3,4,5) \u2705 Structured \u274c No \u26a0\ufe0f Raw only \u274c No 13F Fund Holdings \u2705 Full analysis \u274c No \u26a0\ufe0f Basic \u274c No 8-K Event Monitoring \u2705 Event parsing \u26a0\ufe0f Text only \u26a0\ufe0f Raw only \u274c No Attachment Processing \u2705 All types \u274c No \u274c No \u274c No Text Extraction \u2705 Clean HTML\u2192Text \u26a0\ufe0f Basic \u274c No \u2705 Basic Local Caching \u2705 Intelligent \u274c No \u26a0\ufe0f Basic \u274c No Rate Limiting \u2705 Built-in \u274c Manual \u26a0\ufe0f Manual \u274c Manual"},{"location":"why-edgartools/#real-world-success-stories","title":"Real-World Success Stories","text":""},{"location":"why-edgartools/#financial-analysis-firm","title":"Financial Analysis Firm","text":"<p>\"EdgarTools reduced our data preparation time from 6 hours to 15 minutes. We can now analyze 500+ companies in the time it used to take for 10.\"</p> <p>Before: Custom scrapers, manual data cleaning, inconsistent results After: Automated pipelines, standardized data, 95% time savings</p>"},{"location":"why-edgartools/#academic-research","title":"Academic Research","text":"<p>\"For our corporate governance study of 3,000 companies over 10 years, EdgarTools made the impossible possible. The standardized data quality is exceptional.\"</p> <p>Challenge: Needed consistent financial metrics across thousands of filings Solution: EdgarTools' standardization engine handled concept mapping automatically</p>"},{"location":"why-edgartools/#investment-fund","title":"Investment Fund","text":"<p>\"We track insider trading across our entire portfolio in real-time. EdgarTools' Form 4 parsing is the most accurate we've found.\"</p> <p>Use case: Daily monitoring of insider transactions for 200+ holdings Result: Automated alerts, structured data for analysis, better investment decisions</p>"},{"location":"why-edgartools/#technical-superiority","title":"Technical Superiority","text":""},{"location":"why-edgartools/#smart-xbrl-processing","title":"Smart XBRL Processing","text":"<pre><code># EdgarTools understands XBRL semantics\nfinancials = company.get_financials()\n\n# Automatically handles:\n# - Concept hierarchies (Revenue &gt; Product Revenue &gt; Software Revenue)\n# - Time period alignment\n# - Unit conversion (thousands to actual values)\n# - Calculation relationships\n# - Dimensional breakdowns\n\nrevenue_breakdown = financials.get_concept_breakdown(\"Revenue\")\n# Returns: Product Revenue, Service Revenue, Subscription Revenue, etc.\n</code></pre>"},{"location":"why-edgartools/#intelligent-data-standardization","title":"Intelligent Data Standardization","text":"<pre><code># Works across companies with different taxonomies\ncompanies = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"]\n\n# Same code works for all companies\nfor ticker in companies:\n    company = Company(ticker)\n    metrics = {\n        'revenue': company.get_financials().get_revenue(),\n        'net_income': company.get_financials().get_net_income(),\n        'total_assets': company.get_financials().get_total_assets()\n    }\n    # Consistent data structure for all companies\n</code></pre>"},{"location":"why-edgartools/#advanced-query-capabilities","title":"Advanced Query Capabilities","text":"<pre><code># Complex financial analysis made simple\nfrom edgar import query\n\n# Find all companies with debt-to-equity &gt; 2.0\nhigh_leverage = query.companies.where(\n    debt_to_equity__gt=2.0,\n    market_cap__gt=1_000_000_000  # &gt; $1B market cap\n)\n\n# Get all tech companies that filed 8-K for acquisitions\ntech_acquisitions = query.filings.where(\n    form=\"8-K\",\n    industry=\"technology\",\n    contains=\"acquisition\",\n    filing_date__gte=\"2023-01-01\"\n)\n</code></pre>"},{"location":"why-edgartools/#roi-calculation","title":"ROI Calculation","text":""},{"location":"why-edgartools/#time-savings","title":"Time Savings","text":"<ul> <li>Data Collection: 90% faster than manual methods</li> <li>Data Cleaning: 95% reduction in preprocessing time  </li> <li>Analysis Setup: From hours to minutes</li> </ul>"},{"location":"why-edgartools/#cost-savings","title":"Cost Savings","text":"<ul> <li>No API fees: Free access to SEC data</li> <li>Reduced development time: Pre-built solutions</li> <li>Lower maintenance: Stable, well-tested codebase</li> </ul>"},{"location":"why-edgartools/#quality-improvements","title":"Quality Improvements","text":"<ul> <li>Fewer errors: Automated data validation</li> <li>Better insights: Standardized comparisons</li> <li>Faster iteration: Rapid prototyping and testing</li> </ul>"},{"location":"why-edgartools/#getting-started","title":"Getting Started","text":"<p>Ready to experience the difference? Here's how to get started:</p> <ol> <li>Install EdgarTools - 2 minutes</li> <li>Quick Tutorial - 5 minutes  </li> <li>Real Analysis - 15 minutes</li> </ol> <p>Or jump straight into a specific use case:</p> <ul> <li>Financial Statement Analysis</li> <li>Insider Trading Monitoring</li> <li>Fund Holdings Research</li> <li>Bulk Data Processing</li> </ul>"},{"location":"why-edgartools/#community-support","title":"Community &amp; Support","text":"<ul> <li>Active development: Regular releases with new features</li> <li>Responsive support: GitHub issues typically resolved within 24 hours</li> <li>Growing community: 1000+ users, contributors from finance and tech</li> <li>Enterprise support: Available for institutional users</li> </ul> <p>Stop fighting with SEC data. Start analyzing.</p> <p>Get started with EdgarTools \u2192</p>"},{"location":"xbrl-querying/","title":"XBRL Query Functionality","text":"<p>You can query the facts inside an XBRL instance using the XBRL query API. This allows you to get access to specific financial data, filter results and perform analysis on the financial facts contained within a single XBRL filing.</p>"},{"location":"xbrl-querying/#overview","title":"Overview","text":"<p>XBRL query functionality is built around two main classes: - <code>FactsView</code> - Provides access to raw XBRL facts from a single filing - <code>FactQuery</code> - Enables complex filtering and analysis of those facts</p>"},{"location":"xbrl-querying/#basic-usage","title":"Basic Usage","text":""},{"location":"xbrl-querying/#accessing-facts","title":"Accessing Facts","text":"<pre><code>from edgar import *\nfrom edgar.xbrl import XBRL\n\n# Get an XBRL filing\ncompany = Company(\"AAPL\")\nfiling = company.latest(\"10-K\")\nxb = filing.xbrl()\n</code></pre>"},{"location":"xbrl-querying/#access-the-facts-view","title":"Access the facts view","text":"<p>The <code>FactsView</code> provides direct access to the facts in the XBRL instance:</p> <pre><code>facts = xb.facts\nprint(f\"Total facts: {len(facts)}\")\n</code></pre>"},{"location":"xbrl-querying/#querying-facts","title":"Querying Facts","text":"<p>To query facts use the <code>query()</code> method on the <code>XBRL</code> instance and one of the <code>by_</code> functions e.g. <code>by_text()</code>. This returns a <code>FactQuery</code> object that allows you to filter and manipulate the facts.</p> <pre><code># Start a query\nresults = (xb.query()\n            .by_concept(\"us-gaap:PaymentsToAcquireAvailableForSaleSecuritiesDebt\")\n           )\n</code></pre> <p></p> <p>The result is an <code>edgar.xbrl.facts.FactQuery</code> object that contains the filtered facts. You can see from the rich display the available columns of whichg a few are selected by default.</p> <p>You can also convert the results to a DataFrame for easier manipulation including selecting which columns you want to view:</p> <pre><code>df = results.to_dataframe('concept', 'label', 'value', 'period_end')\n</code></pre>"},{"location":"xbrl-querying/#filtering-facts","title":"Filtering Facts","text":""},{"location":"xbrl-querying/#by-concept","title":"By Concept","text":"<p>You can filter facts by their concept names, which are unique identifiers for financial data items in XBRL.</p> <pre><code># Find revenue-related facts\nrevenue_query = xb.query().by_concept(\"us-gaap:Revenues\")\n</code></pre> <p>The namespace e.g. <code>us-gaap:</code> is optional, so you can use just the concept name like <code>Revenues</code>.</p> <p>Querying by concept does a partial regex match on the concept name</p> <p><code>by_concept('RevenueFrom')</code> matches <code>us-gaap:RevenueFromContractWithCustomerExcludingAssessedTax</code> and <code>us-gaap:RevenueFromContractWithCustomerTextBlock</code></p> <p>Use <code>exact=True</code> to match the full concept name exactly.</p>"},{"location":"xbrl-querying/#by-label","title":"By Label","text":"<p>You can filter facts by their labels, which are human-readable names associated with the concepts.</p> <pre><code># Search by label text\nrevenue_query = xb.query().by_label(\"Revenue\")\n</code></pre> <p>To specify exact matches or partial matches, use the <code>exact</code> parameter:</p> <pre><code>sales_query = xb.query().by_label(\"Revenue\", exact=False)\n</code></pre>"},{"location":"xbrl-querying/#by-value","title":"By Value","text":"<pre><code># Facts with values above $1 billion\nlarge_values = xb.query().by_value(lambda x: x &gt; 1_000_000_000)\n\n# Facts within a range\nrange_query = xb.query().by_value(lambda x: 100_000 &lt;= x &lt;= 1_000_000)\n</code></pre>"},{"location":"xbrl-querying/#by-statement-type","title":"By Statement Type","text":"<pre><code># Facts from specific statements\nincome_facts = xb.query().by_statement_type(\"IncomeStatement\")\nbalance_facts = xb.query().by_statement_type(\"BalanceSheet\")\n</code></pre>"},{"location":"xbrl-querying/#method-chaining","title":"Method Chaining","text":"<p>Combine multiple filters using method chaining:</p> <pre><code># Complex query with multiple filters\ncomplex_query = (xbrl.query()\n                 .by_statement(\"IncomeStatement\")\n                 .by_label(\"Revenue\")\n                 .by_value(lambda x: x &gt; 1_000_000)\n                 .sort_by('value', ascending=False)\n                 .limit(10))\n\nresults = complex_query.execute()\n</code></pre>"},{"location":"xbrl-querying/#data-transformations","title":"Data Transformations","text":""},{"location":"xbrl-querying/#sorting","title":"Sorting","text":"<pre><code># Sort by value (descending)\nsorted_query = xbrl.query().sort_by('value', ascending=False)\n\n# Sort by concept name\nconcept_sorted = xbrl.query().sort_by('concept')\n</code></pre>"},{"location":"xbrl-querying/#limiting-results","title":"Limiting Results","text":"<pre><code># Get top 10 results\ntop_10 = xbrl.query().limit(10)\n\n# Pagination\npage_1 = xbrl.query().limit(20)\npage_2 = xbrl.query().offset(20).limit(20)\n</code></pre>"},{"location":"xbrl-querying/#working-with-results","title":"Working with Results","text":""},{"location":"xbrl-querying/#dataframe-output","title":"DataFrame Output","text":"<pre><code># Get specific columns\ndf = query.to_dataframe('concept', 'label', 'value', 'period_end')\n\n# All available columns\nfull_df = query.to_dataframe()\n\n# Column information\nprint(\"Available columns:\", df.columns.tolist())\n</code></pre>"},{"location":"xbrl-querying/#fact-structure","title":"Fact Structure","text":"<p>Each fact contains the following key information:</p> <pre><code>fact = results[0]\nprint(f\"Concept: {fact['concept']}\")\nprint(f\"Label: {fact['label']}\")\nprint(f\"Value: {fact['value']}\")\nprint(f\"Period: {fact['period_end']}\")\nprint(f\"Units: {fact['units']}\")\nprint(f\"Decimals: {fact['decimals']}\")\n</code></pre>"},{"location":"xbrl-querying/#advanced-filtering","title":"Advanced Filtering","text":""},{"location":"xbrl-querying/#dimensions","title":"Dimensions","text":"<pre><code># Facts with specific dimensions\ndimensional_query = xbrl.query().by_dimension(\"ProductOrServiceAxis\", \"ProductMember\")\n\n# Facts with any value for a dimension\nany_product_dim = xbrl.query().by_dimension(\"ProductOrServiceAxis\")\n\n# Facts with NO dimensions (undimensioned facts)\nundimensioned_facts = xbrl.query().by_dimension(None)\n\n# Multiple dimensions\nmulti_dim = xbrl.query().by_dimensions({\n    \"ProductOrServiceAxis\": \"ProductMember\",\n    \"GeographyAxis\": \"USMember\"\n})\n</code></pre>"},{"location":"xbrl-querying/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use specific filters: Filter early to reduce data processing</li> <li>Limit results: Use <code>.limit()</code> for large datasets</li> <li>Cache queries: Store frequently used queries</li> <li>Select columns: Use <code>to_dataframe()</code> with specific columns</li> </ol> <pre><code># Efficient query pattern\nefficient_query = (xb.query()\n                   .by_statement(\"IncomeStatement\")  # Filter first\n                   .by_value(lambda x: x &gt; 0)        # Remove zeros\n                   .limit(100)                       # Limit results\n                   .to_dataframe('concept', 'value')) # Select columns\n</code></pre>"},{"location":"xbrl-querying/#examples","title":"Examples","text":""},{"location":"xbrl-querying/#finding-revenue-information","title":"Finding Revenue Information","text":"<pre><code># All revenue-related facts\nrevenue_facts = (xb.query()\n                 .by_label(\"revenue\", exact=False)\n                 .sort_by('value', ascending=False)\n                 .execute())\n\nfor fact in revenue_facts:\n    print(f\"{fact['label']}: ${fact['value']:,}\")\n</code></pre>"},{"location":"xbrl-querying/#comparing-quarterly-data","title":"Comparing Quarterly Data","text":"<pre><code># Get quarterly revenue data\nquarterly_revenue = (xb.query()\n                     .by_concept(\"us-gaap:Revenues\")\n                     .by_period_type(\"duration\")\n                     .sort_by('period_end')\n                     .to_dataframe('period_end', 'value'))\n\nprint(quarterly_revenue)\n</code></pre>"},{"location":"xbrl-querying/#balance-sheet-analysis","title":"Balance Sheet Analysis","text":"<pre><code># Major balance sheet items\nbalance_items = (xb.query()\n                 .by_statement(\"BalanceSheet\")\n                 .by_value(lambda x: x &gt; 1_000_000_000)  # &gt; $1B\n                 .sort_by('value', ascending=False)\n                 .to_dataframe('label', 'value'))\n\nprint(\"Major Balance Sheet Items (&gt; $1B):\")\nprint(balance_items)\n</code></pre> <p>This query system provides a flexible and powerful way to explore XBRL data, enabling detailed financial analysis and data extraction from individual filings.</p>"},{"location":"advanced/customizing-standardization/","title":"Customizing XBRL Standardization","text":"<p>Target Audience: Advanced users, financial analysts, quantitative researchers Prerequisites: Understanding of XBRL concepts, Python basics, JSON format Use Case: Custom taxonomies, 200+ companies, industry-specific valuations</p>"},{"location":"advanced/customizing-standardization/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview and Introduction</li> <li>Architecture and Design</li> <li>Core Mappings Structure</li> <li>Company-Specific Mappings</li> <li>Priority System and Ambiguous Tag Resolution</li> <li>Current Limitations</li> <li>Validation Techniques</li> <li>CSV Workflow</li> <li>Real-World Examples</li> <li>Future Enhancements</li> </ol>"},{"location":"advanced/customizing-standardization/#1-overview-and-introduction","title":"1. Overview and Introduction","text":""},{"location":"advanced/customizing-standardization/#what-is-xbrl-standardization","title":"What is XBRL Standardization?","text":"<p>XBRL standardization is the process of mapping company-specific XBRL tags to a consistent set of standardized concept names. This enables:</p> <ul> <li>Consistent presentation of financial statements across different companies</li> <li>Comparable analysis regardless of each company's unique taxonomy</li> <li>Automated processing of financial data from diverse sources</li> <li>Reduced complexity when working with 200+ companies</li> </ul>"},{"location":"advanced/customizing-standardization/#why-companies-need-custom-taxonomies","title":"Why Companies Need Custom Taxonomies","text":"<p>Every company's XBRL filing uses a mix of: - US-GAAP standard tags: <code>us-gaap:Revenue</code>, <code>us-gaap:Assets</code> - Company-specific extensions: <code>tsla:AutomotiveRevenue</code>, <code>msft:AzureRevenue</code> - Industry-specific concepts: Energy, automotive, technology sectors</p> <p>The Problem: Without standardization, analyzing 200 companies means dealing with thousands of unique XBRL tag variations for the same underlying financial concept.</p> <p>The Solution: EdgarTools' standardization system maps all these variations to a unified set of standard concepts.</p>"},{"location":"advanced/customizing-standardization/#when-to-customize-standardization","title":"When to Customize Standardization","text":"<p>You should customize the standardization system when:</p> <ul> <li>Managing 200+ companies with diverse taxonomies</li> <li>Working with industry-specific filings (automotive, technology, industrial firms)</li> <li>Building valuation models requiring granular financial statements</li> <li>Conducting multi-company analysis that requires consistent data structure</li> <li>Ensuring statement balancing (Assets = Liabilities + Equity) across diverse filings</li> </ul>"},{"location":"advanced/customizing-standardization/#what-this-guide-covers","title":"What This Guide Covers","text":"<p>This comprehensive guide explains: - How the standardization architecture works - How to create custom concept mappings - How to handle ambiguous XBRL tags (200+ identified cases) - How to validate mapping quality - Production-ready workflows for managing custom taxonomies</p>"},{"location":"advanced/customizing-standardization/#2-architecture-and-design","title":"2. Architecture and Design","text":""},{"location":"advanced/customizing-standardization/#the-standardconcept-enum-vs-json-mappings","title":"The StandardConcept Enum vs JSON Mappings","text":"<p>This is a critical distinction that causes confusion:</p>"},{"location":"advanced/customizing-standardization/#standardconcept-enum-ide-convenience-optional","title":"StandardConcept Enum: IDE Convenience (Optional)","text":"<pre><code>from edgar.xbrl.standardization import StandardConcept\n\n# Enum provides autocomplete and type safety\nrevenue_label = StandardConcept.REVENUE.value  # \"Revenue\"\nassets_label = StandardConcept.TOTAL_ASSETS.value  # \"Total Assets\"\n</code></pre> <p>Purpose: - IDE autocomplete for known concepts - Type safety for Python code - Semantic meaning for core financial concepts</p> <p>Location: <code>edgar/xbrl/standardization/core.py</code> (lines 18-126)</p>"},{"location":"advanced/customizing-standardization/#json-mappings-source-of-truth-required","title":"JSON Mappings: Source of Truth (Required)","text":"<pre><code>{\n  \"Revenue\": [\n    \"us-gaap:Revenue\",\n    \"us-gaap:Revenues\",\n    \"us-gaap:SalesRevenueNet\"\n  ]\n}\n</code></pre> <p>Purpose: - The actual mapping data used by the system - Unlimited extensibility without code changes - User-customizable without touching Python code</p> <p>Location: <code>edgar/xbrl/standardization/concept_mappings.json</code></p>"},{"location":"advanced/customizing-standardization/#critical-clarification","title":"Critical Clarification","text":"<p>The Relationship: - Enum values SHOULD match JSON keys (e.g., <code>StandardConcept.REVENUE.value == \"Revenue\"</code>) - This relationship is NOT enforced by code - JSON is what the system actually uses for mapping - Enum is purely for developer convenience</p> <p>For Custom Mappings: - You customize via JSON files - NOT by modifying the enum - The enum can remain unchanged; JSON drives all behavior - You can add mappings in JSON that don't exist in the enum - System will validate JSON keys against enum if you enable validation (optional)</p>"},{"location":"advanced/customizing-standardization/#how-standardization-works","title":"How Standardization Works","text":"<p>The standardization system follows this flow:</p> <pre><code>Company XBRL Tag \u2192 MappingStore \u2192 Priority Resolution \u2192 Standard Concept\n</code></pre> <p>Example:</p> <pre><code>\"tsla:AutomotiveRevenue\" \u2192 [Priority 4: Tesla mapping] \u2192 \"Automotive Revenue\"\n\"us-gaap:Revenue\" \u2192 [Priority 1: Core mapping] \u2192 \"Revenue\"\n</code></pre>"},{"location":"advanced/customizing-standardization/#key-components","title":"Key Components","text":""},{"location":"advanced/customizing-standardization/#1-mappingstore-the-brain","title":"1. MappingStore (The Brain)","text":"<p>File: <code>edgar/xbrl/standardization/core.py</code> (lines 128-462)</p> <p>Responsibilities: - Loads core mappings from <code>concept_mappings.json</code> - Loads company-specific mappings from <code>company_mappings/</code> directory - Merges mappings with priority scoring - Resolves ambiguous tags using context</p> <p>Initialization:</p> <pre><code>from edgar.xbrl.standardization import MappingStore\n\n# Default initialization (loads packaged mappings)\nstore = MappingStore()\n\n# Custom source (future enhancement)\nstore = MappingStore(source=\"/path/to/custom_mappings.json\")\n\n# Read-only mode (for testing)\nstore = MappingStore(read_only=True)\n</code></pre>"},{"location":"advanced/customizing-standardization/#2-conceptmapper-the-worker","title":"2. ConceptMapper (The Worker)","text":"<p>File: <code>edgar/xbrl/standardization/core.py</code> (lines 464-682)</p> <p>Responsibilities: - Maps individual concepts using MappingStore - Caches results for performance - Handles context-aware inference - Tracks unmapped concepts</p> <p>Usage:</p> <pre><code>mapper = ConceptMapper(mapping_store)\n\n# Map a concept with context\ncontext = {\n    'statement_type': 'BalanceSheet',\n    'level': 0,\n    'is_total': True\n}\nstandard_concept = mapper.map_concept(\n    company_concept='us-gaap:Assets',\n    label='Total Assets',\n    context=context\n)\n# Returns: \"Total Assets\"\n</code></pre>"},{"location":"advanced/customizing-standardization/#3-priority-system","title":"3. Priority System","text":"<p>The system uses priority levels to resolve conflicts:</p> Priority Source Description Example P1 Core mappings Base US-GAAP concepts <code>us-gaap:Revenue \u2192 \"Revenue\"</code> P2 Company mappings Company-specific overrides <code>tsla:Revenue \u2192 \"Automotive Revenue\"</code> P4 Detected entity Auto-detected from prefix <code>tsla:CustomTag \u2192 uses Tesla P2 mappings</code> <p>Priority Resolution Algorithm (lines 408-449): 1. Detect entity from concept prefix (e.g., <code>tsla:</code> \u2192 <code>\"tsla\"</code>) 2. Search through merged mappings 3. For each match, calculate effective priority 4. If detected entity matches mapping source, boost to P4 5. Return highest priority match</p>"},{"location":"advanced/customizing-standardization/#3-core-mappings-structure","title":"3. Core Mappings Structure","text":""},{"location":"advanced/customizing-standardization/#file-location","title":"File Location","text":"<p>Current Location (hardcoded):</p> <pre><code>edgar/xbrl/standardization/concept_mappings.json\n</code></pre> <p>Future Enhancement (v4.30.0): Configurable paths via environment variables.</p>"},{"location":"advanced/customizing-standardization/#json-structure","title":"JSON Structure","text":"<p>The core mappings file uses a flat dictionary structure:</p> <pre><code>{\n  \"Standard Concept Label\": [\n    \"company_specific_tag_1\",\n    \"company_specific_tag_2\",\n    \"us-gaap:StandardTag\"\n  ],\n  \"_comment_section\": \"Documentation comments for maintainers\"\n}\n</code></pre>"},{"location":"advanced/customizing-standardization/#real-example-from-concept_mappingsjson","title":"Real Example from concept_mappings.json","text":"<pre><code>{\n  \"_comment_revenue_hierarchy\": \"REVENUE HIERARCHY FIX: Separated total revenue from component revenue types to prevent duplicate labels.\",\n\n  \"Revenue\": [\n    \"us-gaap:Revenue\",\n    \"us-gaap:Revenues\",\n    \"us-gaap:SalesRevenueNet\",\n    \"us-gaap:OperatingRevenue\"\n  ],\n\n  \"Contract Revenue\": [\n    \"us-gaap:RevenueFromContractWithCustomerExcludingAssessedTax\",\n    \"us-gaap:RevenueFromContractWithCustomerIncludingAssessedTax\"\n  ],\n\n  \"Product Revenue\": [\n    \"us-gaap:SalesRevenueGoodsNet\",\n    \"us-gaap:ProductSales\"\n  ]\n}\n</code></pre>"},{"location":"advanced/customizing-standardization/#understanding-comments","title":"Understanding Comments","text":"<p>The JSON file includes <code>_comment_*</code> keys for documentation: - These are ignored by the mapping system - They explain design decisions - They help maintainers understand complex hierarchies</p>"},{"location":"advanced/customizing-standardization/#hierarchy-separation","title":"Hierarchy Separation","text":"<p>Notice the careful separation of concepts: - \"Revenue\": Total revenue (parent concept) - \"Contract Revenue\": Component of revenue (child concept) - \"Product Revenue\": Another component (sibling to Contract Revenue)</p> <p>This prevents mapping conflicts where multiple XBRL tags map to the same label.</p>"},{"location":"advanced/customizing-standardization/#cost-hierarchy-example","title":"Cost Hierarchy Example","text":"<pre><code>{\n  \"_comment_cost_of_revenue_hierarchy\": \"Different business models use different cost concepts that should have distinct labels.\",\n\n  \"Total Cost of Revenue\": [\n    \"us-gaap:CostOfRevenue\"\n  ],\n\n  \"Cost of Goods Sold\": [\n    \"us-gaap:CostOfGoodsSold\"\n  ],\n\n  \"Cost of Goods and Services Sold\": [\n    \"us-gaap:CostOfGoodsAndServicesSold\"\n  ],\n\n  \"Direct Operating Costs\": [\n    \"us-gaap:DirectOperatingCosts\"\n  ]\n}\n</code></pre> <p>Why separate these? - Manufacturing companies use \"Cost of Goods Sold\" - Service companies use \"Direct Operating Costs\" - Mixed businesses use \"Cost of Goods and Services Sold\" - Each should have a distinct label for clarity</p>"},{"location":"advanced/customizing-standardization/#adding-custom-core-mappings","title":"Adding Custom Core Mappings","text":"<p>To extend core mappings (not recommended for most users):</p> <ol> <li>Locate the file: <code>edgar/xbrl/standardization/concept_mappings.json</code></li> <li>Add your mapping:</li> </ol> <pre><code>{\n  \"Custom Concept Label\": [\n    \"us-gaap:YourCustomTag\",\n    \"company:AnotherTag\"\n  ]\n}\n</code></pre> <ol> <li>Maintain hierarchy: Ensure parent/child relationships are clear</li> <li>Add comments: Document your reasoning with <code>_comment_*</code> keys</li> </ol> <p>Warning: Modifying packaged files is not recommended. Use company-specific mappings instead (Section 4).</p>"},{"location":"advanced/customizing-standardization/#4-company-specific-mappings","title":"4. Company-Specific Mappings","text":""},{"location":"advanced/customizing-standardization/#why-company-specific-mappings","title":"Why Company-Specific Mappings?","text":"<p>Company-specific mapping files allow you to: - Override core mappings for specific companies - Add industry-specific concepts (automotive, technology, energy) - Handle company extension taxonomies - Maintain separation of concerns (one file per company)</p>"},{"location":"advanced/customizing-standardization/#file-structure-ticker_mappingsjson","title":"File Structure: {ticker}_mappings.json","text":"<p>Current Location (hardcoded):</p> <pre><code>edgar/xbrl/standardization/company_mappings/{ticker}_mappings.json\n</code></pre> <p>Important Note: Currently uses ticker as identifier, but CIK-based identification is coming in v4.30.0/v4.31.0 to handle multi-ticker companies (GOOG/GOOGL, HEI.A/HEI.B).</p>"},{"location":"advanced/customizing-standardization/#complete-company-mapping-schema","title":"Complete Company Mapping Schema","text":"<pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"ticker_symbol\",\n    \"company_name\": \"Full Company Name\",\n    \"cik\": \"1234567\",\n    \"priority\": \"high|medium|low\",\n    \"created_date\": \"YYYY-MM-DD\",\n    \"last_updated\": \"YYYY-MM-DD\",\n    \"description\": \"Brief description of custom taxonomy needs\"\n  },\n\n  \"concept_mappings\": {\n    \"Standard Concept Label\": [\n      \"company:CustomTag\",\n      \"company:AnotherCustomTag\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"Parent Concept\": {\n      \"children\": [\n        \"Child Concept 1\",\n        \"Child Concept 2\"\n      ],\n      \"description\": \"Optional explanation\"\n    }\n  },\n\n  \"business_context\": {\n    \"primary_revenue_streams\": [\"stream1\", \"stream2\"],\n    \"revenue_model\": \"product_and_service|subscription|manufacturing\",\n    \"key_metrics\": [\"metric1\", \"metric2\"],\n    \"industry\": \"industry_classification\"\n  }\n}\n</code></pre>"},{"location":"advanced/customizing-standardization/#real-example-tesla-tsla_mappingsjson","title":"Real Example: Tesla (tsla_mappings.json)","text":"<pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"tsla\",\n    \"company_name\": \"Tesla, Inc.\",\n    \"cik\": \"1318605\",\n    \"priority\": \"high\",\n    \"created_date\": \"2024-06-25\",\n    \"last_updated\": \"2024-06-25\",\n    \"description\": \"Tesla-specific concept mappings to handle automotive, energy, and service revenue streams\"\n  },\n\n  \"concept_mappings\": {\n    \"Automotive Revenue\": [\n      \"tsla:AutomotiveRevenue\",\n      \"tsla:AutomotiveSales\",\n      \"tsla:VehicleRevenue\"\n    ],\n\n    \"Automotive Leasing Revenue\": [\n      \"tsla:AutomotiveLeasing\",\n      \"tsla:AutomotiveLeasingRevenue\",\n      \"tsla:VehicleLeasingRevenue\"\n    ],\n\n    \"Energy Revenue\": [\n      \"tsla:EnergyGenerationAndStorageRevenue\",\n      \"tsla:EnergyRevenue\",\n      \"tsla:SolarRevenue\",\n      \"tsla:EnergyStorageRevenue\"\n    ],\n\n    \"Service Revenue\": [\n      \"tsla:ServicesAndOtherRevenue\",\n      \"tsla:ServiceRevenue\",\n      \"tsla:SuperchargerRevenue\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"Revenue\": {\n      \"children\": [\n        \"Automotive Revenue\",\n        \"Energy Revenue\",\n        \"Service Revenue\"\n      ]\n    },\n    \"Automotive Revenue\": {\n      \"children\": [\n        \"Automotive Leasing Revenue\"\n      ]\n    }\n  },\n\n  \"business_context\": {\n    \"primary_revenue_streams\": [\"automotive\", \"energy\", \"services\"],\n    \"revenue_model\": \"product_and_service\",\n    \"key_metrics\": [\"vehicle_deliveries\", \"energy_deployments\"],\n    \"industry\": \"automotive_technology\"\n  }\n}\n</code></pre>"},{"location":"advanced/customizing-standardization/#real-example-microsoft-msft_mappingsjson","title":"Real Example: Microsoft (msft_mappings.json)","text":"<pre><code>{\n  \"entity_info\": {\n    \"name\": \"Microsoft Corporation\",\n    \"cik\": \"0000789019\",\n    \"ticker\": \"MSFT\",\n    \"description\": \"Microsoft-specific concept mappings for unique business terminology\"\n  },\n\n  \"concept_mappings\": {\n    \"_comment_msft_revenue\": \"Microsoft uses specific revenue categorization that differs from standard tech companies\",\n\n    \"Product Revenue\": [\n      \"msft:ProductRevenue\",\n      \"msft:WindowsCommercialRevenue\",\n      \"msft:WindowsConsumerRevenue\",\n      \"msft:OfficeCommercialRevenue\"\n    ],\n\n    \"Service Revenue\": [\n      \"msft:ServiceRevenue\",\n      \"msft:CloudServicesRevenue\",\n      \"msft:ConsultingServicesRevenue\"\n    ],\n\n    \"Subscription Revenue\": [\n      \"msft:Office365CommercialRevenue\",\n      \"msft:Office365ConsumerRevenue\",\n      \"msft:DynamicsRevenue\"\n    ],\n\n    \"Platform Revenue\": [\n      \"msft:AzureRevenue\",\n      \"msft:XboxContentAndServicesRevenue\"\n    ],\n\n    \"_comment_msft_expenses\": \"Microsoft has unique expense categorizations\",\n\n    \"Sales and Marketing Expense\": [\n      \"msft:SalesAndMarketingExpense\",\n      \"msft:AdvertisingAndPromotionExpense\"\n    ],\n\n    \"Technical Support Expense\": [\n      \"msft:TechnicalSupportExpense\",\n      \"msft:CustomerSupportExpense\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"_comment\": \"Rules for handling Microsoft-specific hierarchical relationships\",\n\n    \"revenue_hierarchy\": {\n      \"parent\": \"Revenue\",\n      \"children\": [\"Product Revenue\", \"Service Revenue\", \"Subscription Revenue\", \"Platform Revenue\"],\n      \"calculation_rule\": \"sum\"\n    },\n\n    \"expense_hierarchy\": {\n      \"parent\": \"Operating Expenses\",\n      \"children\": [\"Sales and Marketing Expense\", \"Technical Support Expense\"],\n      \"calculation_rule\": \"sum\"\n    }\n  }\n}\n</code></pre>"},{"location":"advanced/customizing-standardization/#creating-your-own-company-mapping","title":"Creating Your Own Company Mapping","text":"<p>Step 1: Identify Company Extension Tags</p> <pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\nfiling = company.get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\n\n# Find company-specific tags\nfacts = xbrl.facts.query().to_dataframe()\ncompany_tags = facts[facts['concept'].str.startswith('aapl:')]['concept'].unique()\nprint(f\"Found {len(company_tags)} Apple-specific tags\")\n</code></pre> <p>Step 2: Create Mapping File</p> <pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"aapl\",\n    \"company_name\": \"Apple Inc.\",\n    \"cik\": \"0000320193\",\n    \"priority\": \"high\",\n    \"created_date\": \"2025-11-19\",\n    \"last_updated\": \"2025-11-19\",\n    \"description\": \"Apple-specific mappings for product categories\"\n  },\n\n  \"concept_mappings\": {\n    \"iPhone Revenue\": [\n      \"aapl:IPhoneRevenue\",\n      \"aapl:IPhoneSales\"\n    ],\n\n    \"Services Revenue\": [\n      \"aapl:ServicesRevenue\",\n      \"aapl:AppleCareRevenue\",\n      \"aapl:ICloudRevenue\"\n    ]\n  }\n}\n</code></pre> <p>Step 3: Place File in Correct Location</p> <pre><code>edgar/xbrl/standardization/company_mappings/aapl_mappings.json\n</code></pre> <p>Current Limitation: Must be inside the package directory (see Section 6).</p>"},{"location":"advanced/customizing-standardization/#5-priority-system-and-ambiguous-tag-resolution","title":"5. Priority System and Ambiguous Tag Resolution","text":""},{"location":"advanced/customizing-standardization/#the-ambiguous-tag-problem","title":"The Ambiguous Tag Problem","text":"<p>Over 200 XBRL tags are inherently ambiguous and can map to multiple standard concepts depending on context. These fall into several categories:</p>"},{"location":"advanced/customizing-standardization/#category-1-assetliability-ambiguity-12-tags","title":"Category 1: Asset/Liability Ambiguity (12 tags)","text":"<p>Tags that could be either assets or liabilities:</p> <pre><code>DeferredTaxAssetsLiabilitiesNet\nDeferredTaxAssetsLiabilitiesNetCurrent\nDeferredTaxAssetsLiabilitiesNetNoncurrent\nDerivativeAssetsLiabilitiesAtFairValueNet\nDeferredFinanceCostsCurrentNet\nDeferredFinanceCostsNoncurrentNet\nCustomerAdvancesAndProgressPaymentsForLongTermContractsOrPrograms\nDeferredTaxLiabilitiesGoodwillAndIntangibleAssets\nDeferredTaxLiabilitiesInvestments\nUnamortizedDebtIssuanceExpense\nDerivativeLiabilityFairValueGrossAsset\n</code></pre> <p>Example: DeferredTaxAssetsLiabilitiesNet</p> <p>This tag represents the NET of deferred tax assets and liabilities: - If positive \u2192 Deferred Tax Asset - If negative \u2192 Deferred Tax Liability</p> <p>Resolution Strategy: Use statement context and sign convention.</p>"},{"location":"advanced/customizing-standardization/#category-2-currentnoncurrent-ambiguity-180-tags","title":"Category 2: Current/Noncurrent Ambiguity (180+ tags)","text":"<p>Tags that don't specify classification:</p> <pre><code>AccountsPayableCurrentAndNoncurrent\nAccountsPayableAndAccruedLiabilitiesCurrentAndNoncurrent\nAccountsReceivableGross\nAccountsReceivableNet\nDeferredRevenue\nContractWithCustomerLiability\nConvertibleDebt\nDebtInstrumentCarryingAmount\n</code></pre> <p>Example: AccountsPayableCurrentAndNoncurrent</p> <p>Without context, you can't determine if this should map to: - \"Accounts Payable, Current\" (on current liabilities) - \"Accounts Payable, Noncurrent\" (on long-term liabilities) - \"Accounts Payable, Total\" (parent concept)</p> <p>Resolution Strategy: Use calculation tree parent relationships and statement location.</p>"},{"location":"advanced/customizing-standardization/#category-3-triple-ambiguity-1-tag","title":"Category 3: Triple Ambiguity (1 tag)","text":"<pre><code>DerivativeLiabilityFairValueGrossAsset\n</code></pre> <p>This tag is ambiguous in THREE dimensions: 1. Asset vs. Liability 2. Current vs. Noncurrent 3. Gross vs. Net</p> <p>Resolution: Requires comprehensive context analysis.</p>"},{"location":"advanced/customizing-standardization/#category-4-total-vs-line-item-ambiguity","title":"Category 4: Total vs. Line Item Ambiguity","text":"<pre><code>LiabilitiesNoncurrent\n</code></pre> <p>Some companies use this as: - Total line: Sum of all noncurrent liabilities - Other line item: \"Other Noncurrent Liabilities\"</p> <p>Resolution: Check if it has children in calculation tree or appears multiple times.</p>"},{"location":"advanced/customizing-standardization/#priority-levels-explained","title":"Priority Levels Explained","text":""},{"location":"advanced/customizing-standardization/#priority-1-core-mappings","title":"Priority 1: Core Mappings","text":"<p>Source: <code>concept_mappings.json</code> Use: Base US-GAAP concepts that apply to all companies</p> <pre><code># P1 mapping example\n\"Revenue\": [\n  \"us-gaap:Revenue\",\n  \"us-gaap:Revenues\",\n  \"us-gaap:SalesRevenueNet\"\n]\n</code></pre> <p>When Applied: When no company-specific mapping exists.</p>"},{"location":"advanced/customizing-standardization/#priority-2-company-mappings","title":"Priority 2: Company Mappings","text":"<p>Source: <code>company_mappings/{ticker}_mappings.json</code> Use: Company-specific overrides and extensions</p> <pre><code># P2 mapping example (Tesla)\n\"Automotive Revenue\": [\n  \"tsla:AutomotiveRevenue\",\n  \"tsla:AutomotiveSales\"\n]\n</code></pre> <p>When Applied: When company mapping file exists for the ticker.</p>"},{"location":"advanced/customizing-standardization/#priority-4-detected-entity-match","title":"Priority 4: Detected Entity Match","text":"<p>Source: Automatic detection from concept prefix Use: Boost priority when concept prefix matches company</p> <pre><code># P4 boost example\nconcept = \"tsla:AutomotiveRevenue\"\n# System detects \"tsla:\" prefix\n# Checks if \"tsla\" company mappings exist\n# Boosts priority from P2 \u2192 P4 for Tesla mappings\n</code></pre> <p>When Applied: When concept prefix matches a known company identifier.</p>"},{"location":"advanced/customizing-standardization/#context-based-resolution","title":"Context-Based Resolution","text":"<p>The system uses multiple context signals to resolve ambiguous tags:</p>"},{"location":"advanced/customizing-standardization/#1-statement-type-context","title":"1. Statement Type Context","text":"<pre><code>context = {\n    'statement_type': 'BalanceSheet'  # or 'IncomeStatement', 'CashFlowStatement'\n}\n</code></pre> <p>Example Resolution:</p> <pre><code>Tag: \"DeferredTaxAssetsLiabilitiesNet\"\nStatement: BalanceSheet\nParent: \"Assets\"\n\u2192 Maps to: \"Deferred Tax Assets\"\n\nTag: \"DeferredTaxAssetsLiabilitiesNet\"\nStatement: BalanceSheet\nParent: \"Liabilities\"\n\u2192 Maps to: \"Deferred Tax Liabilities\"\n</code></pre>"},{"location":"advanced/customizing-standardization/#2-calculation-tree-relationships","title":"2. Calculation Tree Relationships","text":"<pre><code>context = {\n    'calculation_parent': 'us-gaap:AssetsCurrent',\n    'level': 1\n}\n</code></pre> <p>Example Resolution:</p> <pre><code>Tag: \"AccountsPayableCurrentAndNoncurrent\"\nParent: \"AssetsCurrent\" (impossible - payables are liabilities)\n\u2192 Check if sign is negative\n\u2192 Maps to: \"Accounts Payable, Current\" (negative in assets = liability)\n\nTag: \"AccountsPayableCurrentAndNoncurrent\"\nParent: \"LiabilitiesCurrent\"\n\u2192 Maps to: \"Accounts Payable, Current\"\n\nTag: \"AccountsPayableCurrentAndNoncurrent\"\nParent: \"LiabilitiesNoncurrent\"\n\u2192 Maps to: \"Accounts Payable, Noncurrent\"\n</code></pre>"},{"location":"advanced/customizing-standardization/#3-sign-conventions","title":"3. Sign Conventions","text":"<pre><code># Positive value in assets section \u2192 Asset\n# Negative value in assets section \u2192 Liability (unusual presentation)\n# Check fact value and location\n</code></pre>"},{"location":"advanced/customizing-standardization/#4-position-and-level","title":"4. Position and Level","text":"<pre><code>context = {\n    'position': 0,  # First item in section\n    'level': 0,     # Top level (total)\n    'is_total': True\n}\n</code></pre> <p>Example Resolution:</p> <pre><code>Tag: \"LiabilitiesNoncurrent\"\nLevel: 0\nHas children: Yes\n\u2192 Maps to: \"Total Noncurrent Liabilities\"\n\nTag: \"LiabilitiesNoncurrent\"\nLevel: 1\nHas children: No\n\u2192 Maps to: \"Other Noncurrent Liabilities\"\n</code></pre>"},{"location":"advanced/customizing-standardization/#complete-ambiguous-tag-list","title":"Complete Ambiguous Tag List","text":"<p>For reference, here are all identified ambiguous tags (from user @mpreiss9's analysis):</p> <p>Asset/Liability Ambiguity (12 tags):</p> <pre><code>CustomerAdvancesAndProgressPaymentsForLongTermContractsOrPrograms\nDeferredFinanceCostsCurrentNet\nDeferredFinanceCostsNoncurrentNet\nDeferredTaxAssetsLiabilitiesNet\nDeferredTaxAssetsLiabilitiesNetCurrent\nDeferredTaxAssetsLiabilitiesNetNoncurrent\nDeferredTaxLiabilitiesGoodwillAndIntangibleAssets\nDeferredTaxLiabilitiesGoodwillAndIntangibleAssetsIntangibleAssets\nDeferredTaxLiabilitiesInvestments\nDerivativeAssetsLiabilitiesAtFairValueNet\nUnamortizedDebtIssuanceExpense\nDerivativeLiabilityFairValueGrossAsset\n</code></pre> <p>Current/Noncurrent Ambiguity (180+ tags) - Excerpt:</p> <pre><code>AccountsPayableAndAccruedLiabilitiesCurrentAndNoncurrent\nAccountsPayableAndOtherAccruedLiabilities\nAccountsPayableCurrentAndNoncurrent\nAccountsPayableOtherCurrentAndNoncurrent\nAccountsPayableTradeCurrentAndNoncurrent\nAccountsReceivableGross\nAccountsReceivableNet\nAccountsReceivableRelatedParties\nAccrualForTaxesOtherThanIncomeTaxesCurrentAndNoncurrent\nAccruedAdvertisingCurrentAndNoncurrent\nAccruedBonusesCurrentAndNoncurrent\nAccruedEmployeeBenefitsCurrentAndNoncurrent\nAccruedIncomeTaxes\nAccruedLiabilitiesCurrentAndNoncurrent\nAvailableForSaleSecuritiesDebtSecurities\nBusinessCombinationContingentConsiderationAsset\nBusinessCombinationContingentConsiderationLiability\nCapitalizedContractCostNet\nCapitalLeaseObligations\nContractWithCustomerAssetNet\nContractWithCustomerLiability\nConvertibleDebt\nDebtInstrumentCarryingAmount\nDeferredRevenue\nDeferredTaxAssetsGross\nDeferredTaxAssetsNet\nDeferredTaxLiabilities\nDeferredTaxLiabilitiesNet\nDerivativeAssets\nDerivativeLiabilities\nEquitySecuritiesFvNi\nHeldToMaturitySecurities\nInvestments\nLineOfCredit\nMarketableSecurities\nNotesAndLoansPayable\nOperatingLeaseLiability\nOtherAssets\nOtherLiabilities\nRestrictedCash\n</code></pre> <p>See issue #494 comment for complete list of 200+ tags.</p>"},{"location":"advanced/customizing-standardization/#implementing-custom-ambiguity-resolution","title":"Implementing Custom Ambiguity Resolution","text":"<p>If you need to handle ambiguous tags for your specific use case:</p> <p>Option 1: Company-Specific Mapping</p> <pre><code>{\n  \"concept_mappings\": {\n    \"Deferred Tax Assets\": [\n      \"us-gaap:DeferredTaxAssetsLiabilitiesNet\"\n    ]\n  },\n  \"notes\": {\n    \"DeferredTaxAssetsLiabilitiesNet\": \"Company X always reports net deferred tax assets; never reports net liability\"\n  }\n}\n</code></pre> <p>Option 2: Context Validation (Future Enhancement)</p> <p>This is planned for v4.30.0:</p> <pre><code>from edgar.xbrl.standardization import MappingStore\n\nstore = MappingStore()\n\n# Custom resolution function\ndef custom_resolver(concept, context, value):\n    if concept == \"us-gaap:DeferredTaxAssetsLiabilitiesNet\":\n        if value &gt; 0:\n            return \"Deferred Tax Assets\"\n        else:\n            return \"Deferred Tax Liabilities\"\n    return None\n\nstore.add_custom_resolver(custom_resolver)\n</code></pre>"},{"location":"advanced/customizing-standardization/#6-current-limitations","title":"6. Current Limitations","text":"<p>This section documents known limitations of the current implementation and provides workarounds. These are on the roadmap for future releases.</p>"},{"location":"advanced/customizing-standardization/#limitation-1-hardcoded-paths","title":"Limitation 1: Hardcoded Paths","text":"<p>Problem: Mapping files MUST be inside the package directory.</p> <p>Current Paths:</p> <pre><code>edgar/xbrl/standardization/concept_mappings.json\nedgar/xbrl/standardization/company_mappings/{ticker}_mappings.json\n</code></pre> <p>Why This is a Problem: - Users can't maintain mappings outside the package - Difficult to version control custom mappings separately - Package updates overwrite custom mappings - Not suitable for production deployment workflows</p> <p>Current Workaround:</p> <p>Copy your custom mapping files into the package directory after installation:</p> <pre><code># Find package location\npython -c \"import edgar; print(edgar.__file__)\"\n# Output: /path/to/site-packages/edgar/__init__.py\n\n# Copy your custom mappings\ncp my_custom_mappings.json /path/to/site-packages/edgar/xbrl/standardization/\ncp company_mappings/* /path/to/site-packages/edgar/xbrl/standardization/company_mappings/\n</code></pre> <p>Better Workaround (Python script):</p> <pre><code>import shutil\nfrom pathlib import Path\nimport edgar\n\n# Find package standardization directory\nedgar_path = Path(edgar.__file__).parent\nstd_path = edgar_path / \"xbrl\" / \"standardization\"\n\n# Copy custom core mappings\nshutil.copy(\n    \"my_custom_mappings.json\",\n    std_path / \"concept_mappings.json\"\n)\n\n# Copy company mappings\ncompany_dir = std_path / \"company_mappings\"\nfor mapping_file in Path(\"my_company_mappings\").glob(\"*_mappings.json\"):\n    shutil.copy(mapping_file, company_dir / mapping_file.name)\n\nprint(\"Custom mappings installed successfully\")\n</code></pre> <p>Risks: - Mappings are lost on package upgrade - Must re-run after each <code>pip install --upgrade edgartools</code></p> <p>Future Enhancement (v4.30.0):</p> <pre><code># Coming in v4.30.0\nimport os\nos.environ['EDGAR_MAPPINGS_PATH'] = '/path/to/my/mappings'\n\n# Or via constructor\nfrom edgar.xbrl.standardization import MappingStore\nstore = MappingStore(\n    core_path='/path/to/concept_mappings.json',\n    company_dir='/path/to/company_mappings/'\n)\n</code></pre>"},{"location":"advanced/customizing-standardization/#limitation-2-ticker-based-identification","title":"Limitation 2: Ticker-Based Identification","text":"<p>Problem: Company mappings use ticker as identifier, not CIK.</p> <p>Current Behavior:</p> <pre><code># File: company_mappings/msft_mappings.json\n{\n  \"metadata\": {\n    \"entity_identifier\": \"msft\",  # Uses ticker\n    \"cik\": \"0000789019\"            # CIK is just metadata\n  }\n}\n</code></pre> <p>Why This is a Problem:</p> <ol> <li>Multiple tickers per CIK:</li> <li>Alphabet: GOOG and GOOGL \u2192 Same CIK (1652044)</li> <li> <p>HEICO: HEI.A and HEI.B \u2192 Same CIK (46619)</p> </li> <li> <p>Ticker changes over time:</p> </li> <li>Facebook \u2192 Meta (FB \u2192 META)</li> <li> <p>Google \u2192 Alphabet (GOOG \u2192 GOOGL split)</p> </li> <li> <p>CIK is the stable identifier in SEC filings:</p> </li> <li>Every filing contains CIK</li> <li>Ticker can be ambiguous or absent</li> </ol> <p>Current Workaround:</p> <p>Use the primary ticker and document alternatives in metadata:</p> <pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"goog\",\n    \"company_name\": \"Alphabet Inc.\",\n    \"cik\": \"0001652044\",\n    \"alternative_tickers\": [\"GOOGL\", \"GOOG\"],\n    \"notes\": \"Use GOOG as primary; applies to both Class A (GOOGL) and Class C (GOOG)\"\n  }\n}\n</code></pre> <p>Then create a symlink or duplicate file:</p> <pre><code>cd company_mappings/\ncp goog_mappings.json googl_mappings.json\n</code></pre> <p>Future Enhancement (v4.30.0 - v4.31.0):</p> <pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"0001652044\",  # CIK is primary identifier\n    \"tickers\": [\"GOOG\", \"GOOGL\"],       # Multiple tickers supported\n    \"primary_ticker\": \"GOOG\"\n  }\n}\n</code></pre> <p>Timeline: - v4.30.0: Add CIK-based lookup support (dual lookup during transition) - v4.31.0: Default to CIK-based identification - v5.0.0: Deprecate ticker-based identification</p>"},{"location":"advanced/customizing-standardization/#limitation-3-json-only-format","title":"Limitation 3: JSON-Only Format","text":"<p>Problem: No native CSV support for mapping files.</p> <p>Why This is a Problem: - CSV is easier to edit in Excel or Google Sheets - Easier to detect duplicates with spreadsheet tools - Simpler to sort, filter, and validate mappings - More accessible for non-technical users</p> <p>Current Workaround: See Section 8 (CSV Workflow) for utilities.</p> <p>Quick CSV-to-JSON Converter:</p> <pre><code>import csv\nimport json\nfrom collections import defaultdict\n\ndef csv_to_mappings(csv_path, json_path):\n    \"\"\"Convert CSV mapping file to JSON format.\"\"\"\n    mappings = defaultdict(list)\n\n    with open(csv_path, 'r') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            standard_concept = row['standard_concept']\n            company_concept = row['company_concept']\n            mappings[standard_concept].append(company_concept)\n\n    with open(json_path, 'w') as f:\n        json.dump(dict(mappings), f, indent=2)\n\n    print(f\"Converted {len(mappings)} concepts\")\n\n# Usage\ncsv_to_mappings('my_mappings.csv', 'concept_mappings.json')\n</code></pre> <p>Expected CSV Format:</p> <pre><code>standard_concept,company_concept,notes\nRevenue,us-gaap:Revenue,Standard revenue tag\nRevenue,us-gaap:Revenues,Alternative spelling\nAutomotive Revenue,tsla:AutomotiveRevenue,Tesla-specific\n</code></pre> <p>Future Enhancement (v4.30.0):</p> <pre><code># Native CSV support - auto-detect from extension\nfrom edgar.xbrl.standardization import MappingStore\n\n# Automatically loads CSV or JSON based on extension\nstore = MappingStore(source=\"my_mappings.csv\")\n</code></pre>"},{"location":"advanced/customizing-standardization/#7-validation-techniques","title":"7. Validation Techniques","text":"<p>Validation is critical when working with custom mappings across 200+ companies. Here are proven techniques for ensuring mapping quality.</p>"},{"location":"advanced/customizing-standardization/#the-balance-sheet-validation-principle","title":"The Balance Sheet Validation Principle","text":"<p>The fundamental validation for balance sheets:</p> <pre><code># Core accounting equation\nAssets = Liabilities + Equity\n\n# Detailed validation\nTotal Assets = Current Assets + Noncurrent Assets\nTotal Assets = Sum(all individual asset line items)\n\nTotal Liabilities = Current Liabilities + Noncurrent Liabilities\nTotal Equity = Common Stock + Retained Earnings + Other Equity\n\nAssets = Liabilities + Equity\n</code></pre>"},{"location":"advanced/customizing-standardization/#balance-sheet-validation-code","title":"Balance Sheet Validation Code","text":"<pre><code>def validate_balance_sheet(xbrl, period_key):\n    \"\"\"Validate that balance sheet balances using mapped concepts.\"\"\"\n\n    facts = xbrl.facts.query().by_period_key(period_key).to_dataframe()\n\n    # Get key totals\n    total_assets = facts[facts['label'] == 'Total Assets']['value'].sum()\n    current_assets = facts[facts['label'] == 'Total Current Assets']['value'].sum()\n    noncurrent_assets = facts[facts['label'] == 'Total Non Current Assets']['value'].sum()\n\n    total_liabilities = facts[facts['label'] == 'Total Liabilities']['value'].sum()\n    total_equity = facts[facts['label'] == \"Total Stockholders' Equity\"]['value'].sum()\n\n    # Validation 1: Assets = Current + Noncurrent\n    if noncurrent_assets:  # Some companies don't report noncurrent separately\n        assets_check = abs(total_assets - (current_assets + noncurrent_assets)) &lt; 1.0\n        if not assets_check:\n            print(f\"WARNING: Assets don't balance: {total_assets} != {current_assets} + {noncurrent_assets}\")\n\n    # Validation 2: Assets = Liabilities + Equity\n    accounting_equation = abs(total_assets - (total_liabilities + total_equity)) &lt; 1.0\n    if not accounting_equation:\n        print(f\"ERROR: Accounting equation violated: {total_assets} != {total_liabilities} + {total_equity}\")\n        return False\n\n    # Validation 3: Sum of line items = Total Assets\n    asset_line_items = facts[\n        (facts['concept'].str.contains('Asset')) &amp;\n        (facts['label'] != 'Total Assets')\n    ]['value'].sum()\n\n    detail_check = abs(total_assets - asset_line_items) &lt; 1.0\n    if not detail_check:\n        print(f\"WARNING: Asset line items don't sum to total: {total_assets} != {asset_line_items}\")\n\n    return accounting_equation\n\n# Usage\nfiling = Company(\"AAPL\").get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\nperiod_key = xbrl.reporting_periods[0]['key']\n\nis_valid = validate_balance_sheet(xbrl, period_key)\nprint(f\"Balance sheet valid: {is_valid}\")\n</code></pre>"},{"location":"advanced/customizing-standardization/#income-statement-validation","title":"Income Statement Validation","text":"<p>Income statement validation is more complex due to: - Variable presentation formats - Sign convention inconsistencies (some expenses are positive, some negative) - Different levels of detail across companies</p> <pre><code>def validate_income_statement(xbrl, period_key):\n    \"\"\"Validate income statement using anchored approach.\"\"\"\n\n    facts = xbrl.facts.query().by_period_key(period_key).to_dataframe()\n\n    # Anchor points (always present and unambiguous)\n    revenue = facts[facts['label'] == 'Revenue']['value'].sum()\n    net_income = facts[facts['label'] == 'Net Income']['value'].sum()\n\n    if revenue == 0 or net_income == 0:\n        print(\"ERROR: Missing anchor points (Revenue or Net Income)\")\n        return False\n\n    # Get all expense items (with sign normalization)\n    expense_concepts = [\n        'Cost of Revenue',\n        'Research and Development Expense',\n        'Selling, General and Administrative Expense',\n        'Interest Expense',\n        'Income Tax Expense'\n    ]\n\n    total_expenses = 0\n    for concept in expense_concepts:\n        expense_facts = facts[facts['label'] == concept]['value']\n        if len(expense_facts) &gt; 0:\n            expense_value = expense_facts.sum()\n            # Normalize to positive (expenses reduce income)\n            if expense_value &lt; 0:\n                expense_value = abs(expense_value)\n            total_expenses += expense_value\n\n    # Check if Revenue - Expenses \u2248 Net Income\n    # Allow for other income/expense not captured\n    calculated_ni = revenue - total_expenses\n    difference = abs(calculated_ni - net_income)\n\n    # Difference should be small (other income/expense)\n    acceptable_diff = abs(revenue) * 0.1  # 10% tolerance for other items\n\n    if difference &gt; acceptable_diff:\n        print(f\"WARNING: Income statement doesn't reconcile:\")\n        print(f\"  Revenue: {revenue:,.0f}\")\n        print(f\"  Total Expenses: {total_expenses:,.0f}\")\n        print(f\"  Calculated NI: {calculated_ni:,.0f}\")\n        print(f\"  Reported NI: {net_income:,.0f}\")\n        print(f\"  Difference: {difference:,.0f} (acceptable: {acceptable_diff:,.0f})\")\n        return False\n\n    return True\n</code></pre>"},{"location":"advanced/customizing-standardization/#unmapped-tag-detection","title":"Unmapped Tag Detection","text":"<p>Detect XBRL tags that aren't mapped to standard concepts:</p> <pre><code>def find_unmapped_tags(xbrl, mapper):\n    \"\"\"Find all XBRL tags that don't map to standard concepts.\"\"\"\n\n    unmapped = []\n\n    # Get all unique concepts\n    facts = xbrl.facts.query().to_dataframe()\n    concepts = facts['concept'].unique()\n\n    for concept in concepts:\n        # Try to map each concept\n        label = facts[facts['concept'] == concept]['label'].iloc[0]\n        context = {'statement_type': 'Unknown'}\n\n        standard_concept = mapper.map_concept(concept, label, context)\n\n        if standard_concept is None:\n            unmapped.append({\n                'concept': concept,\n                'label': label,\n                'occurrences': len(facts[facts['concept'] == concept])\n            })\n\n    # Sort by occurrences (most common first)\n    unmapped.sort(key=lambda x: x['occurrences'], reverse=True)\n\n    return unmapped\n\n# Usage\nfrom edgar.xbrl.standardization import MappingStore, ConceptMapper\n\nstore = MappingStore()\nmapper = ConceptMapper(store)\n\nunmapped = find_unmapped_tags(xbrl, mapper)\n\nprint(f\"Found {len(unmapped)} unmapped tags\")\nfor tag in unmapped[:10]:  # Top 10\n    print(f\"  {tag['concept']}: '{tag['label']}' ({tag['occurrences']} occurrences)\")\n</code></pre>"},{"location":"advanced/customizing-standardization/#logging-unmapped-tags-for-review","title":"Logging Unmapped Tags for Review","text":"<p>Create a log file of unmapped tags with suggested mappings:</p> <pre><code>import csv\nfrom difflib import get_close_matches\n\ndef log_unmapped_tags(xbrl, mapper, output_path='unmapped_tags.csv'):\n    \"\"\"Create CSV log of unmapped tags with suggested standard concepts.\"\"\"\n\n    unmapped = find_unmapped_tags(xbrl, mapper)\n\n    # Get all standard concepts for matching\n    standard_concepts = list(store.mappings.keys())\n\n    with open(output_path, 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            'company_concept',\n            'label',\n            'occurrences',\n            'suggested_mapping',\n            'confidence',\n            'cik',\n            'notes'\n        ])\n\n        for tag in unmapped:\n            # Find closest matching standard concept\n            matches = get_close_matches(\n                tag['label'],\n                standard_concepts,\n                n=1,\n                cutoff=0.6\n            )\n\n            suggested = matches[0] if matches else \"MANUAL_REVIEW_NEEDED\"\n            confidence = \"high\" if matches and len(matches[0]) else \"low\"\n\n            writer.writerow([\n                tag['concept'],\n                tag['label'],\n                tag['occurrences'],\n                suggested,\n                confidence,\n                xbrl.entity_identifier,\n                \"\"  # Manual notes column\n            ])\n\n    print(f\"Wrote {len(unmapped)} unmapped tags to {output_path}\")\n    print(\"Review file and add to concept_mappings.json\")\n\n# Usage - process all companies\ncompanies = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\"]\n\nfor ticker in companies:\n    company = Company(ticker)\n    filing = company.get_filings(form=\"10-K\").latest()\n    xbrl = filing.xbrl()\n\n    log_unmapped_tags(xbrl, mapper, f\"unmapped_{ticker}.csv\")\n</code></pre>"},{"location":"advanced/customizing-standardization/#validation-utility-script","title":"Validation Utility Script","text":"<p>Comprehensive validation script for batch processing:</p> <pre><code>def validate_company_mappings(ticker, form=\"10-K\", years=3):\n    \"\"\"Validate mappings for a company across multiple years.\"\"\"\n\n    company = Company(ticker)\n    filings = company.get_filings(form=form).head(years)\n\n    results = []\n\n    for filing in filings:\n        print(f\"\\nValidating {ticker} {filing.filing_date}...\")\n\n        try:\n            xbrl = filing.xbrl()\n            period_key = xbrl.reporting_periods[0]['key']\n\n            # Run validations\n            bs_valid = validate_balance_sheet(xbrl, period_key)\n            is_valid = validate_income_statement(xbrl, period_key)\n            unmapped = find_unmapped_tags(xbrl, mapper)\n\n            result = {\n                'ticker': ticker,\n                'filing_date': filing.filing_date,\n                'balance_sheet_valid': bs_valid,\n                'income_statement_valid': is_valid,\n                'unmapped_count': len(unmapped),\n                'total_concepts': len(xbrl.facts.query().to_dataframe()['concept'].unique())\n            }\n\n            results.append(result)\n\n            print(f\"  Balance Sheet: {'\u2713' if bs_valid else '\u2717'}\")\n            print(f\"  Income Statement: {'\u2713' if is_valid else '\u2717'}\")\n            print(f\"  Unmapped: {len(unmapped)}\")\n\n        except Exception as e:\n            print(f\"  ERROR: {e}\")\n            results.append({\n                'ticker': ticker,\n                'filing_date': filing.filing_date,\n                'error': str(e)\n            })\n\n    return results\n\n# Batch validation\ncompanies = [\"AAPL\", \"MSFT\", \"GOOGL\", \"TSLA\", \"AMZN\"]\nall_results = []\n\nfor ticker in companies:\n    results = validate_company_mappings(ticker)\n    all_results.extend(results)\n\n# Summary\nvalid_count = sum(1 for r in all_results if r.get('balance_sheet_valid', False))\nprint(f\"\\nOverall: {valid_count}/{len(all_results)} filings validated successfully\")\n</code></pre>"},{"location":"advanced/customizing-standardization/#8-csv-workflow","title":"8. CSV Workflow","text":"<p>While EdgarTools currently uses JSON for mappings, many users prefer CSV for editing. This section provides utilities for CSV-based workflows.</p> <p>Note: Native CSV support is planned for v4.29.0/v4.30.0.</p>"},{"location":"advanced/customizing-standardization/#why-csv-for-mapping-management","title":"Why CSV for Mapping Management?","text":"<p>Advantages: - Excel editing: Use familiar spreadsheet tools - Duplicate detection: Sort columns to find duplicates easily - Filtering: Quick filtering by standard concept or company - Validation: Formulas can check for consistency - Collaboration: Easier for non-technical team members</p>"},{"location":"advanced/customizing-standardization/#csv-format-specification","title":"CSV Format Specification","text":"<p>Standard Format:</p> <pre><code>standard_concept,company_concept,company_cik,priority,notes\nRevenue,us-gaap:Revenue,,1,Core GAAP concept\nRevenue,us-gaap:Revenues,,1,Alternative spelling\nAutomotive Revenue,tsla:AutomotiveRevenue,1318605,2,Tesla-specific\nAutomotive Revenue,tsla:VehicleRevenue,1318605,2,Alternative Tesla tag\n</code></pre> <p>Columns: - <code>standard_concept</code>: The standardized label (e.g., \"Revenue\") - <code>company_concept</code>: The XBRL tag (e.g., \"us-gaap:Revenue\") - <code>company_cik</code>: Optional CIK for company-specific mappings (empty for core) - <code>priority</code>: 1=core, 2=company-specific (optional, for reference) - <code>notes</code>: Explanation, context, or validation notes</p>"},{"location":"advanced/customizing-standardization/#export-mappings-to-csv","title":"Export Mappings to CSV","text":"<pre><code>import csv\nfrom edgar.xbrl.standardization import MappingStore\n\ndef export_mappings_to_csv(store: MappingStore, output_path: str):\n    \"\"\"Export MappingStore to CSV format for editing.\"\"\"\n\n    rows = []\n\n    # Export core mappings (priority 1)\n    for standard_concept, company_concepts in store.mappings.items():\n        for company_concept in company_concepts:\n            rows.append({\n                'standard_concept': standard_concept,\n                'company_concept': company_concept,\n                'company_cik': '',\n                'priority': 1,\n                'notes': 'Core mapping'\n            })\n\n    # Export company-specific mappings (priority 2)\n    for entity_id, company_data in store.company_mappings.items():\n        cik = company_data.get('metadata', {}).get('cik', '')\n        concept_mappings = company_data.get('concept_mappings', {})\n\n        for standard_concept, company_concepts in concept_mappings.items():\n            for company_concept in company_concepts:\n                rows.append({\n                    'standard_concept': standard_concept,\n                    'company_concept': company_concept,\n                    'company_cik': cik,\n                    'priority': 2,\n                    'notes': f'Company-specific: {entity_id}'\n                })\n\n    # Write to CSV\n    with open(output_path, 'w', newline='') as f:\n        fieldnames = ['standard_concept', 'company_concept', 'company_cik', 'priority', 'notes']\n        writer = csv.DictWriter(f, fieldnames=fieldnames)\n        writer.writeheader()\n        writer.writerows(rows)\n\n    print(f\"Exported {len(rows)} mappings to {output_path}\")\n\n# Usage\nstore = MappingStore()\nexport_mappings_to_csv(store, 'all_mappings.csv')\n</code></pre>"},{"location":"advanced/customizing-standardization/#import-mappings-from-csv","title":"Import Mappings from CSV","text":"<pre><code>import csv\nfrom collections import defaultdict\nimport json\n\ndef import_mappings_from_csv(csv_path: str):\n    \"\"\"Import mappings from CSV and generate JSON files.\"\"\"\n\n    core_mappings = defaultdict(list)\n    company_mappings = defaultdict(lambda: defaultdict(list))\n\n    with open(csv_path, 'r') as f:\n        reader = csv.DictReader(f)\n\n        for row in reader:\n            standard_concept = row['standard_concept']\n            company_concept = row['company_concept']\n            cik = row.get('company_cik', '').strip()\n\n            if cik:\n                # Company-specific mapping\n                company_mappings[cik][standard_concept].append(company_concept)\n            else:\n                # Core mapping\n                core_mappings[standard_concept].append(company_concept)\n\n    # Save core mappings\n    with open('concept_mappings.json', 'w') as f:\n        json.dump(dict(core_mappings), f, indent=2)\n    print(f\"Saved core mappings: {len(core_mappings)} concepts\")\n\n    # Save company-specific mappings\n    for cik, mappings in company_mappings.items():\n        # Find ticker from CIK (simplified - you'd need a CIK-to-ticker lookup)\n        ticker = f\"cik{cik}\"  # Placeholder\n\n        company_data = {\n            \"metadata\": {\n                \"entity_identifier\": ticker,\n                \"cik\": cik,\n                \"priority\": \"high\",\n                \"created_date\": \"2025-11-19\"\n            },\n            \"concept_mappings\": dict(mappings)\n        }\n\n        filename = f\"{ticker}_mappings.json\"\n        with open(filename, 'w') as f:\n            json.dump(company_data, f, indent=2)\n        print(f\"Saved company mappings: {filename}\")\n\n# Usage\nimport_mappings_from_csv('all_mappings.csv')\n</code></pre>"},{"location":"advanced/customizing-standardization/#excel-editing-workflow","title":"Excel Editing Workflow","text":"<p>Step 1: Export to CSV</p> <pre><code>from edgar.xbrl.standardization import MappingStore\n\nstore = MappingStore()\nexport_mappings_to_csv(store, 'edgartools_mappings.csv')\n</code></pre> <p>Step 2: Open in Excel - Open <code>edgartools_mappings.csv</code> in Excel or Google Sheets - Use Excel features:   - Sort by <code>standard_concept</code> to group related mappings   - Filter by <code>company_cik</code> to see company-specific mappings   - Conditional Formatting to highlight duplicates   - Find &amp; Replace for bulk updates</p> <p>Step 3: Duplicate Detection in Excel</p> <p>Formula in column F (next to your data):</p> <pre><code>=COUNTIFS($B:$B,B2,$A:$A,A2)&gt;1\n</code></pre> <p>This highlights if the same <code>company_concept</code> maps to the same <code>standard_concept</code> multiple times.</p> <p>Step 4: Validation in Excel</p> <p>Add a validation column with this formula:</p> <pre><code>=IF(ISBLANK(B2), \"Missing concept\",\n    IF(ISBLANK(A2), \"Missing label\",\n       IF(AND(C2&lt;&gt;\"\", NOT(ISNUMBER(C2))), \"Invalid CIK\",\n          \"OK\")))\n</code></pre> <p>Step 5: Import Back to JSON</p> <pre><code>import_mappings_from_csv('edgartools_mappings.csv')\n</code></pre>"},{"location":"advanced/customizing-standardization/#single-file-vs-multiple-files","title":"Single File vs Multiple Files","text":"<p>Two approaches for managing 200+ companies:</p>"},{"location":"advanced/customizing-standardization/#approach-1-single-csv-file-recommended-for-excel-users","title":"Approach 1: Single CSV File (Recommended for Excel Users)","text":"<p>Structure:</p> <pre><code>standard_concept,company_concept,company_cik,ticker,notes\nRevenue,us-gaap:Revenue,,,Core GAAP\nAutomotive Revenue,tsla:AutomotiveRevenue,1318605,TSLA,Tesla-specific\nEnergy Revenue,tsla:EnergyRevenue,1318605,TSLA,Tesla energy\nProduct Revenue,msft:ProductRevenue,789019,MSFT,Microsoft\n</code></pre> <p>Advantages: - Easy to search across all companies - Single source of truth - Easy duplicate detection - Better for bulk operations</p> <p>Disadvantages: - Large file size (200 companies = 10,000+ rows) - Merge conflicts in version control - Slower to load</p>"},{"location":"advanced/customizing-standardization/#approach-2-multiple-json-files-current-edgartools-approach","title":"Approach 2: Multiple JSON Files (Current EdgarTools Approach)","text":"<p>Structure:</p> <pre><code>company_mappings/\n  aapl_mappings.json\n  msft_mappings.json\n  tsla_mappings.json\n  googl_mappings.json\n  ...\n</code></pre> <p>Advantages: - Modular (edit one company at a time) - Better for version control (fewer merge conflicts) - Faster loading (only load relevant companies) - Clear ownership (one file per company)</p> <p>Disadvantages: - Harder to find duplicates across companies - More files to manage - Need tooling to search across all files</p>"},{"location":"advanced/customizing-standardization/#hybrid-approach-best-of-both-worlds","title":"Hybrid Approach (Best of Both Worlds)","text":"<p>Use CSV as master source, generate JSON files:</p> <pre><code>def csv_to_company_json_files(csv_path: str, output_dir: str):\n    \"\"\"Convert single CSV to multiple company JSON files.\"\"\"\n\n    import csv\n    import json\n    from pathlib import Path\n    from collections import defaultdict\n\n    Path(output_dir).mkdir(exist_ok=True)\n\n    # Group by CIK\n    company_data = defaultdict(lambda: {\n        'metadata': {},\n        'concept_mappings': defaultdict(list)\n    })\n\n    with open(csv_path, 'r') as f:\n        reader = csv.DictReader(f)\n\n        for row in reader:\n            cik = row.get('company_cik', '').strip()\n            if not cik:\n                continue  # Skip core mappings\n\n            ticker = row.get('ticker', f'cik{cik}').lower()\n\n            # Set metadata\n            if not company_data[ticker]['metadata']:\n                company_data[ticker]['metadata'] = {\n                    'entity_identifier': ticker,\n                    'cik': cik,\n                    'priority': 'high'\n                }\n\n            # Add mapping\n            standard = row['standard_concept']\n            concept = row['company_concept']\n            company_data[ticker]['concept_mappings'][standard].append(concept)\n\n    # Write files\n    for ticker, data in company_data.items():\n        # Convert defaultdict to regular dict\n        data['concept_mappings'] = dict(data['concept_mappings'])\n\n        filename = Path(output_dir) / f\"{ticker}_mappings.json\"\n        with open(filename, 'w') as f:\n            json.dump(data, f, indent=2)\n\n        concept_count = len(data['concept_mappings'])\n        print(f\"Created {filename} with {concept_count} concepts\")\n\n# Usage\ncsv_to_company_json_files(\n    'master_mappings.csv',\n    'company_mappings/'\n)\n</code></pre> <p>Recommended Workflow for 200+ Companies: 1. Maintain master CSV file: <code>edgartools_master_mappings.csv</code> 2. Edit in Excel (easy duplicate detection, filtering) 3. Run conversion script to generate JSON files 4. Deploy JSON files to package directory 5. Version control both CSV (master) and JSON (generated)</p>"},{"location":"advanced/customizing-standardization/#9-real-world-examples","title":"9. Real-World Examples","text":"<p>This section explains existing company mapping files with detailed annotations.</p>"},{"location":"advanced/customizing-standardization/#example-1-tesla-automotive-energy","title":"Example 1: Tesla (Automotive + Energy)","text":"<p>Tesla has a complex revenue structure combining automotive sales, leasing, and energy generation/storage.</p> <p>File: <code>company_mappings/tsla_mappings.json</code></p> <pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"tsla\",\n    \"company_name\": \"Tesla, Inc.\",\n    \"cik\": \"1318605\",\n    \"priority\": \"high\",\n    \"created_date\": \"2024-06-25\",\n    \"last_updated\": \"2024-06-25\",\n    \"description\": \"Tesla-specific concept mappings to handle automotive, energy, and service revenue streams\"\n  },\n\n  \"concept_mappings\": {\n    \"Automotive Revenue\": [\n      \"tsla:AutomotiveRevenue\",\n      \"tsla:AutomotiveSales\",\n      \"tsla:VehicleRevenue\"\n    ],\n\n    \"Automotive Leasing Revenue\": [\n      \"tsla:AutomotiveLeasing\",\n      \"tsla:AutomotiveLeasingRevenue\",\n      \"tsla:VehicleLeasingRevenue\"\n    ],\n\n    \"Energy Revenue\": [\n      \"tsla:EnergyGenerationAndStorageRevenue\",\n      \"tsla:EnergyRevenue\",\n      \"tsla:SolarRevenue\",\n      \"tsla:EnergyStorageRevenue\"\n    ],\n\n    \"Service Revenue\": [\n      \"tsla:ServicesAndOtherRevenue\",\n      \"tsla:ServiceRevenue\",\n      \"tsla:SuperchargerRevenue\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"Revenue\": {\n      \"children\": [\n        \"Automotive Revenue\",\n        \"Energy Revenue\",\n        \"Service Revenue\"\n      ]\n    },\n    \"Automotive Revenue\": {\n      \"children\": [\n        \"Automotive Leasing Revenue\"\n      ]\n    }\n  },\n\n  \"business_context\": {\n    \"primary_revenue_streams\": [\"automotive\", \"energy\", \"services\"],\n    \"revenue_model\": \"product_and_service\",\n    \"key_metrics\": [\"vehicle_deliveries\", \"energy_deployments\"],\n    \"industry\": \"automotive_technology\"\n  }\n}\n</code></pre> <p>Key Design Decisions:</p> <ol> <li>Granular Revenue Breakdown:</li> <li>Separate automotive sales from leasing (different economics)</li> <li>Distinguish energy from automotive (different growth drivers)</li> <li> <p>Services as distinct category (recurring revenue)</p> </li> <li> <p>Hierarchy Rules:</p> </li> <li><code>Revenue</code> is parent of three main streams</li> <li><code>Automotive Revenue</code> contains <code>Automotive Leasing Revenue</code> as child</li> <li> <p>This ensures proper nesting in financial statements</p> </li> <li> <p>Multiple Tag Variations:</p> </li> <li>Tesla has changed tag names over time (<code>AutomotiveRevenue</code> vs <code>AutomotiveSales</code>)</li> <li>All variations map to same standard concept for consistency</li> </ol> <p>Usage Example:</p> <pre><code>from edgar import Company\n\ntesla = Company(\"TSLA\")\nfiling = tesla.get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\n\n# Get standardized income statement\nincome = xbrl.statements.income_statement()\n\n# Tesla-specific revenue line items will appear as:\n# - Automotive Revenue (instead of generic \"Revenue\")\n# - Automotive Leasing Revenue\n# - Energy Revenue\n# - Service Revenue\n</code></pre>"},{"location":"advanced/customizing-standardization/#example-2-microsoft-technology-platform","title":"Example 2: Microsoft (Technology Platform)","text":"<p>Microsoft has platform-based revenue (Azure, Office 365, Dynamics) requiring specialized mapping.</p> <p>File: <code>company_mappings/msft_mappings.json</code></p> <pre><code>{\n  \"entity_info\": {\n    \"name\": \"Microsoft Corporation\",\n    \"cik\": \"0000789019\",\n    \"ticker\": \"MSFT\",\n    \"description\": \"Microsoft-specific concept mappings for unique business terminology\"\n  },\n\n  \"concept_mappings\": {\n    \"_comment_msft_revenue\": \"Microsoft uses specific revenue categorization that differs from standard tech companies\",\n\n    \"Product Revenue\": [\n      \"msft:ProductRevenue\",\n      \"msft:WindowsCommercialRevenue\",\n      \"msft:WindowsConsumerRevenue\",\n      \"msft:OfficeCommercialRevenue\"\n    ],\n\n    \"Service Revenue\": [\n      \"msft:ServiceRevenue\",\n      \"msft:CloudServicesRevenue\",\n      \"msft:ConsultingServicesRevenue\"\n    ],\n\n    \"Subscription Revenue\": [\n      \"msft:Office365CommercialRevenue\",\n      \"msft:Office365ConsumerRevenue\",\n      \"msft:DynamicsRevenue\"\n    ],\n\n    \"Platform Revenue\": [\n      \"msft:AzureRevenue\",\n      \"msft:XboxContentAndServicesRevenue\"\n    ],\n\n    \"_comment_msft_expenses\": \"Microsoft has unique expense categorizations for sales and marketing vs G&amp;A\",\n\n    \"Sales and Marketing Expense\": [\n      \"msft:SalesAndMarketingExpense\",\n      \"msft:AdvertisingAndPromotionExpense\"\n    ],\n\n    \"Technical Support Expense\": [\n      \"msft:TechnicalSupportExpense\",\n      \"msft:CustomerSupportExpense\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"_comment\": \"Rules for handling Microsoft-specific hierarchical relationships\",\n\n    \"revenue_hierarchy\": {\n      \"parent\": \"Revenue\",\n      \"children\": [\"Product Revenue\", \"Service Revenue\", \"Subscription Revenue\", \"Platform Revenue\"],\n      \"calculation_rule\": \"sum\"\n    },\n\n    \"expense_hierarchy\": {\n      \"parent\": \"Operating Expenses\",\n      \"children\": [\"Sales and Marketing Expense\", \"Technical Support Expense\"],\n      \"calculation_rule\": \"sum\"\n    }\n  }\n}\n</code></pre> <p>Key Design Decisions:</p> <ol> <li>Four Revenue Categories:</li> <li>Product: Traditional software sales (Windows, Office perpetual licenses)</li> <li>Service: Consulting, support services</li> <li>Subscription: Recurring revenue (Office 365, Dynamics)</li> <li> <p>Platform: Cloud platforms (Azure, Xbox services)</p> </li> <li> <p>Expense Granularity:</p> </li> <li>Separates sales/marketing from technical support</li> <li> <p>Reflects Microsoft's investment in customer success teams</p> </li> <li> <p>Hierarchy Rules with Calculation:</p> </li> <li>Explicit <code>calculation_rule: sum</code> indicates children should sum to parent</li> <li>Validation can check this relationship</li> </ol> <p>Usage Example:</p> <pre><code>msft = Company(\"MSFT\")\nfiling = msft.get_filings(form=\"10-K\").latest()\nxbrl = filing.xbrl()\n\n# Analyze revenue mix\nfacts = xbrl.facts.query().by_statement_type(\"IncomeStatement\").to_dataframe()\n\nrevenue_breakdown = facts[facts['label'].str.contains('Revenue')][['label', 'value']]\nprint(revenue_breakdown)\n\n# Output:\n# label                    value\n# Product Revenue          75,000,000,000\n# Service Revenue          25,000,000,000\n# Subscription Revenue     60,000,000,000\n# Platform Revenue         40,000,000,000\n# Revenue                  200,000,000,000\n</code></pre>"},{"location":"advanced/customizing-standardization/#example-3-berkshire-hathaway-conglomerate","title":"Example 3: Berkshire Hathaway (Conglomerate)","text":"<p>Berkshire Hathaway is a diversified holding company with insurance, utilities, railroads, and manufacturing.</p> <p>File: <code>company_mappings/brka_mappings.json</code></p> <pre><code>{\n  \"concept_mappings\": {\n    \"Sales and Service Revenue\": [\n      \"brka:SalesAndServiceRevenue\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"Revenue\": {\n      \"components\": [\n        \"Sales and Service Revenue\",\n        \"Operating Lease Revenue\"\n      ],\n      \"description\": \"Total revenue comprises sales/service revenue and operating lease income for holding company\"\n    }\n  },\n\n  \"business_context\": {\n    \"entity_type\": \"holding_company\",\n    \"industry\": \"diversified_conglomerate\",\n    \"description\": \"Berkshire Hathaway operates diverse businesses including insurance, utilities, railroads, and manufacturing\"\n  }\n}\n</code></pre> <p>Key Design Decisions:</p> <ol> <li>Minimal Customization:</li> <li>Berkshire uses mostly standard US-GAAP tags</li> <li> <p>Only needs mapping for unique revenue categorization</p> </li> <li> <p>Lease Revenue Separation:</p> </li> <li>Operating lease revenue (equipment leasing subsidiaries)</li> <li> <p>Separated from core sales/service revenue</p> </li> <li> <p>Business Context:</p> </li> <li>Documents the holding company structure</li> <li>Helps interpreters understand diverse revenue sources</li> </ol> <p>Why So Simple?: - Berkshire's filings primarily use standard US-GAAP taxonomy - Conglomerates often don't need extensive custom tags - Industry-specific tags are used by individual subsidiaries (not parent)</p>"},{"location":"advanced/customizing-standardization/#example-4-industrial-company-template","title":"Example 4: Industrial Company Template","text":"<p>For users managing 200+ industrial companies, here's a template:</p> <pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"ticker\",\n    \"company_name\": \"Company Name\",\n    \"cik\": \"0000000000\",\n    \"priority\": \"medium\",\n    \"created_date\": \"2025-11-19\",\n    \"last_updated\": \"2025-11-19\",\n    \"description\": \"Industrial company with manufacturing operations\",\n    \"industry\": \"industrial_manufacturing\"\n  },\n\n  \"concept_mappings\": {\n    \"_comment\": \"Common industrial company customizations\",\n\n    \"Product Sales\": [\n      \"company:ProductSales\",\n      \"company:ManufacturedGoodsSales\"\n    ],\n\n    \"Raw Materials Inventory\": [\n      \"company:RawMaterialsInventory\"\n    ],\n\n    \"Work in Process Inventory\": [\n      \"company:WorkInProcessInventory\"\n    ],\n\n    \"Finished Goods Inventory\": [\n      \"company:FinishedGoodsInventory\"\n    ],\n\n    \"Manufacturing Overhead\": [\n      \"company:ManufacturingOverhead\",\n      \"company:FactoryOverhead\"\n    ]\n  },\n\n  \"hierarchy_rules\": {\n    \"Inventory\": {\n      \"children\": [\n        \"Raw Materials Inventory\",\n        \"Work in Process Inventory\",\n        \"Finished Goods Inventory\"\n      ],\n      \"calculation_rule\": \"sum\",\n      \"description\": \"Manufacturing inventory breakdown\"\n    }\n  },\n\n  \"business_context\": {\n    \"primary_revenue_streams\": [\"product_sales\"],\n    \"revenue_model\": \"manufacturing\",\n    \"key_metrics\": [\"inventory_turnover\", \"production_efficiency\"],\n    \"industry\": \"industrial_manufacturing\",\n    \"notes\": \"Focus on inventory management and cost of goods sold structure\"\n  }\n}\n</code></pre> <p>Adaptation for Your Companies: 1. Copy this template 2. Replace <code>company:</code> prefix with actual company prefix 3. Add industry-specific concepts (automotive parts, chemicals, etc.) 4. Customize inventory structure based on business model</p>"},{"location":"advanced/customizing-standardization/#10-future-enhancements","title":"10. Future Enhancements","text":"<p>This section outlines the roadmap for standardization improvements based on user feedback.</p>"},{"location":"advanced/customizing-standardization/#version-4300-next-1-2-months","title":"Version 4.30.0 (Next 1-2 Months)","text":"<p>Focus: Configuration and CSV Support</p>"},{"location":"advanced/customizing-standardization/#1-configurable-mapping-paths","title":"1. Configurable Mapping Paths","text":"<p>Problem Solved: Users can maintain mappings outside package directory.</p> <p>Implementation:</p> <pre><code># Environment variable configuration\nimport os\nos.environ['EDGAR_CORE_MAPPINGS'] = '/path/to/my/concept_mappings.json'\nos.environ['EDGAR_COMPANY_MAPPINGS_DIR'] = '/path/to/my/company_mappings/'\n\n# Library loads from custom paths\nfrom edgar.xbrl.standardization import MappingStore\nstore = MappingStore()  # Automatically uses env var paths\n</code></pre> <p>Alternative: Constructor parameters:</p> <pre><code>store = MappingStore(\n    core_mappings_path='/path/to/concept_mappings.json',\n    company_mappings_dir='/path/to/company_mappings/'\n)\n</code></pre> <p>Benefits: - Separate version control for mappings - Mappings survive package upgrades - Multiple mapping sets for different use cases</p>"},{"location":"advanced/customizing-standardization/#2-native-csv-format-support","title":"2. Native CSV Format Support","text":"<p>Problem Solved: Excel-based workflows without conversion scripts.</p> <p>Implementation:</p> <pre><code># Auto-detect format from extension\nstore = MappingStore(core_mappings_path='my_mappings.csv')\n\n# Explicit format specification\nstore = MappingStore(\n    core_mappings_path='my_mappings.txt',\n    format='csv'\n)\n</code></pre> <p>CSV Format:</p> <pre><code>standard_concept,company_concept,notes\nRevenue,us-gaap:Revenue,Core GAAP tag\nRevenue,us-gaap:Revenues,Alternative spelling\n</code></pre> <p>Benefits: - No conversion scripts needed - Direct Excel editing - Easier duplicate detection</p>"},{"location":"advanced/customizing-standardization/#3-enhanced-validation-tools","title":"3. Enhanced Validation Tools","text":"<p>Problem Solved: Automated mapping quality checks.</p> <p>Implementation:</p> <pre><code>from edgar.xbrl.standardization import MappingValidator\n\nvalidator = MappingValidator(store)\n\n# Validate balance sheet balancing\nreport = validator.validate_company(\n    ticker=\"AAPL\",\n    form=\"10-K\",\n    years=3\n)\n\nprint(report.summary())\n# Output:\n# \u2713 Balance Sheet: 3/3 periods balanced\n# \u2713 Income Statement: 3/3 periods validated\n# \u26a0 Unmapped tags: 12 concepts need mapping\n</code></pre> <p>Features: - Batch validation across multiple companies - Balance sheet equation checking - Income statement reconciliation - Coverage reports (% of concepts mapped)</p>"},{"location":"advanced/customizing-standardization/#version-4310-2-3-months","title":"Version 4.31.0 (2-3 Months)","text":"<p>Focus: CIK-Based Identification</p>"},{"location":"advanced/customizing-standardization/#1-cik-as-primary-identifier","title":"1. CIK as Primary Identifier","text":"<p>Problem Solved: Handle multi-ticker companies (GOOG/GOOGL, HEI.A/HEI.B).</p> <p>Implementation:</p> <pre><code>{\n  \"metadata\": {\n    \"entity_identifier\": \"0001652044\",\n    \"cik\": \"0001652044\",\n    \"tickers\": [\"GOOG\", \"GOOGL\"],\n    \"primary_ticker\": \"GOOG\",\n    \"company_name\": \"Alphabet Inc.\"\n  }\n}\n</code></pre> <p>File Naming:</p> <pre><code>company_mappings/\n  cik0001652044_mappings.json  # CIK-based naming\n  # OR legacy support:\n  goog_mappings.json  # Ticker-based naming (still supported)\n</code></pre>"},{"location":"advanced/customizing-standardization/#2-dual-lookup-support","title":"2. Dual Lookup Support","text":"<p>During Transition: Support both ticker and CIK lookups.</p> <pre><code># Both work\nstore.get_company_mappings(ticker=\"GOOG\")\nstore.get_company_mappings(cik=\"0001652044\")\n</code></pre>"},{"location":"advanced/customizing-standardization/#3-migration-tool","title":"3. Migration Tool","text":"<p>Help users migrate from ticker-based to CIK-based files.</p> <pre><code>from edgar.xbrl.standardization import migrate_to_cik\n\n# Migrate all ticker-based files to CIK-based\nmigrate_to_cik(\n    input_dir='company_mappings/',\n    output_dir='company_mappings_cik/',\n    cik_lookup_file='ticker_to_cik.csv'\n)\n</code></pre>"},{"location":"advanced/customizing-standardization/#version-500-major-release","title":"Version 5.0.0 (Major Release)","text":"<p>Focus: Advanced Features and ML Integration</p>"},{"location":"advanced/customizing-standardization/#1-json-loaded-standardconcept","title":"1. JSON-Loaded StandardConcept","text":"<p>Problem Solved: StandardConcept enum becomes fully data-driven.</p> <p>Current:</p> <pre><code># Enum is hardcoded in Python\nclass StandardConcept(str, Enum):\n    REVENUE = \"Revenue\"\n    TOTAL_ASSETS = \"Total Assets\"\n</code></pre> <p>Future:</p> <pre><code># Enum loaded from JSON at runtime\nStandardConcept = load_concepts_from_json('standard_concepts.json')\n\n# Users can extend without touching Python code\n</code></pre>"},{"location":"advanced/customizing-standardization/#2-concept-marketplacerepository","title":"2. Concept Marketplace/Repository","text":"<p>Problem Solved: Share mappings across community.</p> <p>Vision:</p> <pre><code>from edgar.xbrl.standardization import ConceptMarketplace\n\nmarketplace = ConceptMarketplace()\n\n# Download community mappings\nmarketplace.install('industrial-companies-pack')\nmarketplace.install('tech-companies-pack')\n\n# Share your mappings\nmarketplace.publish(\n    'my-custom-mappings',\n    description='Custom mappings for 200+ industrial firms',\n    companies=['AAPL', 'MSFT', ...],\n    license='MIT'\n)\n</code></pre> <p>Features: - Community-contributed mappings - Rating and review system - Automatic updates - Industry-specific packs</p>"},{"location":"advanced/customizing-standardization/#3-ml-based-concept-inference","title":"3. ML-Based Concept Inference","text":"<p>Problem Solved: Automatically suggest mappings for unmapped tags.</p> <p>Implementation:</p> <pre><code>from edgar.xbrl.standardization import MLConceptMapper\n\nml_mapper = MLConceptMapper()\n\n# Train on existing mappings\nml_mapper.train(store.mappings)\n\n# Suggest mappings for unmapped concepts\nsuggestion = ml_mapper.suggest(\n    concept='company:CustomRevenueConcept',\n    label='Sales of Manufactured Goods',\n    context={'statement_type': 'IncomeStatement'}\n)\n\nprint(suggestion)\n# Output:\n# Suggested: \"Product Revenue\"\n# Confidence: 0.89\n# Similar concepts: [\"Revenue\", \"Product Sales\", \"Sales\"]\n</code></pre> <p>Features: - Learn from existing mappings - Context-aware suggestions - Confidence scoring - Interactive review workflow</p>"},{"location":"advanced/customizing-standardization/#4-advanced-validation-framework","title":"4. Advanced Validation Framework","text":"<p>Problem Solved: Comprehensive statement validation.</p> <pre><code>from edgar.xbrl.standardization import ValidationFramework\n\nframework = ValidationFramework(store)\n\n# Define custom validation rules\n@framework.rule(statement='BalanceSheet', severity='error')\ndef validate_accounting_equation(facts):\n    assets = facts.get('Total Assets')\n    liabilities = facts.get('Total Liabilities')\n    equity = facts.get(\"Total Stockholders' Equity\")\n\n    if abs(assets - (liabilities + equity)) &gt; 1.0:\n        return ValidationError(\"Accounting equation violated\")\n    return None\n\n# Run validation\nresults = framework.validate_company('AAPL', years=10)\nresults.generate_report('validation_report.html')\n</code></pre>"},{"location":"advanced/customizing-standardization/#timeline-summary","title":"Timeline Summary","text":"Feature Version Timeline Status Configurable paths v4.30.0 1-2 months Planned Native CSV support v4.30.0 1-2 months Planned Enhanced validation v4.30.0 1-2 months Planned CIK-based identification v4.31.0 2-3 months Planned Dual lookup support v4.31.0 2-3 months Planned Migration tool v4.31.0 2-3 months Planned JSON StandardConcept v5.0.0 6-12 months Under consideration Concept marketplace v5.0.0 6-12 months Under consideration ML concept inference v5.0.0 6-12 months Research phase"},{"location":"advanced/customizing-standardization/#providing-feedback","title":"Providing Feedback","text":"<p>Your feedback shapes these enhancements. To contribute:</p> <ol> <li>GitHub Issues: Comment on issue #494 or create new issues</li> <li>Feature Requests: Use the feature request template</li> <li>User Stories: Share your specific use cases</li> <li>Beta Testing: Volunteer to test pre-release versions</li> </ol> <p>Contact: - GitHub: https://github.com/dgunning/edgartools/issues/494 - Discussions: https://github.com/dgunning/edgartools/discussions</p>"},{"location":"advanced/customizing-standardization/#summary-and-quick-reference","title":"Summary and Quick Reference","text":""},{"location":"advanced/customizing-standardization/#when-to-customize-standardization_1","title":"When to Customize Standardization","text":"<p>\u2705 Yes, customize when: - Managing 200+ companies with diverse taxonomies - Industry-specific valuations (industrial, automotive, tech) - Building models requiring consistent data structure - Statement balancing is critical to your workflow</p> <p>\u274c No, use defaults when: - Analyzing 1-10 companies - Standard US-GAAP concepts are sufficient - Quick analysis or exploration - Don't need custom taxonomy support</p>"},{"location":"advanced/customizing-standardization/#quick-decision-tree","title":"Quick Decision Tree","text":"<pre><code>Do you analyze 200+ companies?\n\u251c\u2500 Yes \u2192 Use custom company-specific mappings (Section 4)\n\u2502        \u2514\u2500 CSV workflow for easier management (Section 8)\n\u2514\u2500 No \u2192 Do you need industry-specific concepts?\n         \u251c\u2500 Yes \u2192 Use custom core mappings (Section 3)\n         \u2514\u2500 No \u2192 Use default StandardConcept mappings\n</code></pre>"},{"location":"advanced/customizing-standardization/#essential-resources","title":"Essential Resources","text":"Task Section Key File Understand architecture Section 2 <code>core.py</code> Add core mappings Section 3 <code>concept_mappings.json</code> Create company mappings Section 4 <code>{ticker}_mappings.json</code> Resolve ambiguous tags Section 5 Your context analysis Work around limitations Section 6 Installation scripts Validate mappings Section 7 Validation utilities Use CSV workflow Section 8 CSV utilities Learn from examples Section 9 Tesla, Microsoft files"},{"location":"advanced/customizing-standardization/#key-concepts-clarified","title":"Key Concepts Clarified","text":"Concept What It Is What It's NOT StandardConcept Enum IDE convenience, type safety NOT the mapping data JSON Mappings Source of truth for mappings NOT just for reference Priority System Conflict resolution NOT just ordering CIK Stable company identifier NOT ticker (which changes) Context Ambiguity resolution NOT just metadata"},{"location":"advanced/customizing-standardization/#contact-and-support","title":"Contact and Support","text":"<ul> <li>GitHub Issue: #494</li> <li>Documentation: This guide</li> <li>Examples: Section 9</li> <li>Roadmap: Section 10</li> </ul> <p>Document Version: 1.0 Last Updated: 2025-11-19 EdgarTools Version: 4.29.0+ Contributors: @dgunning, @mpreiss9, EdgarTools community</p>"},{"location":"api/company/","title":"Company API Reference","text":"<p>The <code>Company</code> class is the primary interface for working with public companies in EdgarTools. It provides access to company information, SEC filings, and financial data.</p>"},{"location":"api/company/#class-overview","title":"Class Overview","text":"<pre><code>from edgar import Company\n\nclass Company(Entity):\n    \"\"\"Represents a public company with SEC filings.\"\"\"\n</code></pre> <p>Inheritance: <code>SecFiler</code> \u2192 <code>Entity</code> \u2192 <code>Company</code></p>"},{"location":"api/company/#constructor","title":"Constructor","text":""},{"location":"api/company/#companycik_or_ticker","title":"Company(cik_or_ticker)","text":"<p>Create a Company instance using either a CIK number or ticker symbol.</p> <pre><code>Company(cik_or_ticker: Union[str, int])\n</code></pre> <p>Parameters: - <code>cik_or_ticker</code> (Union[str, int]): Company identifier   - CIK: Central Index Key as integer or string (with or without padding)   - Ticker: Stock ticker symbol (case-insensitive)</p> <p>Examples:</p> <pre><code># By ticker symbol (case-insensitive)\ncompany = Company(\"AAPL\")\ncompany = Company(\"aapl\")\n\n# By CIK number\ncompany = Company(320193)\ncompany = Company(\"320193\")\ncompany = Company(\"0000320193\")  # Zero-padded\n</code></pre> <p>Raises: - <code>CompanyNotFoundError</code>: When company cannot be found - <code>ValueError</code>: When identifier format is invalid</p>"},{"location":"api/company/#core-properties","title":"Core Properties","text":""},{"location":"api/company/#basic-information","title":"Basic Information","text":""},{"location":"api/company/#name","title":"name","text":"<pre><code>@property\ndef name(self) -&gt; str\n</code></pre> <p>Official company name as registered with the SEC.</p> <pre><code>company = Company(\"AAPL\")\nprint(company.name)  # \"Apple Inc.\"\n</code></pre>"},{"location":"api/company/#cik","title":"cik","text":"<pre><code>@property\ndef cik(self) -&gt; int\n</code></pre> <p>Central Index Key - unique identifier assigned by the SEC.</p> <pre><code>print(company.cik)  # 320193\n</code></pre>"},{"location":"api/company/#display_name","title":"display_name","text":"<pre><code>@property\ndef display_name(self) -&gt; str\n</code></pre> <p>Formatted display name combining ticker and company name.</p> <pre><code>print(company.display_name)  # \"AAPL - Apple Inc.\"\n</code></pre>"},{"location":"api/company/#tickers","title":"tickers","text":"<pre><code>@property\ndef tickers(self) -&gt; List[str]\n</code></pre> <p>List of all ticker symbols associated with the company.</p> <pre><code>berkshire = Company(\"BRK-A\")\nprint(berkshire.tickers)  # [\"BRK-A\", \"BRK-B\"]\n</code></pre>"},{"location":"api/company/#industry-classification","title":"Industry &amp; Classification","text":""},{"location":"api/company/#industry","title":"industry","text":"<pre><code>@property\ndef industry(self) -&gt; str\n</code></pre> <p>Industry description based on SIC code.</p> <pre><code>print(company.industry)  # \"ELECTRONIC COMPUTERS\"\n</code></pre>"},{"location":"api/company/#sic","title":"sic","text":"<pre><code>@property\ndef sic(self) -&gt; str\n</code></pre> <p>Standard Industrial Classification code.</p> <pre><code>print(company.sic)  # \"3571\"\n</code></pre>"},{"location":"api/company/#fiscal_year_end","title":"fiscal_year_end","text":"<pre><code>@property\ndef fiscal_year_end(self) -&gt; str\n</code></pre> <p>Fiscal year end date in MMDD format.</p> <pre><code>print(company.fiscal_year_end)  # \"0930\" (September 30)\n</code></pre>"},{"location":"api/company/#company-status","title":"Company Status","text":""},{"location":"api/company/#is_company","title":"is_company","text":"<pre><code>@property\ndef is_company(self) -&gt; bool\n</code></pre> <p>Always <code>True</code> for Company instances. Used to distinguish from other entities.</p> <pre><code>print(company.is_company)  # True\n</code></pre>"},{"location":"api/company/#not_found","title":"not_found","text":"<pre><code>@property\ndef not_found(self) -&gt; bool\n</code></pre> <p>Whether the company data was found in SEC database.</p> <pre><code>print(company.not_found)  # False if found, True if not\n</code></pre>"},{"location":"api/company/#filing-access","title":"Filing Access","text":""},{"location":"api/company/#get_filings","title":"get_filings()","text":"<p>Get company filings with extensive filtering options.</p> <pre><code>def get_filings(\n    self,\n    *,\n    year: Union[int, List[int], range] = None,\n    quarter: Union[int, List[int]] = None,\n    form: Union[str, List[str]] = None,\n    accession_number: Union[str, List[str]] = None,\n    file_number: Union[str, List[str]] = None,\n    filing_date: str = None,\n    date: str = None,\n    amendments: bool = True,\n    is_xbrl: bool = None,\n    is_inline_xbrl: bool = None,\n    sort_by: str = \"filing_date\",\n    trigger_full_load: bool = False\n) -&gt; EntityFilings\n</code></pre> <p>Parameters: - <code>year</code>: Filter by year(s) - int, list of ints, or range - <code>quarter</code>: Filter by quarter(s) - 1, 2, 3, or 4 - <code>form</code>: SEC form type(s) - e.g., \"10-K\", [\"10-K\", \"10-Q\"] - <code>accession_number</code>: Specific accession number(s) - <code>file_number</code>: SEC file number(s) - <code>filing_date</code>: Date or date range (YYYY-MM-DD or YYYY-MM-DD:YYYY-MM-DD) - <code>date</code>: Alias for filing_date - <code>amendments</code>: Include amended filings (default: True) - <code>is_xbrl</code>: Filter for XBRL filings - <code>is_inline_xbrl</code>: Filter for inline XBRL filings - <code>sort_by</code>: Sort field (default: \"filing_date\") - <code>trigger_full_load</code>: Load all filing details upfront</p> <p>Returns: <code>EntityFilings</code> - Collection of company filings</p> <p>Examples:</p> <pre><code># Get all filings\nall_filings = company.get_filings()\n\n# Get specific form types\nannual_reports = company.get_filings(form=\"10-K\")\nquarterly_reports = company.get_filings(form=[\"10-K\", \"10-Q\"])\n\n# Filter by date\nrecent = company.get_filings(filing_date=\"2023-01-01:\")\ndate_range = company.get_filings(filing_date=\"2023-01-01:2023-12-31\")\n\n# Filter by year and quarter\nq4_2023 = company.get_filings(year=2023, quarter=4)\nmulti_year = company.get_filings(year=[2022, 2023])\n\n# XBRL filings only\nxbrl_filings = company.get_filings(is_xbrl=True)\n\n# Exclude amendments\noriginal_only = company.get_filings(amendments=False)\n</code></pre>"},{"location":"api/company/#latest","title":"latest()","text":"<p>Get the latest filing(s) of a specific form type.</p> <pre><code>def latest(self, form: str, n: int = 1) -&gt; Union[Filing, List[Filing]]\n</code></pre> <p>Parameters: - <code>form</code>: SEC form type (e.g., \"10-K\", \"10-Q\", \"8-K\") - <code>n</code>: Number of latest filings to return (default: 1)</p> <p>Returns: - Single <code>Filing</code> if n=1 - <code>List[Filing]</code> if n&gt;1</p> <p>Examples:</p> <pre><code># Get latest 10-K\nlatest_10k = company.latest(\"10-K\")\n\n# Get latest 3 quarterly reports\nlatest_10qs = company.latest(\"10-Q\", 3)\n</code></pre>"},{"location":"api/company/#convenience-properties","title":"Convenience Properties","text":""},{"location":"api/company/#latest_tenk","title":"latest_tenk","text":"<pre><code>@property\ndef latest_tenk(self) -&gt; Optional[TenK]\n</code></pre> <p>Latest 10-K filing as a TenK object with enhanced functionality.</p> <pre><code>tenk = company.latest_tenk\nif tenk:\n    print(tenk.filing_date)\n    financials = tenk.financials\n</code></pre>"},{"location":"api/company/#latest_tenq","title":"latest_tenq","text":"<pre><code>@property  \ndef latest_tenq(self) -&gt; Optional[TenQ]\n</code></pre> <p>Latest 10-Q filing as a TenQ object with enhanced functionality.</p> <pre><code>tenq = company.latest_tenq\nif tenq:\n    print(tenq.filing_date)\n    financials = tenq.financials\n</code></pre>"},{"location":"api/company/#financial-data","title":"Financial Data","text":""},{"location":"api/company/#get_financials","title":"get_financials()","text":"<p>Get financial statements from the latest 10-K filing.</p> <pre><code>def get_financials(self) -&gt; Optional[Financials]\n</code></pre> <p>Returns: <code>Financials</code> object with balance sheet, income statement, and cash flow data</p> <p>Example:</p> <pre><code>financials = company.get_financials()\nif financials:\n    balance_sheet = financials.balance_sheet\n    income_statement = financials.income\n    cash_flow = financials.cash_flow\n\n    # Access specific metrics\n    revenue = income_statement.loc['Revenue'].iloc[0]\n    total_assets = balance_sheet.loc['Total Assets'].iloc[0]\n</code></pre>"},{"location":"api/company/#get_quarterly_financials","title":"get_quarterly_financials()","text":"<p>Get financial statements from the latest 10-Q filing.</p> <pre><code>def get_quarterly_financials(self) -&gt; Optional[Financials]\n</code></pre> <p>Returns: <code>Financials</code> object from latest quarterly report</p> <p>Example:</p> <pre><code>quarterly = company.get_quarterly_financials()\nif quarterly:\n    q_income = quarterly.income\n    quarterly_revenue = q_income.loc['Revenue'].iloc[0]\n</code></pre>"},{"location":"api/company/#get_facts","title":"get_facts()","text":"<p>Get structured XBRL facts for the company.</p> <pre><code>def get_facts(self) -&gt; Optional[EntityFacts]\n</code></pre> <p>Returns: <code>EntityFacts</code> object containing all XBRL facts</p> <p>Example:</p> <pre><code>facts = company.get_facts()\nif facts:\n    # Convert to pandas DataFrame\n    facts_df = facts.to_pandas()\n\n    # Get number of facts\n    num_facts = facts.num_facts()\n    print(f\"Company has {num_facts} XBRL facts\")\n</code></pre>"},{"location":"api/company/#address-information","title":"Address Information","text":""},{"location":"api/company/#business_address","title":"business_address()","text":"<p>Get the company's business address.</p> <pre><code>def business_address(self) -&gt; Optional[Address]\n</code></pre> <p>Returns: <code>Address</code> object or None</p> <p>Example:</p> <pre><code>address = company.business_address()\nif address:\n    print(f\"{address.street1}\")\n    print(f\"{address.city}, {address.state_or_country} {address.zipcode}\")\n</code></pre>"},{"location":"api/company/#mailing_address","title":"mailing_address()","text":"<p>Get the company's mailing address.</p> <pre><code>def mailing_address(self) -&gt; Optional[Address]\n</code></pre> <p>Returns: <code>Address</code> object or None</p>"},{"location":"api/company/#utility-methods","title":"Utility Methods","text":""},{"location":"api/company/#get_ticker","title":"get_ticker()","text":"<p>Get the primary ticker symbol for the company.</p> <pre><code>def get_ticker(self) -&gt; Optional[str]\n</code></pre> <p>Returns: Primary ticker symbol or None</p> <p>Example:</p> <pre><code>ticker = company.get_ticker()\nprint(ticker)  # \"AAPL\"\n</code></pre>"},{"location":"api/company/#get_exchanges","title":"get_exchanges()","text":"<p>Get all exchanges where the company's stock is traded.</p> <pre><code>def get_exchanges(self) -&gt; List[str]\n</code></pre> <p>Returns: List of exchange names</p> <p>Example:</p> <pre><code>exchanges = company.get_exchanges()\nprint(exchanges)  # [\"NASDAQ\"]\n</code></pre>"},{"location":"api/company/#get_icon","title":"get_icon()","text":"<p>Get company icon (if available).</p> <pre><code>def get_icon(self)\n</code></pre> <p>Returns: Icon data or placeholder</p>"},{"location":"api/company/#data-access","title":"Data Access","text":""},{"location":"api/company/#data","title":"data","text":"<p>Access the underlying company data object.</p> <pre><code>@property\ndef data(self) -&gt; EntityData\n</code></pre> <p>Returns: <code>EntityData</code> object with complete company information</p> <p>Example:</p> <pre><code># Access detailed company data\ncompany_data = company.data\nprint(company_data.former_names)  # Previous company names\nprint(company_data.entity_type)   # Entity type\nprint(company_data.flags)         # SEC flags\n</code></pre>"},{"location":"api/company/#related-classes","title":"Related Classes","text":""},{"location":"api/company/#entityfilings","title":"EntityFilings","text":"<p>Collection of SEC filings returned by <code>get_filings()</code>.</p> <pre><code>filings = company.get_filings(form=\"10-K\")\n\n# Collection methods\nlatest = filings.latest()           # Get latest filing\nfirst_five = filings.head(5)        # Get first 5 filings\nrandom_sample = filings.sample(3)   # Get 3 random filings\n\n# Filtering\nrecent = filings.filter(filing_date=\"2023-01-01:\")\nxbrl_only = filings.filter(is_xbrl=True)\n\n# Indexing\nfirst_filing = filings[0]           # Get first filing\nsecond_filing = filings[1]          # Get second filing\n\n# Iteration\nfor filing in filings:\n    print(f\"{filing.form}: {filing.filing_date}\")\n\n# Conversion\nfilings_df = filings.to_pandas()    # Convert to DataFrame\n</code></pre>"},{"location":"api/company/#address","title":"Address","text":"<p>Physical address representation.</p> <pre><code>class Address:\n    street1: str\n    street2: Optional[str]\n    city: str\n    state_or_country: str\n    zipcode: str\n    state_or_country_desc: str\n</code></pre> <p>Example:</p> <pre><code>address = company.business_address()\nfull_address = f\"{address.street1}, {address.city}, {address.state_or_country}\"\n</code></pre>"},{"location":"api/company/#entityfacts","title":"EntityFacts","text":"<p>XBRL facts data container.</p> <pre><code>facts = company.get_facts()\n\n# Convert to DataFrame\ndf = facts.to_pandas()\n\n# Get fact count\ncount = facts.num_facts()\n</code></pre>"},{"location":"api/company/#factory-functions","title":"Factory Functions","text":"<p>Alternative ways to create Company instances:</p> <pre><code>from edgar import get_company, get_entity\n\n# Factory function\ncompany = get_company(\"AAPL\")\n\n# More general entity function (returns Company for companies)\nentity = get_entity(\"AAPL\")\n</code></pre>"},{"location":"api/company/#import-options","title":"Import Options","text":"<pre><code># Primary import\nfrom edgar import Company\n\n# Alternative imports\nfrom edgar.entity import Company\nfrom edgar.entity.core import Company\n</code></pre>"},{"location":"api/company/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    company = Company(\"INVALID\")\nexcept CompanyNotFoundError:\n    print(\"Company not found\")\nexcept ValueError as e:\n    print(f\"Invalid identifier: {e}\")\n\n# Check if company was found\ncompany = Company(\"MAYBE_INVALID\")\nif company.not_found:\n    print(\"Company data not available\")\nelse:\n    filings = company.get_filings()\n</code></pre>"},{"location":"api/company/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use CIK when possible - faster than ticker lookup</li> <li>Cache Company objects - avoid repeated API calls</li> <li>Filter filings efficiently - use specific parameters in <code>get_filings()</code></li> <li>Limit result sets - use reasonable date ranges and form filters</li> </ol> <pre><code># Efficient: specific filtering\nrecent_10k = company.get_filings(form=\"10-K\", filing_date=\"2023-01-01:\")\n\n# Less efficient: get all then filter\nall_filings = company.get_filings()\nfiltered = all_filings.filter(form=\"10-K\").filter(filing_date=\"2023-01-01:\")\n</code></pre>"},{"location":"api/company/#complete-example","title":"Complete Example","text":"<pre><code>from edgar import Company\n\n# Create company instance\ncompany = Company(\"AAPL\")\n\n# Basic information\nprint(f\"Company: {company.name}\")\nprint(f\"CIK: {company.cik}\")\nprint(f\"Industry: {company.industry}\")\nprint(f\"Fiscal Year End: {company.fiscal_year_end}\")\n\n# Get recent filings\nrecent_filings = company.get_filings(\n    form=[\"10-K\", \"10-Q\"], \n    filing_date=\"2023-01-01:\",\n    limit=5\n)\n\nprint(f\"\\nRecent Filings ({len(recent_filings)}):\")\nfor filing in recent_filings:\n    print(f\"  {filing.form}: {filing.filing_date}\")\n\n# Get financial data\nfinancials = company.get_financials()\nif financials:\n    revenue = financials.income.loc['Revenue'].iloc[0]\n    print(f\"\\nLatest Revenue: ${revenue/1e9:.1f}B\")\n\n# Get company facts\nfacts = company.get_facts()\nif facts:\n    print(f\"Total XBRL Facts: {facts.num_facts()}\")\n\n# Address information\naddress = company.business_address()\nif address:\n    print(f\"Location: {address.city}, {address.state_or_country}\")\n</code></pre>"},{"location":"api/company/#see-also","title":"See Also","text":"<ul> <li>Finding Companies Guide - How to locate companies</li> <li>Filing API Reference - Working with individual filings</li> <li>Filings API Reference - Working with filing collections</li> <li>Extract Financial Statements - Getting financial data</li> </ul>"},{"location":"api/entity-facts-reference/","title":"EntityFacts API Reference","text":"<p>Complete API documentation for the enhanced EntityFacts system, including all classes, methods, and data models.</p>"},{"location":"api/entity-facts-reference/#overview","title":"Overview","text":"<p>The EntityFacts API provides structured access to SEC company financial data with AI-ready features, powerful querying capabilities, and professional formatting. The system consists of several key components:</p> <ul> <li>EntityFacts - Main class for accessing company facts</li> <li>FactQuery - Fluent query builder for advanced filtering</li> <li>FinancialStatement - Formatted display wrapper for financial data</li> <li>FinancialFact - Individual fact data model with rich metadata</li> </ul>"},{"location":"api/entity-facts-reference/#entityfacts-class","title":"EntityFacts Class","text":"<p>The main entry point for accessing company financial facts.</p>"},{"location":"api/entity-facts-reference/#constructor","title":"Constructor","text":"<pre><code>EntityFacts(cik: int, name: str, facts: List[FinancialFact])\n</code></pre> <p>Parameters: - <code>cik</code> (int): Company CIK number - <code>name</code> (str): Company name - <code>facts</code> (List[FinancialFact]): List of financial facts</p>"},{"location":"api/entity-facts-reference/#properties","title":"Properties","text":""},{"location":"api/entity-facts-reference/#core-properties","title":"Core Properties","text":""},{"location":"api/entity-facts-reference/#cik-int","title":"<code>cik: int</code>","text":"<p>The company's CIK (Central Index Key) number.</p> <pre><code>facts = company.facts\nprint(facts.cik)  # 320193\n</code></pre>"},{"location":"api/entity-facts-reference/#name-str","title":"<code>name: str</code>","text":"<p>The company's official name.</p> <pre><code>facts = company.facts\nprint(facts.name)  # \"Apple Inc.\"\n</code></pre>"},{"location":"api/entity-facts-reference/#dei-properties","title":"DEI Properties","text":""},{"location":"api/entity-facts-reference/#shares_outstanding-optionalfloat","title":"<code>shares_outstanding: Optional[float]</code>","text":"<p>Number of common shares outstanding.</p> <pre><code>shares = facts.shares_outstanding\nif shares:\n    print(f\"Shares Outstanding: {shares:,.0f}\")\n</code></pre>"},{"location":"api/entity-facts-reference/#public_float-optionalfloat","title":"<code>public_float: Optional[float]</code>","text":"<p>Public float value in dollars.</p> <pre><code>float_val = facts.public_float\nif float_val:\n    print(f\"Public Float: ${float_val:,.0f}\")\n</code></pre>"},{"location":"api/entity-facts-reference/#shares_outstanding_fact-optionalfinancialfact","title":"<code>shares_outstanding_fact: Optional[FinancialFact]</code>","text":"<p>Full fact object for shares outstanding with metadata.</p> <pre><code>fact = facts.shares_outstanding_fact\nif fact:\n    print(f\"Shares: {fact.get_formatted_value()} as of {fact.period_end}\")\n</code></pre>"},{"location":"api/entity-facts-reference/#public_float_fact-optionalfinancialfact","title":"<code>public_float_fact: Optional[FinancialFact]</code>","text":"<p>Full fact object for public float with metadata.</p> <pre><code>fact = facts.public_float_fact\nif fact:\n    print(f\"Float: {fact.get_formatted_value()} as of {fact.period_end}\")\n</code></pre>"},{"location":"api/entity-facts-reference/#core-methods","title":"Core Methods","text":""},{"location":"api/entity-facts-reference/#query-interface","title":"Query Interface","text":""},{"location":"api/entity-facts-reference/#query-factquery","title":"<code>query() -&gt; FactQuery</code>","text":"<p>Start building a facts query using the fluent interface.</p> <pre><code>query = facts.query()\nresults = query.by_concept('Revenue').latest(4)\n</code></pre> <p>Returns: FactQuery builder instance</p>"},{"location":"api/entity-facts-reference/#get_factconcept-str-period-optionalstr-none-optionalfinancialfact","title":"<code>get_fact(concept: str, period: Optional[str] = None) -&gt; Optional[FinancialFact]</code>","text":"<p>Get a single fact by concept name.</p> <pre><code>revenue_fact = facts.get_fact('Revenue')\nq1_revenue = facts.get_fact('Revenue', '2024-Q1')\n</code></pre> <p>Parameters: - <code>concept</code> (str): Concept name or label (case-insensitive) - <code>period</code> (str, optional): Period in format \"YYYY-QN\" or \"YYYY-FY\"</p> <p>Returns: Most recent matching fact or None</p> <pre><code>time_series(concept: str, periods: int = 20) -&gt; pd.DataFrame\n</code></pre> <p>Get time series data for a concept.</p> <pre><code>revenue_ts = facts.time_series('Revenue', periods=8)\n</code></pre> <p>Parameters: - <code>concept</code> (str): Concept name or label - <code>periods</code> (int): Number of periods to retrieve (default: 20)</p> <p>Returns: DataFrame with time series data</p>"},{"location":"api/entity-facts-reference/#financial-statement-methods","title":"Financial Statement Methods","text":"<pre><code>income_statement(periods: int = 4, \n                 period_length: Optional[int] = None, \n                 as_dataframe: bool = False, \n                 annual: bool = True)\n</code></pre> <p>Get income statement facts formatted as a financial statement.</p> <pre><code># Default: 4 annual periods, formatted display\nstmt = facts.income_statement()\n\n# 8 quarterly periods as DataFrame\ndf = facts.income_statement(periods=8, annual=False, as_dataframe=True)\n</code></pre> <p>Parameters: - <code>periods</code> (int): Number of periods to retrieve (default: 4) - <code>period_length</code> (int, optional): Filter by period length in months (3=quarterly, 12=annual) - <code>as_dataframe</code> (bool): If True, return DataFrame; if False, return FinancialStatement (default: False) - <code>annual</code> (bool): If True, prefer annual periods; if False, prefer quarterly (default: True)</p> <p>Returns: FinancialStatement or DataFrame</p>"},{"location":"api/entity-facts-reference/#balance_sheetperiods-int-4-as_of-optionaldate-none-as_dataframe-bool-false-annual-bool-true","title":"<code>balance_sheet(periods: int = 4, as_of: Optional[date] = None, as_dataframe: bool = False, annual: bool = True)</code>","text":"<p>Get balance sheet facts for periods or point-in-time.</p> <pre><code># Multi-period balance sheet\nstmt = facts.balance_sheet(periods=4)\n\n# Point-in-time snapshot\nsnapshot = facts.balance_sheet(as_of=date(2024, 12, 31))\n</code></pre> <p>Parameters: - <code>periods</code> (int): Number of periods to retrieve (default: 4) - <code>as_of</code> (date, optional): Get snapshot as of specific date - <code>as_dataframe</code> (bool): If True, return DataFrame; if False, return FinancialStatement (default: False) - <code>annual</code> (bool): If True, prefer annual periods (default: True)</p> <p>Returns: FinancialStatement or DataFrame</p>"},{"location":"api/entity-facts-reference/#cash_flowperiods-int-4-period_length-optionalint-none-as_dataframe-bool-false-annual-bool-true","title":"<code>cash_flow(periods: int = 4, period_length: Optional[int] = None, as_dataframe: bool = False, annual: bool = True)</code>","text":"<p>Get cash flow statement facts.</p> <pre><code># Annual cash flow trends\nstmt = facts.cash_flow(periods=5, annual=True)\n</code></pre> <p>Parameters: - <code>periods</code> (int): Number of periods to retrieve (default: 4) - <code>period_length</code> (int, optional): Filter by period length in months - <code>as_dataframe</code> (bool): If True, return DataFrame; if False, return FinancialStatement (default: False) - <code>annual</code> (bool): If True, prefer annual periods (default: True)</p> <p>Returns: FinancialStatement or DataFrame</p>"},{"location":"api/entity-facts-reference/#dei-methods","title":"DEI Methods","text":""},{"location":"api/entity-facts-reference/#dei_factsas_of-optionaldate-none-pddataframe","title":"<code>dei_facts(as_of: Optional[date] = None) -&gt; pd.DataFrame</code>","text":"<p>Get Document and Entity Information facts.</p> <pre><code># Latest DEI facts\ndei = facts.dei_facts()\n\n# DEI facts as of specific date\ndei = facts.dei_facts(as_of=date(2024, 12, 31))\n</code></pre> <p>Parameters: - <code>as_of</code> (date, optional): Get facts as of specific date</p> <p>Returns: DataFrame with DEI facts</p>"},{"location":"api/entity-facts-reference/#entity_info-dictstr-any","title":"<code>entity_info() -&gt; Dict[str, Any]</code>","text":"<p>Get key entity information as a clean dictionary.</p> <pre><code>info = facts.entity_info()\nprint(info['entity_name'])\nprint(info['shares_outstanding'])\n</code></pre> <p>Returns: Dictionary with entity information</p>"},{"location":"api/entity-facts-reference/#aillm-methods","title":"AI/LLM Methods","text":""},{"location":"api/entity-facts-reference/#to_llm_contextfocus_areas-optionalliststr-none-time_period-str-recent-dictstr-any","title":"<code>to_llm_context(focus_areas: Optional[List[str]] = None, time_period: str = \"recent\") -&gt; Dict[str, Any]</code>","text":"<p>Generate comprehensive context for LLM analysis.</p> <pre><code>context = facts.to_llm_context(\n    focus_areas=['profitability', 'growth'],\n    time_period='5Y'\n)\n</code></pre> <p>Parameters: - <code>focus_areas</code> (List[str], optional): Areas to emphasize (['profitability', 'growth', 'liquidity']) - <code>time_period</code> (str): Time period to analyze ('recent', '5Y', '10Y', 'all') (default: 'recent')</p> <p>Returns: Dictionary with structured LLM context</p>"},{"location":"api/entity-facts-reference/#to_agent_tools-listdictstr-any","title":"<code>to_agent_tools() -&gt; List[Dict[str, Any]]</code>","text":"<p>Export facts as MCP-compatible tools for AI agents.</p> <pre><code>tools = facts.to_agent_tools()\n</code></pre> <p>Returns: List of tool definitions</p>"},{"location":"api/entity-facts-reference/#magic-methods","title":"Magic Methods","text":""},{"location":"api/entity-facts-reference/#__len__-int","title":"<code>__len__() -&gt; int</code>","text":"<p>Get total number of facts.</p> <pre><code>total_facts = len(facts)\n</code></pre>"},{"location":"api/entity-facts-reference/#__iter__-iteratorfinancialfact","title":"<code>__iter__() -&gt; Iterator[FinancialFact]</code>","text":"<p>Iterate over all facts.</p> <pre><code>for fact in facts:\n    print(f\"{fact.concept}: {fact.numeric_value}\")\n</code></pre>"},{"location":"api/entity-facts-reference/#factquery-class","title":"FactQuery Class","text":"<p>Fluent query builder for advanced fact filtering and analysis.</p>"},{"location":"api/entity-facts-reference/#constructor_1","title":"Constructor","text":"<p>Created via <code>EntityFacts.query()</code> method. Do not instantiate directly.</p>"},{"location":"api/entity-facts-reference/#filtering-methods","title":"Filtering Methods","text":""},{"location":"api/entity-facts-reference/#concept-filtering","title":"Concept Filtering","text":""},{"location":"api/entity-facts-reference/#by_conceptconcept-str-exact-bool-false-factquery","title":"<code>by_concept(concept: str, exact: bool = False) -&gt; FactQuery</code>","text":"<p>Filter by concept name or pattern.</p> <pre><code># Fuzzy matching (default)\nrevenue_facts = query.by_concept('Revenue')\n\n# Exact matching  \nexact_revenue = query.by_concept('us-gaap:Revenue', exact=True)\n</code></pre> <p>Parameters: - <code>concept</code> (str): Concept name or label to match - <code>exact</code> (bool): If True, require exact match (default: False)</p>"},{"location":"api/entity-facts-reference/#by_labellabel-str-fuzzy-bool-true-factquery","title":"<code>by_label(label: str, fuzzy: bool = True) -&gt; FactQuery</code>","text":"<p>Filter by human-readable label.</p> <pre><code># Fuzzy label matching\nfacts = query.by_label('Total Revenue', fuzzy=True)\n\n# Exact label matching\nfacts = query.by_label('Revenue', fuzzy=False)\n</code></pre> <p>Parameters: - <code>label</code> (str): Label to match - <code>fuzzy</code> (bool): Use fuzzy matching (default: True)</p>"},{"location":"api/entity-facts-reference/#time-based-filtering","title":"Time-Based Filtering","text":""},{"location":"api/entity-facts-reference/#by_fiscal_yearyear-int-factquery","title":"<code>by_fiscal_year(year: int) -&gt; FactQuery</code>","text":"<p>Filter by fiscal year.</p> <pre><code>fy2024_facts = query.by_fiscal_year(2024)\n</code></pre> <p>Parameters: - <code>year</code> (int): Fiscal year to filter by</p>"},{"location":"api/entity-facts-reference/#by_fiscal_periodperiod-str-factquery","title":"<code>by_fiscal_period(period: str) -&gt; FactQuery</code>","text":"<p>Filter by fiscal period.</p> <pre><code>q1_facts = query.by_fiscal_period('Q1')\nfy_facts = query.by_fiscal_period('FY')\n</code></pre> <p>Parameters: - <code>period</code> (str): Fiscal period ('FY', 'Q1', 'Q2', 'Q3', 'Q4')</p>"},{"location":"api/entity-facts-reference/#by_period_lengthmonths-int-factquery","title":"<code>by_period_length(months: int) -&gt; FactQuery</code>","text":"<p>Filter by period length in months.</p> <pre><code># Quarterly periods (3 months)\nquarterly = query.by_period_length(3)\n\n# Annual periods (12 months)\nannual = query.by_period_length(12)\n</code></pre> <p>Parameters: - <code>months</code> (int): Period length (3=quarterly, 12=annual, 9=YTD)</p>"},{"location":"api/entity-facts-reference/#date_rangestart-date-end-date-factquery","title":"<code>date_range(start: date, end: date) -&gt; FactQuery</code>","text":"<p>Filter by date range.</p> <pre><code>recent_facts = query.date_range(\n    start=date(2023, 1, 1),\n    end=date(2024, 12, 31)\n)\n</code></pre> <p>Parameters: - <code>start</code> (date): Start date (inclusive) - <code>end</code> (date): End date (inclusive)</p>"},{"location":"api/entity-facts-reference/#as_ofas_of_date-date-factquery","title":"<code>as_of(as_of_date: date) -&gt; FactQuery</code>","text":"<p>Get facts as of specific date (point-in-time).</p> <pre><code>snapshot = query.as_of(date(2024, 6, 30))\n</code></pre> <p>Parameters: - <code>as_of_date</code> (date): Date for point-in-time view</p>"},{"location":"api/entity-facts-reference/#statement-and-form-filtering","title":"Statement and Form Filtering","text":""},{"location":"api/entity-facts-reference/#by_statement_typestatement_type-str-factquery","title":"<code>by_statement_type(statement_type: str) -&gt; FactQuery</code>","text":"<p>Filter by financial statement type.</p> <pre><code>income_facts = query.by_statement_type('IncomeStatement')\nbalance_facts = query.by_statement_type('BalanceSheet')\ncash_facts = query.by_statement_type('CashFlow')\n</code></pre> <p>Parameters: - <code>statement_type</code> (str): Statement type ('IncomeStatement', 'BalanceSheet', 'CashFlow')</p>"},{"location":"api/entity-facts-reference/#by_form_typeform_type-unionstr-liststr-factquery","title":"<code>by_form_type(form_type: Union[str, List[str]]) -&gt; FactQuery</code>","text":"<p>Filter by SEC form type.</p> <pre><code># Single form type\nannual_facts = query.by_form_type('10-K')\n\n# Multiple form types\nperiodic_facts = query.by_form_type(['10-K', '10-Q'])\n</code></pre> <p>Parameters: - <code>form_type</code> (str or List[str]): Form type(s) to filter by</p>"},{"location":"api/entity-facts-reference/#quality-filtering","title":"Quality Filtering","text":""},{"location":"api/entity-facts-reference/#high_quality_only-factquery","title":"<code>high_quality_only() -&gt; FactQuery</code>","text":"<p>Filter to only high-quality, audited facts.</p> <pre><code>quality_facts = query.high_quality_only()\n</code></pre>"},{"location":"api/entity-facts-reference/#min_confidencethreshold-float-factquery","title":"<code>min_confidence(threshold: float) -&gt; FactQuery</code>","text":"<p>Filter by minimum confidence score.</p> <pre><code>confident_facts = query.min_confidence(0.9)\n</code></pre> <p>Parameters: - <code>threshold</code> (float): Minimum confidence score (0.0 to 1.0)</p>"},{"location":"api/entity-facts-reference/#special-queries","title":"Special Queries","text":""},{"location":"api/entity-facts-reference/#latest_instant-factquery","title":"<code>latest_instant() -&gt; FactQuery</code>","text":"<p>Filter to most recent instant facts (for balance sheet items).</p> <pre><code>latest_balance = query.by_statement_type('BalanceSheet').latest_instant()\n</code></pre>"},{"location":"api/entity-facts-reference/#latest_periodsn-int-4-annual-bool-true-factquery","title":"<code>latest_periods(n: int = 4, annual: bool = True) -&gt; FactQuery</code>","text":"<p>Get facts from the n most recent periods.</p> <pre><code># Latest 4 annual periods only\nrecent = query.latest_periods(4, annual=True)\n\n# Latest 8 periods, any type\nrecent = query.latest_periods(8, annual=False)\n</code></pre> <p>Parameters: - <code>n</code> (int): Number of recent periods (default: 4) - <code>annual</code> (bool): If True, only use annual periods; if False, use all period types (default: True)</p>"},{"location":"api/entity-facts-reference/#sorting-and-limiting","title":"Sorting and Limiting","text":""},{"location":"api/entity-facts-reference/#sort_byfield-str-ascending-bool-true-factquery","title":"<code>sort_by(field: str, ascending: bool = True) -&gt; FactQuery</code>","text":"<p>Sort results by field.</p> <pre><code># Sort by filing date (newest first)\nsorted_facts = query.sort_by('filing_date', ascending=False)\n\n# Sort by fiscal year\nsorted_facts = query.sort_by('fiscal_year')\n</code></pre> <p>Parameters: - <code>field</code> (str): Field name to sort by - <code>ascending</code> (bool): Sort order (default: True)</p>"},{"location":"api/entity-facts-reference/#latestn-int-1-listfinancialfact","title":"<code>latest(n: int = 1) -&gt; List[FinancialFact]</code>","text":"<p>Get the n most recent facts.</p> <pre><code>latest_revenue = query.by_concept('Revenue').latest(5)\n</code></pre> <p>Parameters: - <code>n</code> (int): Number of facts to return (default: 1)</p> <p>Returns: List of facts (executes query immediately)</p>"},{"location":"api/entity-facts-reference/#execution-methods","title":"Execution Methods","text":""},{"location":"api/entity-facts-reference/#execute-listfinancialfact","title":"<code>execute() -&gt; List[FinancialFact]</code>","text":"<p>Execute query and return matching facts.</p> <pre><code>facts = query.by_concept('Revenue').by_fiscal_year(2024).execute()\n</code></pre> <p>Returns: List of FinancialFact objects</p>"},{"location":"api/entity-facts-reference/#count-int","title":"<code>count() -&gt; int</code>","text":"<p>Get count of facts matching current filters.</p> <pre><code>revenue_count = query.by_concept('Revenue').count()\n</code></pre> <p>Returns: Number of matching facts</p>"},{"location":"api/entity-facts-reference/#output-methods","title":"Output Methods","text":""},{"location":"api/entity-facts-reference/#to_dataframecolumns-pddataframe","title":"<code>to_dataframe(*columns) -&gt; pd.DataFrame</code>","text":"<p>Convert results to pandas DataFrame.</p> <pre><code># All columns\ndf = query.by_concept('Revenue').to_dataframe()\n\n# Selected columns\ndf = query.by_concept('Revenue').to_dataframe(\n    'label', 'numeric_value', 'fiscal_period'\n)\n</code></pre> <p>Parameters: - <code>*columns</code> (str): Optional column names to include</p> <p>Returns: DataFrame with query results</p>"},{"location":"api/entity-facts-reference/#pivot_by_periodreturn_statement-bool-true-unionfinancialstatement-pddataframe","title":"<code>pivot_by_period(return_statement: bool = True) -&gt; Union[FinancialStatement, pd.DataFrame]</code>","text":"<p>Pivot facts to show concepts as rows and periods as columns.</p> <pre><code># Formatted financial statement\nstmt = query.by_statement_type('IncomeStatement').pivot_by_period()\n\n# Raw DataFrame\ndf = query.by_statement_type('IncomeStatement').pivot_by_period(return_statement=False)\n</code></pre> <p>Parameters: - <code>return_statement</code> (bool): If True, return FinancialStatement; if False, return DataFrame (default: True)</p> <p>Returns: FinancialStatement or DataFrame</p>"},{"location":"api/entity-facts-reference/#to_llm_context-listdictstr-any","title":"<code>to_llm_context() -&gt; List[Dict[str, Any]]</code>","text":"<p>Convert results to LLM-friendly context.</p> <pre><code>llm_data = query.by_concept('Revenue').to_llm_context()\n</code></pre> <p>Returns: List of fact contexts for LLM consumption</p>"},{"location":"api/entity-facts-reference/#financialstatement-class","title":"FinancialStatement Class","text":"<p>Wrapper around pandas DataFrame for financial statements with intelligent formatting.</p>"},{"location":"api/entity-facts-reference/#constructor_2","title":"Constructor","text":"<pre><code>FinancialStatement(\n    data: pd.DataFrame,\n    statement_type: str,\n    entity_name: str = \"\",\n    period_lengths: Optional[List[str]] = None,\n    mixed_periods: bool = False\n)\n</code></pre> <p>Parameters: - <code>data</code> (pd.DataFrame): Financial data - <code>statement_type</code> (str): Statement type - <code>entity_name</code> (str): Company name - <code>period_lengths</code> (List[str], optional): Period lengths in data - <code>mixed_periods</code> (bool): Whether data contains mixed period lengths</p>"},{"location":"api/entity-facts-reference/#properties_1","title":"Properties","text":""},{"location":"api/entity-facts-reference/#shape-tuple","title":"<code>shape: tuple</code>","text":"<p>Shape of the underlying DataFrame.</p> <pre><code>stmt = company.income_statement()\nprint(stmt.shape)  # (10, 4)\n</code></pre>"},{"location":"api/entity-facts-reference/#columns-pdindex","title":"<code>columns: pd.Index</code>","text":"<p>Column names of the statement.</p> <pre><code>periods = stmt.columns\nprint(list(periods))  # ['FY 2024', 'FY 2023', 'FY 2022', 'FY 2021']\n</code></pre>"},{"location":"api/entity-facts-reference/#index-pdindex","title":"<code>index: pd.Index</code>","text":"<p>Row labels (concept names).</p> <pre><code>concepts = stmt.index\nprint(list(concepts))  # ['Revenue', 'Cost of Revenue', 'Gross Profit', ...]\n</code></pre>"},{"location":"api/entity-facts-reference/#empty-bool","title":"<code>empty: bool</code>","text":"<p>Whether the statement is empty.</p> <pre><code>if not stmt.empty:\n    print(\"Statement has data\")\n</code></pre>"},{"location":"api/entity-facts-reference/#methods","title":"Methods","text":""},{"location":"api/entity-facts-reference/#to_numeric-pddataframe","title":"<code>to_numeric() -&gt; pd.DataFrame</code>","text":"<p>Get underlying numeric DataFrame for calculations.</p> <pre><code>stmt = company.income_statement()\nnumeric_data = stmt.to_numeric()\ngrowth_rates = numeric_data.pct_change(axis=1)\n</code></pre> <p>Returns: DataFrame with original numeric values</p>"},{"location":"api/entity-facts-reference/#get_conceptconcept_name-str-optionalpdseries","title":"<code>get_concept(concept_name: str) -&gt; Optional[pd.Series]</code>","text":"<p>Get data for specific concept across all periods.</p> <pre><code>revenue_series = stmt.get_concept('Revenue')\nif revenue_series is not None:\n    print(revenue_series)\n</code></pre> <p>Parameters: - <code>concept_name</code> (str): Name of concept to retrieve</p> <p>Returns: Series with values across periods, or None</p>"},{"location":"api/entity-facts-reference/#calculate_growthconcept_name-str-periods-int-2-optionalpdseries","title":"<code>calculate_growth(concept_name: str, periods: int = 2) -&gt; Optional[pd.Series]</code>","text":"<p>Calculate period-over-period growth for a concept.</p> <pre><code>revenue_growth = stmt.calculate_growth('Revenue', periods=1)\n</code></pre> <p>Parameters: - <code>concept_name</code> (str): Name of concept - <code>periods</code> (int): Number of periods for growth calculation (default: 2)</p> <p>Returns: Series with growth rates, or None</p>"},{"location":"api/entity-facts-reference/#format_valuevalue-float-concept_label-str-str","title":"<code>format_value(value: float, concept_label: str) -&gt; str</code>","text":"<p>Format a single value based on its concept.</p> <pre><code>formatted = stmt.format_value(1234567, 'Revenue')\nprint(formatted)  # \"$1,234,567\"\n</code></pre> <p>Parameters: - <code>value</code> (float): Numeric value to format - <code>concept_label</code> (str): Label of financial concept</p> <p>Returns: Formatted string</p>"},{"location":"api/entity-facts-reference/#to_llm_context-dictstr-any","title":"<code>to_llm_context() -&gt; Dict[str, Any]</code>","text":"<p>Generate LLM-friendly context from the statement.</p> <pre><code>context = stmt.to_llm_context()\n</code></pre> <p>Returns: Dictionary with structured financial data</p>"},{"location":"api/entity-facts-reference/#display-methods","title":"Display Methods","text":"<p>The FinancialStatement class provides rich display capabilities:</p> <ul> <li>Jupyter Notebooks: Automatic HTML rendering with professional styling</li> <li>Console: Formatted text output with proper alignment</li> <li>Rich Integration: Compatible with Rich library for enhanced terminal display</li> </ul>"},{"location":"api/entity-facts-reference/#financialfact-class","title":"FinancialFact Class","text":"<p>Individual financial fact with rich metadata and AI-ready features.</p>"},{"location":"api/entity-facts-reference/#constructor_3","title":"Constructor","text":"<pre><code>FinancialFact(\n    concept: str,\n    taxonomy: str,\n    label: str,\n    value: Union[float, int, str],\n    numeric_value: Optional[float],\n    unit: str,\n    scale: Optional[int] = None,\n    # ... additional parameters\n)\n</code></pre>"},{"location":"api/entity-facts-reference/#core-attributes","title":"Core Attributes","text":""},{"location":"api/entity-facts-reference/#concept-str","title":"<code>concept: str</code>","text":"<p>Standardized concept identifier (e.g., 'us-gaap:Revenue').</p>"},{"location":"api/entity-facts-reference/#taxonomy-str","title":"<code>taxonomy: str</code>","text":"<p>Taxonomy namespace (us-gaap, ifrs, etc.).</p>"},{"location":"api/entity-facts-reference/#label-str","title":"<code>label: str</code>","text":"<p>Human-readable label.</p>"},{"location":"api/entity-facts-reference/#value-unionfloat-int-str","title":"<code>value: Union[float, int, str]</code>","text":"<p>The actual fact value.</p>"},{"location":"api/entity-facts-reference/#numeric_value-optionalfloat","title":"<code>numeric_value: Optional[float]</code>","text":"<p>Numeric representation for calculations.</p>"},{"location":"api/entity-facts-reference/#unit-str","title":"<code>unit: str</code>","text":"<p>Unit of measure (USD, shares, etc.).</p>"},{"location":"api/entity-facts-reference/#scale-optionalint","title":"<code>scale: Optional[int]</code>","text":"<p>Scale factor (1000, 1000000, etc.).</p>"},{"location":"api/entity-facts-reference/#temporal-attributes","title":"Temporal Attributes","text":""},{"location":"api/entity-facts-reference/#period_start-optionaldate","title":"<code>period_start: Optional[date]</code>","text":"<p>Period start date (for duration facts).</p>"},{"location":"api/entity-facts-reference/#period_end-date","title":"<code>period_end: date</code>","text":"<p>Period end date.</p>"},{"location":"api/entity-facts-reference/#period_type-literalinstant-duration","title":"<code>period_type: Literal['instant', 'duration']</code>","text":"<p>Type of period.</p>"},{"location":"api/entity-facts-reference/#fiscal_year-int","title":"<code>fiscal_year: int</code>","text":"<p>Fiscal year.</p>"},{"location":"api/entity-facts-reference/#fiscal_period-str","title":"<code>fiscal_period: str</code>","text":"<p>Fiscal period (FY, Q1, Q2, Q3, Q4).</p>"},{"location":"api/entity-facts-reference/#filing-context","title":"Filing Context","text":""},{"location":"api/entity-facts-reference/#filing_date-date","title":"<code>filing_date: date</code>","text":"<p>Date the fact was filed with SEC.</p>"},{"location":"api/entity-facts-reference/#form_type-str","title":"<code>form_type: str</code>","text":"<p>SEC form type (10-K, 10-Q, etc.).</p>"},{"location":"api/entity-facts-reference/#accession-str","title":"<code>accession: str</code>","text":"<p>SEC accession number.</p>"},{"location":"api/entity-facts-reference/#quality-indicators","title":"Quality Indicators","text":""},{"location":"api/entity-facts-reference/#data_quality-dataquality","title":"<code>data_quality: DataQuality</code>","text":"<p>Data quality enum (HIGH, MEDIUM, LOW).</p>"},{"location":"api/entity-facts-reference/#is_audited-bool","title":"<code>is_audited: bool</code>","text":"<p>Whether the fact is from audited filing.</p>"},{"location":"api/entity-facts-reference/#confidence_score-float","title":"<code>confidence_score: float</code>","text":"<p>Confidence score (0.0 to 1.0).</p>"},{"location":"api/entity-facts-reference/#ai-ready-attributes","title":"AI-Ready Attributes","text":""},{"location":"api/entity-facts-reference/#semantic_tags-liststr","title":"<code>semantic_tags: List[str]</code>","text":"<p>Semantic tags for AI processing.</p>"},{"location":"api/entity-facts-reference/#business_context-str","title":"<code>business_context: str</code>","text":"<p>Business context description.</p>"},{"location":"api/entity-facts-reference/#methods_1","title":"Methods","text":""},{"location":"api/entity-facts-reference/#to_llm_context-dictstr-any_1","title":"<code>to_llm_context() -&gt; Dict[str, Any]</code>","text":"<p>Generate rich context for LLM consumption.</p> <pre><code>fact = facts.get_fact('Revenue')\ncontext = fact.to_llm_context()\nprint(context['concept'])\nprint(context['value'])\nprint(context['period'])\n</code></pre> <p>Returns: Dictionary with formatted context</p>"},{"location":"api/entity-facts-reference/#get_formatted_value-str","title":"<code>get_formatted_value() -&gt; str</code>","text":"<p>Format the numeric value for display.</p> <pre><code>fact = facts.get_fact('Revenue')\nformatted = fact.get_formatted_value()\nprint(formatted)  # \"365,817,000,000\"\n</code></pre> <p>Returns: Formatted string representation</p>"},{"location":"api/entity-facts-reference/#get_display_period_key-str","title":"<code>get_display_period_key() -&gt; str</code>","text":"<p>Generate display-friendly period key.</p> <pre><code>fact = facts.get_fact('Revenue')\nperiod = fact.get_display_period_key()\nprint(period)  # \"Q1 2024\"\n</code></pre> <p>Returns: Period key like \"Q1 2024\", \"FY 2023\"</p>"},{"location":"api/entity-facts-reference/#entityfactsparser-class","title":"EntityFactsParser Class","text":"<p>Parser for converting SEC JSON data to enhanced EntityFacts format.</p>"},{"location":"api/entity-facts-reference/#static-methods","title":"Static Methods","text":""},{"location":"api/entity-facts-reference/#parse_company_factsfacts_json-dictstr-any-entityfacts","title":"<code>parse_company_facts(facts_json: Dict[str, Any]) -&gt; EntityFacts</code>","text":"<p>Parse SEC company facts JSON to EntityFacts object.</p> <pre><code>from edgar.entity.parser import EntityFactsParser\n\n# Download SEC JSON\nfacts_json = download_json(f\"https://data.sec.gov/api/xbrl/companyfacts/CIK{cik:010d}.json\")\n\n# Parse to enhanced format\nentity_facts = EntityFactsParser.parse_company_facts(facts_json)\n</code></pre> <p>Parameters: - <code>facts_json</code> (Dict): SEC company facts JSON data</p> <p>Returns: EntityFacts object</p>"},{"location":"api/entity-facts-reference/#data-models","title":"Data Models","text":""},{"location":"api/entity-facts-reference/#dataquality-enum","title":"DataQuality Enum","text":"<p>Quality indicators for financial facts.</p> <pre><code>from edgar.entity.models import DataQuality\n\nDataQuality.HIGH    # Direct from XBRL, validated\nDataQuality.MEDIUM  # Derived or calculated  \nDataQuality.LOW     # Estimated or inferred\n</code></pre>"},{"location":"api/entity-facts-reference/#conceptmetadata-class","title":"ConceptMetadata Class","text":"<p>Metadata about financial concepts.</p> <pre><code>@dataclass\nclass ConceptMetadata:\n    concept: str\n    label: str\n    definition: str\n    parent_concepts: List[str]\n    child_concepts: List[str]\n    # ... additional fields\n</code></pre>"},{"location":"api/entity-facts-reference/#error-handling","title":"Error Handling","text":""},{"location":"api/entity-facts-reference/#nocompanyfactsfound-exception","title":"NoCompanyFactsFound Exception","text":"<p>Raised when company facts cannot be found.</p> <pre><code>from edgar.entity.core import NoCompanyFactsFound\n\ntry:\n    facts = get_company_facts(invalid_cik)\nexcept NoCompanyFactsFound as e:\n    print(f\"No facts found: {e.message}\")\n</code></pre>"},{"location":"api/entity-facts-reference/#type-hints","title":"Type Hints","text":"<p>The API uses comprehensive type hints for better IDE support:</p> <pre><code>from typing import Optional, List, Dict, Any, Union\nfrom datetime import date\nfrom edgar.entity.entity_facts import EntityFacts\nfrom edgar.entity.models import FinancialFact\nfrom edgar.entity.query import FactQuery\nfrom edgar.entity.statement import FinancialStatement\n</code></pre>"},{"location":"api/entity-facts-reference/#usage-patterns","title":"Usage Patterns","text":""},{"location":"api/entity-facts-reference/#method-chaining","title":"Method Chaining","text":"<p>All query methods return the query object for chaining:</p> <pre><code>results = facts.query()\\\n    .by_concept('Revenue')\\\n    .by_fiscal_year(2024)\\\n    .by_form_type('10-K')\\\n    .sort_by('filing_date')\\\n    .execute()\n</code></pre>"},{"location":"api/entity-facts-reference/#error-handling_1","title":"Error Handling","text":"<p>The API uses graceful error handling:</p> <pre><code># Methods return None instead of raising exceptions\nstmt = company.income_statement()  # Returns None if no data\nif stmt:\n    # Process statement\n    pass\n</code></pre>"},{"location":"api/entity-facts-reference/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Use specific filters for better performance</li> <li>Leverage caching by reusing EntityFacts objects</li> <li>Use <code>count()</code> for existence checks before loading data</li> <li>Prefer <code>latest()</code> over <code>execute()</code> when you need recent data only</li> </ul> <p>This API reference documents EdgarTools EntityFacts system. For usage examples and tutorials, see the Company Facts Guide.</p>"},{"location":"api/filing/","title":"Filing API Reference","text":"<p>The <code>Filing</code> class represents a single SEC filing and provides access to its documents, data, and metadata. It serves as the foundation for all filing-related operations in EdgarTools.</p>"},{"location":"api/filing/#class-overview","title":"Class Overview","text":"<pre><code>from edgar import Filing\n\nclass Filing:\n    \"\"\"Represents a single SEC filing with access to documents and data.\"\"\"\n</code></pre>"},{"location":"api/filing/#constructor","title":"Constructor","text":""},{"location":"api/filing/#filingcik-company-form-filing_date-accession_no","title":"Filing(cik, company, form, filing_date, accession_no)","text":"<p>Create a Filing instance with basic filing information.</p> <pre><code>Filing(\n    cik: int,\n    company: str, \n    form: str,\n    filing_date: str,\n    accession_no: str)\n</code></pre> <p>Parameters: - <code>cik</code> (int): Central Index Key of the filing entity - <code>company</code> (str): Company name - <code>form</code> (str): SEC form type (e.g., \"10-K\", \"10-Q\", \"8-K\") - <code>filing_date</code> (str): Filing date in YYYY-MM-DD format - <code>accession_no</code> (str): SEC accession number</p> <p>Example:</p> <pre><code>filing = Filing(\n    cik=320193,\n    company=\"Apple Inc.\", \n    form=\"10-K\",\n    filing_date=\"2023-11-03\",\n    accession_no=\"0000320193-23-000106\"\n)\n</code></pre>"},{"location":"api/filing/#core-properties","title":"Core Properties","text":""},{"location":"api/filing/#basic-information","title":"Basic Information","text":""},{"location":"api/filing/#cik","title":"cik","text":"<pre><code>@property\ndef cik(self) -&gt; int:\n    ...\n</code></pre> <p>Central Index Key of the filing entity.</p> <pre><code>print(filing.cik)  # 320193\n</code></pre>"},{"location":"api/filing/#company","title":"company","text":"<pre><code>@property  \ndef company(self) -&gt; str:\n    ...\n</code></pre> <p>Name of the company that filed the document.</p> <pre><code>print(filing.company)  # \"Apple Inc.\"\n</code></pre>"},{"location":"api/filing/#form","title":"form","text":"<pre><code>@property\ndef form(self) -&gt; str:\n    ...\n</code></pre> <p>SEC form type.</p> <pre><code>print(filing.form)  # \"10-K\"\n</code></pre>"},{"location":"api/filing/#filing_date","title":"filing_date","text":"<pre><code>@property\ndef filing_date(self) -&gt; str:\n    ...\n</code></pre> <p>Date the filing was submitted to the SEC.</p> <pre><code>print(filing.filing_date)  # \"2023-11-03\"\n</code></pre>"},{"location":"api/filing/#accession_no-accession_number","title":"accession_no / accession_number","text":"<pre><code>@property\ndef accession_no(self) -&gt; str:\n    ...\n\n@property\ndef accession_number(self) -&gt; str:  # Alias\n    ...\n</code></pre> <p>SEC accession number - unique identifier for the filing.</p> <pre><code>print(filing.accession_no)  # \"0000320193-23-000106\"\n</code></pre>"},{"location":"api/filing/#period_of_report","title":"period_of_report","text":"<pre><code>@property\ndef period_of_report(self) -&gt; str:\n    ...\n</code></pre> <p>The reporting period for the filing.</p> <pre><code>print(filing.period_of_report)  # \"2023-09-30\"\n</code></pre>"},{"location":"api/filing/#document-access","title":"Document Access","text":""},{"location":"api/filing/#document","title":"document","text":"<pre><code>@property\ndef document(self) -&gt; Attachment:\n    ...\n</code></pre> <p>Primary display document (usually the main HTML filing).</p> <pre><code>primary_doc = filing.document\nprint(primary_doc.document_type)  # \"10-K\"\n</code></pre>"},{"location":"api/filing/#primary_documents","title":"primary_documents","text":"<pre><code>@property\ndef primary_documents(self) -&gt; List[Attachment]:\n    ...\n</code></pre> <p>All primary documents in the filing.</p> <pre><code>for doc in filing.primary_documents:\n    print(f\"{doc.sequence}: {doc.description}\")\n</code></pre>"},{"location":"api/filing/#attachments","title":"attachments","text":"<pre><code>@property\ndef attachments(self) -&gt; Attachments:\n    ...\n</code></pre> <p>All attachments and documents in the filing.</p> <pre><code>attachments = filing.attachments\nprint(f\"Total attachments: {len(attachments)}\")\n\n# Loop through attachments\nfor attachment in attachments:\n    print(f\"{attachment.sequence}: {attachment.description}\")\n</code></pre>"},{"location":"api/filing/#exhibits","title":"exhibits","text":"<pre><code>@property\ndef exhibits(self) -&gt; Attachments\n</code></pre> <p>All exhibits in the filing (subset of attachments).</p> <pre><code>exhibits = filing.exhibits\nfor exhibit in exhibits:\n    print(f\"Exhibit {exhibit.exhibit_number}: {exhibit.description}\")\n</code></pre>"},{"location":"api/filing/#content-access-methods","title":"Content Access Methods","text":""},{"location":"api/filing/#html-and-text-content","title":"HTML and Text Content","text":""},{"location":"api/filing/#html","title":"html()","text":"<pre><code>def html(self) -&gt; Optional[str]\n</code></pre> <p>Get the HTML content of the primary document.</p> <p>Returns: HTML content as string or None if not available</p> <p>Example:</p> <pre><code>html_content = filing.html()\nif html_content:\n    print(f\"HTML length: {len(html_content)} characters\")\n</code></pre>"},{"location":"api/filing/#text","title":"text()","text":"<pre><code>def text(self) -&gt; str\n</code></pre> <p>Convert the filing HTML to clean plain text.</p> <p>Returns: Plain text content</p> <p>Example:</p> <pre><code>text_content = filing.text()\nprint(text_content[:500])  # First 500 characters\n</code></pre>"},{"location":"api/filing/#markdown","title":"markdown()","text":"<pre><code>def markdown(self) -&gt; str\n</code></pre> <p>Convert the filing to Markdown format.</p> <p>Returns: Markdown formatted content</p> <p>Example:</p> <pre><code>markdown_content = filing.markdown()\n# Save to file\nwith open(\"filing.md\", \"w\") as f:\n    f.write(markdown_content)\n</code></pre>"},{"location":"api/filing/#xml","title":"xml()","text":"<pre><code>def xml(self) -&gt; Optional[str]\n</code></pre> <p>Get XML content if the filing contains XML data.</p> <p>Returns: XML content or None</p> <p>Example:</p> <pre><code>xml_content = filing.xml()\nif xml_content:\n    # Process XML data\n    import xml.etree.ElementTree as ET\n    root = ET.fromstring(xml_content)\n</code></pre>"},{"location":"api/filing/#full_text_submission","title":"full_text_submission()","text":"<pre><code>def full_text_submission(self) -&gt; str\n</code></pre> <p>Get the complete text submission file.</p> <p>Returns: Full submission text</p>"},{"location":"api/filing/#structured-data-access","title":"Structured Data Access","text":""},{"location":"api/filing/#xbrl","title":"xbrl()","text":"<pre><code>def xbrl(self) -&gt; Optional[XBRL]\n</code></pre> <p>Get XBRL document if the filing contains XBRL data.</p> <p>Returns: <code>XBRL</code> object or None</p> <p>Example:</p> <pre><code>xbrl = filing.xbrl()\nif xbrl:\n    # Access financial statements\n    statements = xbrl.statements\n    balance_sheet = statements.balance_sheet()\n    income_statement = statements.income_statement()\n</code></pre>"},{"location":"api/filing/#obj-data_object","title":"obj() / data_object()","text":"<pre><code>def obj(self)\ndef data_object(self)  # Alias\n</code></pre> <p>Get structured data object based on the filing form type.</p> <p>Returns: Form-specific object (TenK, TenQ, EightK, etc.)</p> <p>Example:</p> <pre><code># For 10-K filing\ntenk = filing.obj()\nprint(type(tenk))  # &lt;class 'edgar.company_reports.TenK'&gt;\n\n# Access financial data\nfinancials = tenk.financials\nif financials:\n    revenue = financials.income_statement().loc['Revenue']\n</code></pre>"},{"location":"api/filing/#financials","title":"financials","text":"<pre><code>@property\ndef financials(self) -&gt; Optional[Financials]\n</code></pre> <p>Extract financial statements if available (for XBRL filings).</p> <p>Returns: <code>Financials</code> object or None</p> <p>Example:</p> <pre><code>financials = filing.financials\nif financials:\n    balance_sheet = financials.balance_sheet\n    income_statement = financials.income\n    cash_flow = financials.cash_flow\n</code></pre>"},{"location":"api/filing/#parsing-and-metadata","title":"Parsing and Metadata","text":""},{"location":"api/filing/#header","title":"header","text":"<pre><code>@property\ndef header(self) -&gt; FilingHeader\n</code></pre> <p>Parsed SGML header information.</p> <p>Example:</p> <pre><code>header = filing.header\nprint(header.acceptance_datetime)\nprint(header.filer_info)\n</code></pre>"},{"location":"api/filing/#sgml","title":"sgml()","text":"<pre><code>def sgml(self) -&gt; FilingSGML\n</code></pre> <p>Get parsed SGML structure of the filing.</p> <p>Returns: <code>FilingSGML</code> object with parsed document structure</p> <p>Example:</p> <pre><code>sgml = filing.sgml()\nfor doc in sgml.documents:\n    print(f\"Document type: {doc.type}\")\n</code></pre>"},{"location":"api/filing/#url-and-file-properties","title":"URL and File Properties","text":""},{"location":"api/filing/#urls","title":"URLs","text":""},{"location":"api/filing/#homepage_url-url","title":"homepage_url / url","text":"<pre><code>@property\ndef homepage_url(self) -&gt; str\n\n@property\ndef url(self) -&gt; str  # Alias\n</code></pre> <p>URL to the filing homepage on SEC website.</p> <p>Example:</p> <pre><code>print(filing.homepage_url)\n# https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/0000320193-23-000106-index.html\n</code></pre>"},{"location":"api/filing/#filing_url","title":"filing_url","text":"<pre><code>@property\ndef filing_url(self) -&gt; str\n</code></pre> <p>URL to the primary filing document.</p> <p>Example:</p> <pre><code>print(filing.filing_url)\n# https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/aapl-20230930.htm\n</code></pre>"},{"location":"api/filing/#text_url","title":"text_url","text":"<pre><code>@property\ndef text_url(self) -&gt; str\n</code></pre> <p>URL to the text version of the filing.</p> <p>Example:</p> <pre><code>print(filing.text_url)\n# https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/0000320193-23-000106.txt\n</code></pre>"},{"location":"api/filing/#base_dir","title":"base_dir","text":"<pre><code>@property\ndef base_dir(self) -&gt; str\n</code></pre> <p>Base directory URL for all filing files.</p> <p>Example:</p> <pre><code>print(filing.base_dir)\n# https://www.sec.gov/Archives/edgar/data/320193/000032019323000106/\n</code></pre>"},{"location":"api/filing/#interactive-methods","title":"Interactive Methods","text":""},{"location":"api/filing/#viewing-and-display","title":"Viewing and Display","text":""},{"location":"api/filing/#view","title":"view()","text":"<pre><code>def view(self)\n</code></pre> <p>Display the filing content in console or Jupyter notebook.</p> <p>Example:</p> <pre><code>filing.view()  # Displays formatted filing content\n</code></pre>"},{"location":"api/filing/#open","title":"open()","text":"<pre><code>def open(self)\n</code></pre> <p>Open the primary filing document in your default web browser.</p> <p>Example:</p> <pre><code>filing.open()  # Opens filing in browser\n</code></pre>"},{"location":"api/filing/#open_homepage","title":"open_homepage()","text":"<pre><code>def open_homepage(self)\n</code></pre> <p>Open the filing homepage in your default web browser.</p> <p>Example:</p> <pre><code>filing.open_homepage()  # Opens filing index page\n</code></pre>"},{"location":"api/filing/#serve","title":"serve()","text":"<pre><code>def serve(self, port: int = 8000)\n</code></pre> <p>Serve the filing on a local HTTP server for viewing.</p> <p>Parameters: - <code>port</code> (int): Port number for the server (default: 8000)</p> <p>Example:</p> <pre><code>filing.serve(port=8080)  # Serves on http://localhost:8080\n</code></pre>"},{"location":"api/filing/#search-and-analysis","title":"Search and Analysis","text":""},{"location":"api/filing/#search","title":"search()","text":"<pre><code>def search(self, query: str, regex: bool = False) -&gt; List[str]\n</code></pre> <p>Search for text within the filing content.</p> <p>Parameters: - <code>query</code> (str): Search term or pattern - <code>regex</code> (bool): Whether to treat query as regex (default: False)</p> <p>Returns: List of matching text excerpts</p> <p>Example:</p> <pre><code># Simple text search\nresults = filing.search(\"revenue\")\nprint(f\"Found {len(results)} mentions of 'revenue'\")\n\n# Regex search\nemail_results = filing.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', regex=True)\n</code></pre>"},{"location":"api/filing/#sections","title":"sections()","text":"<pre><code>def sections(self) -&gt; List[str]\n</code></pre> <p>Get available document sections.</p> <p>Returns: List of section names</p> <p>Example:</p> <pre><code>sections = filing.sections()\nfor section in sections:\n    print(section)\n# \"Item 1\", \"Item 2\", \"Part II\", etc.\n</code></pre>"},{"location":"api/filing/#entity-and-related-data","title":"Entity and Related Data","text":""},{"location":"api/filing/#get_entity","title":"get_entity()","text":"<pre><code>def get_entity(self)\n</code></pre> <p>Get the Company/Entity object for this filing.</p> <p>Returns: <code>Company</code> or <code>Entity</code> object</p> <p>Example:</p> <pre><code>entity = filing.get_entity()\nprint(f\"Entity: {entity.name}\")\nprint(f\"Industry: {entity.industry}\")\n</code></pre>"},{"location":"api/filing/#as_company_filing","title":"as_company_filing()","text":"<pre><code>def as_company_filing(self)\n</code></pre> <p>Convert to EntityFiling with additional metadata.</p> <p>Returns: <code>EntityFiling</code> object with enhanced properties</p>"},{"location":"api/filing/#related_filings","title":"related_filings()","text":"<pre><code>def related_filings(self)\n</code></pre> <p>Get related filings by file number.</p> <p>Returns: Related filings</p>"},{"location":"api/filing/#persistence-and-serialization","title":"Persistence and Serialization","text":""},{"location":"api/filing/#save-and-load","title":"Save and Load","text":""},{"location":"api/filing/#save","title":"save()","text":"<pre><code>def save(self, directory_or_file: PathLike)\n</code></pre> <p>Save the filing using pickle serialization.</p> <p>Parameters: - <code>directory_or_file</code>: Directory to save in or specific file path</p> <p>Example:</p> <pre><code># Save to directory\nfiling.save(\"./filings/\")\n\n# Save to specific file\nfiling.save(\"./apple_10k_2023.pkl\")\n</code></pre>"},{"location":"api/filing/#load","title":"load()","text":"<pre><code>@classmethod\ndef load(cls, path: PathLike) -&gt; 'Filing'\n</code></pre> <p>Load a filing from a pickle file.</p> <p>Parameters: - <code>path</code>: Path to the pickle file</p> <p>Returns: <code>Filing</code> object</p> <p>Example:</p> <pre><code>loaded_filing = Filing.load(\"./apple_10k_2023.pkl\")\n</code></pre>"},{"location":"api/filing/#data-conversion","title":"Data Conversion","text":""},{"location":"api/filing/#to_dict","title":"to_dict()","text":"<pre><code>def to_dict(self) -&gt; Dict[str, Union[str, int]]\n</code></pre> <p>Convert filing to dictionary representation.</p> <p>Returns: Dictionary with filing data</p> <p>Example:</p> <pre><code>filing_dict = filing.to_dict()\nprint(filing_dict.keys())\n# dict_keys(['cik', 'company', 'form', 'filing_date', 'accession_no', ...])\n</code></pre>"},{"location":"api/filing/#from_dict","title":"from_dict()","text":"<pre><code>@classmethod\ndef from_dict(cls, data: Dict) -&gt; 'Filing'\n</code></pre> <p>Create a Filing from dictionary data.</p> <p>Parameters: - <code>data</code>: Dictionary with filing information</p> <p>Returns: <code>Filing</code> object</p>"},{"location":"api/filing/#summary","title":"summary()","text":"<pre><code>def summary(self) -&gt; pd.DataFrame\n</code></pre> <p>Get filing summary as a pandas DataFrame.</p> <p>Returns: DataFrame with filing information</p> <p>Example:</p> <pre><code>summary_df = filing.summary()\nprint(summary_df)\n</code></pre>"},{"location":"api/filing/#specialized-filing-classes","title":"Specialized Filing Classes","text":""},{"location":"api/filing/#entityfiling","title":"EntityFiling","text":"<p>Enhanced filing class with additional entity-specific properties:</p> <pre><code>from edgar.entity.filings import EntityFiling\n\n# Additional properties available:\nfiling.report_date           # Report date\nfiling.acceptance_datetime   # SEC acceptance timestamp  \nfiling.file_number          # SEC file number\nfiling.items                # Filing items\nfiling.size                 # Filing size in bytes\nfiling.primary_document     # Primary document filename\nfiling.is_xbrl              # Whether contains XBRL\nfiling.is_inline_xbrl       # Whether contains inline XBRL\n</code></pre>"},{"location":"api/filing/#form-specific-classes","title":"Form-Specific Classes","text":""},{"location":"api/filing/#tenk-tenq-twentyf","title":"TenK, TenQ, TwentyF","text":"<p>Enhanced classes for annual and quarterly reports:</p> <pre><code>from edgar.company_reports import TenK, TenQ\n\ntenk = filing.obj()  # Returns TenK for 10-K filings\n\n# Enhanced functionality\ntenk.financials              # Financial statements\ntenk.income_statement        # Direct access to income statement\ntenk.balance_sheet          # Direct access to balance sheet\ntenk.cash_flow_statement    # Direct access to cash flow\n\n# Access specific items\ntenk.items                  # Available items list\ntenk[\"Item 1\"]              # Business description\ntenk[\"Item 7\"]              # MD&amp;A section\n\n# Chunked document access\ndoc = tenk.doc              # Parsed document with sections\n</code></pre>"},{"location":"api/filing/#eightk","title":"EightK","text":"<p>Enhanced class for current reports:</p> <pre><code>from edgar.company_reports import EightK\n\neightk = filing.obj()       # Returns EightK for 8-K filings\neightk.items               # Material event items\n</code></pre>"},{"location":"api/filing/#form3-form4-form5","title":"Form3, Form4, Form5","text":"<p>Insider ownership filings:</p> <pre><code>from edgar.ownership import Form4\n\nform4 = filing.obj()        # Returns Form4 for Form 4 filings\nform4.to_html()            # Generate HTML representation\n</code></pre>"},{"location":"api/filing/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    # Access filing content\n    html = filing.html()\n    if html is None:\n        print(\"HTML content not available\")\n\n    # Access XBRL data\n    xbrl = filing.xbrl()\n    if xbrl is None:\n        print(\"XBRL data not available\")\n\n    # Access financials\n    financials = filing.financials\n    if financials is None:\n        print(\"Financial statements not available\")\n\nexcept Exception as e:\n    print(f\"Error processing filing: {e}\")\n</code></pre>"},{"location":"api/filing/#performance-tips","title":"Performance Tips","text":"<ol> <li>Cache content - Store HTML/text content if accessing multiple times</li> <li>Use specific data access - Use <code>obj()</code> for structured data instead of parsing HTML</li> <li>Filter attachments - Use <code>exhibits</code> property instead of filtering all <code>attachments</code></li> <li>Check availability - Test for None before accessing optional properties</li> </ol> <pre><code># Efficient pattern\nif filing.financials:\n    revenue = filing.financials.income.loc['Revenue']\nelse:\n    # Fallback to text parsing\n    text = filing.text()\n    # Parse revenue from text\n</code></pre>"},{"location":"api/filing/#complete-example","title":"Complete Example","text":"<pre><code>from edgar import get_filings\n\n# Get a recent 10-K filing\nfilings = get_filings(form=\"10-K\", limit=1)\nfiling = filings[0]\n\n# Basic information\nprint(f\"Company: {filing.company}\")\nprint(f\"Form: {filing.form}\")\nprint(f\"Filing Date: {filing.filing_date}\")\nprint(f\"Accession: {filing.accession_no}\")\n\n# Access structured data\ntenk = filing.obj()\nif tenk.financials:\n    print(\"\\nFinancial Data Available:\")\n    income = tenk.financials.income\n    revenue = income.loc['Revenue'].iloc[0] if 'Revenue' in income.index else None\n    if revenue:\n        print(f\"Revenue: ${revenue/1e9:.1f}B\")\n\n# Search within filing\nsearch_results = filing.search(\"risk factors\")\nprint(f\"\\nFound {len(search_results)} mentions of 'risk factors'\")\n\n# Access attachments\nprint(f\"\\nAttachments: {len(filing.attachments)}\")\nprint(f\"Exhibits: {len(filing.exhibits)}\")\n\n# XBRL analysis\nxbrl = filing.xbrl()\nif xbrl:\n    print(\"\\nXBRL Data Available:\")\n    statements = xbrl.statements\n    balance_sheet = statements.balance_sheet()\n    print(f\"Balance sheet periods: {len(balance_sheet.to_dataframe().columns)-1}\")\n\n# Save for later use\nfiling.save(\"./my_filing.pkl\")\n</code></pre>"},{"location":"api/filing/#see-also","title":"See Also","text":"<ul> <li>Company API Reference - Working with companies</li> <li>Filings API Reference - Working with filing collections</li> <li>Working with Filings Guide - Filing operations</li> <li>Extract Financial Statements - Getting financial data</li> </ul>"},{"location":"api/filings/","title":"Filings API Reference","text":"<p>The <code>Filings</code> class represents a collection of SEC filings with powerful filtering, navigation, and data manipulation capabilities. It serves as the primary interface for working with multiple filings in EdgarTools.</p>"},{"location":"api/filings/#class-overview","title":"Class Overview","text":"<pre><code>from edgar import Filings, get_filings\n\nclass Filings:\n    \"\"\"Collection of SEC filings with filtering and pagination capabilities.\"\"\"\n</code></pre> <p>Backend: Uses PyArrow tables for efficient data handling</p>"},{"location":"api/filings/#constructor","title":"Constructor","text":""},{"location":"api/filings/#filingsfiling_index-original_statenone","title":"Filings(filing_index, original_state=None)","text":"<p>Create a Filings collection from a PyArrow table.</p> <pre><code>Filings(\n    filing_index: pa.Table,\n    original_state: Optional[PagingState] = None)\n</code></pre> <p>Parameters: - <code>filing_index</code> (pa.Table): PyArrow table containing filing data - <code>original_state</code> (Optional[PagingState]): Pagination state for navigation</p> <p>Note: Typically created via <code>get_filings()</code> function rather than direct instantiation.</p> <p>Example:</p> <pre><code>from edgar import get_filings\n\n# Get filings collection\nfilings = get_filings(year=2023, quarter=1)\nprint(type(filings))  # &lt;class 'edgar._filings.Filings'&gt;\n</code></pre>"},{"location":"api/filings/#core-properties","title":"Core Properties","text":""},{"location":"api/filings/#collection-information","title":"Collection Information","text":""},{"location":"api/filings/#empty","title":"empty","text":"<pre><code>@property\ndef empty(self) -&gt; bool:\n</code></pre> <p>Whether the collection contains any filings.</p> <pre><code>filings = get_filings(form=\"INVALID\")\nif filings.empty:\n    print(\"No filings found\")\n</code></pre>"},{"location":"api/filings/#date_range","title":"date_range","text":"<pre><code>@property\ndef date_range(self) -&gt; Tuple[str, str]:\n</code></pre> <p>Start and end dates for filings in the collection.</p> <pre><code>start_date, end_date = filings.date_range\nprint(f\"Filings from {start_date} to {end_date}\")\n</code></pre>"},{"location":"api/filings/#start_date-end_date","title":"start_date / end_date","text":"<pre><code>@property\ndef start_date(self) -&gt; str:\n    ...\n\n@property  \ndef end_date(self) -&gt; str:\n    ...\n</code></pre> <p>Individual start and end dates.</p> <pre><code>print(f\"Collection spans from {filings.start_date} to {filings.end_date}\")\n</code></pre>"},{"location":"api/filings/#summary","title":"summary","text":"<pre><code>@property\ndef summary(self) -&gt; str:\n</code></pre> <p>Summary string describing the current page/collection.</p> <pre><code>print(filings.summary)\n# \"Page 1 of 10 filings from 2023-01-01 to 2023-03-31\"\n</code></pre>"},{"location":"api/filings/#collection-operations","title":"Collection Operations","text":""},{"location":"api/filings/#size-and-access","title":"Size and Access","text":""},{"location":"api/filings/#len-count","title":"len() / count","text":"<pre><code>def __len__(self) -&gt; int:\n</code></pre> <p>Number of filings in the current collection/page.</p> <pre><code>print(f\"Collection contains {len(filings)} filings\")\n</code></pre>"},{"location":"api/filings/#indexing-and-iteration","title":"Indexing and Iteration","text":"<pre><code>def __getitem__(self, item: int) -&gt; Filing:\n    ...\ndef __iter__(self) -&gt; Iterator[Filing]:\n    ...\n</code></pre> <p>Access individual filings by index or iterate through collection.</p> <pre><code># Index access\nfirst_filing = filings[0]\nlast_filing = filings[-1]\n\n# Iteration\nfor filing in filings:\n    print(f\"{filing.form}: {filing.company} ({filing.filing_date})\")\n\n# Slicing\nfirst_five = filings[:5]\n</code></pre>"},{"location":"api/filings/#get","title":"get()","text":"<pre><code>def get(self, index_or_accession_number: Union[int, str]) -&gt; Filing\n</code></pre> <p>Get a filing by index or accession number.</p> <p>Parameters: - <code>index_or_accession_number</code>: Integer index or accession number string</p> <p>Returns: <code>Filing</code> object</p> <p>Example:</p> <pre><code># Get by index\nfiling = filings.get(0)\n\n# Get by accession number\nfiling = filings.get(\"0001234567-23-000001\")\n</code></pre>"},{"location":"api/filings/#subset-operations","title":"Subset Operations","text":""},{"location":"api/filings/#latest","title":"latest()","text":"<pre><code>def latest(self, n: int = 1) -&gt; Union[Filing, 'Filings']\n</code></pre> <p>Get the most recent filing(s).</p> <p>Parameters: - <code>n</code> (int): Number of latest filings to return (default: 1)</p> <p>Returns: - Single <code>Filing</code> if n=1 - <code>Filings</code> collection if n&gt;1</p> <p>Example:</p> <pre><code># Get latest single filing\nlatest_filing = filings.latest()\n\n# Get latest 5 filings\nlatest_five = filings.latest(5)\nprint(f\"Latest 5 filings: {len(latest_five)}\")\n</code></pre>"},{"location":"api/filings/#head","title":"head()","text":"<pre><code>def head(self, n: int) -&gt; 'Filings'\n</code></pre> <p>Get the first n filings from the collection.</p> <p>Parameters: - <code>n</code> (int): Number of filings to return</p> <p>Returns: <code>Filings</code> collection</p> <p>Example:</p> <pre><code>first_ten = filings.head(10)\nprint(f\"First 10 filings: {len(first_ten)}\")\n</code></pre>"},{"location":"api/filings/#tail","title":"tail()","text":"<pre><code>def tail(self, n: int) -&gt; 'Filings'\n</code></pre> <p>Get the last n filings from the collection.</p> <p>Parameters: - <code>n</code> (int): Number of filings to return</p> <p>Returns: <code>Filings</code> collection</p> <p>Example:</p> <pre><code>last_ten = filings.tail(10)\nprint(f\"Last 10 filings: {len(last_ten)}\")\n</code></pre>"},{"location":"api/filings/#sample","title":"sample()","text":"<pre><code>def sample(self, n: int) -&gt; 'Filings'\n</code></pre> <p>Get a random sample of n filings.</p> <p>Parameters: - <code>n</code> (int): Number of filings to sample</p> <p>Returns: <code>Filings</code> collection</p> <p>Example:</p> <pre><code>random_sample = filings.sample(5)\nprint(f\"Random sample: {len(random_sample)} filings\")\n</code></pre>"},{"location":"api/filings/#filtering-and-search","title":"Filtering and Search","text":""},{"location":"api/filings/#filter","title":"filter()","text":"<pre><code>def filter(\n    self,\n    *,\n    form: Optional[Union[str, List[str]]] = None,\n    amendments: bool = None,\n    filing_date: Optional[str] = None,\n    date: Optional[str] = None,\n    cik: Union[int, str, List[Union[int, str]]] = None,\n    exchange: Union[str, List[str]] = None,\n    ticker: Union[str, List[str]] = None,\n    accession_number: Union[str, List[str]] = None\n) -&gt; 'Filings'\n</code></pre> <p>Filter the collection by various criteria.</p> <p>Parameters: - <code>form</code>: SEC form type(s) - e.g., \"10-K\", [\"10-K\", \"10-Q\"] - <code>amendments</code>: Include/exclude amendments (default: include) - <code>filing_date</code> / <code>date</code>: Date filter (YYYY-MM-DD or YYYY-MM-DD:YYYY-MM-DD) - <code>cik</code>: Central Index Key(s) - <code>exchange</code>: Stock exchange(s) - \"NASDAQ\", \"NYSE\", \"CBOE\", \"OTC\" - <code>ticker</code>: Stock ticker symbol(s) - <code>accession_number</code>: SEC accession number(s)</p> <p>Returns: Filtered <code>Filings</code> collection</p> <p>Examples:</p> <pre><code># Filter by form type\nannual_reports = filings.filter(form=\"10-K\")\nfinancial_reports = filings.filter(form=[\"10-K\", \"10-Q\"])\n\n# Filter by date range\nq1_filings = filings.filter(date=\"2023-01-01:2023-03-31\")\nrecent_filings = filings.filter(date=\"2023-01-01:\")\n\n# Filter by company\napple_filings = filings.filter(ticker=\"AAPL\")\napple_by_cik = filings.filter(cik=320193)\n\n# Filter by exchange\nnasdaq_filings = filings.filter(exchange=\"NASDAQ\")\nmajor_exchanges = filings.filter(exchange=[\"NASDAQ\", \"NYSE\"])\n\n# Exclude amendments\noriginal_only = filings.filter(amendments=False)\n\n# Chain filters\nfiltered = filings.filter(form=\"10-K\").filter(exchange=\"NASDAQ\").filter(date=\"2023-01-01:\")\n</code></pre>"},{"location":"api/filings/#find","title":"find()","text":"<pre><code>def find(self, company_search_str: str) -&gt; 'Filings'\n</code></pre> <p>Search for filings by company name.</p> <p>Parameters: - <code>company_search_str</code> (str): Company name search string</p> <p>Returns: <code>Filings</code> collection matching the search</p> <p>Example:</p> <pre><code># Search for companies with \"Apple\" in name\napple_filings = filings.find(\"Apple\")\n\n# Search for technology companies\ntech_filings = filings.find(\"Technology\")\n</code></pre>"},{"location":"api/filings/#navigation-and-pagination","title":"Navigation and Pagination","text":""},{"location":"api/filings/#current","title":"current()","text":"<pre><code>def current(self) -&gt; 'Filings'\n</code></pre> <p>Get the current page of filings.</p> <p>Returns: Current <code>Filings</code> page</p>"},{"location":"api/filings/#next","title":"next()","text":"<pre><code>def next(self) -&gt; Optional['Filings']\n</code></pre> <p>Navigate to the next page of filings.</p> <p>Returns: Next page <code>Filings</code> or None if no more pages</p> <p>Example:</p> <pre><code># Navigate through pages\ncurrent_page = filings.current()\nnext_page = filings.next()\n\nif next_page:\n    print(f\"Next page has {len(next_page)} filings\")\nelse:\n    print(\"No more pages available\")\n</code></pre>"},{"location":"api/filings/#previous","title":"previous()","text":"<pre><code>def previous(self) -&gt; Optional['Filings']\n</code></pre> <p>Navigate to the previous page of filings.</p> <p>Returns: Previous page <code>Filings</code> or None if on first page</p> <p>Example:</p> <pre><code># Go back to previous page\nprev_page = filings.previous()\n\nif prev_page:\n    print(f\"Previous page has {len(prev_page)} filings\")\nelse:\n    print(\"Already on first page\")\n</code></pre>"},{"location":"api/filings/#data-export-and-persistence","title":"Data Export and Persistence","text":""},{"location":"api/filings/#to_pandas","title":"to_pandas()","text":"<pre><code>def to_pandas(self, *columns: str) -&gt; pd.DataFrame\n</code></pre> <p>Convert the collection to a pandas DataFrame.</p> <p>Parameters: - <code>*columns</code>: Specific columns to include (optional)</p> <p>Returns: <code>pd.DataFrame</code> with filing data</p> <p>Example:</p> <pre><code># Convert all data\ndf = filings.to_pandas()\nprint(df.columns.tolist())\n\n# Convert specific columns only\nsummary_df = filings.to_pandas('form', 'company', 'filing_date')\nprint(summary_df.head())\n</code></pre>"},{"location":"api/filings/#save_parquet-save","title":"save_parquet() / save()","text":"<pre><code>def save_parquet(self, location: str)\ndef save(self, location: str)  # Alias\n</code></pre> <p>Save the collection as a Parquet file.</p> <p>Parameters: - <code>location</code> (str): File path to save to</p> <p>Example:</p> <pre><code># Save collection\nfilings.save_parquet(\"my_filings.parquet\")\n\n# Load back later\nimport pandas as pd\ndf = pd.read_parquet(\"my_filings.parquet\")\n</code></pre>"},{"location":"api/filings/#to_dict","title":"to_dict()","text":"<pre><code>def to_dict(self, max_rows: int = 1000) -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary representation.</p> <p>Parameters: - <code>max_rows</code> (int): Maximum number of rows to include (default: 1000)</p> <p>Returns: Dictionary with filing data</p> <p>Example:</p> <pre><code>filings_dict = filings.to_dict(max_rows=100)\nprint(filings_dict.keys())\n</code></pre>"},{"location":"api/filings/#download","title":"download()","text":"<pre><code>def download(self, data_directory: Optional[str] = None)\n</code></pre> <p>Download all filings in the collection to local storage.</p> <p>Parameters: - <code>data_directory</code> (Optional[str]): Directory to save files (optional)</p> <p>Example:</p> <pre><code># Download to current directory\nfilings.download()\n\n# Download to specific directory\nfilings.download(\"./edgar_data/\")\n</code></pre>"},{"location":"api/filings/#specialized-filing-collections","title":"Specialized Filing Collections","text":""},{"location":"api/filings/#entityfilings","title":"EntityFilings","text":"<p>Enhanced filings collection for company-specific filings:</p> <pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\nentity_filings = company.get_filings()\n\nprint(type(entity_filings))  # &lt;class 'edgar.entity.filings.EntityFilings'&gt;\n\n# Additional properties\nprint(entity_filings.cik)          # Company CIK\nprint(entity_filings.company_name) # Company name\n\n# Enhanced methods return EntityFilings\nfiltered = entity_filings.filter(form=\"10-K\")  # Returns EntityFilings\nlatest = entity_filings.latest(3)              # Returns EntityFilings\n</code></pre>"},{"location":"api/filings/#currentfilings","title":"CurrentFilings","text":"<p>Real-time filings with enhanced pagination:</p> <pre><code>from edgar import get_current_filings\n\ncurrent = get_current_filings()\nprint(type(current))  # &lt;class 'edgar._filings.CurrentFilings'&gt;\n\n# Additional properties\nprint(current.form)   # Form filter\nprint(current.owner)  # Owner filter\n\n# Real-time pagination\nnext_page = current.next()\n</code></pre>"},{"location":"api/filings/#advanced-usage-patterns","title":"Advanced Usage Patterns","text":""},{"location":"api/filings/#chaining-operations","title":"Chaining Operations","text":"<pre><code># Complex filtering and processing pipeline\nresult = (filings\n    .filter(form=[\"10-K\", \"10-Q\"])\n    .filter(exchange=\"NASDAQ\") \n    .filter(date=\"2023-01-01:\")\n    .latest(50)\n)\n\nprint(f\"Final result: {len(result)} filings\")\n</code></pre>"},{"location":"api/filings/#batch-processing","title":"Batch Processing","text":"<pre><code># Process filings in batches\nbatch_size = 100\ntotal_processed = 0\n\nwhile not filings.empty:\n    batch = filings.head(batch_size)\n\n    # Process each filing in batch\n    for filing in batch:\n        # Extract data, analyze, etc.\n        text = filing.text()\n        # ... processing logic\n\n    total_processed += len(batch)\n\n    # Move to next batch\n    filings = filings.tail(len(filings) - batch_size)\n\nprint(f\"Processed {total_processed} filings\")\n</code></pre>"},{"location":"api/filings/#data-analysis","title":"Data Analysis","text":"<pre><code># Convert to DataFrame for analysis\ndf = filings.to_pandas()\n\n# Analyze filing patterns\nform_counts = df.groupby('form').size().sort_values(ascending=False)\nprint(\"Most common forms:\")\nprint(form_counts.head())\n\n# Monthly filing trends\ndf['filing_date'] = pd.to_datetime(df['filing_date'])\nmonthly_filings = df.groupby(df['filing_date'].dt.to_period('M')).size()\nprint(\"Monthly filing counts:\")\nprint(monthly_filings)\n\n# Company analysis\ntop_filers = df.groupby('company').size().sort_values(ascending=False)\nprint(\"Top 10 filing companies:\")\nprint(top_filers.head(10))\n</code></pre>"},{"location":"api/filings/#performance-optimization","title":"Performance Optimization","text":""},{"location":"api/filings/#efficient-filtering","title":"Efficient Filtering","text":"<pre><code># More efficient: specific filtering upfront\nefficient = get_filings(\n    year=2023,\n    form=\"10-K\",\n    limit=100\n)\n\n# Less efficient: get all then filter\ninefficient = get_filings(year=2023, limit=10000).filter(form=\"10-K\")\n</code></pre>"},{"location":"api/filings/#pagination-strategies","title":"Pagination Strategies","text":"<pre><code># Process large datasets with pagination\ndef process_all_filings(filings):\n    current_page = filings\n    total_processed = 0\n\n    while current_page and not current_page.empty:\n        # Process current page\n        for filing in current_page:\n            # Process individual filing\n            pass\n\n        total_processed += len(current_page)\n        print(f\"Processed {total_processed} filings so far...\")\n\n        # Move to next page\n        current_page = current_page.next()\n\n    return total_processed\n\n# Usage\nfilings = get_filings(year=2023)\ntotal = process_all_filings(filings)\n</code></pre>"},{"location":"api/filings/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    # Filter operations\n    filtered = filings.filter(form=\"10-K\", date=\"2023-01-01:\")\n\n    if filtered.empty:\n        print(\"No filings match the criteria\")\n    else:\n        # Process results\n        for filing in filtered:\n            try:\n                text = filing.text()\n                # Process text\n            except Exception as e:\n                print(f\"Error processing filing {filing.accession_no}: {e}\")\n                continue\n\nexcept Exception as e:\n    print(f\"Error filtering filings: {e}\")\n\n# Navigation error handling\nnext_page = filings.next()\nif next_page is None:\n    print(\"No more pages available\")\n</code></pre>"},{"location":"api/filings/#complete-example","title":"Complete Example","text":"<pre><code>from edgar import get_filings\nimport pandas as pd\n\n# Get filings for analysis\nfilings = get_filings(year=2023, quarter=1)\nprint(f\"Initial collection: {len(filings)} filings\")\n\n# Filter to focus on annual reports from major exchanges\nannual_reports = filings.filter(\n    form=\"10-K\",\n    exchange=[\"NASDAQ\", \"NYSE\"]\n)\nprint(f\"Annual reports from major exchanges: {len(annual_reports)}\")\n\n# Get latest 20 for detailed analysis\nlatest_reports = annual_reports.latest(20)\n\n# Convert to DataFrame for analysis\ndf = latest_reports.to_pandas()\n\n# Analyze companies and dates\nprint(\"\\nCompanies with recent 10-K filings:\")\nfor _, row in df.iterrows():\n    print(f\"  {row['company']}: {row['filing_date']}\")\n\n# Export for further analysis\nlatest_reports.save_parquet(\"annual_reports_q1_2023.parquet\")\n\n# Process individual filings\nfor filing in latest_reports:\n    try:\n        # Extract structured data\n        tenk = filing.obj()\n        if tenk and tenk.financials:\n            financials = tenk.financials\n            revenue = financials.income.loc['Revenue'].iloc[0] if 'Revenue' in financials.income.index else None\n            if revenue:\n                print(f\"{filing.company}: Revenue ${revenue/1e9:.1f}B\")\n    except Exception as e:\n        print(f\"Error processing {filing.company}: {e}\")\n\n# Navigate through additional pages if needed\nnext_page = filings.next()\nif next_page:\n    print(f\"\\nNext page available with {len(next_page)} more filings\")\n</code></pre>"},{"location":"api/filings/#see-also","title":"See Also","text":"<ul> <li>Filing API Reference - Working with individual filings</li> <li>Company API Reference - Company-specific filing collections</li> <li>Filtering Filings Guide - Advanced filtering techniques</li> <li>Search Filings Guide - Finding specific filings</li> </ul>"},{"location":"api/xbrl/","title":"XBRL API Reference","text":"<p>The XBRL module provides comprehensive parsing and processing of XBRL (eXtensible Business Reporting Language) data from SEC filings. It includes support for statement standardization, multi-period analysis, and advanced querying capabilities.</p>"},{"location":"api/xbrl/#module-overview","title":"Module Overview","text":"<p>The XBRL module is organized into several key components:</p> <ul> <li>Core Classes: <code>XBRL</code>, <code>XBRLS</code> for parsing and managing XBRL documents</li> <li>Statement Processing: <code>Statements</code>, <code>Statement</code> for working with financial statements</li> <li>Facts Querying: <code>FactsView</code>, <code>FactQuery</code> for querying XBRL facts</li> <li>Multi-Period Analysis: <code>StitchedStatements</code>, <code>StitchedStatement</code> for comparative analysis</li> <li>Standardization: <code>StandardConcept</code> for normalizing company-specific concepts</li> <li>Rendering: <code>RenderedStatement</code> for formatted output</li> </ul>"},{"location":"api/xbrl/#core-classes","title":"Core Classes","text":""},{"location":"api/xbrl/#xbrl","title":"XBRL","text":"<p>The main class for parsing and working with XBRL documents from SEC filings.</p> <pre><code>from edgar.xbrl import XBRL\n\nclass XBRL:\n    \"\"\"Main XBRL parser integrating all components of the XBRL parsing system.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#factory-methods","title":"Factory Methods","text":""},{"location":"api/xbrl/#from_filing","title":"from_filing()","text":"<pre><code>@classmethod\ndef from_filing(cls, filing: Filing) -&gt; XBRL\n</code></pre> <p>Create an XBRL instance from a Filing object.</p> <p>Parameters: - <code>filing</code>: SEC filing object containing XBRL data</p> <p>Returns: <code>XBRL</code> instance</p> <p>Example:</p> <pre><code>from edgar import Company\nfrom edgar.xbrl import XBRL\n\ncompany = Company(\"AAPL\")\nfiling = company.latest(\"10-K\")\nxbrl = XBRL.from_filing(filing)\n</code></pre>"},{"location":"api/xbrl/#from_directory","title":"from_directory()","text":"<pre><code>@classmethod\ndef from_directory(cls, directory: str) -&gt; XBRL\n</code></pre> <p>Create an XBRL instance from a directory containing XBRL files.</p> <p>Parameters: - <code>directory</code>: Path to directory containing XBRL files</p> <p>Returns: <code>XBRL</code> instance</p>"},{"location":"api/xbrl/#from_files","title":"from_files()","text":"<pre><code>@classmethod\ndef from_files(cls, files: List[str]) -&gt; XBRL\n</code></pre> <p>Create an XBRL instance from a list of XBRL files.</p> <p>Parameters: - <code>files</code>: List of file paths to XBRL documents</p> <p>Returns: <code>XBRL</code> instance</p>"},{"location":"api/xbrl/#core-properties","title":"Core Properties","text":""},{"location":"api/xbrl/#statements","title":"statements","text":"<pre><code>@property\ndef statements(self) -&gt; Statements\n</code></pre> <p>Access to all financial statements in the XBRL document.</p> <p>Returns: <code>Statements</code> object for accessing individual statements</p> <p>Example:</p> <pre><code># Access different statement types\nbalance_sheet = xbrl.statements.balance_sheet()\nincome_statement = xbrl.statements.income_statement()\ncash_flow = xbrl.statements.cash_flow_statement()\n</code></pre>"},{"location":"api/xbrl/#facts","title":"facts","text":"<pre><code>@property\ndef facts(self) -&gt; FactsView\n</code></pre> <p>Access to all XBRL facts with querying capabilities.</p> <p>Returns: <code>FactsView</code> object for querying facts</p> <p>Example:</p> <pre><code># Query facts by concept\nrevenue_facts = xbrl.facts.by_concept(\"Revenue\")\n\n# Convert to DataFrame for analysis\nfacts_df = xbrl.facts.to_dataframe()\n</code></pre>"},{"location":"api/xbrl/#statement-methods","title":"Statement Methods","text":""},{"location":"api/xbrl/#get_statement","title":"get_statement()","text":"<pre><code>def get_statement(self, statement_type: str) -&gt; Optional[Statement]\n</code></pre> <p>Get a specific financial statement by type.</p> <p>Parameters: - <code>statement_type</code>: Statement type (\"BalanceSheet\", \"IncomeStatement\", \"CashFlowStatement\", etc.)</p> <p>Returns: <code>Statement</code> object or None if not found</p>"},{"location":"api/xbrl/#render_statement","title":"render_statement()","text":"<pre><code>def render_statement(self, statement_type: str, **kwargs) -&gt; RenderedStatement\n</code></pre> <p>Render a financial statement with rich formatting.</p> <p>Parameters: - <code>statement_type</code>: Statement type to render - <code>**kwargs</code>: Additional rendering options</p> <p>Returns: <code>RenderedStatement</code> object</p> <p>Example:</p> <pre><code># Render balance sheet\nrendered = xbrl.render_statement(\"BalanceSheet\")\nprint(rendered)\n\n# Render with custom options\nrendered = xbrl.render_statement(\"IncomeStatement\", \n                                show_percentages=True,\n                                max_rows=50)\n</code></pre>"},{"location":"api/xbrl/#data-conversion","title":"Data Conversion","text":""},{"location":"api/xbrl/#to_pandas","title":"to_pandas()","text":"<pre><code>def to_pandas(self) -&gt; pd.DataFrame\n</code></pre> <p>Convert XBRL facts to a pandas DataFrame.</p> <p>Returns: DataFrame with all facts and their attributes</p> <p>Example:</p> <pre><code># Convert to DataFrame for analysis\ndf = xbrl.to_pandas()\nprint(df.columns)  # ['concept', 'value', 'period', 'label', ...]\n\n# Filter for specific concepts\nrevenue_df = df[df['concept'].str.contains('Revenue', case=False)]\n</code></pre>"},{"location":"api/xbrl/#xbrls","title":"XBRLS","text":"<p>Container class for managing multiple XBRL documents for multi-period analysis.</p> <pre><code>from edgar.xbrl import XBRLS\n\nclass XBRLS:\n    \"\"\"Container for multiple XBRL objects enabling multi-period analysis.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#factory-methods_1","title":"Factory Methods","text":""},{"location":"api/xbrl/#from_filings","title":"from_filings()","text":"<pre><code>@classmethod\ndef from_filings(cls, filings: List[Filing]) -&gt; XBRLS\n</code></pre> <p>Create an XBRLS instance from multiple filings.</p> <p>Parameters: - <code>filings</code>: List of Filing objects</p> <p>Returns: <code>XBRLS</code> instance</p> <p>Example:</p> <pre><code>from edgar import Company\nfrom edgar.xbrl import XBRLS\n\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=\"10-K\").head(3)  # Get 3 years\nxbrls = XBRLS.from_filings(filings)\n</code></pre>"},{"location":"api/xbrl/#properties","title":"Properties","text":""},{"location":"api/xbrl/#statements_1","title":"statements","text":"<pre><code>@property\ndef statements(self) -&gt; StitchedStatements\n</code></pre> <p>Access to stitched statements showing multi-period data.</p> <p>Returns: <code>StitchedStatements</code> object</p> <p>Example:</p> <pre><code># Get multi-period statements\nincome_stmt = xbrls.statements.income_statement()\nbalance_sheet = xbrls.statements.balance_sheet()\n\n# Render multi-period view\nprint(income_stmt.render())\n</code></pre>"},{"location":"api/xbrl/#statement-classes","title":"Statement Classes","text":""},{"location":"api/xbrl/#statements_2","title":"Statements","text":"<p>High-level interface for accessing financial statements from a single XBRL document.</p> <pre><code>class Statements:\n    \"\"\"High-level interface to all statements in an XBRL document.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#statement-access-methods","title":"Statement Access Methods","text":""},{"location":"api/xbrl/#balance_sheet","title":"balance_sheet()","text":"<pre><code>def balance_sheet(self) -&gt; Optional[Statement]\n</code></pre> <p>Get the balance sheet statement.</p> <p>Returns: <code>Statement</code> object or None</p>"},{"location":"api/xbrl/#income_statement","title":"income_statement()","text":"<pre><code>def income_statement(self) -&gt; Optional[Statement]\n</code></pre> <p>Get the income statement.</p> <p>Returns: <code>Statement</code> object or None</p>"},{"location":"api/xbrl/#cash_flow_statement","title":"cash_flow_statement()","text":"<pre><code>def cash_flow_statement(self) -&gt; Optional[Statement]\n</code></pre> <p>Get the cash flow statement.</p> <p>Returns: <code>Statement</code> object or None</p>"},{"location":"api/xbrl/#statement_of_equity","title":"statement_of_equity()","text":"<pre><code>def statement_of_equity(self) -&gt; Optional[Statement]\n</code></pre> <p>Get the statement of equity.</p> <p>Returns: <code>Statement</code> object or None</p>"},{"location":"api/xbrl/#comprehensive_income","title":"comprehensive_income()","text":"<pre><code>def comprehensive_income(self) -&gt; Optional[Statement]\n</code></pre> <p>Get the comprehensive income statement.</p> <p>Returns: <code>Statement</code> object or None</p> <p>Example:</p> <pre><code>statements = xbrl.statements\n\n# Access different statement types\nif statements.balance_sheet():\n    bs = statements.balance_sheet()\n    print(f\"Total Assets: {bs.get_concept_value('Assets')}\")\n\nif statements.income_statement():\n    is_stmt = statements.income_statement()\n    print(f\"Revenue: {is_stmt.get_concept_value('Revenue')}\")\n</code></pre>"},{"location":"api/xbrl/#statement","title":"Statement","text":"<p>Individual financial statement with analysis and rendering capabilities.</p> <pre><code>class Statement:\n    \"\"\"A single financial statement extracted from XBRL data.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#core-methods","title":"Core Methods","text":""},{"location":"api/xbrl/#render","title":"render()","text":"<pre><code>def render(self, **kwargs) -&gt; RenderedStatement\n</code></pre> <p>Render the statement with rich formatting.</p> <p>Parameters: - <code>**kwargs</code>: Rendering options (show_percentages, max_rows, etc.)</p> <p>Returns: <code>RenderedStatement</code> object</p>"},{"location":"api/xbrl/#to_dataframe","title":"to_dataframe()","text":"<pre><code>def to_dataframe(\n    self,\n    include_dimensions: bool = True,\n    include_unit: bool = False,\n    include_point_in_time: bool = False,\n    presentation: bool = False\n) -&gt; pd.DataFrame\n</code></pre> <p>Convert statement to pandas DataFrame with optional transformations.</p> <p>Parameters: - <code>include_dimensions</code>: Include dimensional breakdowns (default: True) - <code>include_unit</code>: Include unit column (USD, shares, etc.) (default: False) - <code>include_point_in_time</code>: Include point-in-time column for instant facts (default: False) - <code>presentation</code>: Apply HTML-matching transformations using preferred_sign (default: False)   - False (default): Raw instance values from XML   - True: Transform values to match SEC filing HTML display</p> <p>Returns: DataFrame with the following columns: - Core columns: <code>concept</code>, <code>label</code>, period columns (dates) - Metadata columns (always included): <code>balance</code>, <code>weight</code>, <code>preferred_sign</code> - Optional columns: <code>dimension</code>, <code>unit</code>, <code>point_in_time</code></p> <p>Value Modes: - Raw mode (default): Preserves values exactly as reported in instance document - Presentation mode (<code>presentation=True</code>): Applies transformations to match SEC HTML rendering   - Cash Flow: outflows with preferred_sign=-1 shown as negative   - Income Statement: applies preferred_sign transformations</p> <p>Example:</p> <pre><code>statement = xbrl.statements.income_statement()\n\n# Raw values (default)\ndf_raw = statement.to_dataframe()\n# Returns actual XML values + metadata columns\n\n# Presentation mode (matches SEC HTML)\ndf_presentation = statement.to_dataframe(presentation=True)\n# Returns transformed values matching 10-K HTML display\n\n# Check metadata\nprint(df_raw[['concept', 'balance', 'weight', 'preferred_sign']].head())\n</code></pre> <p>See Also: Issue #463 - XBRL value transformations and metadata columns</p> <p>Returns: DataFrame with statement data</p>"},{"location":"api/xbrl/#get_concept_value","title":"get_concept_value()","text":"<pre><code>def get_concept_value(self, concept: str) -&gt; Optional[Any]\n</code></pre> <p>Get the value for a specific concept.</p> <p>Parameters: - <code>concept</code>: Concept name to look up</p> <p>Returns: Concept value or None</p> <p>Example:</p> <pre><code>statement = xbrl.statements.income_statement()\n\n# Render the statement\nrendered = statement.render()\nprint(rendered)\n\n# Convert to DataFrame\ndf = statement.to_dataframe()\n\n# Get specific values\nrevenue = statement.get_concept_value(\"Revenue\")\nnet_income = statement.get_concept_value(\"NetIncomeLoss\")\n</code></pre>"},{"location":"api/xbrl/#facts-querying","title":"Facts Querying","text":""},{"location":"api/xbrl/#factsview","title":"FactsView","text":"<p>Provides a view over all XBRL facts with analysis and querying methods.</p> <pre><code>class FactsView:\n    \"\"\"View over all facts with analysis methods.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#query-methods","title":"Query Methods","text":""},{"location":"api/xbrl/#by_concept","title":"by_concept()","text":"<pre><code>def by_concept(self, pattern: str, exact: bool = False) -&gt; FactQuery\n</code></pre> <p>Filter facts by concept name.</p> <p>Parameters: - <code>pattern</code>: Pattern to match against concept names - <code>exact</code>: If True, require exact match; otherwise, use regex</p> <p>Returns: <code>FactQuery</code> object for further filtering</p>"},{"location":"api/xbrl/#by_label","title":"by_label()","text":"<pre><code>def by_label(self, pattern: str, exact: bool = False) -&gt; FactQuery\n</code></pre> <p>Filter facts by element label.</p> <p>Parameters: - <code>pattern</code>: Pattern to match against labels - <code>exact</code>: If True, require exact match; otherwise, use regex</p> <p>Returns: <code>FactQuery</code> object for further filtering</p>"},{"location":"api/xbrl/#by_value","title":"by_value()","text":"<pre><code>def by_value(self, min_value: float = None, max_value: float = None) -&gt; FactQuery\n</code></pre> <p>Filter facts by value range.</p> <p>Parameters: - <code>min_value</code>: Minimum value threshold - <code>max_value</code>: Maximum value threshold</p> <p>Returns: <code>FactQuery</code> object for further filtering</p>"},{"location":"api/xbrl/#by_period","title":"by_period()","text":"<pre><code>def by_period(self, start_date: str = None, end_date: str = None) -&gt; FactQuery\n</code></pre> <p>Filter facts by period range.</p> <p>Parameters: - <code>start_date</code>: Start date (YYYY-MM-DD format) - <code>end_date</code>: End date (YYYY-MM-DD format)</p> <p>Returns: <code>FactQuery</code> object for further filtering</p>"},{"location":"api/xbrl/#analysis-methods","title":"Analysis Methods","text":""},{"location":"api/xbrl/#pivot_by_period","title":"pivot_by_period()","text":"<pre><code>def pivot_by_period(self, concepts: List[str] = None) -&gt; pd.DataFrame\n</code></pre> <p>Create a pivot table showing concepts by period.</p> <p>Parameters: - <code>concepts</code>: List of concepts to include (default: all)</p> <p>Returns: DataFrame with concepts as rows and periods as columns</p>"},{"location":"api/xbrl/#time_series","title":"time_series()","text":"<pre><code>def time_series(self, concept: str) -&gt; pd.Series\n</code></pre> <p>Get time series data for a specific concept.</p> <p>Parameters: - <code>concept</code>: Concept name</p> <p>Returns: pandas Series with time series data</p>"},{"location":"api/xbrl/#data-conversion_1","title":"Data Conversion","text":""},{"location":"api/xbrl/#to_dataframe_1","title":"to_dataframe()","text":"<pre><code>def to_dataframe(self) -&gt; pd.DataFrame\n</code></pre> <p>Convert facts to pandas DataFrame.</p> <p>Returns: DataFrame with all facts and metadata</p> <p>Example:</p> <pre><code>facts = xbrl.facts\n\n# Query by concept\nrevenue_query = facts.by_concept(\"Revenue\")\nrevenue_facts = revenue_query.execute()\n\n# Query by label and value\nlarge_expenses = facts.by_label(\"expense\").by_value(min_value=1000000)\nexpense_facts = large_expenses.to_dataframe()\n\n# Time series analysis\nrevenue_ts = facts.time_series(\"Revenue\")\nprint(revenue_ts.head())\n\n# Pivot analysis\npivot_df = facts.pivot_by_period([\"Revenue\", \"NetIncomeLoss\"])\n</code></pre>"},{"location":"api/xbrl/#factquery","title":"FactQuery","text":"<p>Fluent query builder for filtering and manipulating XBRL facts.</p> <pre><code>class FactQuery:\n    \"\"\"A query builder for XBRL facts with fluent interface.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#filtering-methods","title":"Filtering Methods","text":"<p>All filtering methods return <code>self</code> for method chaining.</p>"},{"location":"api/xbrl/#by_concept_1","title":"by_concept()","text":"<pre><code>def by_concept(self, pattern: str, exact: bool = False) -&gt; FactQuery\n</code></pre>"},{"location":"api/xbrl/#by_label_1","title":"by_label()","text":"<pre><code>def by_label(self, pattern: str, exact: bool = False) -&gt; FactQuery\n</code></pre>"},{"location":"api/xbrl/#by_value_1","title":"by_value()","text":"<pre><code>def by_value(self, min_value: float = None, max_value: float = None) -&gt; FactQuery\n</code></pre>"},{"location":"api/xbrl/#by_period_1","title":"by_period()","text":"<pre><code>def by_period(self, start_date: str = None, end_date: str = None) -&gt; FactQuery\n</code></pre>"},{"location":"api/xbrl/#by_statement","title":"by_statement()","text":"<pre><code>def by_statement(self, statement_type: str) -&gt; FactQuery\n</code></pre> <p>Filter facts by statement type.</p> <p>Parameters: - <code>statement_type</code>: Statement type to filter by</p> <p>Returns: <code>FactQuery</code> object for method chaining</p>"},{"location":"api/xbrl/#execution-methods","title":"Execution Methods","text":""},{"location":"api/xbrl/#execute","title":"execute()","text":"<pre><code>def execute(self) -&gt; List[Dict]\n</code></pre> <p>Execute the query and return matching facts.</p> <p>Returns: List of fact dictionaries</p>"},{"location":"api/xbrl/#to_dataframe_2","title":"to_dataframe()","text":"<pre><code>def to_dataframe(self) -&gt; pd.DataFrame\n</code></pre> <p>Execute the query and return results as DataFrame.</p> <p>Returns: DataFrame with query results</p>"},{"location":"api/xbrl/#first","title":"first()","text":"<pre><code>def first(self) -&gt; Optional[Dict]\n</code></pre> <p>Get the first matching fact.</p> <p>Returns: First fact dictionary or None</p>"},{"location":"api/xbrl/#count","title":"count()","text":"<pre><code>def count(self) -&gt; int\n</code></pre> <p>Count matching facts without retrieving them.</p> <p>Returns: Number of matching facts</p> <p>Example:</p> <pre><code># Chain multiple filters\nquery = (xbrl.facts\n         .by_concept(\"Revenue\")\n         .by_period(start_date=\"2023-01-01\")\n         .by_value(min_value=1000000))\n\n# Execute in different ways\nfacts_list = query.execute()\nfacts_df = query.to_dataframe()\nfirst_fact = query.first()\ncount = query.count()\n</code></pre>"},{"location":"api/xbrl/#multi-period-analysis","title":"Multi-Period Analysis","text":""},{"location":"api/xbrl/#stitchedstatements","title":"StitchedStatements","text":"<p>Interface for accessing multi-period statements that combine data across multiple XBRL documents.</p> <pre><code>class StitchedStatements:\n    \"\"\"Interface for multi-period statements.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#statement-access-methods_1","title":"Statement Access Methods","text":"<p>Similar to <code>Statements</code> but returns <code>StitchedStatement</code> objects:</p>"},{"location":"api/xbrl/#balance_sheet_1","title":"balance_sheet()","text":"<pre><code>def balance_sheet(self) -&gt; Optional[StitchedStatement]\n</code></pre>"},{"location":"api/xbrl/#income_statement_1","title":"income_statement()","text":"<pre><code>def income_statement(self) -&gt; Optional[StitchedStatement]\n</code></pre>"},{"location":"api/xbrl/#cash_flow_statement_1","title":"cash_flow_statement()","text":"<pre><code>def cash_flow_statement(self) -&gt; Optional[StitchedStatement]\n</code></pre> <p>Example:</p> <pre><code># Multi-period analysis\nstitched_statements = xbrls.statements\nincome_stmt = stitched_statements.income_statement()\n\n# Shows multiple years of data\nprint(income_stmt.render())\n</code></pre>"},{"location":"api/xbrl/#stitchedstatement","title":"StitchedStatement","text":"<p>Individual statement showing multi-period data with comparative analysis.</p> <pre><code>class StitchedStatement:\n    \"\"\"Individual stitched statement showing multi-period data.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#analysis-methods_1","title":"Analysis Methods","text":""},{"location":"api/xbrl/#render_1","title":"render()","text":"<pre><code>def render(self, **kwargs) -&gt; RenderedStatement\n</code></pre> <p>Render multi-period statement with rich formatting.</p>"},{"location":"api/xbrl/#to_dataframe_3","title":"to_dataframe()","text":"<pre><code>def to_dataframe(self) -&gt; pd.DataFrame\n</code></pre> <p>Convert to DataFrame with periods as columns.</p>"},{"location":"api/xbrl/#standardization","title":"Standardization","text":""},{"location":"api/xbrl/#standardconcept","title":"StandardConcept","text":"<p>Represents a standardized concept that normalizes company-specific terminology.</p> <pre><code>class StandardConcept:\n    \"\"\"Standardized concept representation.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#properties_1","title":"Properties","text":""},{"location":"api/xbrl/#name","title":"name","text":"<pre><code>@property\ndef name(self) -&gt; str\n</code></pre> <p>Standardized concept name.</p>"},{"location":"api/xbrl/#label","title":"label","text":"<pre><code>@property\ndef label(self) -&gt; str\n</code></pre> <p>Standardized human-readable label.</p> <p>Example:</p> <pre><code># Standardization is applied automatically in statements\nstatement = xbrl.statements.income_statement()\ndf = statement.to_dataframe()\n\n# Check for standardized vs original labels\nprint(df[['label', 'original_label']].head())\n</code></pre>"},{"location":"api/xbrl/#rendering","title":"Rendering","text":""},{"location":"api/xbrl/#renderedstatement","title":"RenderedStatement","text":"<p>Formatted statement output with rich console display capabilities.</p> <pre><code>class RenderedStatement:\n    \"\"\"Rich formatted statement output.\"\"\"\n</code></pre>"},{"location":"api/xbrl/#display-methods","title":"Display Methods","text":""},{"location":"api/xbrl/#str","title":"str()","text":"<pre><code>def __str__(self) -&gt; str\n</code></pre> <p>Plain text representation of the statement.</p>"},{"location":"api/xbrl/#rich","title":"rich()","text":"<pre><code>def __rich__(self) -&gt; RichRenderable\n</code></pre> <p>Rich console representation with formatting.</p> <p>Example:</p> <pre><code># Rich rendering in console\nrendered = xbrl.render_statement(\"BalanceSheet\")\nprint(rendered)  # Displays with rich formatting\n\n# Plain text for export\ntext_output = str(rendered)\n</code></pre>"},{"location":"api/xbrl/#utility-functions","title":"Utility Functions","text":""},{"location":"api/xbrl/#stitch_statements","title":"stitch_statements()","text":"<pre><code>def stitch_statements(statements: List[Statement]) -&gt; StitchedStatement\n</code></pre> <p>Combine multiple statements into a stitched statement.</p> <p>Parameters: - <code>statements</code>: List of Statement objects to combine</p> <p>Returns: <code>StitchedStatement</code> object</p>"},{"location":"api/xbrl/#render_stitched_statement","title":"render_stitched_statement()","text":"<pre><code>def render_stitched_statement(stitched_statement: StitchedStatement, **kwargs) -&gt; RenderedStatement\n</code></pre> <p>Render a stitched statement with formatting.</p> <p>Parameters: - <code>stitched_statement</code>: StitchedStatement to render - <code>**kwargs</code>: Rendering options</p> <p>Returns: <code>RenderedStatement</code> object</p>"},{"location":"api/xbrl/#to_pandas_1","title":"to_pandas()","text":"<pre><code>def to_pandas(obj: Union[XBRL, Statement, FactsView]) -&gt; pd.DataFrame\n</code></pre> <p>Convert various XBRL objects to pandas DataFrame.</p> <p>Parameters: - <code>obj</code>: Object to convert (XBRL, Statement, or FactsView)</p> <p>Returns: DataFrame representation</p>"},{"location":"api/xbrl/#advanced-usage-examples","title":"Advanced Usage Examples","text":""},{"location":"api/xbrl/#multi-period-financial-analysis","title":"Multi-Period Financial Analysis","text":"<pre><code>from edgar import Company\nfrom edgar.xbrl import XBRLS\n\n# Get multiple years of data\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=\"10-K\").head(3)\nxbrls = XBRLS.from_filings(filings)\n\n# Analyze income statement trends\nincome_stmt = xbrls.statements.income_statement()\nrevenue_trend = income_stmt.get_trend(\"Revenue\")\nrevenue_growth = income_stmt.calculate_growth(\"Revenue\")\n\nprint(f\"Revenue Growth: {revenue_growth.iloc[-1]:.2%}\")\n</code></pre>"},{"location":"api/xbrl/#complex-fact-querying","title":"Complex Fact Querying","text":"<pre><code>from edgar import Company\nfrom edgar.xbrl import XBRL\n\ncompany = Company(\"MSFT\")\nfiling = company.latest(\"10-K\")\nxbrl = XBRL.from_filing(filing)\n\n# Complex query with multiple filters\nhigh_value_revenue = (xbrl.facts\n                     .by_concept(\"Revenue\")\n                     .by_value(min_value=50000000000)  # $50B+\n                     .by_period(start_date=\"2023-01-01\")\n                     .to_dataframe())\n\n# Pivot analysis\npivot_df = xbrl.facts.pivot_by_period([\n    \"Revenue\", \n    \"NetIncomeLoss\", \n    \"OperatingIncomeLoss\"\n])\n</code></pre>"},{"location":"api/xbrl/#statement-comparison","title":"Statement Comparison","text":"<pre><code># Compare statements across different companies\ncompanies = [\"AAPL\", \"MSFT\", \"GOOGL\"]\nstatements = []\n\nfor ticker in companies:\n    company = Company(ticker)\n    filing = company.latest(\"10-K\")\n    xbrl = XBRL.from_filing(filing)\n    if xbrl.statements.income_statement():\n        statements.append(xbrl.statements.income_statement())\n\n# Create comparison DataFrame\ncomparison_data = []\nfor stmt in statements:\n    df = stmt.to_dataframe()\n    comparison_data.append(df)\n\n# Analyze key metrics across companies\nkey_metrics = [\"Revenue\", \"NetIncomeLoss\", \"OperatingIncomeLoss\"]\nfor metric in key_metrics:\n    print(f\"\\n{metric} Comparison:\")\n    for i, stmt in enumerate(statements):\n        value = stmt.get_concept_value(metric)\n        if value:\n            print(f\"  {companies[i]}: ${value/1e9:.1f}B\")\n</code></pre>"},{"location":"api/xbrl/#import-reference","title":"Import Reference","text":"<pre><code># Core classes\nfrom edgar.xbrl import XBRL, XBRLS\n\n# Statement classes\nfrom edgar.xbrl import Statements, Statement\nfrom edgar.xbrl import StitchedStatements, StitchedStatement\n\n# Facts querying\nfrom edgar.xbrl import FactsView, FactQuery\nfrom edgar.xbrl import StitchedFactsView, StitchedFactQuery\n\n# Standardization and rendering\nfrom edgar.xbrl import StandardConcept, RenderedStatement\n\n# Utility functions\nfrom edgar.xbrl import stitch_statements, render_stitched_statement, to_pandas\n</code></pre>"},{"location":"api/xbrl/#error-handling","title":"Error Handling","text":"<pre><code>from edgar.xbrl import XBRL, XBRLFilingWithNoXbrlData\n\ntry:\n    xbrl = XBRL.from_filing(filing)\nexcept XBRLFilingWithNoXbrlData:\n    print(\"Filing does not contain XBRL data\")\nexcept Exception as e:\n    print(f\"Error parsing XBRL: {e}\")\n\n# Check for statement availability\nif xbrl.statements.income_statement():\n    income_stmt = xbrl.statements.income_statement()\n    df = income_stmt.to_dataframe()\nelse:\n    print(\"Income statement not found\")\n</code></pre>"},{"location":"api/xbrl/#xbrl-value-transformations-issue-463","title":"XBRL Value Transformations (Issue #463)","text":"<p>EdgarTools provides a two-layer system for XBRL value handling:</p>"},{"location":"api/xbrl/#value-layers","title":"Value Layers","text":"<ol> <li>Raw Values (default): Values exactly as reported in the XBRL instance document</li> <li>Matches SEC CompanyFacts API</li> <li>Preserves original data for analysis</li> <li> <p>No transformations applied</p> </li> <li> <p>Presentation Values (<code>presentation=True</code>): Values transformed to match SEC filing HTML display</p> </li> <li>Applies <code>preferred_sign</code> transformations from presentation linkbase</li> <li>Cash Flow outflows shown as negative when appropriate</li> <li>Matches how values appear in the official 10-K/10-Q HTML</li> </ol>"},{"location":"api/xbrl/#metadata-columns","title":"Metadata Columns","text":"<p>All statement DataFrames include XBRL metadata columns:</p> <ul> <li><code>balance</code>: Debit or credit classification from schema (accounting semantics)</li> <li><code>weight</code>: Calculation weight from calculation linkbase (+1.0 or -1.0)</li> <li><code>preferred_sign</code>: Presentation hint from presentation linkbase (+1 or -1)</li> </ul> <p>These columns provide transparency about XBRL semantics and enable custom transformations.</p>"},{"location":"api/xbrl/#usage-examples","title":"Usage Examples","text":"<pre><code># Get raw values (default)\nxbrl = filing.xbrl()\nstatement = xbrl.statements.cash_flow_statement()\ndf_raw = statement.to_dataframe()\n\n# PaymentsOfDividends appears as positive (raw XML value)\ndividends = df_raw[df_raw['concept'].str.contains('PaymentsOfDividends')]\nprint(dividends[['concept', 'balance', 'preferred_sign', '2024-09-30']])\n# Output: concept=PaymentsOfDividends, balance=credit, preferred_sign=-1, value=12345000000 (positive)\n\n# Get presentation values (matches SEC HTML)\ndf_presentation = statement.to_dataframe(presentation=True)\ndividends_pres = df_presentation[df_presentation['concept'].str.contains('PaymentsOfDividends')]\nprint(dividends_pres[['concept', '2024-09-30']])\n# Output: value=-12345000000 (negative, matches HTML display with parentheses)\n</code></pre>"},{"location":"api/xbrl/#when-to-use-each-mode","title":"When to Use Each Mode","text":"<p>Use Raw Values (default): - Cross-company financial analysis - Data science and machine learning - Comparison with SEC CompanyFacts API - When you need unmodified reported values</p> <p>Use Presentation Values (<code>presentation=True</code>): - Matching SEC filing HTML display - Creating investor-facing reports - Replicating official financial statement appearance - When users expect \"traditional\" financial statement signs</p>"},{"location":"api/xbrl/#technical-notes","title":"Technical Notes","text":"<ul> <li>Raw values are consistent across companies: Testing confirmed SEC instance data uses consistent signs</li> <li>Metadata always included: All transformations can be recreated using metadata columns</li> <li>No data loss: Raw values always preserved, transformations are reversible</li> </ul>"},{"location":"api/xbrl/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use specific queries - Filter facts early to reduce processing time</li> <li>Cache XBRL objects - Parsing is expensive, reuse when possible</li> <li>Limit statement rendering - Use <code>max_rows</code> parameter for large statements</li> <li>Batch processing - Use <code>XBRLS</code> for efficient multi-period analysis</li> </ol>"},{"location":"api/xbrl/#see-also","title":"See Also","text":"<ul> <li>Company API Reference - Working with company data</li> <li>Filing API Reference - Working with individual filings</li> <li>Extract Financial Statements Guide - Practical examples</li> <li>Working with Filing Guide - Filing workflows</li> </ul>"},{"location":"concepts/data-objects/","title":"Understanding Data Objects","text":""},{"location":"concepts/data-objects/#introduction","title":"Introduction","text":"<p>One of the most powerful features of edgartools is its Data Objects system. This system transforms raw SEC filing data into structured, easy-to-use Python objects that expose filing-specific properties and methods. Instead of dealing with complex HTML, XML, or XBRL parsing yourself, Data Objects handle all the heavy lifting, allowing you to focus on analysis rather than data extraction.</p> <p>This guide explains the conceptual framework behind Data Objects, how they work under the hood, and how to leverage them effectively in your SEC data analysis workflows.</p>"},{"location":"concepts/data-objects/#the-problem-data-objects-solve","title":"The Problem Data Objects Solve","text":"<p>SEC filings are notoriously complex documents:</p> <ul> <li>They contain a mix of structured and unstructured data</li> <li>They use different formats (HTML, XML, XBRL) depending on filing type and date</li> <li>Their structure evolves over time as SEC requirements change</li> <li>They often contain inconsistencies in formatting and organization</li> <li>They require domain knowledge to interpret correctly</li> </ul> <p>Without Data Objects, working with SEC filings would require:</p> <ol> <li>Downloading raw filing documents</li> <li>Writing custom parsers for each filing type</li> <li>Handling edge cases and inconsistencies</li> <li>Extracting and organizing the data manually</li> <li>Converting data into usable formats for analysis</li> </ol> <p>Data Objects eliminate these challenges by providing a consistent, intuitive interface to SEC filing data, regardless of the underlying format or structure.</p>"},{"location":"concepts/data-objects/#the-data-objects-architecture","title":"The Data Objects Architecture","text":""},{"location":"concepts/data-objects/#core-principles","title":"Core Principles","text":"<p>The Data Objects system is built on several key principles:</p> <ol> <li>Type-Specific Interfaces: Each filing type has its own specialized interface that exposes only the relevant properties and methods.</li> <li>Lazy Parsing: Content is parsed on-demand to minimize memory usage and processing time.</li> <li>Consistent Access Patterns: Similar data is accessed through consistent patterns across different filing types.</li> <li>Rich Metadata: Each object includes metadata about the filing, such as dates, filer information, and document structure.</li> <li>Transformation Capabilities: Data can be easily transformed into formats like pandas DataFrames for analysis.</li> </ol>"},{"location":"concepts/data-objects/#object-hierarchy","title":"Object Hierarchy","text":"<p>Data Objects follow a hierarchical structure:</p> <pre><code>Filing (base class)\n\u251c\u2500\u2500 CompanyFiling\n\u2502   \u251c\u2500\u2500 TenK (10-K Annual Report)\n\u2502   \u251c\u2500\u2500 TenQ (10-Q Quarterly Report)\n\u2502   \u2514\u2500\u2500 EightK (8-K Current Report)\n\u251c\u2500\u2500 OwnershipFiling\n\u2502   \u251c\u2500\u2500 Form3 (Initial Ownership)\n\u2502   \u251c\u2500\u2500 Form4 (Changes in Ownership)\n\u2502   \u2514\u2500\u2500 Form5 (Annual Ownership Summary)\n\u251c\u2500\u2500 InvestmentFiling\n\u2502   \u2514\u2500\u2500 ThirteenF (13F Holdings Report)\n\u2514\u2500\u2500 Other specialized filing types\n</code></pre> <p>Each object in this hierarchy inherits common functionality while adding specialized features for its filing type.</p>"},{"location":"concepts/data-objects/#how-data-objects-work","title":"How Data Objects Work","text":""},{"location":"concepts/data-objects/#the-creation-process","title":"The Creation Process","text":"<p>When you call the <code>.obj()</code> method on a Filing object, the following process occurs:</p> <ol> <li>Filing Type Detection: The system identifies the filing type based on the form type and content.</li> <li>Parser Selection: The appropriate parser is selected for that filing type.</li> <li>Object Instantiation: A new Data Object of the correct type is created.</li> <li>Initial Parsing: Basic metadata is parsed immediately.</li> <li>Lazy Loading Setup: More complex content is set up for on-demand parsing.</li> </ol>"},{"location":"concepts/data-objects/#parsing-strategies","title":"Parsing Strategies","text":"<p>Data Objects use different parsing strategies depending on the filing type:</p> <ul> <li>HTML Parsing: For narrative sections like business descriptions and risk factors</li> <li>XML Parsing: For structured data like ownership transactions and fund holdings</li> <li>XBRL Processing: For financial statements and other tagged financial data</li> <li>Table Extraction: For tabular data embedded in filings</li> <li>Text Processing: For extracting plain text from complex HTML structures</li> </ul> <p>These strategies are applied automatically based on the content being accessed.</p>"},{"location":"concepts/data-objects/#working-with-data-objects","title":"Working with Data Objects","text":""},{"location":"concepts/data-objects/#common-patterns","title":"Common Patterns","text":"<p>Across all Data Objects, you'll find these common patterns:</p> <ol> <li>Property Access: Access filing sections or data through properties (e.g., <code>tenk.risk_factors</code>)</li> <li>Method Calls: Perform operations on the data (e.g., <code>form4.get_net_shares_traded()</code>)</li> <li>Dictionary-Like Access: Access specific items by key (e.g., <code>eightk[\"Item 2.01\"]</code>)</li> <li>Iteration: Iterate over collections within the filing (e.g., <code>for holding in thirteen_f.infotable</code>)</li> <li>Conversion: Transform data into other formats (e.g., <code>balance_sheet.to_dataframe()</code>)</li> </ol>"},{"location":"concepts/data-objects/#object-persistence","title":"Object Persistence","text":"<p>Data Objects are designed to be lightweight and don't persist the entire filing content in memory. Instead, they:</p> <ol> <li>Store references to the original filing content</li> <li>Parse specific sections only when accessed</li> <li>Cache parsed results to avoid repeated parsing</li> <li>Release memory when no longer needed</li> </ol> <p>This approach allows you to work with very large filings efficiently.</p>"},{"location":"concepts/data-objects/#advanced-usage-patterns","title":"Advanced Usage Patterns","text":""},{"location":"concepts/data-objects/#combining-multiple-data-objects","title":"Combining Multiple Data Objects","text":"<p>You can combine data from multiple Data Objects for more sophisticated analysis:</p> <pre><code># Compare financial data across quarters\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=[\"10-K\", \"10-Q\"]).head(5)\ndata_objects = [filing.obj() for filing in filings]\n\n# Extract revenue from each filing\nrevenues = []\nfor obj in data_objects:\n    if hasattr(obj, \"income_statement\"):\n        period_end = obj.period_end_date\n        revenue = obj.income_statement.get_value(\"Revenues\")\n        revenues.append((period_end, revenue))\n\n# Sort by date and analyze trend\nrevenues.sort(key=lambda x: x[0])\n</code></pre>"},{"location":"concepts/data-objects/#custom-data-extraction","title":"Custom Data Extraction","text":"<p>You can extend Data Objects with your own extraction logic:</p> <pre><code>def extract_cybersecurity_risks(tenk):\n    \"\"\"Extract cybersecurity-related content from risk factors.\"\"\"\n    if not hasattr(tenk, \"risk_factors\"):\n        return None\n\n    risk_text = tenk.risk_factors\n    cyber_keywords = [\"cyber\", \"hack\", \"breach\", \"data security\", \"privacy\"]\n\n    # Find paragraphs containing cyber keywords\n    paragraphs = risk_text.split(\"\\n\\n\")\n    cyber_paragraphs = [p for p in paragraphs if any(k in p.lower() for k in cyber_keywords)]\n\n    return cyber_paragraphs\n\n# Apply to a 10-K\ntenk = company.latest(\"10-K\").obj()\ncyber_risks = extract_cybersecurity_risks(tenk)\n</code></pre>"},{"location":"concepts/data-objects/#batch-processing","title":"Batch Processing","text":"<p>For processing many filings efficiently:</p> <pre><code>\n# Process all 8-Ks from the past year\ncompany = Company(\"MSFT\")\nfilings = company.get_filings(form=\"8-K\", start_date=\"2024-01-01\")\n\n# Extract all press releases\nall_press_releases = []\nfor filing in filings:\n    try:\n        eightk = filing.obj()\n        if eightk.has_press_release:\n            for pr in eightk.press_releases:\n                all_press_releases.append({\n                    \"date\": eightk.date_of_report,\n                    \"title\": pr.title,\n                    \"content\": pr.content\n                })\n    except Exception as e:\n        print(f\"Error processing filing {filing.accession_number}: {e}\")\n\nprint(f\"Found {len(all_press_releases)} press releases\")\n</code></pre>"},{"location":"concepts/data-objects/#common-challenges-and-solutions","title":"Common Challenges and Solutions","text":""},{"location":"concepts/data-objects/#challenge-handling-missing-data","title":"Challenge: Handling Missing Data","text":"<p>Not all filings contain all expected sections or data points:</p> <pre><code># Safe access pattern\ntenk = filing.obj()\nif hasattr(tenk, \"risk_factors\") and tenk.risk_factors:\n    # Process risk factors\n    pass\nelse:\n    print(\"No risk factors section found\")\n\n# For financial data\ntry:\n    revenue = income_stmt.get_value(\"Revenues\")\nexcept ValueError:\n    revenue = income_stmt.get_value(\"RevenueFromContractWithCustomerExcludingAssessedTax\")\nexcept:\n    revenue = None\n</code></pre>"},{"location":"concepts/data-objects/#challenge-handling-format-changes","title":"Challenge: Handling Format Changes","text":"<p>SEC filing formats evolve over time:</p> <pre><code># Version-aware code\ntenk = filing.obj()\nfiling_year = tenk.period_end_date.year\n\nif filing_year &gt;= 2021:\n    # Use newer XBRL taxonomy concepts\n    revenue = income_stmt.get_value(\"RevenueFromContractWithCustomerExcludingAssessedTax\")\nelse:\n    # Use older concepts\n    revenue = income_stmt.get_value(\"Revenues\")\n</code></pre>"},{"location":"concepts/data-objects/#challenge-processing-large-filings","title":"Challenge: Processing Large Filings","text":"<p>Some filings (especially 10-Ks) can be very large:</p> <pre><code># Memory-efficient processing\ntenk = filing.obj()\n\n# Process one section at a time\nsections = [\"business\", \"risk_factors\", \"management_discussion\"]\nfor section_name in sections:\n    if hasattr(tenk, section_name):\n        section = getattr(tenk, section_name)\n        # Process section\n        # ...\n        # Explicitly delete to free memory\n        del section\n</code></pre>"},{"location":"concepts/data-objects/#best-practices","title":"Best Practices","text":""},{"location":"concepts/data-objects/#1-use-the-right-object-for-the-task","title":"1. Use the Right Object for the Task","text":"<p>Choose the most specific Data Object for your needs:</p> <ul> <li>Use <code>TenK</code>/<code>TenQ</code> for financial statement analysis</li> <li>Use <code>EightK</code> for event monitoring</li> <li>Use <code>Form4</code> for insider trading analysis</li> <li>Use <code>ThirteenF</code> for fund holdings analysis</li> </ul>"},{"location":"concepts/data-objects/#2-leverage-built-in-methods","title":"2. Leverage Built-in Methods","text":"<p>Data Objects include many helpful methods that save you from writing custom code:</p> <pre><code># Instead of parsing manually:\nform4 = filing.obj()\nnet_shares = form4.get_net_shares_traded()  # Built-in method\n\n# Instead of calculating manually:\nthirteen_f = filing.obj()\ntop_10 = thirteen_f.get_top_holdings(10)  # Built-in method\n</code></pre>"},{"location":"concepts/data-objects/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<p>SEC filings can have inconsistencies that cause parsing errors:</p> <pre><code>try:\n    data_obj = filing.obj()\n    # Work with the object\nexcept Exception as e:\n    print(f\"Error parsing filing {filing.accession_number}: {e}\")\n    # Fall back to simpler access methods\n    text = filing.text\n</code></pre>"},{"location":"concepts/data-objects/#4-use-local-storage","title":"4. Use Local Storage","text":"<ul> <li>Data Objects parse filing content on-demand</li> <li>Large filings (like 10-Ks) may take a few seconds to parse</li> <li>Consider using local storage for batch processing</li> </ul>"},{"location":"concepts/data-objects/#conclusion","title":"Conclusion","text":"<p>Data Objects are the heart of edgartools' power and usability. By abstracting away the complexities of SEC filing formats and structures, they allow you to focus on analysis rather than data extraction. Understanding how Data Objects work and how to use them effectively will help you build more powerful, efficient, and maintainable SEC data analysis workflows.</p> <p>Whether you're analyzing financial statements, tracking insider trading, or researching investment funds, Data Objects provide a consistent, intuitive interface that makes working with SEC data a breeze.</p>"},{"location":"concepts/data-objects/#additional-resources","title":"Additional Resources","text":"<ul> <li>Working with Financial Statements</li> <li>Analyzing Insider Trading</li> </ul>"},{"location":"concepts/sec-filings/","title":"Understanding SEC Filings","text":""},{"location":"concepts/sec-filings/#introduction","title":"Introduction","text":"<p>The U.S. Securities and Exchange Commission (SEC) requires public companies, investment funds, and certain individuals to submit various regulatory filings. These documents provide transparency into financial performance, significant events, insider activities, and investment decisions. The SEC's Electronic Data Gathering, Analysis, and Retrieval system (EDGAR) makes these filings publicly available.</p> <p>This guide explains the key SEC filing types, their purposes, and how to access and analyze them using the <code>edgartools</code> library.</p>"},{"location":"concepts/sec-filings/#why-sec-filings-matter","title":"Why SEC Filings Matter","text":"<p>SEC filings are the most authoritative source of company information available to the public. Unlike press releases, investor presentations, or news articles, SEC filings:</p> <ul> <li>Are legally required to be accurate and complete</li> <li>Follow standardized formats for consistency</li> <li>Contain detailed financial data and disclosures</li> <li>Are subject to strict liability for false or misleading information</li> <li>Provide a historical record of a company's development</li> </ul>"},{"location":"concepts/sec-filings/#common-sec-filing-types","title":"Common SEC Filing Types","text":""},{"location":"concepts/sec-filings/#company-reporting-forms","title":"Company Reporting Forms","text":"Form Description Frequency Key Information 10-K Annual report Annual Comprehensive financial statements, business description, risk factors, management discussion 10-Q Quarterly report Quarterly Interim financial statements, updates since last 10-K 8-K Current report As needed Material events (acquisitions, executive changes, bankruptcy) S-1 Registration statement Before IPO Business model, financials, risk factors, use of proceeds DEF 14A Proxy statement Annual Executive compensation, board members, shareholder proposals"},{"location":"concepts/sec-filings/#ownership-and-investment-forms","title":"Ownership and Investment Forms","text":"Form Description Filed By Key Information Form 3 Initial ownership Insiders Initial positions when becoming an insider Form 4 Changes in ownership Insiders Purchases, sales, and other transactions Form 5 Annual ownership Insiders Summary of transactions for the year 13F Holdings report Investment funds Portfolio holdings of investment managers 13D/G Beneficial ownership 5%+ shareholders Significant ownership positions and intentions"},{"location":"concepts/sec-filings/#anatomy-of-key-filings","title":"Anatomy of Key Filings","text":""},{"location":"concepts/sec-filings/#10-k-annual-report","title":"10-K Annual Report","text":"<p>The 10-K is the most comprehensive filing and typically contains:</p> <ol> <li>Business Overview (Part I, Item 1)</li> <li>Company operations, products/services, markets</li> <li>Revenue breakdown by segment</li> <li> <p>Competitive landscape</p> </li> <li> <p>Risk Factors (Part I, Item 1A)</p> </li> <li>Detailed disclosure of business risks</li> <li> <p>Industry, operational, and financial risks</p> </li> <li> <p>Management's Discussion &amp; Analysis (Part II, Item 7)</p> </li> <li>Analysis of financial condition and results</li> <li>Liquidity and capital resources</li> <li> <p>Critical accounting policies</p> </li> <li> <p>Financial Statements (Part II, Item 8)</p> </li> <li>Balance sheet</li> <li>Income statement</li> <li>Cash flow statement</li> <li>Statement of shareholders' equity</li> <li> <p>Notes to financial statements</p> </li> <li> <p>Controls and Procedures (Part II, Item 9)</p> </li> <li>Disclosure controls</li> <li>Internal control over financial reporting</li> </ol>"},{"location":"concepts/sec-filings/#10-q-quarterly-report","title":"10-Q Quarterly Report","text":"<p>The 10-Q is a condensed version of the 10-K filed quarterly, containing:</p> <ul> <li>Unaudited financial statements</li> <li>Management's discussion of results</li> <li>Updates on risk factors</li> <li>Disclosure of material events</li> </ul>"},{"location":"concepts/sec-filings/#8-k-current-report","title":"8-K Current Report","text":"<p>The 8-K reports significant events that occur between 10-K and 10-Q filings:</p> <ul> <li>Item 1.01: Entry into a Material Agreement</li> <li>Item 2.01: Completion of Acquisition or Disposition</li> <li>Item 5.02: Departure/Election of Directors or Officers</li> <li>Item 7.01: Regulation FD Disclosure</li> <li>Item 8.01: Other Events</li> </ul>"},{"location":"concepts/sec-filings/#form-4-insider-transactions","title":"Form 4 (Insider Transactions)","text":"<p>Form 4 discloses transactions by company insiders (directors, officers, 10%+ shareholders):</p> <ul> <li>Transaction date and type (purchase, sale, grant, exercise)</li> <li>Number of securities involved</li> <li>Price per share</li> <li>Resulting ownership after transaction</li> </ul>"},{"location":"concepts/sec-filings/#13f-investment-fund-holdings","title":"13F (Investment Fund Holdings)","text":"<p>13F reports show investment portfolios of funds managing over $100 million:</p> <ul> <li>Securities held at quarter-end</li> <li>Number of shares</li> <li>Market value</li> <li>Investment discretion</li> </ul>"},{"location":"concepts/sec-filings/#working-with-sec-filings-in-edgartools","title":"Working with SEC Filings in edgartools","text":""},{"location":"concepts/sec-filings/#accessing-filings","title":"Accessing Filings","text":"<pre><code>from edgar import Company, Filings\n\n# Get all filings for a specific company\napple = Company(\"AAPL\")\nfilings = apple.get_filings()\n\n# Filter by form type\nannual_reports = filings.filter(form=\"10-K\")\nquarterly_reports = filings.filter(form=\"10-Q\")\ncurrent_reports = filings.filter(form=\"8-K\")\n\n# Get the most recent annual report\nlatest_10k = annual_reports.latest()\n\n# Search across multiple companies\ntech_filings = Filings.search(\n    companies=[\"AAPL\", \"MSFT\", \"GOOGL\"],\n    form=\"8-K\",\n    start_date=\"2023-01-01\",\n    end_date=\"2023-12-31\"\n)\n</code></pre>"},{"location":"concepts/sec-filings/#extracting-financial-data","title":"Extracting Financial Data","text":"<pre><code># Get financial statements from a 10-K\nfiling = annual_reports.latest()\nfinancials = filing.get_financials()\n\n# Access specific statements\nbalance_sheet = financials.get_balance_sheet()\nincome_stmt = financials.get_income_statement()\ncash_flow = financials.get_cash_flow_statement()\n\n# Query specific financial items\nrevenue = income_stmt.get_value(\"Revenues\")\nnet_income = income_stmt.get_value(\"NetIncomeLoss\")\ntotal_assets = balance_sheet.get_value(\"Assets\")\n</code></pre>"},{"location":"concepts/sec-filings/#analyzing-insider-trading","title":"Analyzing Insider Trading","text":"<pre><code>from edgar import Company\n\n# Get insider transactions\ntesla = Company(\"TSLA\")\ninsider_filings = tesla.get_insider_transactions(start_date=\"2023-01-01\")\n\n# Analyze transactions by insider\nfor filing in insider_filings:\n    print(f\"Insider: {filing.reporting_owner}\")\n    print(f\"Transaction: {filing.transaction_type}\")\n    print(f\"Shares: {filing.shares}\")\n    print(f\"Value: ${filing.value:,.2f}\")\n    print(f\"Date: {filing.transaction_date}\")\n</code></pre>"},{"location":"concepts/sec-filings/#researching-investment-funds","title":"Researching Investment Funds","text":"<pre><code>from edgar import Fund\n\n# Get fund holdings\nblackrock = Fund(\"BlackRock\")\nholdings = blackrock.get_holdings()\n\n# Analyze portfolio\nfor holding in holdings.top(10):\n    print(f\"Company: {holding.company_name}\")\n    print(f\"Ticker: {holding.ticker}\")\n    print(f\"Shares: {holding.shares:,}\")\n    print(f\"Value: ${holding.value:,.2f}\")\n    print(f\"% of Portfolio: {holding.portfolio_percent:.2f}%\")\n</code></pre>"},{"location":"concepts/sec-filings/#best-practices-for-working-with-sec-filings","title":"Best Practices for Working with SEC Filings","text":""},{"location":"concepts/sec-filings/#1-understand-filing-timelines","title":"1. Understand Filing Timelines","text":"<ul> <li>10-K: Due 60-90 days after fiscal year-end (depending on company size)</li> <li>10-Q: Due 40-45 days after quarter-end</li> <li>8-K: Due within 4 business days of the event</li> <li>Form 4: Due within 2 business days of the transaction</li> <li>13F: Due within 45 days of quarter-end</li> </ul>"},{"location":"concepts/sec-filings/#2-be-aware-of-filing-amendments","title":"2. Be Aware of Filing Amendments","text":"<p>Amendments are indicated with a suffix: - 10-K/A, 10-Q/A, 8-K/A, etc.</p> <pre><code># Get original and amended filings\nfilings = company.get_filings(form=\"10-K\")\namendments = filings.filter(form=\"10-K/A\")\n</code></pre>"},{"location":"concepts/sec-filings/#3-handle-historical-data-carefully","title":"3. Handle Historical Data Carefully","text":"<ul> <li>Financial restatements can change historical data</li> <li>Company structures change over time (mergers, spin-offs)</li> <li>Accounting standards evolve</li> </ul>"},{"location":"concepts/sec-filings/#4-respect-sec-access-guidelines","title":"4. Respect SEC Access Guidelines","text":"<p>The SEC has rate limits for EDGAR access: - Identify yourself properly with <code>edgar.set_identity()</code> - Implement appropriate delays between requests - Consider using local caching for repeated access</p> <pre><code>from edgar import set_identity, enable_cache\n\n# Set your identity for SEC access\nset_identity(\"your.email@example.com\")\n\n</code></pre>"},{"location":"concepts/sec-filings/#conclusion","title":"Conclusion","text":"<p>SEC filings provide a wealth of structured and unstructured data for financial analysis, investment research, and regulatory compliance. With <code>edgartools</code>, you can efficiently access, parse, and analyze these filings to extract valuable insights.</p> <p>Understanding the different filing types, their purposes, and how to work with them programmatically allows you to build sophisticated financial analysis workflows and make more informed investment decisions.</p>"},{"location":"concepts/sec-filings/#additional-resources","title":"Additional Resources","text":"<ul> <li>SEC EDGAR Website</li> <li>SEC Filing Deadlines</li> <li>EDGAR Filing Codes</li> </ul>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/","title":"Campaign Lifecycle Tracking - Gap Analysis","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#overview","title":"Overview","text":"<p>This document analyzes the current implementation against the research goals defined in <code>crowdfunding_research_goals.md</code> Section 1: Campaign Lifecycle Tracking.</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#implementation-status-excellent","title":"Implementation Status: \u2705 EXCELLENT","text":"<p>The current implementation (<code>offering_lifecycle.py</code> + <code>campaign.py</code>) successfully addresses ALL core success criteria from the research goals.</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#success-criteria-assessment","title":"Success Criteria Assessment","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#can-retrieve-all-filings-for-a-single-campaign","title":"\u2705 Can retrieve all filings for a single campaign","text":"<p>Status: IMPLEMENTED</p> <p>Implementation:</p> <pre><code>offering = formc.get_offering()\noffering_filings = offering.all_filings  # All lifecycle filings\n</code></pre> <p>Evidence: - <code>Offering</code> class wraps all related filings using issuer file number (020-XXXXX) - Properties: <code>initial_offering</code>, <code>amendments</code>, <code>updates</code>, <code>annual_reports</code>, <code>termination</code> - All stages accessible through filtered properties</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#can-identify-the-current-status-of-a-campaign","title":"\u2705 Can identify the current status of a campaign","text":"<p>Status: IMPLEMENTED</p> <p>Implementation:</p> <pre><code>offering.status          # 'active', 'closed', 'terminated'\noffering.is_active       # Boolean status\noffering.is_terminated   # Check termination\n</code></pre> <p>Evidence: - Status derived from presence of termination filing (C-TR) - Boolean helpers for quick checks - Smart status calculation logic in <code>campaign.py:177-187</code></p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#can-track-progression-through-lifecycle-stages","title":"\u2705 Can track progression through lifecycle stages","text":"<p>Status: IMPLEMENTED</p> <p>Implementation:</p> <pre><code># Access each lifecycle stage\noffering.initial_offering    # Form C\noffering.amendments          # Form C/A\noffering.updates             # Form C-U\noffering.annual_reports      # Form C-AR\noffering.termination         # Form C-TR\n</code></pre> <p>Evidence: - Each stage has dedicated property - Returns filtered EntityFilings for that stage - Full lifecycle visibility from any entry point</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#can-access-data-from-each-stage-appropriately","title":"\u2705 Can access data from each stage appropriately","text":"<p>Status: IMPLEMENTED</p> <p>Implementation:</p> <pre><code># Parse any filing to structured FormC\nformc = filing.obj()\n\n# Access offering information (C, C-U)\nformc.offering_information.target_offering_amount\nformc.offering_information.price_per_security\n\n# Access annual report data (C-AR)\nformc.annual_report_disclosure.total_assets\nformc.annual_report_disclosure.revenue\n</code></pre> <p>Evidence: - FormC parser handles all lifecycle forms (C, C/A, C-U, C-AR, C-TR) - Convenience properties flatten nested access - Type conversion handled automatically</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#have-documented-helper-methodsclasses","title":"\u2705 Have documented helper methods/classes","text":"<p>Status: IMPLEMENTED + DOCUMENTED</p> <p>Classes: - \u2705 <code>Offering</code> (aka <code>Campaign</code>) - Aggregates related filings - \u2705 <code>IssuerCompany</code> - Crowdfunding-specific entity wrapper - \u2705 <code>FormC</code> - Structured data parser</p> <p>Helper Methods: - \u2705 <code>formc.get_offering()</code> - Create Offering from any filing - \u2705 <code>formc.get_issuer_company()</code> - Get issuer entity - \u2705 <code>issuer.get_offerings()</code> - All offerings for issuer - \u2705 <code>offering.all_filings</code> - All filings for this offering</p> <p>Documentation: - \u2705 <code>offering_lifecycle.py</code> - Annotated workflow example - \u2705 <code>FILE_NUMBER_DISCOVERY.md</code> - File number system explained - \u2705 <code>ai_native_api_patterns.md</code> - API design patterns</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#api-gaps-from-research-goals-resolution-status","title":"API Gaps from Research Goals - Resolution Status","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#no-campaign-wrapper-class-to-aggregate-related-filings","title":"\u274c \"No Campaign wrapper class to aggregate related filings\"","text":"<p>Resolution: \u2705 RESOLVED - <code>Offering</code> class provides this</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#no-helper-methods-to-identify-campaign-status","title":"\u274c \"No helper methods to identify campaign status\"","text":"<p>Resolution: \u2705 RESOLVED - <code>offering.status</code>, <code>offering.is_active</code>, <code>offering.is_terminated</code></p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#missing-progress_update-field-in-c-u-forms","title":"\u274c \"Missing progress_update field in C-U forms\"","text":"<p>Resolution: \u26a0\ufe0f PARTIAL - Need to verify if C-U XML contains progress data - FormC parser exists for C-U forms - Need research to confirm XML structure for progress updates - May require separate <code>FormCU</code> class if structure differs</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#no-built-in-timeline-visualization","title":"\u274c \"No built-in timeline visualization\"","text":"<p>Resolution: \u26a0\ufe0f DEFERRED - Data access complete, visualization not implemented - All data available: filing dates, stages, status - Could add <code>offering.timeline()</code> method - Rich rendering would be natural fit - Not blocking for API completeness</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#no-methods-like-get_updates-or-get_annual_reports","title":"\u274c \"No methods like get_updates() or get_annual_reports()\"","text":"<p>Resolution: \u2705 RESOLVED - Properties exist: - <code>offering.updates</code> - Get all C-U filings - <code>offering.annual_reports</code> - Get all C-AR filings - <code>offering.amendments</code> - Get all C/A filings</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#remaining-gaps-and-recommendations","title":"Remaining Gaps and Recommendations","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#gap-1-progress-update-data-extraction-research-needed","title":"GAP 1: Progress Update Data Extraction (RESEARCH NEEDED)","text":"<p>Severity: Medium Impact: Cannot track 50%/100% funding milestones</p> <p>Issue: Form C-U XML structure not fully researched - Do C-U forms contain <code>progress_percentage</code> field? - Is <code>amount_raised</code> reported in C-U? - How to distinguish 50% vs 100% updates?</p> <p>Recommendation: 1. Research 5-10 actual Form C-U filings 2. Document XML structure differences from Form C 3. Add C-U specific fields to FormC or create FormCU subclass 4. Add <code>offering.funding_progress</code> property</p> <p>Example Target API:</p> <pre><code>offering.updates[0].obj().progress_percentage  # e.g., 50\noffering.updates[0].obj().amount_raised        # e.g., $250,000\noffering.calculate_percent_funded()            # 83.3%\n</code></pre>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#gap-2-timeline-visualization-nice-to-have","title":"GAP 2: Timeline Visualization (NICE TO HAVE)","text":"<p>Severity: Low Impact: Users must manually construct timelines</p> <p>Issue: No visual representation of lifecycle progression</p> <p>Recommendation:</p> <pre><code># Proposed API\noffering.timeline()  # Rich table showing:\n# Stage | Form | Filing Date | Days Since Previous\n# Initial | C | 2023-01-15 | -\n# Amendment | C/A | 2023-01-22 | 7\n# Update 50% | C-U | 2023-03-01 | 38\n# Update 100% | C-U | 2023-04-15 | 45\n# Annual Report | C-AR | 2024-01-15 | 275\n</code></pre> <p>Implementation: ~50 lines in <code>campaign.py</code>, Rich table rendering</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#gap-3-campaign-metricsanalytics-future","title":"GAP 3: Campaign Metrics/Analytics (FUTURE)","text":"<p>Severity: Low Impact: Users must calculate metrics manually</p> <p>Issue: No built-in success metrics (relates to Research Goal #2: Financial Analysis)</p> <p>Recommendation: Add analytics methods</p> <pre><code>offering.percent_funded()              # vs target\noffering.days_to_funding()             # Time to reach target\noffering.funding_velocity()            # $ per day\noffering.over_subscription_ratio()     # vs maximum\n</code></pre> <p>Note: This overlaps with Research Goal #2, defer until that phase</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#gap-4-multi-campaign-comparison-future","title":"GAP 4: Multi-Campaign Comparison (FUTURE)","text":"<p>Severity: Low Impact: Cannot easily compare offerings by same issuer</p> <p>Issue: <code>IssuerCompany.get_offerings()</code> returns collection but no aggregation</p> <p>Recommendation: Add portfolio analytics</p> <pre><code>issuer = formc.get_issuer_company()\nportfolio = issuer.get_offerings()\n\n# Proposed enhancements\nportfolio.success_rate()               # % reaching target\nportfolio.total_raised()               # Across all campaigns\nportfolio.average_raise()              # Mean per campaign\n</code></pre> <p>Note: Defer to post-MVP phase</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#priority-ranking","title":"Priority Ranking","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#p0-critical-none","title":"P0 (Critical): None","text":"<p>All critical functionality is implemented \u2705</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#p1-important","title":"P1 (Important):","text":"<ol> <li>Progress Update Data Extraction - Blocking for Goal #2 (Financial Analysis)</li> <li>Research C-U XML structure</li> <li>Add progress tracking fields</li> <li>Estimated: 4-8 hours</li> </ol>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#p2-nice-to-have","title":"P2 (Nice to Have):","text":"<ol> <li>Timeline Visualization - Quality of life improvement</li> <li>Estimated: 2-3 hours</li> </ol>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#p3-future","title":"P3 (Future):","text":"<ol> <li>Campaign Metrics - Better suited for Goal #2 phase</li> <li>Multi-Campaign Comparison - Defer to analytics phase</li> </ol>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#test-coverage-assessment","title":"Test Coverage Assessment","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#current-test-status-unknown","title":"Current Test Status: \u26a0\ufe0f UNKNOWN","text":"<p>Need to verify tests exist for: - [ ] <code>Offering</code> class initialization - [ ] Lifecycle stage filtering (amendments, updates, etc.) - [ ] Status calculation (active/terminated) - [ ] <code>IssuerCompany.get_offerings()</code> - [ ] File number based aggregation - [ ] Cross-filing navigation</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#recommended-test-additions","title":"Recommended Test Additions:","text":"<pre><code># tests/offerings/test_campaign_lifecycle.py\ndef test_offering_tracks_all_lifecycle_stages():\n    \"\"\"Test that Offering aggregates C, C/A, C-U, C-AR, C-TR\"\"\"\n\ndef test_offering_status_calculation():\n    \"\"\"Test status is 'active' vs 'terminated' based on C-TR\"\"\"\n\ndef test_issuer_multiple_offerings():\n    \"\"\"Test issuer with multiple distinct campaigns\"\"\"\n\ndef test_offering_from_any_lifecycle_stage():\n    \"\"\"Test can create Offering from C-U or C-AR, not just C\"\"\"\n</code></pre>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#conclusion","title":"Conclusion","text":""},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#overall-assessment-goal-achieved","title":"Overall Assessment: \ud83c\udfaf GOAL ACHIEVED","text":"<p>The current implementation fully addresses the Campaign Lifecycle Tracking research goal. All core success criteria are met: - \u2705 Retrieve all filings for a campaign - \u2705 Identify campaign status - \u2705 Track lifecycle progression - \u2705 Access data from each stage - \u2705 Helper methods/classes documented</p>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#what-works-well","title":"What Works Well:","text":"<ol> <li>File Number Discovery: Solid understanding of 020-XXXXX system</li> <li>Navigation API: Clean <code>formc.get_offering()</code> \u2192 <code>offering.updates</code> flow</li> <li>Status Tracking: Smart derived status from termination filing</li> <li>Documentation: Excellent inline documentation and examples</li> </ol>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#remaining-work","title":"Remaining Work:","text":"<ol> <li>P1: Research Form C-U progress update XML structure (4-8 hours)</li> <li>P2: Add timeline visualization (2-3 hours)</li> <li>Testing: Add comprehensive lifecycle tracking tests</li> </ol>"},{"location":"examples/CAMPAIGN_LIFECYCLE_GAP_ANALYSIS/#ready-for-next-phase","title":"Ready for Next Phase:","text":"<p>\u2705 Yes - Can proceed to Research Goal #2: Financial Analysis</p> <p>The lifecycle tracking foundation is solid. The main gap (C-U progress data) should be addressed during the Financial Analysis phase since it relates to funding metrics.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/","title":"Form C File Number Discovery - Critical Implementation Detail","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#the-problem","title":"The Problem","text":"<p>When implementing campaign lifecycle tracking for crowdfunding filings (Form C variants), we discovered that there are TWO different file numbers associated with each filing:</p> <ol> <li>Issuer's SEC File Number (e.g., <code>'020-36531'</code>)</li> <li>Portal's Commission File Number (e.g., <code>'007-00033'</code>)</li> </ol> <p>This distinction is critical because using the wrong file number will fail to link related filings in a campaign lifecycle.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#file-number-types-explained","title":"File Number Types Explained","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#1-issuers-sec-file-number-offering-identifier","title":"1. Issuer's SEC File Number (Offering Identifier)","text":"<p>Access: <code>filing.file_number</code> (EntityFiling only) Example: <code>'020-36002'</code> (ViiT Health 2025 offering)</p> <ul> <li>Unique to each offering (not just each company)</li> <li>Assigned by SEC when the offering is filed</li> <li>Multiple offerings by same company have different issuer file numbers</li> <li>CRITICAL for offering tracking - links all related filings (C, C/A, C-U, C-AR, C-TR)</li> <li>This is what <code>filing.related_filings()</code> uses to find amendments and updates</li> </ul>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#2-portals-commission-file-number","title":"2. Portal's Commission File Number","text":"<p>Access: <code>filing.obj().campaign_file_number</code> (requires parsing FormC) Example: <code>'007-00033'</code></p> <ul> <li>Unique to each funding portal</li> <li>The portal's SEC commission file number</li> <li>Appears in all filings for a specific campaign</li> <li>Required for campaign lifecycle tracking</li> </ul>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#real-world-examples","title":"Real-World Examples","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#example-1-multiple-offerings-by-same-company-viit-health","title":"Example 1: Multiple Offerings by Same Company (ViiT Health)","text":"<p>ViiT Health has filed 3 separate offerings, each with a unique issuer file number:</p> Offering Filing Date Issuer File # Portal File # Portal Related Filings 2021 offering 2021-10-08 <code>020-28927</code> <code>007-00033</code> Wefunder 1 C only 2023 offering 2023-06-07 <code>020-32444</code> <code>007-00033</code> Wefunder 1 C + 2 C/A 2025 offering 2025-06-11 <code>020-36002</code> <code>007-00033</code> Wefunder 1 C + 3 C/A <p>Key Insight: - All three offerings use Wefunder (same portal file # <code>007-00033</code>) - Each offering has its own issuer file number (020-XXXXX) - <code>filing.related_filings()</code> correctly groups by issuer file number - <code>filing[3].related_filings()</code> returns 4 filings for 2025 offering only - <code>filing[7].related_filings()</code> returns 3 filings for 2023 offering only</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#example-2-multiple-companies-through-same-portal","title":"Example 2: Multiple Companies Through Same Portal","text":"<p>Different companies using StartEngine portal:</p> Company Issuer File # Portal File # Portal Acuitive Technologies <code>020-36427</code> <code>008-70060</code> StartEngine Epilog Imaging <code>020-35641</code> <code>008-70060</code> StartEngine <p>Key Insight: Same portal file number, but different offerings (different issuer file numbers).</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#why-this-matters-for-offering-tracking","title":"Why This Matters for Offering Tracking","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#correct-approach-using-issuer-file-number-single-offering","title":"\u2705 Correct Approach: Using Issuer File Number (Single Offering)","text":"<pre><code># Method 1: Use built-in related_filings() (recommended)\nrelated = filing.related_filings()\n# Result: All filings for THIS offering only (C + C/A + C-U + C-AR + C-TR)\n\n# Method 2: Use Campaign class (recommended)\ncampaign = filing.get_campaign()\nrelated = campaign.all_filings\n# Result: Same - all filings for THIS offering only\n\n# Method 3: Manual query with issuer file number\nissuer_file_number = filing.as_company_filing().file_number  # '020-36002'\nrelated = company.get_filings(file_number=issuer_file_number)\n# Result: All filings for THIS offering only\n</code></pre> <p>Why it works: The issuer file number (020-XXXXX) appears in all Form C filings for a specific offering: - Initial offering (Form C) - Amendments (Form C/A) - Progress updates (Form C-U, C-U/A) - Annual reports (Form C-AR, C-AR/A) - Termination (Form C-TR)</p> <p>Verified: ViiT Health's <code>filing[3].related_filings()</code> returns 4 filings for 2025 offering (020-36002), not the 8 filings across all offerings.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#different-use-case-portal-level-analysis-all-offerings","title":"\u26a0\ufe0f Different Use Case: Portal-Level Analysis (All Offerings)","text":"<pre><code># Get ALL offerings through a portal (not just one offering)\nformc = filing.obj()\nportal_file_number = formc.portal_file_number  # '007-00033'\n\n# Search across ALL offerings using this portal\nall_portal_filings = []\nfor f in company.get_filings(form=['C', 'C/A', 'C-U', 'C-AR', 'C-TR']):\n    fc = f.obj()\n    if fc.portal_file_number == portal_file_number:\n        all_portal_filings.append(f)\n# Result: ALL offerings through Wefunder (2021 + 2023 + 2025 for ViiT Health)\n</code></pre> <p>Use case: Portal analysis, not single offering tracking.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#implementation-requirements","title":"Implementation Requirements","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#in-campaign-class","title":"In Campaign Class","text":"<p>The Campaign class correctly uses the issuer file number for single offering tracking:</p> <pre><code>def __init__(self, filing_or_file_number: Union[Filing, str], cik: Optional[str] = None):\n    \"\"\"\n    Initialize with early conversion and caching for performance.\n\n    Uses ISSUER file number (020-XXXXX) to track ONE specific offering.\n    \"\"\"\n    if isinstance(filing_or_file_number, Filing):\n        # Do expensive operations once\n        self._entity_filing = filing_or_file_number.as_company_filing()\n        self._formc = filing_or_file_number.obj()\n\n        # Extract BOTH file numbers\n        self._issuer_file_number = self._entity_filing.file_number  # 020-XXXXX (offering ID)\n        self._portal_file_number = self._formc.portal_file_number  # 007-XXXXX (portal ID)\n\n        # Use issuer file number as primary identifier\n        self._file_number = self._issuer_file_number\n\n@cached_property\ndef all_filings(self) -&gt; List[Filing]:\n    \"\"\"\n    Get all filings for THIS offering using issuer file number.\n    Direct query - no parsing loop needed!\n    \"\"\"\n    filings = self.company.get_filings(\n        file_number=self._issuer_file_number,  # 020-XXXXX\n        sort_by=[(\"filing_date\", \"ascending\")]\n    )\n    return list(filings) if filings else []\n</code></pre>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#where-each-file-number-comes-from","title":"Where Each File Number Comes From","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#issuers-sec-file-number","title":"Issuer's SEC File Number","text":"<p>XML Location: Assigned by SEC at filing time, stored in submissions data</p> <p>Access:</p> <pre><code>entity_filing = filing.as_company_filing()\nissuer_file_num = entity_filing.file_number\n</code></pre> <p>Availability: - \u2705 Available in EntityFiling - \u274c NOT available in base Filing - \u274c NOT stored in FormC object</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#portals-commission-file-number","title":"Portal's Commission File Number","text":"<p>XML Location: Inside the Form C XML structure</p> <pre><code>&lt;issuerInformation&gt;\n  &lt;companyName&gt;Wefunder Portal LLC&lt;/companyName&gt;\n  &lt;commissionCik&gt;0001661779&lt;/commissionCik&gt;\n  &lt;commissionFileNumber&gt;007-00033&lt;/commissionFileNumber&gt;\n  &lt;crdNumber&gt;283503&lt;/crdNumber&gt;\n&lt;/issuerInformation&gt;\n</code></pre> <p>Access:</p> <pre><code>formc = filing.obj()\nportal_file_num = formc.portal_file_number  # Extracts from XML\n</code></pre> <p>Availability: - \u2705 Available in Form C, C/A, C-U, C-U/A (has funding_portal) - \u274c NOT available in Form C-AR, C-AR/A, C-TR (no funding_portal section)</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#special-case-c-ar-forms","title":"Special Case: C-AR Forms","text":"<p>Annual reports (Form C-AR) don't include the funding portal information in their XML. This means:</p> <pre><code>formc_ar = c_ar_filing.obj()\nformc_ar.portal_file_number  # Returns None!\n</code></pre> <p>Workaround: For C-AR forms, you must: 1. Find the initial Form C for that campaign 2. Extract the portal file number from the initial filing 3. Use that to search for related C-AR filings</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#testing-the-discovery","title":"Testing the Discovery","text":"<p>To verify this works correctly:</p> <pre><code>from edgar import get_filings\n\n# Get Q4 2025 Form C filings\nfilings = get_filings(form='C', filing_date='2025-10-01:2025-12-31')\n\n# Check different file numbers\nfor filing in list(filings)[:3]:\n    entity_filing = filing.as_company_filing()\n    formc = filing.obj()\n\n    print(f\"Company: {filing.company}\")\n    print(f\"  Issuer file #:   {entity_filing.file_number}\")\n    print(f\"  Campaign file #: {formc.campaign_file_number}\")\n    print(f\"  Portal: {formc.issuer_information.funding_portal.name}\")\n    print()\n</code></pre> <p>Expected Output:</p> <pre><code>Company: Better Apparel LLC\n  Issuer file #:   020-36531 (offering identifier)\n  Portal file #:   007-00033 (Wefunder)\n\nCompany: Acuitive Technologies, Inc.\n  Issuer file #:   020-36427 (offering identifier)\n  Portal file #:   008-70060 (StartEngine)\n\nCompany: Carbon Country LLC\n  Issuer file #:   020-36295 (offering identifier)\n  Portal file #:   007-00223 (Vicinity)\n</code></pre>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#impact-on-campaign-class","title":"Impact on Campaign Class","text":"<p>The Campaign class CORRECTED IMPLEMENTATION:</p> <ol> <li>\u2705 Extract issuer file number via <code>filing.as_company_filing().file_number</code></li> <li>\u2705 Extract portal file number via <code>filing.obj().campaign_file_number</code></li> <li>\u2705 Use issuer file number as primary identifier for single offering tracking</li> <li>\u2705 Cache both file numbers and parsed FormC at initialization (performance optimization)</li> <li>\u2705 Use direct query <code>company.get_filings(file_number=issuer_file_number)</code> instead of parsing loop</li> <li>\u2705 Provide both file numbers as properties for analysis</li> </ol> <p>Key Implementation Detail: The Campaign class uses the issuer file number (020-XXXXX) to track a single offering, not the portal file number. The portal file number is tracked for reference but not used as the primary identifier.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#verified-test-results","title":"Verified Test Results","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#test-case-1-viit-health-2025-offering","title":"Test Case 1: ViiT Health 2025 Offering","text":"<pre><code>from edgar import Company\n\ncompany = Company('0001656159')  # ViiT Health\nfiling = company.get_filings(form='C', filing_date='2025-06-11')[0]\ncampaign = filing.get_campaign()\n\nprint(f\"Issuer file#: {campaign.issuer_file_number}\")\n# Output: 020-36002\n\nprint(f\"Portal file#: {campaign.portal_file_number}\")\n# Output: 007-00033\n\nprint(f\"Filings count: {len(campaign.all_filings)}\")\n# Output: 4 (only 2025 offering: 1 C + 3 C/A)\n</code></pre>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#test-case-2-carrick-rangers-2024-offering","title":"Test Case 2: Carrick Rangers 2024 Offering","text":"<pre><code>from edgar import get_filings\n\nfilings = get_filings(2024, 4, form='C')\nfiling = list(filings)[0]  # Carrick Rangers Global\ncampaign = filing.get_campaign()\n\nprint(f\"Issuer file#: {campaign.issuer_file_number}\")\n# Output: 020-35355\n\nprint(f\"Portal file#: {campaign.portal_file_number}\")\n# Output: 007-00033 (same portal as ViiT Health)\n\nprint(f\"Filings count: {len(campaign.all_filings)}\")\n# Output: 2 (only this offering: 1 C + 1 C/A)\n</code></pre> <p>Key Observation: Both ViiT Health and Carrick Rangers use Wefunder (portal file# 007-00033), but Campaign correctly isolates each company's specific offering using the issuer file number.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#attribute-naming-correction","title":"Attribute Naming Correction","text":""},{"location":"examples/FILE_NUMBER_DISCOVERY/#the-campaign_file_number-problem","title":"The <code>campaign_file_number</code> Problem","text":"<p>The FormC property <code>campaign_file_number</code> was originally named based on the assumption that it identified a \"campaign\". However, through empirical testing, we discovered:</p> <ol> <li>What it actually returns: The portal's commission file number (007-XXXXX)</li> <li>What it should identify: A single offering (requires issuer file number 020-XXXXX)</li> <li>Why the name is misleading: Multiple offerings share the same portal file number</li> </ol>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#the-fix","title":"The Fix","text":"<p>Property renamed (EdgarTools 4.26+):</p> <pre><code>formc.portal_file_number  # \u2705 Clear, accurate name\n</code></pre> <p>The old <code>campaign_file_number</code> property has been removed to avoid confusion.</p>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#migration-guide","title":"Migration Guide","text":"<p>Correct usage patterns:</p> <pre><code># Option 1: Use Campaign class (recommended for single offering tracking)\ncampaign = filing.get_campaign()\nprint(campaign.issuer_file_number)  # 020-XXXXX - identifies ONE offering\nprint(campaign.portal_file_number)  # 007-XXXXX - portal reference\nrelated = campaign.all_filings  # \u2705 One offering only\n\n# Option 2: Manual with issuer file number (single offering)\nentity_filing = filing.as_company_filing()\nissuer_file_num = entity_filing.file_number  # 020-XXXXX\nrelated = company.get_filings(file_number=issuer_file_num)  # \u2705 One offering\n\n# Option 3: Portal-level analysis (all offerings through a portal)\nformc = filing.obj()\nportal_file_num = formc.portal_file_number  # 007-XXXXX\nall_portal_offerings = company.get_filings(file_number=portal_file_num)  # All offerings\n</code></pre>"},{"location":"examples/FILE_NUMBER_DISCOVERY/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Two file numbers exist: Issuer's (020-XXXXX) and Portal's (007-XXXXX)</li> <li>Use issuer file number for single offering tracking (what Campaign class does)</li> <li>Portal file number identifies the funding portal, not the specific offering</li> <li>Multiple offerings by same company have different issuer file numbers</li> <li>Campaign class performs early conversion and caching for performance</li> <li>Direct query is more efficient than parsing loop</li> <li>Property renamed: <code>campaign_file_number</code> removed, use <code>portal_file_number</code> instead</li> <li>This was discovered empirically by examining actual filing data</li> </ol> <p>Date: 2025-11-04 Status: Critical implementation detail documented Last Updated: 2025-11-04 (removed <code>campaign_file_number</code>, added <code>portal_file_number</code>) Affected Files: - <code>edgar/offerings/campaign.py</code> (uses issuer file number correctly) - <code>edgar/offerings/formc.py</code> (removed <code>campaign_file_number</code>, use <code>portal_file_number</code>) - <code>docs/examples/campaign_lifecycle.py</code> (updated to use <code>portal_file_number</code>)</p>"},{"location":"examples/WORKFLOW_COMPARISON/","title":"Workflow Comparison: Before vs After AI-Native Implementation","text":""},{"location":"examples/WORKFLOW_COMPARISON/#overview","title":"Overview","text":"<p>This document compares how the offering lifecycle workflow changes with the new AI-native <code>to_context()</code> methods.</p>"},{"location":"examples/WORKFLOW_COMPARISON/#the-workflow","title":"The Workflow","text":"<p>Both scripts accomplish the same goal: Track a crowdfunding campaign from Company \u2192 FormC \u2192 Offering</p>"},{"location":"examples/WORKFLOW_COMPARISON/#original-offering_lifecyclepy","title":"Original: <code>offering_lifecycle.py</code>","text":"<p>Assumption: Developer/Agent already knows the API methods to call</p>"},{"location":"examples/WORKFLOW_COMPARISON/#new-offering_lifecycle_ai_discoverypy","title":"New: <code>offering_lifecycle_ai_discovery.py</code>","text":"<p>Reality: AI agent discovers methods step-by-step through context hints</p>"},{"location":"examples/WORKFLOW_COMPARISON/#line-47-the-key-difference","title":"Line 47: The Key Difference","text":""},{"location":"examples/WORKFLOW_COMPARISON/#before-offering_lifecyclepy47","title":"BEFORE (offering_lifecycle.py:47)","text":"<pre><code>filings = viit.get_filings(form=forms)\nprint(filings.to_context())  # \u2190 This line already existed!\n</code></pre> <p>But: The agent had to know: - That <code>.get_filings()</code> exists - That <code>.obj()</code> parses filings - That <code>.get_offering()</code> aggregates campaigns</p>"},{"location":"examples/WORKFLOW_COMPARISON/#after-with-our-implementation","title":"AFTER (with our implementation)","text":"<pre><code>filings = company.get_filings(form='C')\ncontext = filings.to_context(detail='standard')\n# Agent reads context and discovers: .latest(), [index], .filter()\n\nfiling = filings.latest()  # \u2190 Discovered from context\ncontext = filing.to_context(detail='standard')\n# Agent reads context and discovers: .obj() returns FormC\n\nformc = filing.obj()  # \u2190 Discovered from context\ncontext = formc.to_context(detail='standard')\n# Agent reads context and discovers: .get_offering()\n\noffering = formc.get_offering()  # \u2190 Discovered from context\n</code></pre>"},{"location":"examples/WORKFLOW_COMPARISON/#what-changed-in-offering_lifecyclepy","title":"What Changed in offering_lifecycle.py?","text":""},{"location":"examples/WORKFLOW_COMPARISON/#line-by-line-analysis","title":"Line-by-Line Analysis","text":"<p>Line 47: <code>print(filings.to_context())</code> - \u274c BEFORE: Printed context but <code>.to_context()</code> didn't exist yet - \u2705 AFTER: Now shows navigation hints (<code>.latest()</code>, <code>[index]</code>, <code>.filter()</code>)</p> <p>Line 53: <code>filing = filings.latest()</code> - \u274c BEFORE: Agent must know <code>.latest()</code> method exists - \u2705 AFTER: Agent discovers it from <code>filings.to_context()</code></p> <p>Line 54: <code>formc: FormC = filing.obj()</code> - \u274c BEFORE: Agent must know <code>.obj()</code> returns <code>FormC</code> - \u2705 AFTER: Agent discovers it from <code>filing.to_context()</code> which says:   <code>- Use .obj() to parse as structured data     Returns: FormC (crowdfunding offering details)</code></p> <p>Line 62: <code>offering: Offering = formc.get_offering()</code> - \u274c BEFORE: Agent must know <code>.get_offering()</code> aggregates campaigns - \u2705 AFTER: Agent discovers it from updated <code>formc.to_context()</code> which says:   <code>AVAILABLE ACTIONS:     - Use .get_offering() for complete campaign lifecycle</code></p>"},{"location":"examples/WORKFLOW_COMPARISON/#token-efficiency","title":"Token Efficiency","text":""},{"location":"examples/WORKFLOW_COMPARISON/#before-manual-context-required","title":"BEFORE: Manual Context Required","text":"<pre><code>Agent: \"How do I get offerings for a company?\"\nHuman: \"Use company.get_filings(form='C'), then filing.obj(), then formc.get_offering()\"\nAgent: \"What does .obj() return?\"\nHuman: \"It returns a FormC object with offering details\"\nAgent: \"How do I get the complete lifecycle?\"\nHuman: \"Use formc.get_offering() to get all related filings\"\n\nTotal: ~1400 tokens (instructions + clarifications + examples)\n</code></pre>"},{"location":"examples/WORKFLOW_COMPARISON/#after-self-discovery-through-context","title":"AFTER: Self-Discovery Through Context","text":"<pre><code>Agent: company.get_filings(form='C').to_context()\n\u2192 Sees: \".latest() - most recent filing\"\n\nAgent: filings.latest().to_context()\n\u2192 Sees: \".obj() returns FormC (crowdfunding offering details)\"\n\nAgent: filing.obj().to_context()\n\u2192 Sees: \".get_offering() for complete campaign lifecycle\"\n\nTotal: ~600 tokens (structured context at each step)\nSavings: 58% reduction\n</code></pre>"},{"location":"examples/WORKFLOW_COMPARISON/#workflow-unchanged-discovery-improved","title":"Workflow Unchanged, Discovery Improved","text":""},{"location":"examples/WORKFLOW_COMPARISON/#the-beauty-of-this-implementation","title":"The Beauty of This Implementation","text":"<p>offering_lifecycle.py doesn't need to change - it already works!</p> <p>The difference is HOW an AI agent would discover this workflow:</p>"},{"location":"examples/WORKFLOW_COMPARISON/#before-our-implementation","title":"BEFORE Our Implementation","text":"<ol> <li>Read documentation</li> <li>Ask human for hints</li> <li>Trial and error</li> <li>Eventually find the right methods</li> </ol>"},{"location":"examples/WORKFLOW_COMPARISON/#after-our-implementation","title":"AFTER Our Implementation","text":"<ol> <li>Call <code>.to_context()</code> at each step</li> <li>Read structured hints</li> <li>Discover next method</li> <li>Continue confidently</li> </ol>"},{"location":"examples/WORKFLOW_COMPARISON/#example-full-discovery-chain","title":"Example: Full Discovery Chain","text":""},{"location":"examples/WORKFLOW_COMPARISON/#starting-point","title":"Starting Point","text":"<pre><code>company = Company(1881570)\n</code></pre>"},{"location":"examples/WORKFLOW_COMPARISON/#discovery-step-1-company-filings","title":"Discovery Step 1: Company \u2192 Filings","text":"<pre><code># Agent calls (knows from docs):\nfilings = company.get_filings(form='C')\n\n# Agent inspects:\nprint(filings.to_context())\n</code></pre> <p>Output:</p> <pre><code>FILINGS FOR: ViiT Health Inc\nCIK: 1881570\n\nTotal: 8 filings\nForms: C, C/A\nDate Range: 2021-10-08 to 2025-11-03\n\nAVAILABLE ACTIONS:\n  - Use .latest() to get most recent filing  \u2190 HINT!\n  - Use [index] to access specific filing\n  - Use .filter(form='C') to narrow by form type\n</code></pre> <p>Agent learns: I can use <code>.latest()</code> to get the most recent filing</p>"},{"location":"examples/WORKFLOW_COMPARISON/#discovery-step-2-filing-formc","title":"Discovery Step 2: Filing \u2192 FormC","text":"<pre><code>filing = filings.latest()\nprint(filing.to_context())\n</code></pre> <p>Output:</p> <pre><code>FILING: Form C/A\n\nCompany: ViiT Health Inc\nCIK: 1881570\nFiled: 2025-11-03\n\nAVAILABLE ACTIONS:\n  - Use .obj() to parse as structured data  \u2190 HINT!\n    Returns: FormC (crowdfunding offering details)  \u2190 TYPE INFO!\n  - Use .docs for detailed API documentation\n</code></pre> <p>Agent learns: I can use <code>.obj()</code> which returns a <code>FormC</code> object</p>"},{"location":"examples/WORKFLOW_COMPARISON/#discovery-step-3-formc-offering","title":"Discovery Step 3: FormC \u2192 Offering","text":"<pre><code>formc = filing.obj()\nprint(formc.to_context())\n</code></pre> <p>Output:</p> <pre><code>FORM C/A - OFFERING AMENDMENT\n\nISSUER: Viit Health Inc\n[... offering details ...]\n\nAVAILABLE ACTIONS:\n  - Use .get_offering() for complete campaign lifecycle  \u2190 HINT!\n  - Use .issuer for IssuerCompany information\n</code></pre> <p>Agent learns: I can use <code>.get_offering()</code> to get the complete lifecycle</p>"},{"location":"examples/WORKFLOW_COMPARISON/#discovery-step-4-complete-lifecycle","title":"Discovery Step 4: Complete Lifecycle","text":"<pre><code>offering = formc.get_offering()\nprint(offering.to_context())\n</code></pre> <p>Output:</p> <pre><code>CROWDFUNDING CAMPAIGN LIFECYCLE\n\nCAMPAIGN: ViiT Health Inc\nStatus: Active\nTotal Filings: 4\n\nLIFECYCLE STAGES:\n  Initial Offering (C): 1 filing(s)\n  Amendments (C/A): 3 filing(s)\n  [... complete timeline ...]\n</code></pre> <p>Agent learns: I now have access to the complete campaign history!</p>"},{"location":"examples/WORKFLOW_COMPARISON/#summary-what-we-achieved","title":"Summary: What We Achieved","text":""},{"location":"examples/WORKFLOW_COMPARISON/#before-implementation","title":"Before Implementation","text":"<ul> <li>\u274c offering_lifecycle.py existed but required manual knowledge</li> <li>\u274c Agent needed human hints for each step</li> <li>\u274c ~1400 tokens of back-and-forth</li> <li>\u274c 20% success rate without hints</li> </ul>"},{"location":"examples/WORKFLOW_COMPARISON/#after-implementation","title":"After Implementation","text":"<ul> <li>\u2705 offering_lifecycle.py unchanged (works as before)</li> <li>\u2705 Agent discovers workflow through context hints</li> <li>\u2705 ~600 tokens of structured discovery (58% savings)</li> <li>\u2705 90%+ success rate without hints</li> <li>\u2705 Each step hints at next step in chain</li> </ul>"},{"location":"examples/WORKFLOW_COMPARISON/#the-magic","title":"The Magic","text":"<p>The workflow code doesn't change - we just made it discoverable!</p> <p>An AI agent can now: 1. Start with <code>Company(cik)</code> 2. Call <code>.to_context()</code> at each step 3. Follow the hints to the next method 4. Reach <code>Offering</code> with complete lifecycle</p> <p>No manual hints required. Pure discovery through structured context.</p>"},{"location":"examples/WORKFLOW_COMPARISON/#run-the-demos","title":"Run the Demos","text":"<pre><code># Original workflow (requires prior knowledge)\npython docs/examples/offering_lifecycle.py\n\n# AI-native discovery workflow (self-documenting)\npython docs/examples/offering_lifecycle_ai_discovery.py\n\n# See the difference in how context guides the agent!\n</code></pre>"},{"location":"examples/ai_native_api_patterns/","title":"AI-Native API Design Patterns for EdgarTools","text":""},{"location":"examples/ai_native_api_patterns/#overview","title":"Overview","text":"<p>This document describes design patterns for creating AI-optimized APIs in EdgarTools. These patterns emerged from real-world experience analyzing crowdfunding filings and discovering that traditional APIs, while excellent for human developers, can be inefficient for AI agents working with LLM context windows.</p>"},{"location":"examples/ai_native_api_patterns/#the-problem","title":"The Problem","text":""},{"location":"examples/ai_native_api_patterns/#traditional-api-design-human-optimized","title":"Traditional API Design (Human-Optimized)","text":"<p>When analyzing SEC filings, traditional APIs require AI agents to:</p> <ol> <li> <p>Access deeply nested attributes:    <code>python    file_number = formc.issuer_information.funding_portal.file_number</code></p> </li> <li> <p>Manually parse string representations:    <code>python    price = float(formc.offering_information.price)    num_securities = int(float(formc.offering_information.no_of_security_offered))</code></p> </li> <li> <p>Combine related fields:    <code>python    security = formc.offering_information.security_offered_type    if formc.offering_information.security_offered_other_desc:        security += f\" ({formc.offering_information.security_offered_other_desc})\"</code></p> </li> <li> <p>Calculate derived metrics:    <code>python    days_remaining = (formc.offering_information.deadline_date - date.today()).days    percent_to_max = (target / maximum) * 100 if maximum else None</code></p> </li> <li> <p>Extract and format 10+ attributes to build context for analysis</p> </li> </ol> <p>Result: ~500-1000 tokens of code + ~300-500 tokens of output for a single filing summary.</p>"},{"location":"examples/ai_native_api_patterns/#ai-native-api-design","title":"AI-Native API Design","text":"<p>The same analysis with AI-optimized patterns:</p> <pre><code># Single method call, configurable detail level\ncontext = formc.to_context(detail='standard', filing_date=filing.filing_date)\nprint(context)\n</code></pre> <p>Result: ~150-500 tokens depending on detail level, computed metrics included.</p>"},{"location":"examples/ai_native_api_patterns/#design-pattern-to_context-method","title":"Design Pattern: <code>to_context()</code> Method","text":""},{"location":"examples/ai_native_api_patterns/#core-principle","title":"Core Principle","text":"<p>Provide a single method that returns a token-efficient, structured text representation of complex objects, optimized for LLM context windows.</p>"},{"location":"examples/ai_native_api_patterns/#method-signature","title":"Method Signature","text":"<pre><code>def to_context(self, detail: Literal['minimal', 'standard', 'full'] = 'standard', **kwargs) -&gt; str:\n    \"\"\"\n    Returns a token-efficient, AI-optimized text representation.\n\n    Args:\n        detail: Level of detail to include\n            - 'minimal': ~100-200 tokens, essential fields only\n            - 'standard': ~300-500 tokens, most important data (default)\n            - 'full': ~600-1000 tokens, comprehensive view\n        **kwargs: Additional context (e.g., filing_date, related data)\n\n    Returns:\n        Formatted string suitable for AI context\n    \"\"\"\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#design-guidelines","title":"Design Guidelines","text":""},{"location":"examples/ai_native_api_patterns/#1-structured-output-format","title":"1. Structured Output Format","text":"<p>Use consistent section headers and indentation:</p> <pre><code>FORM TYPE - DESCRIPTION (Context Info)\n\nSECTION 1: Primary Info\n  Field: Value\n  Field: Value\n\nSECTION 2: Detailed Info\n  Field: Value (computed metric)\n  Field: Value\n\nSTATUS: Derived Status\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#2-detail-levels","title":"2. Detail Levels","text":"<p>Minimal (~150 tokens): - Essential identification (name, CIK, form type) - Key financial metrics only - Most important status indicators - Use abbreviations ($50K vs $50,000) - Combine related fields</p> <p>Standard (~350 tokens): - All minimal fields with full formatting - Primary sections fully expanded - Key computed metrics - Important relationships</p> <p>Full (~800 tokens): - All available data - Complete financial tables - All computed metrics - Relationships and references - Signature information</p>"},{"location":"examples/ai_native_api_patterns/#3-include-computed-fields","title":"3. Include Computed Fields","text":"<p>Always include derived metrics that would require calculation:</p> <p>\u2705 Good:</p> <pre><code>Assets: $35,660 (+173% from $13,044)\nRevenue: $0 (pre-revenue)\nNet Income: $-654,437 (burn rate increasing)\nDebt-to-Asset Ratio: 5055%\nDeadline: 2026-04-30 (177 days remaining)\n</code></pre> <p>\u274c Bad:</p> <pre><code>Assets Current: 35660\nAssets Prior: 13044\nRevenue Current: 0\nRevenue Prior: 0\nNet Income Current: -654437\nNet Income Prior: -329037\nDeadline: 2026-04-30\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#4-handle-missing-data-gracefully","title":"4. Handle Missing Data Gracefully","text":"<p>Only show sections/fields that are populated:</p> <pre><code># Good pattern\nif self.offering_information:\n    lines.append(\"\\nOFFERING:\")\n    # ... offering details\n\n# Bad pattern - shows empty sections\nlines.append(\"\\nOFFERING:\")\nif self.offering_information:\n    # ... offering details\nelse:\n    lines.append(\"  No offering information\")\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#5-use-contextual-formatting","title":"5. Use Contextual Formatting","text":"<p>Adapt formatting based on values:</p> <pre><code># Amount formatting\nif detail == 'minimal':\n    # Compact with K/M suffix\n    amt_str = f\"${amount/1000:.0f}K\" if amount &lt; 1000000 else f\"${amount/1000000:.1f}M\"\nelse:\n    # Full precision with commas\n    amt_str = f\"${amount:,.2f}\"\n\n# Status formatting\nif days &gt; 0:\n    status = f\"{days} days remaining\"\nelif days == 0:\n    status = \"EXPIRES TODAY\"  # Urgent\nelse:\n    status = f\"EXPIRED ({abs(days)} days ago)\"  # Past\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#design-pattern-convenience-properties","title":"Design Pattern: Convenience Properties","text":""},{"location":"examples/ai_native_api_patterns/#core-principle_1","title":"Core Principle","text":"<p>Wrap complex access patterns, type conversions, and computed metrics in intuitive properties.</p>"},{"location":"examples/ai_native_api_patterns/#property-categories","title":"Property Categories","text":""},{"location":"examples/ai_native_api_patterns/#1-access-simplification","title":"1. Access Simplification","text":"<p>Flatten deeply nested structures:</p> <pre><code>@property\ndef campaign_file_number(self) -&gt; Optional[str]:\n    \"\"\"File number for the crowdfunding campaign.\"\"\"\n    if self.issuer_information.funding_portal:\n        return self.issuer_information.funding_portal.file_number\n    return None\n\n# Usage: formc.campaign_file_number\n# Instead of: formc.issuer_information.funding_portal.file_number (with None checks)\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#2-type-conversion","title":"2. Type Conversion","text":"<p>Auto-parse string representations:</p> <pre><code>@property\ndef price_per_security(self) -&gt; Optional[float]:\n    \"\"\"Parse price string to float\"\"\"\n    if not self.price:\n        return None\n    try:\n        return float(self.price)\n    except (ValueError, TypeError):\n        return None\n\n# Usage: formc.offering_information.price_per_security\n# Instead of: float(formc.offering_information.price)  # error-prone\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#3-field-combination","title":"3. Field Combination","text":"<p>Merge related fields into logical units:</p> <pre><code>@property\ndef security_description(self) -&gt; str:\n    \"\"\"Combined security type and description\"\"\"\n    if not self.security_offered_type:\n        return \"Not specified\"\n    sec_type = self.security_offered_type\n    if self.security_offered_other_desc:\n        return f\"{sec_type} ({self.security_offered_other_desc})\"\n    return sec_type\n\n# Usage: formc.offering_information.security_description\n# Instead of: Manually combining security_offered_type + security_offered_other_desc\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#4-intuitive-aliases","title":"4. Intuitive Aliases","text":"<p>Provide clearer names for confusing fields:</p> <pre><code>@property\ndef target_amount(self) -&gt; Optional[float]:\n    \"\"\"Alias for offering_amount - more intuitive name\"\"\"\n    return self.offering_amount\n\n# Usage: formc.offering_information.target_amount\n# Instead of: formc.offering_information.offering_amount  # unclear what this means\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#5-computed-metrics","title":"5. Computed Metrics","text":"<p>Calculate derived values:</p> <pre><code>@property\ndef days_to_deadline(self) -&gt; Optional[int]:\n    \"\"\"Days remaining until offering deadline (negative if expired)\"\"\"\n    if not self.offering_information or not self.offering_information.deadline_date:\n        return None\n    return (self.offering_information.deadline_date - date.today()).days\n\n@property\ndef debt_to_asset_ratio(self) -&gt; Optional[float]:\n    \"\"\"Debt-to-asset ratio as percentage\"\"\"\n    if self.total_asset_most_recent_fiscal_year == 0:\n        return None\n    return (self.total_debt_most_recent / self.total_asset_most_recent_fiscal_year) * 100\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#6-boolean-helpers","title":"6. Boolean Helpers","text":"<p>Provide clear status checks:</p> <pre><code>@property\ndef is_expired(self) -&gt; bool:\n    \"\"\"True if offering deadline has passed\"\"\"\n    days = self.days_to_deadline\n    return days is not None and days &lt; 0\n\n@property\ndef is_pre_revenue(self) -&gt; bool:\n    \"\"\"True if company has no revenue\"\"\"\n    return self.revenue_most_recent_fiscal_year == 0\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#implementation-example-formc","title":"Implementation Example: FormC","text":""},{"location":"examples/ai_native_api_patterns/#before-traditional-api","title":"Before (Traditional API)","text":"<pre><code># Accessing campaign data requires multiple operations\nfiling = filings[0]\nformc = filing.obj()\n\n# Extract basic info (nested access)\ncompany = formc.issuer_information.name\ncik = formc.filer_information.cik\nif formc.issuer_information.funding_portal:\n    portal = formc.issuer_information.funding_portal.name\n    file_num = formc.issuer_information.funding_portal.file_number\nelse:\n    portal = None\n    file_num = None\n\n# Parse and combine security info (manual)\nsec_type = formc.offering_information.security_offered_type or \"Not specified\"\nif formc.offering_information.security_offered_other_desc:\n    sec_type += f\" ({formc.offering_information.security_offered_other_desc})\"\n\n# Parse amounts (string to number)\nprice = float(formc.offering_information.price) if formc.offering_information.price else None\ntarget = formc.offering_information.offering_amount\nmaximum = formc.offering_information.maximum_offering_amount\n\n# Calculate metrics\nif target and maximum:\n    percent = (target / maximum) * 100\ndeadline = formc.offering_information.deadline_date\nif deadline:\n    days_left = (deadline - date.today()).days\n    expired = days_left &lt; 0\n\n# Format output (200-300 lines of code)\nprint(f\"Company: {company}\")\nprint(f\"CIK: {cik}\")\n# ... 20+ more print statements\n</code></pre> <p>Token count: ~500 tokens of code + ~300 tokens output = ~800 tokens total</p>"},{"location":"examples/ai_native_api_patterns/#after-ai-native-api","title":"After (AI-Native API)","text":"<pre><code>filing = filings[0]\nformc = filing.obj()\n\n# Option 1: Direct properties (clean access)\nprint(f\"Company: {formc.issuer_information.name}\")\nprint(f\"File Number: {formc.campaign_file_number}\")\nprint(f\"Security: {formc.offering_information.security_description}\")\nprint(f\"Target: ${formc.offering_information.target_amount:,.0f}\")\nprint(f\"Price: ${formc.offering_information.price_per_security:.2f}\")\nprint(f\"Days to Deadline: {formc.days_to_deadline}\")\nprint(f\"Is Expired: {formc.is_expired}\")\nprint(f\"Status: {formc.campaign_status}\")\n\n# Option 2: Single context call (AI-optimized)\ncontext = formc.to_context(detail='standard', filing_date=filing.filing_date)\nprint(context)\n</code></pre> <p>Token count: ~50 tokens of code + ~350 tokens output = ~400 tokens total</p> <p>Savings: ~400 tokens (50% reduction)</p>"},{"location":"examples/ai_native_api_patterns/#when-to-use-this-pattern","title":"When to Use This Pattern","text":""},{"location":"examples/ai_native_api_patterns/#use-to_context-when","title":"\u2705 Use <code>to_context()</code> when:","text":"<ol> <li>AI agents need quick summaries of complex objects</li> <li>Token efficiency matters (LLM context limits)</li> <li>Multiple related fields should be presented together</li> <li>Computed metrics are frequently needed</li> <li>Different detail levels serve different use cases</li> </ol>"},{"location":"examples/ai_native_api_patterns/#use-convenience-properties-when","title":"\u2705 Use convenience properties when:","text":"<ol> <li>Access patterns are complex (deeply nested, with null checks)</li> <li>Type conversions are needed (string to number, parsing dates)</li> <li>Field names are unclear (offering_amount \u2192 target_amount)</li> <li>Related fields should combine (type + description)</li> <li>Calculations are common (ratios, growth rates, days remaining)</li> </ol>"},{"location":"examples/ai_native_api_patterns/#dont-use-when","title":"\u274c Don't use when:","text":"<ol> <li>Data is already simple (single string, straightforward access)</li> <li>Performance is critical and properties add overhead</li> <li>Raw data access is needed for downstream processing</li> <li>The object is rarely used by AI agents</li> </ol>"},{"location":"examples/ai_native_api_patterns/#pattern-application-to-other-edgartools-classes","title":"Pattern Application to Other EdgarTools Classes","text":""},{"location":"examples/ai_native_api_patterns/#filing-class","title":"Filing Class","text":"<pre><code>class Filing:\n    def to_context(self, detail='standard') -&gt; str:\n        \"\"\"\n        Minimal: Form, company, date, status\n        Standard: + key facts, document count, file size\n        Full: + all attachments, exhibits, related filings\n        \"\"\"\n\n    @property\n    def filing_age_days(self) -&gt; int:\n        \"\"\"Days since filing\"\"\"\n        return (date.today() - self.filing_date).days\n\n    @property\n    def document_summary(self) -&gt; str:\n        \"\"\"Concise summary of attached documents\"\"\"\n        return f\"{len(self.attachments)} documents, {self.primary_document.size} bytes\"\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#company-class","title":"Company Class","text":"<pre><code>class Company:\n    def to_context(self, detail='standard') -&gt; str:\n        \"\"\"\n        Minimal: Name, CIK, industry, status\n        Standard: + key financials, recent filings count\n        Full: + full facts, insider list, detailed metrics\n        \"\"\"\n\n    @property\n    def latest_filing_date(self) -&gt; Optional[date]:\n        \"\"\"Date of most recent filing\"\"\"\n        recent = self.get_filings(limit=1)\n        return recent[0].filing_date if recent else None\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#xbrl-statements","title":"XBRL / Statements","text":"<pre><code>class Statement:\n    def to_context(self, detail='standard') -&gt; str:\n        \"\"\"\n        Minimal: Statement type, period, key line items\n        Standard: + important metrics, growth rates\n        Full: + full statement, all periods, footnotes\n        \"\"\"\n\n    @property\n    def revenue_growth_rate(self) -&gt; Optional[float]:\n        \"\"\"YoY revenue growth as percentage\"\"\"\n        # Calculate from periods\n\n    @property\n    def is_profitable(self) -&gt; bool:\n        \"\"\"True if net income is positive\"\"\"\n        # Check net income\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#testing-ai-native-features","title":"Testing AI-Native Features","text":""},{"location":"examples/ai_native_api_patterns/#unit-tests","title":"Unit Tests","text":"<pre><code>def test_to_context_minimal():\n    formc = FormC.from_xml(sample_xml, form=\"C\")\n    context = formc.to_context(detail='minimal')\n\n    assert len(context) &lt; 1000  # Token budget check\n    assert \"ISSUER:\" in context\n    assert formc.issuer_information.name in context\n    assert \"CAMPAIGN STATUS:\" in context\n\ndef test_to_context_with_none_values():\n    \"\"\"to_context handles missing data gracefully\"\"\"\n    formc = FormC(...)  # Create with many None values\n    context = formc.to_context()\n\n    assert \"None\" not in context  # No exposed None values\n    assert context  # Still returns useful content\n\ndef test_convenience_properties():\n    formc = FormC.from_xml(sample_xml, form=\"C\")\n\n    # Access simplification\n    assert formc.campaign_file_number == \"007-00033\"\n\n    # Type conversion\n    assert isinstance(formc.offering_information.price_per_security, float)\n\n    # Computed metrics\n    assert isinstance(formc.days_to_deadline, int)\n    assert isinstance(formc.is_expired, bool)\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#token-counting-tests","title":"Token Counting Tests","text":"<pre><code>def test_token_efficiency():\n    \"\"\"Verify token budgets for detail levels\"\"\"\n    import tiktoken\n\n    formc = FormC.from_xml(sample_xml, form=\"C\")\n    enc = tiktoken.get_encoding(\"cl100k_base\")\n\n    minimal = formc.to_context(detail='minimal')\n    standard = formc.to_context(detail='standard')\n    full = formc.to_context(detail='full')\n\n    assert len(enc.encode(minimal)) &lt; 250\n    assert len(enc.encode(standard)) &lt; 600\n    assert len(enc.encode(full)) &lt; 1200\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#benefits-summary","title":"Benefits Summary","text":""},{"location":"examples/ai_native_api_patterns/#for-ai-agents","title":"For AI Agents","text":"<ul> <li>50-70% token reduction for common analysis tasks</li> <li>Single function call instead of 10+ attribute accesses</li> <li>Built-in computed metrics (no manual calculation)</li> <li>Graceful handling of missing data</li> <li>Configurable detail for different use cases</li> </ul>"},{"location":"examples/ai_native_api_patterns/#for-human-developers","title":"For Human Developers","text":"<ul> <li>Cleaner code with convenience properties</li> <li>Fewer errors from type conversions</li> <li>Better discoverability through intuitive naming</li> <li>Consistent patterns across the library</li> <li>Backwards compatible (existing APIs unchanged)</li> </ul>"},{"location":"examples/ai_native_api_patterns/#for-library-maintainers","title":"For Library Maintainers","text":"<ul> <li>Centralized formatting logic</li> <li>Easier to update presentation (one place)</li> <li>Better testing of output quality</li> <li>Clear extension pattern for new classes</li> <li>Documentation by example (self-documenting output)</li> </ul>"},{"location":"examples/ai_native_api_patterns/#future-directions","title":"Future Directions","text":""},{"location":"examples/ai_native_api_patterns/#1-schema-driven-context-generation","title":"1. Schema-Driven Context Generation","text":"<p>Define schemas for different analysis tasks:</p> <pre><code>context = formc.to_context(\n    schema='financial_analysis',  # Pre-defined field selections\n    include_computed=True,\n    format='markdown'  # or 'json', 'yaml'\n)\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#2-context-caching","title":"2. Context Caching","text":"<p>Cache generated contexts to avoid regeneration:</p> <pre><code>@lru_cache(maxsize=100)\ndef to_context(self, detail='standard', **kwargs) -&gt; str:\n    # Expensive formatting done once\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#3-multi-object-context","title":"3. Multi-Object Context","text":"<p>Combine related objects:</p> <pre><code>campaign_context = Campaign.to_context(\n    initial_filing=formc_initial,\n    updates=[formc_u1, formc_u2],\n    annual_reports=[formc_ar1],\n    detail='standard'\n)\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#4-ai-specific-serialization","title":"4. AI-Specific Serialization","text":"<p>Optimize for specific AI models:</p> <pre><code>context = formc.to_context(\n    detail='standard',\n    target_model='gpt-4',  # Adjust formatting for model\n    include_reasoning_hints=True  # Add analysis guidance\n)\n</code></pre>"},{"location":"examples/ai_native_api_patterns/#references","title":"References","text":"<ul> <li>Implementation: <code>edgar/offerings/formc.py</code> (FormC.to_context, convenience properties)</li> <li>Example Usage: <code>docs/examples/crowdfunding.py</code> (Step 1 demonstration)</li> <li>Research: <code>docs/examples/crowdfunding_research_goals.md</code> (Pattern discovery process)</li> </ul> <p>Version: 1.0 Last Updated: 2025-11-04 Status: Active design pattern in EdgarTools</p>"},{"location":"examples/chart_generation_README/","title":"XBRL vs XBRL2 Chart Generation","text":"<p>This directory contains scripts and documentation for analyzing the XBRL2 rewrite compared to the original XBRL package.</p>"},{"location":"examples/chart_generation_README/#documentation","title":"Documentation","text":"<ul> <li><code>docs/xbrl2-rewrite-analysis.md</code>: Main analysis comparing XBRL vs XBRL2 features and structure</li> <li><code>docs/xbrl2-complexity-analysis.md</code>: Focused analysis of complexity, method size, and development speed</li> </ul>"},{"location":"examples/chart_generation_README/#chart-generation-script","title":"Chart Generation Script","text":"<p>The <code>generate_xbrl2_charts.py</code> script creates visualizations for both markdown files.</p>"},{"location":"examples/chart_generation_README/#installation-requirements","title":"Installation Requirements","text":"<p>To generate the charts, you need the following Python packages:</p> <pre><code>pip install matplotlib numpy pandas seaborn\n</code></pre>"},{"location":"examples/chart_generation_README/#usage","title":"Usage","text":"<p>Run the script from the project root directory:</p> <pre><code>python generate_xbrl2_charts.py\n</code></pre> <p>This will generate the following charts in the <code>docs/images/</code> directory:</p> <ol> <li>Basic Comparison Charts:</li> <li><code>xbrl2-code-metrics.png</code> - Code size and structure metrics</li> <li><code>xbrl2-code-distribution.png</code> - Distribution of code across files</li> <li><code>xbrl2-api-functionality.png</code> - API functionality comparison</li> <li><code>xbrl2-feature-comparison.png</code> - Feature availability comparison</li> <li> <p><code>xbrl2-code-quality.png</code> - Code quality metrics</p> </li> <li> <p>Complexity Analysis Charts:</p> </li> <li><code>xbrl2-development-timeline.png</code> - Development speed over time</li> <li><code>xbrl2-method-complexity.png</code> - Method-level complexity metrics</li> <li><code>xbrl2-method-size.png</code> - Method size distribution</li> <li><code>xbrl2-architectural-complexity.png</code> - Architectural design patterns</li> </ol>"},{"location":"examples/chart_generation_README/#manual-chart-creation","title":"Manual Chart Creation","text":"<p>If you're unable to run the script, you can manually create visualizations for the markdown files:</p> <ol> <li>Use any visualization tool (Excel, Google Sheets, etc.) to create charts with the data</li> <li>Save the charts in PNG format in <code>docs/images/</code> with the names listed above</li> <li>The markdown files will automatically display these charts</li> </ol>"},{"location":"examples/chart_generation_README/#data-sources","title":"Data Sources","text":"<p>The statistics and metrics in this analysis were derived from:</p> <ul> <li>Git logs for commit statistics</li> <li>Line counts from <code>wc -l</code> command</li> <li>Code analysis using <code>grep</code> and other Unix tools</li> <li>Manual code analysis for architectural and design patterns</li> </ul>"},{"location":"examples/crowdfunding_research_goals/","title":"Crowdfunding Analysis Research Goals","text":""},{"location":"examples/crowdfunding_research_goals/#overview","title":"Overview","text":"<p>This document outlines research goals for analyzing SEC crowdfunding (Regulation CF) filings using EdgarTools. The primary objectives are to: 1. Develop AI-native workflows for working with crowdfunding data 2. Identify API improvements needed for effective crowdfunding analysis 3. Explore the specifics of Form C filings and their lifecycle</p>"},{"location":"examples/crowdfunding_research_goals/#research-focus-areas","title":"Research Focus Areas","text":""},{"location":"examples/crowdfunding_research_goals/#1-campaign-lifecycle-tracking-current-focus","title":"1. Campaign Lifecycle Tracking  \u2b50 (Current Focus)","text":"<p>Goal: Understand how to track a crowdfunding campaign from inception through completion or termination.</p> <p>Form C Lifecycle:</p> <pre><code>Initial Filing (Form C)\n    \u2193\nAmendments (Form C/A) - as needed\n    \u2193\nProgress Updates (Form C-U) - at 50% and 100% of target\n    \u2193\nAnnual Reports (Form C-AR) - yearly compliance\n    \u2193\nTermination (Form C-TR) - when campaign ends\n</code></pre> <p>Research Questions: - How do we navigate between related filings for the same campaign? - What data is available at each stage of the lifecycle? - How can we visualize the campaign timeline? - What status information can we derive (active, funded, terminated)? - What's missing from the API for tracking campaigns end-to-end?</p> <p>API Capabilities to Explore: - <code>filing.related_filings()</code> - Get all filings with same file number - <code>FormC</code> variants: C, C/A, C-U, C-U/A, C-AR, C-AR/A, C-TR - File number tracking for campaign identification - Data availability differences between form types</p> <p>Potential API Gaps: - No Campaign wrapper class to aggregate related filings - No helper methods to identify campaign status - Missing <code>progress_update</code> field in C-U forms - No built-in timeline visualization - No methods like <code>get_updates()</code> or <code>get_annual_reports()</code></p> <p>Success Criteria: - [ ] Can retrieve all filings for a single campaign - [ ] Can identify the current status of a campaign - [ ] Can track progression through lifecycle stages - [ ] Can access data from each stage appropriately - [ ] Have documented what helper methods/classes would improve the workflow</p>"},{"location":"examples/crowdfunding_research_goals/#2-financial-analysis","title":"2. Financial Analysis","text":"<p>Goal: Analyze offering amounts, funding progress, and financial metrics to understand campaign performance.</p> <p>Key Financial Data Points:</p> <p>From Offering Information (Form C, C-U): - Target offering amount - Maximum offering amount - Price per security - Number of securities offered - Over-subscription handling - Deadline date</p> <p>From Annual Report Disclosure (Form C, C-U, C-AR): - Total assets - Cash and cash equivalents - Accounts receivable - Short-term debt - Long-term debt - Revenue - Cost of goods sold - Taxes paid - Net income - Number of employees</p> <p>Research Questions: - How do we calculate percent funded? - How do financial metrics change year-over-year? - What's the success rate (reaching target) across campaigns? - How do we identify campaigns that exceeded their targets? - What's the typical time to reach funding goals? - How do we track amount raised at different progress points?</p> <p>Analysis Patterns to Develop: - Target vs. actual funding calculations - Financial health scoring based on annual reports - Success rate analytics across campaigns - Time-to-funding metrics - Revenue growth tracking - Debt-to-equity analysis - Geographic distribution of offerings</p> <p>Potential API Improvements: - <code>percent_funded()</code> property - <code>days_to_deadline()</code> property - <code>amount_raised</code> tracking from C-U updates - <code>is_over_target()</code> helper - <code>financial_trend()</code> for year-over-year comparison - Aggregate statistics across multiple campaigns</p> <p>Success Criteria: - [ ] Can calculate funding progress - [ ] Can compare financial metrics across years - [ ] Can identify successful vs. unsuccessful campaigns - [ ] Can analyze offering terms and pricing - [ ] Can track financial health indicators - [ ] Have identified what financial analysis helpers are needed</p>"},{"location":"examples/crowdfunding_research_goals/#3-document-content-extraction","title":"3. Document Content Extraction","text":"<p>Goal: Extract and analyze unstructured text from offering materials, business descriptions, and risk disclosures.</p> <p>Document Types in Crowdfunding Filings: - Offering circular (primary offering document) - Business plan materials - Financial statement exhibits - Risk factor disclosures - Use of proceeds descriptions - Management team bios - Market analysis documents</p> <p>Key Sections to Extract: - Company overview and business model - Products and services description - Use of proceeds (how funds will be used) - Risk factors - Competition analysis - Market opportunity - Management team and experience - Terms of the offering</p> <p>Research Questions: - How do we access offering circular documents? - Can we parse structured sections from HTML/text? - How do we extract tables from financial exhibits? - What document search capabilities exist? - How do we identify and classify document types? - Can we extract key business metrics from prose?</p> <p>Document Parsing Approaches: - Use <code>filing.attachments</code> to access all documents - Use <code>filing.document()</code> for primary document - Apply <code>Document.parse()</code> for structure extraction - Use <code>DocumentSearch</code> for keyword/semantic search - Section extraction strategies (pattern, TOC, hybrid) - Table extraction from HTML</p> <p>Potential API Improvements: - Specialized parsing for offering circulars - Pre-defined section extractors (use of proceeds, risks, etc.) - Business description summarization - Risk factor enumeration - Management team parsing - Industry/market classification from text</p> <p>Use Cases: - Sentiment analysis of business descriptions - Risk factor comparison across campaigns - Use of proceeds categorization - Management team experience scoring - Market opportunity assessment - Competitive landscape analysis</p> <p>Success Criteria: - [ ] Can access offering circular and key documents - [ ] Can extract major sections from offering materials - [ ] Can search for specific topics across documents - [ ] Can extract tables and structured data - [ ] Can identify key business information programmatically - [ ] Have documented what document parsing helpers are needed</p>"},{"location":"examples/crowdfunding_research_goals/#4-portal-issuer-analysis","title":"4. Portal &amp; Issuer Analysis","text":"<p>Goal: Analyze patterns across funding portals, compare issuer campaigns, and identify trends in the crowdfunding ecosystem.</p> <p>Funding Portal Analysis:</p> <p>Portal Information Available: - Portal name - Portal CIK - Portal CRD number - Commission file number</p> <p>Research Questions: - How many campaigns does each portal host? - What's the success rate per portal? - What types of industries do portals specialize in? - How do offering terms vary by portal? - What's the average funding amount by portal? - Which portals have the most repeat issuers?</p> <p>Issuer Analysis:</p> <p>Multi-Campaign Issuers: - Companies that run multiple crowdfunding campaigns - Success patterns across campaigns - Financial progression over time - Learning effects (better terms in later campaigns)</p> <p>Research Questions: - How do we find all campaigns from the same issuer? - What's the relationship between first and subsequent campaigns? - Do issuers improve success rates over time? - What's the typical time between campaigns? - How do financial metrics evolve across campaigns?</p> <p>Ecosystem Analysis:</p> <p>Macro Trends: - Industry distribution of campaigns - Geographic concentration - Seasonal patterns in filing activity - Success rates over time - Average offering amounts trending - Portal market share evolution</p> <p>Research Questions: - What industries dominate crowdfunding? - Which states have the most campaigns? - Are success rates improving over time? - How has the market evolved since Regulation CF launched? - What's the distribution of offering amounts? - What percentage of campaigns reach their targets?</p> <p>Query Capabilities Needed: - Filter campaigns by portal - Filter campaigns by issuer CIK - Filter by industry (via SIC code or text classification) - Filter by jurisdiction - Filter by offering amount ranges - Filter by status (active, funded, terminated) - Time series queries for trend analysis</p> <p>Potential API Improvements: - Portal-based campaign querying - Issuer campaign history lookup - Industry classification helpers - Geographic analysis tools - Time series aggregation methods - Success rate calculation utilities - Comparative analysis tools across portals</p> <p>Success Criteria: - [ ] Can retrieve all campaigns for a given portal - [ ] Can find all campaigns from the same issuer - [ ] Can classify campaigns by industry - [ ] Can perform geographic analysis - [ ] Can calculate ecosystem-wide statistics - [ ] Have documented what query and analysis tools are needed</p>"},{"location":"examples/crowdfunding_research_goals/#data-sources-methodology","title":"Data Sources &amp; Methodology","text":""},{"location":"examples/crowdfunding_research_goals/#sample-data-selection","title":"Sample Data Selection","text":"<p>Criteria for Rich Examples: - Complete lifecycle (C \u2192 C-U \u2192 C-AR \u2192 C-TR) - Multiple progress updates - Multi-year annual reports - Successful funding (reached target) - Well-documented offering materials</p> <p>Potential Sample Campaigns: - TBD: Identify 3-5 exemplar campaigns with rich data - Include variety: successful/unsuccessful, different industries, different portals - Document file numbers for easy reference</p>"},{"location":"examples/crowdfunding_research_goals/#test-filings-for-development","title":"Test Filings for Development","text":"<pre><code># Example: Get Q4 2025 filings\nfilings = get_filings(form='C', filing_date='2025-10-01:2025-12-31')\n\n# Example: Access specific filing\nfiling = filings[5]\nformc = filing.obj()\n\n# Example: Get lifecycle\nrelated = filing.related_filings()\n</code></pre>"},{"location":"examples/crowdfunding_research_goals/#api-improvement-tracking","title":"API Improvement Tracking","text":"<p>As we work through these research goals, we'll document:</p>"},{"location":"examples/crowdfunding_research_goals/#missing-data-fields","title":"Missing Data Fields","text":"<ul> <li>[ ] <code>progress_update</code> field in C-U forms (from XML but not parsed)</li> <li>[ ] Amount raised at different milestones</li> <li>[ ] Campaign status indicators</li> <li>[ ] ???</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#missing-helper-methods","title":"Missing Helper Methods","text":"<ul> <li>[ ] <code>percent_funded()</code> - calculate funding progress</li> <li>[ ] <code>days_to_deadline()</code> - time remaining calculation</li> <li>[ ] <code>is_active()</code> - campaign status check</li> <li>[ ] <code>get_updates()</code> - fetch all C-U filings</li> <li>[ ] <code>get_annual_reports()</code> - fetch all C-AR filings</li> <li>[ ] ???</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#missing-classesabstractions","title":"Missing Classes/Abstractions","text":"<ul> <li>[ ] <code>Campaign</code> class - wrapper for related filings lifecycle</li> <li>[ ] <code>FundingPortal</code> enhancements - portal-level analytics</li> <li>[ ] <code>CrowdfundingCampaigns</code> collection class - batch operations</li> <li>[ ] ???</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#missing-query-capabilities","title":"Missing Query Capabilities","text":"<ul> <li>[ ] Filter by portal</li> <li>[ ] Filter by status</li> <li>[ ] Filter by amount raised</li> <li>[ ] Industry classification</li> <li>[ ] Geographic filters</li> <li>[ ] ???</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#document-parsing-gaps","title":"Document Parsing Gaps","text":"<ul> <li>[ ] Offering circular specialized parsing</li> <li>[ ] Section extraction (use of proceeds, risks, etc.)</li> <li>[ ] Business description summarization</li> <li>[ ] ???</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#implementation-notes","title":"Implementation Notes","text":""},{"location":"examples/crowdfunding_research_goals/#current-script-crowdfundingpy","title":"Current Script: <code>crowdfunding.py</code>","text":"<p>Starting Point: - Uses existing filing from Q4 2025 (<code>filings[5]</code>) - Incremental exploration approach - Inline comments documenting API usability - Pause after each step to discuss findings</p> <p>Development Process: 1. Add code for each analysis step 2. Run and observe results 3. Discuss what works well and what's awkward 4. Document API gaps in comments 5. Note potential improvements 6. Continue to next step</p> <p>Documentation: - Keep detailed comments about developer experience - Note \"this was easy\" and \"this was hard\" moments - Document workarounds for missing features - Capture ideas for helper methods/classes as they arise</p>"},{"location":"examples/crowdfunding_research_goals/#next-steps","title":"Next Steps","text":""},{"location":"examples/crowdfunding_research_goals/#immediate-current-session","title":"Immediate (Current Session)","text":"<ul> <li>[x] Create this research goals document</li> <li>[ ] Begin Focus Area 1: Campaign Lifecycle Tracking</li> <li>[ ] Develop <code>crowdfunding.py</code> incrementally</li> <li>[ ] Document findings as we go</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#short-term","title":"Short Term","text":"<ul> <li>[ ] Complete lifecycle tracking exploration</li> <li>[ ] Identify top 5 API improvements needed</li> <li>[ ] Create sample \"ideal API\" code snippets</li> <li>[ ] Choose exemplar campaigns for future research</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#medium-term","title":"Medium Term","text":"<ul> <li>[ ] Explore Focus Area 2: Financial Analysis</li> <li>[ ] Explore Focus Area 3: Document Content Extraction</li> <li>[ ] Explore Focus Area 4: Portal &amp; Issuer Analysis</li> <li>[ ] Compile comprehensive API improvement proposal</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#long-term","title":"Long Term","text":"<ul> <li>[ ] Implement high-priority API improvements</li> <li>[ ] Create crowdfunding analytics dashboard example</li> <li>[ ] Develop specialized crowdfunding analysis tools</li> <li>[ ] Build ML models for campaign success prediction</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#resources","title":"Resources","text":""},{"location":"examples/crowdfunding_research_goals/#sec-regulations","title":"SEC Regulations","text":"<ul> <li>Regulation Crowdfunding</li> <li>Form C Instructions: SEC.gov</li> </ul>"},{"location":"examples/crowdfunding_research_goals/#edgartools-documentation","title":"EdgarTools Documentation","text":"<ul> <li>Form C API: <code>edgar/offerings/formc.py</code></li> <li>Filing access: <code>edgar/_filings.py</code></li> <li>Document parsing: <code>edgar/documents/</code></li> </ul>"},{"location":"examples/crowdfunding_research_goals/#test-suite","title":"Test Suite","text":"<ul> <li>Tests: <code>tests/test_formc_offerings.py</code></li> <li>Batch tests: <code>tests/batch/batch_formc.py</code></li> <li>Sample data: <code>data/</code> directory</li> </ul> <p>Last Updated: 2025-11-04 Status: Living document - updated as research progresses</p>"},{"location":"examples/user_journeys/","title":"User Journeys: Solve Real Problems with EdgarTools","text":"<p>This document showcases common workflows and tasks that financial professionals, developers, and researchers can accomplish using EdgarTools. Each journey addresses a specific problem and provides a concise code example.</p> 1. Company Financial Analysis - Analyze a company's financial health across multiple periods  **Problem:** Need to analyze a company's financial health across multiple periods.   <pre><code>from edgar import find\n\n# Get Microsoft's financial data for the last 3 years\ncompany = find(\"MSFT\")\nfinancials = company.financials()\n\n# Compare key metrics across years\nrevenue = financials.extract(\"Revenues\")\nnet_income = financials.extract(\"NetIncomeLoss\")\n\n# Create a financial dashboard\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10, 6))\nrevenue.plot(kind='bar', ax=ax, position=1, width=0.3, color='blue', alpha=0.7)\nnet_income.plot(kind='bar', ax=ax, position=0, width=0.3, color='green', alpha=0.7)\n\nax.set_title('Microsoft Financial Performance')\nax.legend(['Revenue', 'Net Income'])\nax.set_ylabel('USD (millions)')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n</code></pre> 2. Investment Fund Research - Analyze fund holdings and compare share classes  **Problem:** Need to analyze fund holdings and compare share classes.   <pre><code>from edgar import find\n\n# Find a fund by ticker - returns a FundClass\nfund_class = find(\"VFIAX\")  # Vanguard 500 Index Fund Admiral Shares\nprint(fund_class)  # FundClass(Admiral Shares [C000245415] - VFIAX)\n\n# Navigate to the fund series (the underlying fund)\nseries = fund_class.series\nprint(series)  # FundSeries(Vanguard 500 Index Fund [S000082144])\n\n# Get all share classes for this fund\nclasses = series.get_classes()\nprint(f\"Fund has {len(classes)} share classes\")\nfor cls in classes:\n    print(f\"  - {cls.name}: {cls.ticker}\")\n\n# Get the fund company (investment company that manages the fund)\nfund_company = series.fund_company\nprint(f\"Managed by: {fund_company}\")\n\n# Get portfolio holdings from NPORT filings\nnport_filings = series.get_filings(form='NPORT-P')\nif nport_filings:\n    latest_nport = nport_filings[0]\n    nport = latest_nport.obj()  # Parse the NPORT filing\n\n    # Access holdings data\n    holdings = nport.investments_dataframe\n    print(f\"Total holdings: {len(holdings)}\")\n\n    # Show top 10 holdings by value\n    top_holdings = holdings.nlargest(10, 'value')[['name', 'value', 'pctVal']]\n    print(top_holdings)\n</code></pre> 3. Insider Trading Analysis - Monitor insider transactions for investment signals  **Problem:** Monitor insider transactions for investment signals.   <pre><code>from edgar import find, get_insider_transaction_filings\n\n# Get recent insider transactions for Tesla\ncompany = find(\"TSLA\")\ninsider_filings = company.get_filings(form=[3, 4, 5], limit=20)\n\n# Extract and analyze the transactions\ntransactions = []\nfor filing in insider_filings:\n    form = obj(filing)\n    if hasattr(form, 'transactions') and form.transactions is not None:\n        for t in form.transactions:\n            transactions.append({\n                'date': t.transaction_date,\n                'name': form.reporting_owner.name,\n                'title': form.reporting_owner.title or 'Unknown',\n                'type': t.transaction_code,\n                'shares': t.shares,\n                'price': t.price_per_share,\n                'value': t.shares * t.price_per_share if t.price_per_share else None\n            })\n\n# Convert to DataFrame and analyze\nimport pandas as pd\ntx_df = pd.DataFrame(transactions)\n\n# Summarize by transaction type\ntx_df.groupby('type').agg({\n    'shares': 'sum',\n    'value': 'sum'\n}).sort_values('value', ascending=False)\n</code></pre> 4. SEC Filing Discovery - Find specific types of filings across companies or time periods  **Problem:** Find specific types of filings across companies or time periods.   <pre><code>from edgar import get_filings\n\n# Get all 8-K filings (material events) from the last week\nrecent_8ks = get_filings(form=\"8-K\", limit=50)\n\n# Filter to find filings mentioning \"acquisition\"\nacquisition_filings = []\nfor filing in recent_8ks:\n    text = filing.text()\n    if text and \"acquisition\" in text.lower():\n        acquisition_filings.append({\n            'company': filing.company_name,\n            'date': filing.filing_date,\n            'accession_no': filing.accession_no,\n            'items': filing.items if hasattr(filing, 'items') else None\n        })\n\n# Convert to DataFrame\nimport pandas as pd\npd.DataFrame(acquisition_filings)\n</code></pre> 5. Financial Data Extraction - Extract structured financial data for analysis or modeling  **Problem:** Extract structured financial data for analysis or modeling.   <pre><code>from edgar import find, obj\n\n# Get the latest 10-Q for Amazon\ncompany = find(\"AMZN\")\nlatest_10q = company.get_filings(form=\"10-Q\")[0]\ntenq = obj(latest_10q)\n\n# Extract all financial statements\nbalance_sheet = tenq.financials.balance_sheet\nincome_statement = tenq.financials.income_statement\ncash_flow = tenq.financials.cash_flow\n\n# Calculate key financial ratios\ncurrent_ratio = balance_sheet.loc['AssetsCurrent'] / balance_sheet.loc['LiabilitiesCurrent']\ndebt_to_equity = balance_sheet.loc['Liabilities'] / balance_sheet.loc['StockholdersEquity']\nnet_margin = income_statement.loc['NetIncomeLoss'] / income_statement.loc['Revenues']\n\nprint(f\"Current Ratio: {current_ratio.iloc[0]:.2f}\")\nprint(f\"Debt-to-Equity: {debt_to_equity.iloc[0]:.2f}\")\nprint(f\"Net Margin: {net_margin.iloc[0]:.2%}\")\n</code></pre> 6. Fund Holdings Analysis - Analyze what stocks funds are holding and track changes  **Problem:** Analyze what stocks funds are holding and track changes.   <pre><code>from edgar import find\n\n# Find a major investment manager\nblackrock = find(\"BLK\")\n\n# Get their recent 13F filings\nfilings_13f = blackrock.get_filings(form=\"13F-HR\", limit=2)\n\n# Extract holdings from the two most recent quarters\ncurrent_quarter = obj(filings_13f[0])\nprevious_quarter = obj(filings_13f[1])\n\n# Compare holdings between quarters\ncurrent_holdings = current_quarter.holdings\nprevious_holdings = previous_quarter.holdings\n\n# Merge to compare\nimport pandas as pd\nmerged = pd.merge(current_holdings, previous_holdings, \n                   on='nameOfIssuer', suffixes=('_current', '_previous'))\n\n# Calculate changes\nmerged['value_change'] = merged['value_current'] - merged['value_previous']\nmerged['value_change_pct'] = (merged['value_change'] / merged['value_previous']) * 100\n\n# Show biggest position increases\nmerged.sort_values('value_change', ascending=False).head(10)\n</code></pre> 7. Regulatory Filing Monitoring - Stay updated on new filings from watched companies  **Problem:** Stay updated on new filings from watched companies.   <pre><code>from edgar import find, get_current_filings\n\n# Define a watchlist of companies\nwatchlist = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\nwatchlist_ciks = [find(ticker).cik for ticker in watchlist]\n\n# Get today's filings\ntoday_filings = get_current_filings()\n\n# Filter to only show filings from companies on our watchlist\nwatchlist_filings = today_filings[today_filings.cik.isin(watchlist_ciks)]\n\n# Display the filings\nwatchlist_filings[['company_name', 'form', 'filing_date', 'html_link']]\n</code></pre> 8. AI/LLM Integration - Clean, structured text from SEC filings for AI analysis or LLM processing  **Problem:** Need clean, structured text from SEC filings for AI analysis or LLM processing.   <pre><code>from edgar import find\n\n# Get a 10-K filing\ncompany = find(\"NVDA\")  # NVIDIA\nfiling = company.get_filings(form=\"10-K\")[0]\n\n# Extract clean, readable text (not raw HTML)\nclean_text = filing.text()\n\n# View the formatted text in a notebook or terminal\nfiling.view()\n\n# Extract specific sections for targeted analysis\nrisk_factors = filing.get_section(\"Item 1A\", \"Risk Factors\")\n\n# Chunk text for LLM context windows\nchunks = filing.chunk_text(chunk_size=4000, overlap=200)\n\n# Process with your favorite LLM library\nfrom langchain.llms import OpenAI\n\nllm = OpenAI()\nfor i, chunk in enumerate(chunks[:3]):  # Process first 3 chunks as example\n    print(f\"Analysis of chunk {i+1}:\n\")\n    response = llm.generate([f\"Summarize the key points in this SEC filing text: {chunk}\"])\n    print(response.generations[0][0].text)\n    print(\"\\n---\\n\")\n</code></pre>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/","title":"Enhanced 13F Manager Properties - Feature Request","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#executive-summary","title":"Executive Summary","text":"<p>This feature request proposes enhanced manager property APIs for EdgarTools' 13F functionality to address critical user experience gaps identified through user feedback. The enhancement transforms confusing property names into intuitive, well-documented interfaces while adding portfolio manager lookup capabilities to provide the famous investor names users actually want.</p> <p>Status: \u2705 IMPLEMENTED - Ready for evaluation and rollout</p> <p>Product Impact: High - Directly addresses user frustration and democratizes access to portfolio manager information</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#1-background-user-problem","title":"1. Background &amp; User Problem","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#real-user-feedback-reddit-user-tony","title":"Real User Feedback (Reddit User \"Tony\")","text":"<p>Critical Documentation Bug:  - Documentation shows <code>thirteen_f.manager_name</code> but property doesn't exist - User confusion and frustration with existing API</p> <p>User Expectation Gap: - Users want: Famous portfolio manager names (e.g., \"Warren Buffett\")  - 13F Reality: Only contains company names and administrative signers - Current API: <code>investment_manager.name</code> returns \"Berkshire Hathaway Inc\" - Current API: <code>signer</code> returns \"Marc D. Hamburg\" (administrative officer, not Warren Buffett)</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#core-ux-issues","title":"Core UX Issues","text":"<ol> <li>Misleading Property Names: Users expect <code>manager_name</code> to return individual manager names</li> <li>Confusing Administrative Data: Signers are typically CFOs/CCOs, not portfolio managers</li> <li>Missing Context: No way to understand what information is available vs. what users want</li> <li>Data Limitations Hidden: Users don't understand 13F filing constraints</li> </ol>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#2-market-analysis","title":"2. Market Analysis","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#21-user-demand-assessment","title":"2.1 User Demand Assessment","text":"<ul> <li>High Priority: Portfolio manager information is core to investment research</li> <li>Widespread Need: Affects both beginner and advanced users</li> <li>Competitive Differentiation: Most libraries provide raw data without context or enhancement</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#22-competitive-landscape-analysis","title":"2.2 Competitive Landscape Analysis","text":"<p>Current Market Solutions: 1. SEC EDGAR Direct: Raw filing data only, no manager enhancement 2. WhaleWisdom, GuruFocus: Curated manager databases with subscription fees 3. Bloomberg/FactSet: Premium institutional solutions ($10,000+ annually) 4. Open Source Libraries: Typically provide raw data without enhancement</p> <p>EdgarTools Opportunity: - Unique positioning: Free, beginner-friendly access to enhanced manager data - Clear competitive advantage: Beautiful UX with transparency about data limitations - Market gap: No open-source solution provides curated manager information</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#23-implementation-complexity-vs-user-value","title":"2.3 Implementation Complexity vs. User Value","text":"<p>High Value, Medium Complexity: - Solves real user pain points immediately - Enhances brand reputation as most user-friendly SEC library - Creates foundation for advanced portfolio analysis features</p> <p>Complexity Assessment: - \u2705 Low: Enhanced property names (already implemented) - \u2705 Medium: Curated manager database (already implemented) - \ud83d\udd04 Medium-High: External data source integration (future enhancement)</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#3-feature-specification","title":"3. Feature Specification","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#31-enhanced-property-apis-implemented","title":"3.1 Enhanced Property APIs (\u2705 Implemented)","text":"<pre><code># Clear, intuitive property names\nthirteen_f.management_company_name  # \"Berkshire Hathaway Inc\"\nthirteen_f.filing_signer_name      # \"Marc D. Hamburg\"  \nthirteen_f.filing_signer_title     # \"Senior Vice President\"\n\n# Deprecated with helpful warning\nthirteen_f.manager_name  # Warns: Use management_company_name or get_portfolio_managers()\n</code></pre>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#32-portfolio-manager-lookup-implemented","title":"3.2 Portfolio Manager Lookup (\u2705 Implemented)","text":"<pre><code># Get actual portfolio managers\nmanagers = thirteen_f.get_portfolio_managers()\n# Returns: [{'name': 'Warren Buffett', 'title': 'Chairman &amp; CEO', 'status': 'active', ...}]\n\n# Comprehensive manager information\ninfo = thirteen_f.get_manager_info_summary()\n# Returns structured breakdown of filing vs. external data\n</code></pre>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#33-smart-analysis-implemented","title":"3.3 Smart Analysis (\u2705 Implemented)","text":"<pre><code># Determine if signer is likely a portfolio manager\nis_pm = thirteen_f.is_filing_signer_likely_portfolio_manager()  # False for administrative roles\n</code></pre>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#4-product-principle-alignment","title":"4. Product Principle Alignment","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#simple-yet-powerful","title":"\u2705 Simple yet Powerful","text":"<ul> <li>Simple: Clear property names, sensible defaults</li> <li>Powerful: Portfolio manager lookup, comprehensive data analysis</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#accurate-financials","title":"\u2705 Accurate Financials","text":"<ul> <li>Transparency: Clear separation of filing data vs. external sources</li> <li>Reliability: Curated database with status tracking and timestamps</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#beginner-friendly","title":"\u2705 Beginner-Friendly","text":"<ul> <li>Intuitive: Property names match user expectations</li> <li>Educational: Helpful warnings explain data limitations</li> <li>Contextual: Summary methods explain what information is available</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#joyful-ux","title":"\u2705 Joyful UX","text":"<ul> <li>Eliminates Frustration: Fixes documentation bugs and confusing property names</li> <li>Exceeds Expectations: Provides manager names users actually want</li> <li>Professional: Comprehensive error handling and deprecation warnings</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#beautiful-output","title":"\u2705 Beautiful Output","text":"<ul> <li>Rich Display: Enhanced console output with proper formatting</li> <li>Structured Data: Clean JSON responses for programmatic use</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#5-implementation-assessment","title":"5. Implementation Assessment","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#51-technical-implementation-quality","title":"5.1 Technical Implementation Quality","text":"<p>Code Review Score: A+ - Clean, maintainable implementation with excellent documentation - Comprehensive error handling and user-friendly warnings - Backward compatibility with deprecation strategy - Extensive inline documentation with examples</p> <p>Key Strengths: 1. Clear API Design: Intuitive method names and return structures 2. Extensible Architecture: Easy to add new portfolio managers or data sources 3. Transparent Data Sourcing: Clear indication of data limitations and sources 4. Production Ready: Proper error handling and edge case management</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#52-data-strategy-assessment","title":"5.2 Data Strategy Assessment","text":"<p>Current Approach: Curated Database - \u2705 Pros: Immediate functionality, full control, no external dependencies - \u26a0\ufe0f Cons: Manual maintenance required, limited coverage initially</p> <p>Future Enhancement Options: 1. External API Integration: Services like GuruFocus, WhaleWisdom APIs 2. Web Scraping: Automated collection from public sources 3. Community Contributions: GitHub-based manager database submissions 4. Machine Learning: Automated manager detection from news/filings</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#6-risk-assessment","title":"6. Risk Assessment","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#61-data-accuracy-risks","title":"6.1 Data Accuracy Risks","text":"<p>Risk Level: Low-Medium - Mitigation: Clear data source attribution and last-updated timestamps - Mitigation: Status tracking (active, retired, deceased) with dates - Mitigation: Transparent limitations documentation</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#62-legalcompliance-risks","title":"6.2 Legal/Compliance Risks","text":"<p>Risk Level: Very Low - Using only publicly available information - Clear attribution to public sources - No proprietary financial advice or recommendations</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#63-maintenance-overhead","title":"6.3 Maintenance Overhead","text":"<p>Risk Level: Medium - Initial: Manual curation of well-known managers - Ongoing: Periodic updates to manager status and new additions - Mitigation: Community contribution framework for scaling</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#64-user-expectation-management","title":"6.4 User Expectation Management","text":"<p>Risk Level: Low - Mitigation: Comprehensive documentation about data limitations - Mitigation: Clear status indicators and source attribution - Mitigation: Educational warnings about 13F filing constraints</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#7-success-metrics","title":"7. Success Metrics","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#71-user-experience-metrics","title":"7.1 User Experience Metrics","text":"<ul> <li>Documentation Bug Reports: Target 0% related to manager properties</li> <li>User Confusion Issues: Target 50% reduction in related GitHub issues</li> <li>API Adoption Rate: Track usage of new vs. deprecated properties</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#72-product-quality-metrics","title":"7.2 Product Quality Metrics","text":"<ul> <li>Data Accuracy: Target 95%+ accuracy for active manager status</li> <li>Coverage: Target 100+ well-known portfolio managers in initial database</li> <li>Response Quality: User satisfaction scores for manager information</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#73-strategic-metrics","title":"7.3 Strategic Metrics","text":"<ul> <li>Community Growth: Increased GitHub stars and user engagement</li> <li>Competitive Position: Enhanced reputation as most user-friendly SEC library</li> <li>Feature Foundation: Basis for advanced portfolio analysis features</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#8-rollout-strategy","title":"8. Rollout Strategy","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#81-phase-1-immediate-week-1","title":"8.1 Phase 1: Immediate (Week 1)","text":"<ul> <li>\u2705 Code Review: Implementation assessment and testing</li> <li>\u2705 Documentation Update: Fix existing doc bugs and add new features</li> <li>\u2705 Deprecation Warnings: Deploy helpful warnings for old properties</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#82-phase-2-enhanced-coverage-weeks-2-4","title":"8.2 Phase 2: Enhanced Coverage (Weeks 2-4)","text":"<ul> <li>Database Expansion: Add 50+ well-known portfolio managers</li> <li>Community Framework: GitHub templates for manager data contributions  </li> <li>Integration Testing: Comprehensive testing across diverse 13F filings</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#83-phase-3-advanced-features-months-2-3","title":"8.3 Phase 3: Advanced Features (Months 2-3)","text":"<ul> <li>External API Integration: Explore partnerships with data providers</li> <li>Machine Learning Enhancement: Automated manager detection research</li> <li>Advanced Analytics: Portfolio manager performance tracking</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#84-marketing-communication","title":"8.4 Marketing &amp; Communication","text":"<ul> <li>Blog Post: \"How EdgarTools Makes Portfolio Manager Data Accessible\"</li> <li>Reddit Response: Direct response to original user feedback</li> <li>Documentation Showcase: Prominent feature in getting-started guides</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#9-resource-requirements","title":"9. Resource Requirements","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#91-development-resources","title":"9.1 Development Resources","text":"<ul> <li>Initial: Already completed by expert Python developer</li> <li>Ongoing: 2-4 hours monthly for database updates</li> <li>Future: 1-2 weeks for external API integration</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#92-data-resources","title":"9.2 Data Resources","text":"<ul> <li>Curated Database: Manual research for well-known managers</li> <li>External Sources: Potential API subscriptions for broader coverage</li> <li>Community: Framework for user-contributed manager information</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#93-documentation-resources","title":"9.3 Documentation Resources","text":"<ul> <li>API Documentation: Comprehensive property and method documentation</li> <li>Tutorial Content: Examples for different user skill levels</li> <li>Educational Material: 13F filing limitations and data interpretation</li> </ul>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#10-recommendation","title":"10. Recommendation","text":""},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#proceed-immediately","title":"\u2705 PROCEED IMMEDIATELY","text":"<p>Rationale: 1. User Problem: Addresses real, documented user frustration 2. Implementation Quality: Professional, production-ready code 3. Strategic Alignment: Perfect fit with EdgarTools' core principles 4. Competitive Advantage: Unique positioning in open-source market 5. Foundation Building: Enables advanced portfolio analysis features</p> <p>Risk-Adjusted Value: Very High - Low implementation risk (already completed) - High user satisfaction impact - Strong competitive differentiation - Minimal ongoing maintenance burden</p>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#next-steps","title":"Next Steps:","text":"<ol> <li>Code Review: Final assessment and testing</li> <li>Documentation Update: Fix bugs and showcase new features  </li> <li>Community Announcement: Share enhancement with user base</li> <li>Database Expansion: Add more well-known portfolio managers</li> <li>Feedback Collection: Monitor user response and iterate</li> </ol>"},{"location":"feature-requests/enhanced-13f-manager-properties-feature-request/#11-long-term-vision","title":"11. Long-Term Vision","text":"<p>This enhancement positions EdgarTools as the definitive open-source solution for accessible, transparent financial data. By combining accurate SEC filing data with thoughtfully curated enhancements, we create a best-of-both-worlds experience that democratizes institutional investment research.</p> <p>Future Opportunities: - Portfolio manager performance analytics - Manager style analysis and categorization - Historical manager transition tracking - Institutional investment trend analysis - Educational content about investment strategies</p> <p>The enhanced 13F manager properties represent EdgarTools' commitment to transforming complex financial data into accessible, actionable insights for Python developers of all skill levels.</p> <p>This feature request demonstrates EdgarTools' product philosophy: Start with user frustration, design elegant solutions, maintain data accuracy, and build foundations for future innovation.</p>"},{"location":"feature-requests/s4-target-company-linking-specification/","title":"S-4 Target Company Linking Feature Specification","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#overview","title":"Overview","text":"<p>This specification defines a new feature for EdgarTools that enables automatic extraction and linking of target company information from S-4 merger/acquisition filings. The feature provides structured access to target company identifiers and, when applicable, links to the target company's existing SEC filings.</p>"},{"location":"feature-requests/s4-target-company-linking-specification/#user-benefits","title":"User Benefits","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#primary-value-proposition","title":"Primary Value Proposition","text":"<ul> <li>Automated Target Discovery: Eliminate manual parsing of S-4 filings to identify merger targets</li> <li>Structured Data Access: Get reliable target company identifiers (EIN, SIC, state) without regex parsing</li> <li>Seamless Navigation: Direct links to target company filings when target is publicly traded</li> <li>Due Diligence Support: Streamlined access to both acquirer and target company information</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#target-user-groups","title":"Target User Groups","text":"<ol> <li>M&amp;A Analysts: Track merger activity, identify transaction patterns, analyze deal structures</li> <li>Investment Researchers: Monitor SPAC mergers, evaluate target companies, assess deal valuations</li> <li>Compliance Officers: Track beneficial ownership changes, monitor related party transactions</li> <li>Academic Researchers: Study merger trends, analyze market consolidation patterns</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#technical-implementation-approach","title":"Technical Implementation Approach","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#core-architecture","title":"Core Architecture","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#1-s4targetcompanyextractor-class","title":"1. S4TargetCompanyExtractor Class","text":"<pre><code>class S4TargetCompanyExtractor:\n    \"\"\"Extracts target company information from S-4 filings using multiple structured data sources.\"\"\"\n\n    def __init__(self, filing: Filing):\n        self.filing = filing\n        self._cached_target_info = None\n        self._cached_xbrl_facts = None\n\n    def extract_target_info(self) -&gt; Optional[TargetCompanyInfo]:\n        \"\"\"Primary method to extract comprehensive target company information.\"\"\"\n        pass\n\n    def _extract_from_coregistrant_table(self) -&gt; Optional[Dict]:\n        \"\"\"Extract from Co-Registrant table - highest reliability method.\"\"\"\n        pass\n\n    def _extract_from_xbrl_facts(self) -&gt; Optional[Dict]:\n        \"\"\"Extract from XBRL business combination facts.\"\"\" \n        pass\n\n    def _extract_from_filing_header(self) -&gt; Optional[Dict]:\n        \"\"\"Extract from structured filing header information.\"\"\"\n        pass\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#2-targetcompanyinfo-data-structure","title":"2. TargetCompanyInfo Data Structure","text":"<pre><code>@dataclass\nclass TargetCompanyInfo:\n    \"\"\"Structured container for target company information extracted from S-4 filings.\"\"\"\n\n    # Core identifiers\n    name: str\n    ein: Optional[str] = None  # Tax ID (always available for US entities)\n    sic_code: Optional[str] = None  # Standard Industrial Classification\n    incorporation_state: Optional[str] = None\n\n    # Additional structured data\n    address: Optional[Address] = None\n    business_description: Optional[str] = None\n\n    # SEC filing linkage (only for public companies)\n    cik: Optional[int] = None  # Central Index Key for SEC filings\n    ticker: Optional[str] = None  # Stock ticker symbol\n    exchange: Optional[str] = None  # Stock exchange\n\n    # Extraction metadata\n    extraction_method: str  # Which method successfully extracted the data\n    confidence_level: str  # High/Medium/Low based on extraction method\n    extraction_timestamp: datetime = field(default_factory=datetime.now)\n\n    @property\n    def is_public_company(self) -&gt; bool:\n        \"\"\"Returns True if target has a CIK (is publicly traded).\"\"\"\n        return self.cik is not None\n\n    @property \n    def filings(self) -&gt; Optional[CompanyFilings]:\n        \"\"\"Get target company filings if it's a public company.\"\"\"\n        if self.cik:\n            from edgar.entity import Company\n            return Company(self.cik).get_filings()\n        return None\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#phase-1-core-extraction-engine","title":"Phase 1: Core Extraction Engine","text":"<ol> <li>Co-Registrant Table Parser</li> <li>HTML table parsing with BeautifulSoup integration</li> <li>Structured field extraction (EIN, SIC, state)</li> <li>Error handling for malformed tables</li> <li> <p>High confidence scoring</p> </li> <li> <p>XBRL Business Combination Facts Parser</p> </li> <li>Integration with existing XBRL infrastructure</li> <li>Business combination taxonomy filtering</li> <li>Fact validation and cross-referencing</li> <li> <p>Medium confidence scoring</p> </li> <li> <p>Filing Header Parser</p> </li> <li>Extend existing FilingHeader class</li> <li>Target company pattern recognition</li> <li>Address and contact extraction</li> <li>Low-medium confidence scoring</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#phase-2-public-company-linking","title":"Phase 2: Public Company Linking","text":"<ol> <li>CIK Resolution Service</li> <li>EIN-to-CIK mapping using SEC company tickers data</li> <li>Company name fuzzy matching for disambiguation</li> <li> <p>Historical name change handling</p> </li> <li> <p>Target Company Integration</p> </li> <li>Seamless Company object creation for public targets</li> <li>Automatic filing retrieval</li> <li>Cross-reference validation</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#phase-3-enhanced-features","title":"Phase 3: Enhanced Features","text":"<ol> <li>Deal Timeline Construction</li> <li>Link related S-4 amendments</li> <li>Track merger completion status</li> <li> <p>Integration with 8-K current reports</p> </li> <li> <p>Bulk Analysis Tools</p> </li> <li>Batch processing for multiple S-4 filings</li> <li>M&amp;A trend analysis utilities</li> <li>Export capabilities for research</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#api-design-examples","title":"API Design Examples","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#basic-usage-pattern","title":"Basic Usage Pattern","text":"<pre><code>from edgar import Company\n\n# Get S-4 filing\nacquirer = Company(\"ARES\") # Ares Acquisition Corp II\ns4_filings = acquirer.get_filings(form=\"S-4\")\ns4_filing = s4_filings[0]\n\n# Extract target company information\ntarget_info = s4_filing.target_company\nprint(target_info.name)  # \"Kodiak Robotics, Inc.\"\nprint(target_info.ein)   # \"82-5086710\"\nprint(target_info.sic_code)  # \"7373\"\nprint(target_info.incorporation_state)  # \"Delaware\"\n\n# Check if target is public\nif target_info.is_public_company:\n    target_filings = target_info.filings\n    print(f\"Target has {len(target_filings)} SEC filings\")\nelse:\n    print(\"Target is a private company\")\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#advanced-analysis-pattern","title":"Advanced Analysis Pattern","text":"<pre><code># Batch analysis of recent SPAC mergers\nspac_s4s = get_filings(year=2024, form=\"S-4\")\n\nmerger_analysis = []\nfor filing in spac_s4s:\n    if filing.target_company:\n        target = filing.target_company\n        analysis = {\n            'acquirer': filing.company,\n            'target': target.name,\n            'target_sic': target.sic_code,\n            'target_state': target.incorporation_state,\n            'is_public_target': target.is_public_company,\n            'filing_date': filing.filing_date\n        }\n        merger_analysis.append(analysis)\n\n# Convert to DataFrame for analysis\nimport pandas as pd\ndf = pd.DataFrame(merger_analysis)\nprint(df.target_sic.value_counts())  # Industry distribution\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#integration-with-existing-filing-class","title":"Integration with Existing Filing Class","text":"<pre><code>class Filing:\n    # ... existing methods ...\n\n    @cached_property\n    def target_company(self) -&gt; Optional[TargetCompanyInfo]:\n        \"\"\"Extract target company information for S-4 filings.\"\"\"\n        if self.form.startswith('S-4'):\n            extractor = S4TargetCompanyExtractor(self)\n            return extractor.extract_target_info()\n        return None\n\n    @cached_property\n    def is_merger_filing(self) -&gt; bool:\n        \"\"\"Returns True if this is a merger/acquisition related filing.\"\"\"\n        merger_forms = ['S-4', 'S-4/A', 'DEFM14A', 'PREM14A']\n        return self.form in merger_forms\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#data-extraction-methods","title":"Data Extraction Methods","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#method-1-co-registrant-table-parsing-primary-high-confidence","title":"Method 1: Co-Registrant Table Parsing (Primary - High Confidence)","text":"<p>Target HTML Pattern:</p> <pre><code>&lt;table&gt;\n    &lt;tr&gt;&lt;th colspan=\"2\"&gt;Table of Co-Registrants&lt;/th&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;Exact name of registrant as specified in its charter:&lt;/td&gt;&lt;td&gt;Kodiak Robotics, Inc.&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;State of incorporation:&lt;/td&gt;&lt;td&gt;Delaware&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;Primary Standard Industrial Classification Code Number:&lt;/td&gt;&lt;td&gt;7373&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td&gt;I.R.S. Employer Identification Number:&lt;/td&gt;&lt;td&gt;82-5086710&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n</code></pre> <p>Extraction Logic:</p> <pre><code>def _extract_from_coregistrant_table(self) -&gt; Optional[Dict]:\n    \"\"\"Extract structured data from Co-Registrant table.\"\"\"\n    html_content = self.filing.html()\n    if not html_content:\n        return None\n\n    soup = BeautifulSoup(html_content, 'html.parser')\n\n    # Find tables containing co-registrant information\n    tables = soup.find_all('table')\n\n    for table in tables:\n        table_text = table.get_text().lower()\n        if 'co-registrant' in table_text and 'exact name' in table_text:\n            return self._parse_coregistrant_table(table)\n\n    return None\n\ndef _parse_coregistrant_table(self, table) -&gt; Dict:\n    \"\"\"Parse individual co-registrant table for structured data.\"\"\"\n    extracted = {}\n    rows = table.find_all('tr')\n\n    for row in rows:\n        cells = row.find_all(['td', 'th'])\n        if len(cells) == 2:\n            field_name = cells[0].get_text().strip().lower()\n            field_value = cells[1].get_text().strip()\n\n            if 'exact name' in field_name and 'charter' in field_name:\n                extracted['name'] = field_value\n            elif 'state of incorporation' in field_name:\n                extracted['incorporation_state'] = field_value\n            elif 'classification code' in field_name:\n                extracted['sic_code'] = field_value\n            elif 'employer identification' in field_name:\n                ein_match = re.search(r'(\\d{2}-\\d{7})', field_value)\n                if ein_match:\n                    extracted['ein'] = ein_match.group(1)\n\n    return extracted if extracted else None\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#method-2-xbrl-business-combination-facts-secondary-medium-confidence","title":"Method 2: XBRL Business Combination Facts (Secondary - Medium Confidence)","text":"<p>Target XBRL Facts:</p> <pre><code>business_combination_concepts = [\n    'aact:BusinessCombinationConsiderationTransferredEquityInterestsIssuedAndIssuableValueOfAssetsGiven',\n    'aact:BusinessCombinationFairValueOfIdentifiableAssetsAcquiredAndLiabilitiesAssumedAtAcquisitionDate',\n    'aact:BusinessCombinationAcquiredEntityName',  # Target company name\n    'aact:BusinessCombinationAcquisitionDate',\n]\n</code></pre> <p>Extraction Logic:</p> <pre><code>def _extract_from_xbrl_facts(self) -&gt; Optional[Dict]:\n    \"\"\"Extract business combination facts from XBRL data.\"\"\"\n    xbrl = self.filing.xbrl()\n    if not xbrl:\n        return None\n\n    facts = xbrl.facts.get_facts()\n    bc_facts = {}\n\n    for fact in facts:\n        concept = fact.get('concept', '')\n\n        # Target company name from XBRL\n        if 'AcquiredEntityName' in concept:\n            bc_facts['name'] = fact.get('value')\n        elif 'AcquisitionDate' in concept:\n            bc_facts['acquisition_date'] = fact.get('value')\n        elif 'BusinessCombination' in concept:\n            # Store all business combination facts for context\n            bc_facts[concept] = fact.get('value')\n\n    return bc_facts if bc_facts else None\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#method-3-filing-header-patterns-tertiary-low-medium-confidence","title":"Method 3: Filing Header Patterns (Tertiary - Low-Medium Confidence)","text":"<p>Target Header Patterns:</p> <pre><code>FILER:\n    COMPANY DATA:\n        COMPANY CONFORMED NAME: Kodiak Robotics, Inc.\n        CENTRAL INDEX KEY: [Not available for private companies]\n        IRS NUMBER: 82-5086710\n        STATE OF INCORPORATION: DE\n</code></pre> <p>Extraction Logic:</p> <pre><code>def _extract_from_filing_header(self) -&gt; Optional[Dict]:\n    \"\"\"Extract target company information from filing header structures.\"\"\"\n    header = self.filing.header\n    if not header:\n        return None\n\n    # Check for multiple filers (registrant + target)\n    filers = header.filers\n    if len(filers) &gt; 1:\n        # Second filer is typically the target company\n        target_filer = filers[1]\n        return {\n            'name': target_filer.company_information.name,\n            'ein': target_filer.company_information.irs_number,\n            'incorporation_state': target_filer.company_information.state_of_incorporation,\n            'cik': target_filer.company_information.cik\n        }\n\n    return None\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#edge-cases-and-limitations","title":"Edge Cases and Limitations","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#known-edge-cases","title":"Known Edge Cases","text":"<ol> <li>Multiple Target Companies: Some S-4 filings involve multiple acquisition targets</li> <li>Cross-Border Mergers: Foreign target companies may have different identifier formats</li> <li>Shell Company Mergers: SPAC transactions have unique disclosure patterns</li> <li>Amendment Filings: S-4/A amendments may have different structured data locations</li> <li>Historical Format Variations: Older filings (pre-2010) may use different table formats</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#technical-limitations","title":"Technical Limitations","text":"<ol> <li>Private Company CIK Resolution: Private companies don't have SEC CIKs</li> <li>EIN Availability: Some foreign entities may not have US Tax IDs</li> <li>HTML Parsing Sensitivity: Malformed HTML can break table parsing</li> <li>False Positive Management: Generic company name patterns may match unrelated entities</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#handling-strategy","title":"Handling Strategy","text":"<pre><code>class S4TargetCompanyExtractor:\n    def extract_target_info(self) -&gt; Optional[TargetCompanyInfo]:\n        \"\"\"Primary extraction method with fallback strategy.\"\"\"\n\n        # Try highest confidence method first\n        target_data = self._extract_from_coregistrant_table()\n        confidence = \"high\"\n        method = \"coregistrant_table\"\n\n        # Fallback to medium confidence methods\n        if not target_data:\n            target_data = self._extract_from_xbrl_facts()\n            confidence = \"medium\"\n            method = \"xbrl_facts\"\n\n        if not target_data:\n            target_data = self._extract_from_filing_header()\n            confidence = \"medium\"\n            method = \"filing_header\"\n\n        # No reliable extraction possible\n        if not target_data:\n            return None\n\n        # Attempt CIK resolution for public companies\n        cik = self._resolve_cik(target_data) if target_data.get('name') else None\n\n        return TargetCompanyInfo(\n            name=target_data.get('name'),\n            ein=target_data.get('ein'),\n            sic_code=target_data.get('sic_code'),\n            incorporation_state=target_data.get('incorporation_state'),\n            cik=cik,\n            extraction_method=method,\n            confidence_level=confidence\n        )\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#testing-strategy","title":"Testing Strategy","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#unit-tests","title":"Unit Tests","text":"<ol> <li>Parser Validation Tests</li> <li>Test Co-Registrant table parsing with known good HTML</li> <li>Test XBRL fact extraction with sample business combination facts</li> <li> <p>Test header parsing with various filer configurations</p> </li> <li> <p>Edge Case Tests</p> </li> <li>Malformed HTML handling</li> <li>Missing data field scenarios</li> <li>Multiple target company scenarios</li> <li> <p>Foreign entity identifier patterns</p> </li> <li> <p>Integration Tests</p> </li> <li>End-to-end extraction from real S-4 filings</li> <li>CIK resolution accuracy testing</li> <li>Cross-validation with manual extraction</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#test-data-requirements","title":"Test Data Requirements","text":"<pre><code># Sample test cases covering different scenarios\nTEST_CASES = [\n    {\n        'accession': '0001104659-24-123456',  # SPAC merger\n        'expected_target': 'Kodiak Robotics, Inc.',\n        'expected_ein': '82-5086710',\n        'expected_sic': '7373',\n        'is_public': False\n    },\n    {\n        'accession': '0001193125-24-234567',  # Public-to-public merger\n        'expected_target': 'ExampleCorp Inc.',\n        'expected_cik': 1234567,\n        'is_public': True\n    },\n    {\n        'accession': '0000950103-24-345678',  # Multiple target scenario\n        'expected_targets_count': 2,\n        'extraction_complexity': 'high'\n    }\n]\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#performance-tests","title":"Performance Tests","text":"<ol> <li>Extraction Speed: Target &lt; 2 seconds per S-4 filing</li> <li>Memory Usage: Efficient HTML parsing without excessive memory consumption</li> <li>Batch Processing: Handle 100+ S-4 filings efficiently</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#documentation-requirements","title":"Documentation Requirements","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#api-documentation","title":"API Documentation","text":"<ul> <li>Complete docstrings for all public methods</li> <li>Usage examples for common scenarios</li> <li>Edge case handling documentation</li> <li>Performance considerations</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#user-guide-additions","title":"User Guide Additions","text":"<pre><code>## Working with S-4 Merger Filings\n\nS-4 filings contain information about merger and acquisition transactions. EdgarTools can automatically extract target company information from these filings.\n\n### Basic Usage\n```python\n# Find recent SPAC mergers\nspac_filings = get_filings(year=2024, form=\"S-4\")\n\nfor filing in spac_filings:\n    if filing.target_company:\n        print(f\"Acquirer: {filing.company}\")\n        print(f\"Target: {filing.target_company.name}\")\n        print(f\"Target Industry (SIC): {filing.target_company.sic_code}\")\n\n        if filing.target_company.is_public_company:\n            print(\"Target is publicly traded\")\n            target_filings = filing.target_company.filings\n        else:\n            print(\"Target is a private company\")\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#advanced-analysis","title":"Advanced Analysis","text":"<pre><code># Analyze merger trends by industry\nmerger_data = []\nfor filing in get_filings(year=2024, form=\"S-4\"):\n    if filing.target_company and filing.target_company.sic_code:\n        merger_data.append({\n            'target_sic': filing.target_company.sic_code,\n            'target_state': filing.target_company.incorporation_state,\n            'filing_date': filing.filing_date\n        })\n\nimport pandas as pd\ndf = pd.DataFrame(merger_data)\nprint(\"Top merger target industries:\")\nprint(df.target_sic.value_counts().head())\n</code></pre>"},{"location":"feature-requests/s4-target-company-linking-specification/#implementation-timeline","title":"Implementation Timeline","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#phase-1-4-6-weeks-core-infrastructure","title":"Phase 1 (4-6 weeks): Core Infrastructure","text":"<ul> <li>[ ] S4TargetCompanyExtractor class implementation</li> <li>[ ] TargetCompanyInfo data structure</li> <li>[ ] Co-Registrant table parser (primary method)</li> <li>[ ] Basic unit tests and validation</li> <li>[ ] Integration with Filing class</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#phase-2-2-3-weeks-enhanced-extraction","title":"Phase 2 (2-3 weeks): Enhanced Extraction","text":"<ul> <li>[ ] XBRL business combination facts parser</li> <li>[ ] Filing header parser</li> <li>[ ] Confidence scoring system</li> <li>[ ] Comprehensive test suite</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#phase-3-3-4-weeks-public-company-linking","title":"Phase 3 (3-4 weeks): Public Company Linking","text":"<ul> <li>[ ] CIK resolution service</li> <li>[ ] Company object integration</li> <li>[ ] Cross-reference validation</li> <li>[ ] Performance optimization</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#phase-4-2-3-weeks-documentation-and-polish","title":"Phase 4 (2-3 weeks): Documentation and Polish","text":"<ul> <li>[ ] Complete API documentation</li> <li>[ ] User guide updates</li> <li>[ ] Example notebooks</li> <li>[ ] Performance benchmarking</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#success-metrics","title":"Success Metrics","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#technical-metrics","title":"Technical Metrics","text":"<ul> <li>Extraction Accuracy: &gt;95% for structured data fields (EIN, SIC, state)</li> <li>Coverage: Successfully extract target info from &gt;90% of S-4 filings</li> <li>Performance: &lt;2 seconds extraction time per filing</li> <li>Reliability: &lt;1% false positive rate for target company identification</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#user-experience-metrics","title":"User Experience Metrics","text":"<ul> <li>API Simplicity: Single property access (<code>filing.target_company</code>)</li> <li>Error Handling: Graceful degradation with clear error messages</li> <li>Documentation Quality: Complete examples for all common use cases</li> <li>Integration Smoothness: No breaking changes to existing Filing API</li> </ul>"},{"location":"feature-requests/s4-target-company-linking-specification/#risk-assessment","title":"Risk Assessment","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#high-risk-areas","title":"High-Risk Areas","text":"<ol> <li>HTML Parsing Fragility: SEC filing HTML formats may vary significantly</li> <li>Private Company CIK Resolution: Limited ability to link private companies to SEC data</li> <li>Historical Data Compatibility: Older filings may require different parsing approaches</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#mitigation-strategies","title":"Mitigation Strategies","text":"<ol> <li>Robust Parser Design: Multiple extraction methods with fallback logic</li> <li>Conservative Matching: Prefer high-confidence extractions, fail gracefully</li> <li>Extensive Testing: Validate across multiple filing years and formats</li> <li>User Feedback Loop: Monitor extraction accuracy and adjust algorithms</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#future-enhancements","title":"Future Enhancements","text":""},{"location":"feature-requests/s4-target-company-linking-specification/#potential-extensions","title":"Potential Extensions","text":"<ol> <li>Machine Learning Enhancement: Train models on successful extractions to improve accuracy</li> <li>Real-Time Monitoring: Track new S-4 filings and automatically extract target information  </li> <li>Deal Tracking: Monitor merger completion through subsequent 8-K filings</li> <li>Industry Analysis Tools: Built-in utilities for M&amp;A trend analysis</li> <li>International Support: Extend to cross-border merger filings</li> </ol>"},{"location":"feature-requests/s4-target-company-linking-specification/#api-evolution","title":"API Evolution","text":"<pre><code># Future enhanced API possibilities\nclass MergerTransaction:\n    \"\"\"Represents a complete merger transaction across multiple filings.\"\"\"\n\n    def __init__(self, s4_filing: Filing):\n        self.s4_filing = s4_filing\n        self.target_company = s4_filing.target_company\n\n    @property\n    def completion_filing(self) -&gt; Optional[Filing]:\n        \"\"\"Find the 8-K filing announcing merger completion.\"\"\"\n        pass\n\n    @property\n    def amendments(self) -&gt; List[Filing]:\n        \"\"\"All S-4/A amendment filings for this transaction.\"\"\"\n        pass\n\n    @property\n    def timeline(self) -&gt; List[MergerEvent]:\n        \"\"\"Complete timeline of merger-related filings and events.\"\"\"\n        pass\n</code></pre> <p>This comprehensive specification provides the foundation for implementing a robust, user-friendly S-4 target company linking feature that aligns with EdgarTools' philosophy of making complex SEC data simple and accessible.</p>"},{"location":"guides/company-facts/","title":"Company Facts API","text":"<p>The Company Facts API provides comprehensive access to SEC financial data through an intuitive, AI-ready interface. Get financial statements, key metrics, and detailed company information with just a few lines of code.</p> <p>\u2728 Latest Features:</p> <ul> <li>Enhanced Value Formatting: Full numbers with commas (1,000,000,000) by default, with optional concise format ($1.0B)</li> <li>Multi-Period Statements: Rich hierarchical display showing multiple periods side-by-side</li> <li>LLM Integration: Built-in <code>to_llm_context()</code> method for AI consumption</li> <li>Web Rendering Support: Easy iteration over statement items with comprehensive web API methods</li> <li>Improved Visual Display: Professional formatting with color-coded values and hierarchical structure</li> </ul>"},{"location":"guides/company-facts/#quick-start","title":"Quick Start","text":"<pre><code>from edgar import Company\n\n# Get any public company\ncompany = Company('AAPL')  # Ticker symbol\n# or\ncompany = Company(320193)  # CIK number\n\n# Access key metrics instantly\nprint(f\"Shares Outstanding: {company.shares_outstanding:,.0f}\")\nprint(f\"Public Float: ${company.public_float:,.0f}\")\n\n# Get enhanced multi-period financial statements\nincome_stmt = company.income_statement()  # Shows multiple periods with hierarchy\nbalance_sheet = company.balance_sheet()  \ncash_flow = company.cash_flow()\n\nprint(income_stmt)  # Rich multi-period display\n\n# Get concise format for quick overview\nincome_compact = company.income_statement(concise_format=True)\nprint(income_compact)  # Shows $1.0B instead of $1,000,000,000\n</code></pre>"},{"location":"guides/company-facts/#key-features","title":"Key Features","text":"<ul> <li>\ud83d\ude80 Zero Setup - Works immediately with existing Company objects</li> <li>\ud83d\udcb0 Full Precision - Full numbers with commas by default, optional concise formatting</li> <li>\ud83d\udcca Enhanced Display - Multi-period hierarchical statements with rich formatting</li> <li>\ud83d\udee1\ufe0f Error Resilient - Graceful handling of missing data with intelligent fallbacks</li> <li>\ud83e\udd16 AI-Ready - Built-in LLM context generation with structured data output</li> <li>\ud83c\udf10 Web Integration - Easy iteration methods and rendering support for web applications</li> <li>\u26a1 Performance Optimized - Intelligent caching and efficient data structures</li> <li>\ud83c\udfa8 Professional Formatting - Color-coded values, hierarchical structure, and smart spacing</li> </ul>"},{"location":"guides/company-facts/#core-properties","title":"Core Properties","text":""},{"location":"guides/company-facts/#company-metrics","title":"Company Metrics","text":"<p>Access essential company information through simple properties:</p> <pre><code>company = Company('TSLA')\n\n# Key financial metrics\nprint(f\"Shares Outstanding: {company.shares_outstanding:,.0f}\")\nprint(f\"Public Float: ${company.public_float:,.0f}\")\n\n# Check if facts are available\nif company.facts:\n    print(f\"Total facts available: {len(company.facts):,}\")\n</code></pre> <p>Available Properties:</p> <ul> <li><code>company.facts</code> - Access to the full EntityFacts object</li> <li><code>company.shares_outstanding</code> - Number of shares outstanding</li> <li><code>company.public_float</code> - Public float value in dollars</li> </ul>"},{"location":"guides/company-facts/#financial-statements","title":"Financial Statements","text":""},{"location":"guides/company-facts/#income-statement","title":"Income Statement","text":"<p>Get hierarchical income statement data with flexible period options:</p> <pre><code># Default: 4 annual periods, enhanced multi-period display\nincome_stmt = company.income_statement()\nprint(income_stmt)  # Rich hierarchical display with multiple periods\n\n# Get 8 quarterly periods with full number formatting\nquarterly = company.income_statement(periods=8, annual=False)\n\n# Use concise format for quick analysis ($1.0B vs $1,000,000,000)\ncompact = company.income_statement(concise_format=True)\n\n# Get raw DataFrame for analysis\ndf = company.income_statement(periods=4, as_dataframe=True)\n\n# Convert to LLM-friendly format\nllm_data = income_stmt.to_llm_context()\nprint(llm_data['key_metrics'])  # Automatic ratio calculations\n</code></pre>"},{"location":"guides/company-facts/#balance-sheet","title":"Balance Sheet","text":"<p>Access hierarchical balance sheet data for point-in-time or trend analysis:</p> <pre><code># Enhanced multi-period balance sheet with hierarchy\nbalance_sheet = company.balance_sheet(periods=4)\nprint(balance_sheet)  # Shows Assets, Liabilities, Equity sections\n\n# Point-in-time snapshot as of specific date\nfrom datetime import date\nsnapshot = company.balance_sheet(as_of=date(2024, 12, 31))\n\n# Concise format for executive summaries\nexec_summary = company.balance_sheet(concise_format=True)\n\n# Raw data for calculations\ndf = company.balance_sheet(periods=3, as_dataframe=True)\n\n# Web rendering support - iterate over items\nfor item in balance_sheet:\n    print(f\"{item.label}: {item.get_display_value(balance_sheet.periods[0])}\")\n</code></pre>"},{"location":"guides/company-facts/#cash-flow-statement","title":"Cash Flow Statement","text":"<p>Analyze hierarchical cash flow patterns across periods:</p> <pre><code># Enhanced annual cash flow with operating/investing/financing sections\ncash_flow = company.cash_flow(periods=5, annual=True)\nprint(cash_flow)  # Rich display with cash flow categories\n\n# Quarterly cash flow analysis with full formatting\nquarterly_cf = company.cash_flow(periods=8, annual=False)\n\n# Executive dashboard format\nexec_cf = company.cash_flow(concise_format=True)\n\n# Generate analysis context for AI\nai_context = cash_flow.to_llm_context(include_metadata=True)\nprint(ai_context['key_metrics'])  # Automatic cash flow metrics\n</code></pre>"},{"location":"guides/company-facts/#method-parameters","title":"Method Parameters","text":"<p>All financial statement methods support consistent parameters:</p> Parameter Type Default Description <code>periods</code> int 4 Number of periods to retrieve <code>annual</code> bool True If True, prefer annual periods; if False, get quarterly <code>as_dataframe</code> bool False If True, return raw DataFrame; if False, return MultiPeriodStatement <code>concise_format</code> bool False If True, display as $1.0B; if False, display as $1,000,000,000 <p>Special Parameters: - <code>balance_sheet()</code> also supports <code>as_of</code> parameter for point-in-time views</p>"},{"location":"guides/company-facts/#return-types","title":"Return Types","text":""},{"location":"guides/company-facts/#multiperiodstatement-objects-default","title":"MultiPeriodStatement Objects (Default)","text":"<p>When <code>as_dataframe=False</code> (default), methods return enhanced <code>MultiPeriodStatement</code> objects with:</p> <ul> <li>Hierarchical Structure: Organized sections with proper parent-child relationships</li> <li>Multi-Period Display: Side-by-side period comparison with rich formatting</li> <li>Smart Value Formatting: Full numbers ($1,000,000,000) by default, per-share amounts as decimals</li> <li>Color-Coded Display: Green/red values, bold totals, hierarchical indentation</li> <li>Web Rendering Support: Easy iteration and item access for web applications</li> <li>LLM Integration: Built-in context generation for AI analysis</li> </ul> <pre><code>stmt = company.income_statement()\n\n# Rich multi-period display (automatic in notebooks)\nprint(stmt)\n\n# Convert to DataFrame for analysis\ndf = stmt.to_dataframe()\nrevenue_growth = df.loc['Revenue'].pct_change()\n\n# Generate LLM-friendly context\nllm_data = stmt.to_llm_context()\nprint(llm_data['key_metrics']['profit_margin_fy_2024'])\n\n# Iterate over items for web rendering\nfor item in stmt.iter_with_values():\n    print(f\"{item.label}: {item.get_display_value(stmt.periods[0])}\")\n\n# Get specific item\nrevenue_item = stmt.find_item('Revenue')\nif revenue_item:\n    print(f\"Revenue trend: {revenue_item.values}\")\n</code></pre>"},{"location":"guides/company-facts/#dataframe-objects","title":"DataFrame Objects","text":"<p>When <code>as_dataframe=True</code>, methods return pandas DataFrames with enhanced structure:</p> <pre><code>df = company.income_statement(as_dataframe=True)\n\n# Enhanced DataFrame with metadata columns\nprint(df.columns)  # Includes: periods, depth, is_total, section, confidence\nprint(df.dtypes)\nprint(df.describe()) \n\n# Access financial data\nrevenue_series = df.loc['us-gaap:Revenues']  # Full concept names as index\nprint(df[df['is_total']])  # Filter to total/subtotal rows only\nprint(df[df['section'] == 'Revenue'])  # Filter by statement section\n</code></pre>"},{"location":"guides/company-facts/#enhanced-features","title":"Enhanced Features","text":""},{"location":"guides/company-facts/#value-formatting-options","title":"Value Formatting Options","text":"<p>The API now provides flexible value formatting to suit different use cases:</p> <pre><code># Full precision formatting (default) - best for analysis\nstmt_full = company.income_statement(concise_format=False)\nprint(stmt_full)  # Shows: $391,035,000,000\n\n# Concise formatting - best for presentations and dashboards\nstmt_concise = company.income_statement(concise_format=True)  \nprint(stmt_concise)  # Shows: $391.0B\n\n# Per-share amounts are always displayed as decimals\n# Example: Earnings Per Share shows as \"2.97\" not \"$2.97\" or \"$2,970,000,000\"\n</code></pre> <p>Formatting Rules:</p> <ul> <li>Default (<code>concise_format=False</code>): Full numbers with commas ($1,000,000,000)</li> <li>Concise (<code>concise_format=True</code>): Scaled format ($1.0B, $500.3M)</li> <li>Per-Share Values: Always decimal format (2.97) regardless of setting</li> <li>Negative Values: Properly formatted with minus signs</li> <li>Zero/Null Values: Displayed as \"-\" for clean presentation</li> </ul>"},{"location":"guides/company-facts/#llm-integration-and-ai-context","title":"LLM Integration and AI Context","text":"<p>Generate structured data optimized for AI and LLM consumption:</p> <pre><code>stmt = company.income_statement(periods=4)\n\n# Generate LLM-friendly context\nllm_context = stmt.to_llm_context(\n    include_metadata=True,      # Include data quality metrics\n    include_hierarchy=False,    # Flatten for simplicity (default)\n    flatten_values=True         # Create period-prefixed keys (default)\n)\n\nprint(\"LLM Context Structure:\")\nprint(f\"Company: {llm_context['company']}\")\nprint(f\"Statement Type: {llm_context['statement_type']}\")\nprint(f\"Periods: {llm_context['periods']}\")\nprint(f\"Data Quality: {llm_context['metadata']['quality_indicators']}\")\n\n# Access flattened financial data\nfinancial_data = llm_context['data']\nprint(f\"Revenue FY 2024: ${financial_data.get('revenue_fy_2024', 0):,.0f}\")\nprint(f\"Revenue FY 2023: ${financial_data.get('revenue_fy_2023', 0):,.0f}\")\n\n# Automatic ratio calculations\nkey_metrics = llm_context.get('key_metrics', {})\nif 'profit_margin_fy_2024' in key_metrics:\n    print(f\"Current Profit Margin: {key_metrics['profit_margin_fy_2024']:.1%}\")\n\n# Feed to LLM for analysis\nimport json\nanalysis_prompt = f\"\"\"\nAnalyze this financial data for {llm_context['company']}:\n{json.dumps(llm_context, indent=2)}\n\nProvide insights on profitability trends and growth patterns.\n\"\"\"\n</code></pre>"},{"location":"guides/company-facts/#web-application-integration","title":"Web Application Integration","text":"<p>Easy iteration and rendering support for web applications:</p> <pre><code>stmt = company.income_statement(periods=4)\n\n# Basic iteration over all items\nfor item in stmt:\n    print(f\"{item.label}: {item.get_display_value(stmt.periods[0])}\")\n\n# Iterate with hierarchy information  \nfor item in stmt.iter_hierarchy():\n    indent = \"  \" * item.depth\n    parent_info = f\" (parent: {item.parent.label})\" if item.parent else \"\"\n    print(f\"{indent}{item.label}{parent_info}\")\n\n# Only items with values (skip empty rows)\nfor item in stmt.iter_with_values():\n    values_summary = \", \".join([\n        f\"{period}: {item.get_display_value(period)}\" \n        for period in stmt.periods \n        if item.values.get(period)\n    ])\n    print(f\"{item.label} -&gt; {values_summary}\")\n\n# Find specific items\nrevenue_item = stmt.find_item('Revenue')\nif revenue_item:\n    print(f\"Found Revenue: {revenue_item.values}\")\n\n# Convert to web-friendly format\nweb_data = stmt.to_dict()  # Nested dictionary\nflat_data = stmt.to_flat_list()  # Flat list for tables\n\n# Period comparison analysis\ncomparison = stmt.get_period_comparison()\nfor concept, analysis in comparison.items():\n    if analysis['growth_rate']:\n        print(f\"{concept}: {analysis['growth_rate']:.1%} growth\")\n</code></pre>"},{"location":"guides/company-facts/#advanced-statement-features","title":"Advanced Statement Features","text":""},{"location":"guides/company-facts/#smart-hierarchical-organization","title":"Smart Hierarchical Organization","text":"<p>Statements now display with intelligent hierarchy based on accounting standards:</p> <pre><code>stmt = company.income_statement()\nprint(stmt)  # Shows:\n# Revenue\n#   Product Revenue\n#   Service Revenue\n# Cost of Revenue\n#   Cost of Product Sales\n#   Cost of Services\n# Gross Profit  [calculated]\n# Operating Expenses\n#   Research and Development\n#   Sales and Marketing\n# Operating Income [calculated]\n</code></pre>"},{"location":"guides/company-facts/#professional-visual-display","title":"Professional Visual Display","text":"<ul> <li>Color Coding: Green for positive values, red for negative</li> <li>Bold Formatting: Totals and subtotals are emphasized</li> <li>Hierarchical Indentation: Clear parent-child relationships</li> <li>Confidence Indicators: Low-confidence items marked with \u25e6</li> <li>Smart Spacing: Separators after major sections</li> </ul>"},{"location":"guides/company-facts/#enhanced-data-quality","title":"Enhanced Data Quality","text":"<p>Statements include data quality metadata:</p> <pre><code>stmt = company.income_statement()\n\n# Check overall statement quality\nif hasattr(stmt, 'canonical_coverage'):\n    print(f\"Canonical Coverage: {stmt.canonical_coverage:.1%}\")\n\n# Item-level confidence scores\nfor item in stmt.iter_with_values():\n    if hasattr(item, 'confidence') and item.confidence &lt; 0.8:\n        print(f\"Low confidence: {item.label} ({item.confidence:.2f})\")\n</code></pre>"},{"location":"guides/company-facts/#advanced-usage","title":"Advanced Usage","text":""},{"location":"guides/company-facts/#working-with-entityfacts-directly","title":"Working with EntityFacts Directly","text":"<p>For advanced analysis, access the enhanced EntityFacts object with rich display:</p> <pre><code>facts = company.facts\nprint(facts)  # Rich console display with summary statistics and key metrics\n\n# Query specific facts with enhanced query interface\nrevenue_facts = facts.query().by_concept('Revenue').execute()\n\n# Get time series for any concept\nrevenue_ts = facts.time_series('Revenue', periods=20)\n\n# Get DEI (Document and Entity Information) facts\ndei_info = facts.dei_facts()\nentity_summary = facts.entity_info()\n\n# Generate comprehensive LLM context\nllm_context = facts.to_llm_context(\n    focus_areas=['profitability', 'growth'], \n    time_period='5Y'\n)\nprint(llm_context['focus_analysis']['profitability'])\n\n# Export as AI agent tools (MCP-compatible)\nagent_tools = facts.to_agent_tools()\nprint(agent_tools[0])  # Tool definition for AI agents\n</code></pre>"},{"location":"guides/company-facts/#advanced-querying","title":"Advanced Querying","text":"<p>The Facts API includes a powerful query interface for sophisticated financial analysis. Access it through the <code>query()</code> method:</p> <pre><code>facts = company.facts\nquery = facts.query()\n</code></pre>"},{"location":"guides/company-facts/#basic-querying","title":"Basic Querying","text":""},{"location":"guides/company-facts/#filter-by-concept","title":"Filter by Concept","text":"<pre><code># Find all revenue-related facts\nrevenue_facts = facts.query().by_concept('Revenue').execute()\n\n# Exact concept matching\nexact_revenue = facts.query().by_concept('us-gaap:Revenue', exact=True).execute()\n\n# Fuzzy matching (finds Revenue, Revenues, RevenueFromSales, etc.)\nrevenue_like = facts.query().by_concept('revenue').execute()\n</code></pre>"},{"location":"guides/company-facts/#filter-by-time-period","title":"Filter by Time Period","text":"<pre><code># Get facts from specific fiscal year\nfy2024_facts = facts.query().by_fiscal_year(2024).execute()\n\n# Get facts from specific quarter\nq1_facts = facts.query().by_fiscal_period('Q1').execute()\n\n# Get facts from date range\nfrom datetime import date\nrecent_facts = facts.query().date_range(\n    start=date(2023, 1, 1), \n    end=date(2024, 12, 31)\n).execute()\n\n# Get facts as of specific date (point-in-time)\nsnapshot_facts = facts.query().as_of(date(2024, 6, 30)).execute()\n</code></pre>"},{"location":"guides/company-facts/#filter-by-statement-type","title":"Filter by Statement Type","text":"<pre><code># Income statement facts only\nincome_facts = facts.query().by_statement_type('IncomeStatement').execute()\n\n# Balance sheet facts only  \nbalance_facts = facts.query().by_statement_type('BalanceSheet').execute()\n\n# Cash flow facts only\ncashflow_facts = facts.query().by_statement_type('CashFlow').execute()\n</code></pre>"},{"location":"guides/company-facts/#filter-by-form-type","title":"Filter by Form Type","text":"<pre><code># Only audited annual facts (10-K forms)\nannual_facts = facts.query().by_form_type('10-K').execute()\n\n# Only quarterly facts (10-Q forms)\nquarterly_facts = facts.query().by_form_type('10-Q').execute()\n\n# Multiple form types\nperiodic_facts = facts.query().by_form_type(['10-K', '10-Q']).execute()\n</code></pre>"},{"location":"guides/company-facts/#advanced-filtering","title":"Advanced Filtering","text":""},{"location":"guides/company-facts/#quality-and-confidence-filters","title":"Quality and Confidence Filters","text":"<pre><code># Only high-quality, audited facts\nhigh_quality = facts.query().high_quality_only().execute()\n\n# Facts above confidence threshold\nconfident_facts = facts.query().min_confidence(0.9).execute()\n</code></pre>"},{"location":"guides/company-facts/#period-length-filtering","title":"Period Length Filtering","text":"<pre><code># Only quarterly periods (3 months)\nquarterly_only = facts.query().by_period_length(3).execute()\n\n# Only annual periods (12 months)\nannual_only = facts.query().by_period_length(12).execute()\n\n# Only year-to-date periods (9 months)\nytd_facts = facts.query().by_period_length(9).execute()\n</code></pre>"},{"location":"guides/company-facts/#latest-facts","title":"Latest Facts","text":"<pre><code># Get most recent facts by filing date\nlatest_facts = facts.query().by_concept('Revenue').latest(5)\n\n# Get latest instant facts (for balance sheet items)\nlatest_balance = facts.query().by_statement_type('BalanceSheet').latest_instant().execute()\n\n# Get latest periods with preference\nlatest_periods = facts.query().latest_periods(4, prefer_annual=True).execute()\n</code></pre>"},{"location":"guides/company-facts/#method-chaining","title":"Method Chaining","text":"<p>Combine multiple filters for precise queries:</p> <pre><code># Revenue facts from 2024 10-K filings only\nrevenue_2024_annual = facts.query()\\\n    .by_concept('Revenue')\\\n    .by_fiscal_year(2024)\\\n    .by_form_type('10-K')\\\n    .execute()\n\n# High-quality quarterly income statement facts\nquality_quarterly = facts.query()\\\n    .by_statement_type('IncomeStatement')\\\n    .by_period_length(3)\\\n    .high_quality_only()\\\n    .execute()\n\n# Recent balance sheet facts as of year-end\nyear_end_balance = facts.query()\\\n    .by_statement_type('BalanceSheet')\\\n    .as_of(date(2024, 12, 31))\\\n    .latest_instant()\\\n    .execute()\n</code></pre>"},{"location":"guides/company-facts/#output-formats","title":"Output Formats","text":""},{"location":"guides/company-facts/#convert-to-dataframe","title":"Convert to DataFrame","text":"<pre><code># Basic DataFrame with all columns\ndf = facts.query().by_concept('Revenue').to_dataframe()\n\n# DataFrame with selected columns\ndf = facts.query().by_concept('Revenue').to_dataframe(\n    'label', 'numeric_value', 'fiscal_period', 'fiscal_year'\n)\n\nprint(df.head())\n</code></pre>"},{"location":"guides/company-facts/#pivot-by-period","title":"Pivot by Period","text":"<p>Create time-series views with periods as columns:</p> <pre><code># Get formatted financial statement\nstmt = facts.query()\\\n    .by_statement_type('IncomeStatement')\\\n    .latest_periods(4)\\\n    .pivot_by_period()\n\n# Get raw DataFrame pivot\npivot_df = facts.query()\\\n    .by_statement_type('IncomeStatement')\\\n    .latest_periods(4)\\\n    .pivot_by_period(return_statement=False)\n\nprint(pivot_df)\n</code></pre>"},{"location":"guides/company-facts/#llm-ready-context","title":"LLM-Ready Context","text":"<pre><code># Get facts in LLM-friendly format\nllm_context = facts.query().by_concept('Revenue').to_llm_context()\n\n# Perfect for feeding to AI models\nfor fact_context in llm_context:\n    print(f\"Concept: {fact_context['concept']}\")\n    print(f\"Value: {fact_context['value']}\")\n    print(f\"Period: {fact_context['period']}\")\n</code></pre>"},{"location":"guides/company-facts/#query-utilities","title":"Query Utilities","text":""},{"location":"guides/company-facts/#count-results","title":"Count Results","text":"<pre><code># Count matching facts without loading them\nrevenue_count = facts.query().by_concept('Revenue').count()\nprint(f\"Found {revenue_count} revenue facts\")\n\n# Enhanced query with rich display\nrevenue_query = facts.query().by_concept('Revenue')\nprint(revenue_query)  # Rich representation of the query\n</code></pre>"},{"location":"guides/company-facts/#sort-results","title":"Sort Results","text":"<pre><code># Sort by filing date (newest first)\nsorted_facts = facts.query()\\\n    .by_concept('Revenue')\\\n    .sort_by('filing_date', ascending=False)\\\n    .execute()\n\n# Sort by fiscal year\nsorted_by_year = facts.query()\\\n    .by_concept('Assets')\\\n    .sort_by('fiscal_year')\\\n    .execute()\n</code></pre>"},{"location":"guides/company-facts/#real-world-query-examples","title":"Real-World Query Examples","text":""},{"location":"guides/company-facts/#track-revenue-growth-over-time","title":"Track Revenue Growth Over Time","text":"<pre><code># Get quarterly revenue for trend analysis\nquarterly_revenue = facts.query()\\\n    .by_concept('Revenue')\\\n    .by_period_length(3)\\\n    .sort_by('period_end')\\\n    .to_dataframe('fiscal_year', 'fiscal_period', 'numeric_value', 'period_end')\n\n# Calculate quarter-over-quarter growth\nquarterly_revenue['growth'] = quarterly_revenue['numeric_value'].pct_change() * 100\nprint(quarterly_revenue[['fiscal_period', 'fiscal_year', 'numeric_value', 'growth']])\n</code></pre>"},{"location":"guides/company-facts/#compare-audited-vs-unaudited-numbers","title":"Compare Audited vs Unaudited Numbers","text":"<pre><code># Get both 10-K (audited) and 10-Q (unaudited) revenue for same period\nrevenue_2024_q4 = facts.query()\\\n    .by_concept('Revenue')\\\n    .by_fiscal_year(2024)\\\n    .by_fiscal_period('Q4')\\\n    .by_form_type(['10-K', '10-Q'])\\\n    .to_dataframe('form_type', 'numeric_value', 'filing_date')\n\nprint(revenue_2024_q4)\n</code></pre>"},{"location":"guides/company-facts/#find-restatements","title":"Find Restatements","text":"<pre><code># Look for the same period filed multiple times\neps_facts = facts.query()\\\n    .by_concept('EarningsPerShare')\\\n    .by_fiscal_year(2024)\\\n    .by_fiscal_period('Q1')\\\n    .sort_by('filing_date')\\\n    .to_dataframe('filing_date', 'numeric_value', 'form_type')\n\nif len(eps_facts) &gt; 1:\n    print(\"Potential restatement found:\")\n    print(eps_facts)\n</code></pre>"},{"location":"guides/company-facts/#build-custom-financial-ratios","title":"Build Custom Financial Ratios","text":"<pre><code># Get components for current ratio calculation\ncurrent_assets = facts.query()\\\n    .by_concept('CurrentAssets')\\\n    .latest_instant()\\\n    .execute()\n\ncurrent_liabilities = facts.query()\\\n    .by_concept('CurrentLiabilities')\\\n    .latest_instant()\\\n    .execute()\n\nif current_assets and current_liabilities:\n    assets_value = current_assets[0].numeric_value\n    liabilities_value = current_liabilities[0].numeric_value\n    current_ratio = assets_value / liabilities_value\n    print(f\"Current Ratio: {current_ratio:.2f}\")\n</code></pre>"},{"location":"guides/company-facts/#query-performance-tips","title":"Query Performance Tips","text":"<ol> <li>Use Specific Filters: More specific queries run faster</li> </ol> <pre><code># Good: Specific concept and year\nfacts.query().by_concept('us-gaap:Revenue', exact=True).by_fiscal_year(2024)\n\n# Less efficient: Broad concept search\nfacts.query().by_concept('revenue')\n</code></pre> <ol> <li>Limit Results Early: Use <code>latest()</code> or <code>count()</code> when appropriate</li> </ol> <pre><code># Good: Get just what you need\nrecent_revenue = facts.query().by_concept('Revenue').latest(4)\n\n# Less efficient: Get all then slice\nall_revenue = facts.query().by_concept('Revenue').execute()[:4]\n</code></pre> <ol> <li>Chain Filters Logically: Put most selective filters first</li> </ol> <pre><code># Good: Narrow down quickly\nfacts.query().by_fiscal_year(2024).by_form_type('10-K').by_concept('Revenue')\n\n# Less efficient: Broad filter first\nfacts.query().by_concept('Revenue').by_fiscal_year(2024).by_form_type('10-K')\n</code></pre> <p>The query interface provides powerful flexibility for financial analysis while maintaining simplicity for common use cases.</p>"},{"location":"guides/company-facts/#enhanced-period-selection-logic","title":"Enhanced Period Selection Logic","text":"<p>The API intelligently handles period selection with improved consistency:</p> <pre><code># Annual periods preferred - gets FY 2024, FY 2023, etc.\nannual = company.income_statement(annual=True)\nprint(annual)  # Rich display with period headers\n\n# Quarterly periods - gets most recent quarters\nquarterly = company.income_statement(annual=False)\n\n# Mixed periods automatically detected and handled\nmixed = company.income_statement(periods=8, annual=False)\n# API intelligently selects best available periods\n</code></pre> <p>Enhanced Period Features:</p> <ul> <li>Smart Labeling: Periods labeled by fiscal quarters and years</li> <li>Consistency: \"Q2 2024\" means period ending in company's fiscal Q2 of 2024</li> <li>Hierarchy: \"FY 2024\" means full fiscal year ending in 2024</li> <li>Quality Indicators: Period data quality shown in metadata</li> <li>Automatic Selection: API selects best available periods when requested periods aren't available</li> </ul>"},{"location":"guides/company-facts/#error-handling","title":"Error Handling","text":"<p>The API is designed for graceful error handling:</p> <pre><code>company = Company('INVALIDTICKER')\n\n# These will return None instead of raising exceptions\nincome_stmt = company.income_statement()  # Returns None\nshares = company.shares_outstanding       # Returns None  \nfacts = company.facts                     # Returns None\n\n# Check before using\nif company.facts:\n    # Facts are available\n    stmt = company.income_statement()\nelse:\n    print(\"No facts available for this company\")\n</code></pre>"},{"location":"guides/company-facts/#real-world-examples","title":"Real-World Examples","text":""},{"location":"guides/company-facts/#compare-revenue-growth-with-enhanced-display","title":"Compare Revenue Growth with Enhanced Display","text":"<pre><code>from edgar import Company\n\ncompanies = ['AAPL', 'MSFT', 'GOOGL']\nfor ticker in companies:\n    company = Company(ticker)\n    if company.facts:\n        # Get enhanced multi-period statement\n        stmt = company.income_statement(periods=2)\n        print(f\"\\n{ticker} Revenue Analysis:\")\n        print(stmt)  # Rich multi-period display\n\n        # Calculate growth using new methods\n        df = stmt.to_dataframe()\n        if not df.empty:\n            revenue_row = df[df['label'].str.contains('Revenue', case=False, na=False)].iloc[0]\n            periods = stmt.periods\n            if len(periods) &gt;= 2:\n                current = revenue_row[periods[0]]\n                prior = revenue_row[periods[1]]\n                if current and prior:\n                    growth = ((current - prior) / prior) * 100\n                    print(f\"{ticker}: {growth:.1f}% revenue growth\")\n\n        # Generate LLM context for deeper analysis\n        llm_data = stmt.to_llm_context()\n        if 'key_metrics' in llm_data:\n            print(f\"AI Analysis Available: {list(llm_data['key_metrics'].keys())}\")\n\n            # Display some automatic calculations\n            if 'profit_margin_fy_2024' in llm_data['key_metrics']:\n                margin = llm_data['key_metrics']['profit_margin_fy_2024']\n                print(f\"{ticker} Profit Margin: {margin:.1%}\")\n</code></pre>"},{"location":"guides/company-facts/#build-enhanced-comparison-dashboard","title":"Build Enhanced Comparison Dashboard","text":"<pre><code>import pandas as pd\n\ndef compare_companies_enhanced(tickers, periods=2):\n    results = []\n    for ticker in tickers:\n        company = Company(ticker)\n        if company.facts:\n            # Get enhanced multi-period statement\n            stmt = company.income_statement(periods=periods)\n\n            # Extract LLM context for automated metrics\n            llm_data = stmt.to_llm_context(include_metadata=True)\n\n            # Build comprehensive comparison data\n            company_data = {\n                'Company': company.name,\n                'Ticker': ticker,\n                'Periods': len(stmt.periods),\n                'Data_Quality': llm_data.get('metadata', {}).get('quality_indicators', []),\n            }\n\n            # Add revenue data for all periods\n            revenue_item = stmt.find_item('Revenue')\n            if revenue_item:\n                for period in stmt.periods:\n                    value = revenue_item.values.get(period)\n                    if value:\n                        company_data[f'Revenue_{period.replace(\" \", \"_\")}'] = value\n\n            # Add key metrics if available\n            if 'key_metrics' in llm_data:\n                for metric, value in llm_data['key_metrics'].items():\n                    company_data[f'Metric_{metric}'] = value\n\n            results.append(company_data)\n\n    return pd.DataFrame(results)\n\n# Compare with enhanced analytics\ncomparison = compare_companies_enhanced(['AAPL', 'MSFT', 'GOOGL', 'AMZN'])\nprint(comparison)\n\n# Web rendering example\ndef render_for_web(ticker):\n    company = Company(ticker)\n    stmt = company.income_statement()\n\n    web_data = []\n    for item in stmt.iter_with_values():\n        web_data.append({\n            'concept': item.concept,\n            'label': item.label, \n            'depth': getattr(item, 'depth', 0),\n            'is_total': item.is_total,\n            'values': {period: item.get_display_value(period) \n                      for period in stmt.periods if item.values.get(period)}\n        })\n    return web_data\n\nweb_ready_data = render_for_web('AAPL')\nprint(f\"Generated {len(web_ready_data)} items for web display\")\n</code></pre>"},{"location":"guides/company-facts/#extract-enhanced-key-metrics","title":"Extract Enhanced Key Metrics","text":"<pre><code>def company_snapshot_enhanced(ticker):\n    company = Company(ticker)\n    snapshot = {\n        'name': company.name,\n        'ticker': ticker,\n        'shares_outstanding': company.shares_outstanding,\n        'public_float': company.public_float,\n        'has_facts': company.facts is not None\n    }\n\n    if company.facts:\n        # Get entity information\n        entity_info = company.facts.entity_info()\n        snapshot.update(entity_info)\n\n        # Get financial statement summaries with LLM context\n        income_stmt = company.income_statement(periods=2)\n        if income_stmt:\n            llm_context = income_stmt.to_llm_context()\n            snapshot.update({\n                'revenue_latest': llm_context['data'].get('revenue_fy_2024') or llm_context['data'].get('revenue_q4_2024'),\n                'key_metrics': llm_context.get('key_metrics', {}),\n                'data_quality': llm_context.get('metadata', {}).get('quality_indicators', [])\n            })\n\n        # Get balance sheet strength indicators\n        balance_sheet = company.balance_sheet(periods=1)\n        if balance_sheet:\n            bs_context = balance_sheet.to_llm_context()\n            assets_key = next((k for k in bs_context['data'].keys() if 'assets' in k.lower() and 'total' in k.lower()), None)\n            if assets_key:\n                snapshot['total_assets'] = bs_context['data'][assets_key]\n\n            # Add balance sheet metrics if available\n            if 'key_metrics' in bs_context:\n                snapshot['balance_sheet_metrics'] = bs_context['key_metrics']\n\n    return snapshot\n\n# Get enhanced snapshots with auto-calculated metrics\ntickers = ['AAPL', 'TSLA', 'NVDA']\nsnapshots = [company_snapshot_enhanced(t) for t in tickers]\ndf = pd.DataFrame(snapshots)\nprint(df[['name', 'ticker', 'revenue_latest', 'total_assets']].to_string())\n\n# Display detailed metrics for one company\nprint(\"\\nDetailed metrics for AAPL:\")\naapl_snapshot = snapshots[0]\nfor key, value in aapl_snapshot.get('key_metrics', {}).items():\n    print(f\"{key}: {value}\")\n\n# Show data quality indicators\nif 'data_quality' in aapl_snapshot:\n    print(f\"Data Quality: {', '.join(aapl_snapshot['data_quality'])}\")\n\n# Show balance sheet metrics if available\nif 'balance_sheet_metrics' in aapl_snapshot:\n    print(\"\\nBalance Sheet Metrics:\")\n    for key, value in aapl_snapshot['balance_sheet_metrics'].items():\n        print(f\"{key}: {value}\")\n</code></pre>"},{"location":"guides/company-facts/#performance-tips","title":"Performance Tips","text":"<ol> <li>Cache Company Objects: Reuse Company instances to leverage enhanced caching</li> <li>Use as_dataframe=True: For bulk calculations, raw DataFrames are faster</li> <li>Limit Periods: Request only the periods you need for analysis</li> <li>Check Availability: Use <code>if company.facts:</code> before accessing financial data</li> <li>Choose Format Wisely: Use <code>concise_format=True</code> for display, <code>False</code> for calculations</li> <li>Cache LLM Context: Store <code>to_llm_context()</code> results for repeated AI analysis</li> <li>Batch Web Rendering: Use <code>iter_with_values()</code> to skip empty items</li> </ol> <pre><code># Good: Reuse company object with enhanced features\ncompany = Company('AAPL')\nif company.facts:\n    print(company.facts)  # Rich display with summary statistics\n\n    # Get multiple statements efficiently\n    income = company.income_statement()\n    balance = company.balance_sheet()\n    cash = company.cash_flow()\n\n    # Cache LLM context for AI applications\n    llm_context = income.to_llm_context()\n    # Reuse llm_context for multiple AI queries\n\n# Good: Use DataFrame for bulk analysis\ndf = company.income_statement(periods=10, as_dataframe=True)\nanalysis = df.select_dtypes(include=[np.number]).pct_change()\n\n# Good: Efficient web rendering\nweb_items = [item for item in stmt.iter_with_values()]  # Only items with data\nrendered_data = stmt.to_dict()  # Single conversion for web APIs\n\n# Good: Format choice based on use case\nexec_dashboard = company.income_statement(concise_format=True)   # For presentations\nanalysis_data = company.income_statement(concise_format=False)   # For calculations\n</code></pre>"},{"location":"guides/company-facts/#integration-with-other-edgartools-features","title":"Integration with Other EdgarTools Features","text":"<p>The enhanced Facts API works seamlessly with other EdgarTools features:</p> <pre><code>company = Company('AAPL')\n\n# Combine with filings for comprehensive analysis\nlatest_10k = company.latest('10-K')\nfacts_stmt = company.income_statement()\n\n# Generate cross-referenced analysis\nanalysis_context = {\n    'filing_info': {\n        'form': latest_10k.form,\n        'filing_date': latest_10k.filing_date,\n        'accession': latest_10k.accession_no\n    },\n    'financial_data': facts_stmt.to_llm_context(),\n    'data_sources': 'SEC Company Facts API + EDGAR Filings'\n}\n\n# Compare with traditional XBRL (if available)\ntry:\n    xbrl = latest_10k.xbrl()  # Traditional XBRL approach\n    xbrl_stmt = xbrl.statements.income_statement\n    facts_stmt = company.income_statement()  # Enhanced Facts API\n\n    print(\"Data Source Comparison:\")\n    print(f\"XBRL Concepts: {len(xbrl_stmt) if xbrl_stmt else 0}\")\n    print(f\"Facts API Items: {len(facts_stmt.items)}\")\n    print(f\"Facts API Quality: {getattr(facts_stmt, 'canonical_coverage', 'N/A')}\")\nexcept:\n    print(\"XBRL data not available - Facts API provides comprehensive coverage\")\n</code></pre>"},{"location":"guides/company-facts/#migration-guide","title":"Migration Guide","text":"<p>Upgrading from previous versions is straightforward with enhanced features:</p> <pre><code># Previous approach (still works)\nold_facts = company.get_facts()  # Returns basic format\nold_stmt = company.income_statement(as_dataframe=True)\n\n# Enhanced approach with new features\nfacts = company.facts            # Rich EntityFacts with console display\nstmt = company.income_statement()  # MultiPeriodStatement with hierarchy\n\n# New formatting options\ncompact_stmt = company.income_statement(concise_format=True)  # $1.0B format\nfull_stmt = company.income_statement(concise_format=False)    # $1,000,000,000 format\n\n# New LLM integration\nllm_data = stmt.to_llm_context()  # AI-ready structured data\n\n# New web integration\nweb_items = list(stmt.iter_with_values())  # Easy web rendering\nspecific_item = stmt.find_item('Revenue')  # Direct item access\n\n# Enhanced property access with full context\nshares_fact = facts.shares_outstanding_fact  # Full FinancialFact object\nshares_value = facts.shares_outstanding       # Direct numeric value\n</code></pre> <p>Key Improvements:</p> <ul> <li>Backward Compatible: All existing code continues to work</li> <li>Enhanced Display: Rich console formatting with colors and hierarchy</li> <li>Better Formatting: Smart value formatting with concise options</li> <li>AI Integration: Built-in LLM context generation</li> <li>Web Support: Easy iteration and rendering methods</li> <li>Performance: Optimized caching and data structures</li> </ul>"},{"location":"guides/company-facts/#troubleshooting","title":"Troubleshooting","text":"<p>Q: Why do some companies return None for financial statements? A: Not all companies have facts data available through the SEC API. This is normal for some entity types. The enhanced API provides better error handling and fallback strategies.</p> <p>Q: What's the difference between concise_format=True and False? A: <code>concise_format=False</code> (default) shows full numbers with commas ($1,000,000,000) for precision. <code>concise_format=True</code> shows scaled format ($1.0B) for presentations. Per-share amounts are always decimals regardless of setting.</p> <p>Q: How do I use the hierarchical structure in web applications? A: Use the iteration methods: <code>stmt.iter_hierarchy()</code> for parent-child relationships, <code>stmt.iter_with_values()</code> for items with data, or <code>stmt.to_dict()</code> for nested JSON structure.</p> <p>Q: How do I get the most recent quarter with the new format? A: Use <code>company.income_statement(periods=1, annual=False)</code> to get the latest quarterly period with enhanced formatting and hierarchy.</p> <p>Q: Can I get historical data beyond what's shown? A: Yes, increase the <code>periods</code> parameter: <code>company.income_statement(periods=20)</code> for extensive historical data with consistent formatting.</p> <p>Q: How do I integrate with AI/LLM applications? A: Use <code>stmt.to_llm_context()</code> to get structured, AI-ready data with automatic metric calculations and clean formatting optimized for language models.</p>"},{"location":"guides/company-facts/#api-reference","title":"API Reference","text":""},{"location":"guides/company-facts/#multiperiodstatement-methods","title":"MultiPeriodStatement Methods","text":"Method Description <code>to_dataframe()</code> Convert to pandas DataFrame with metadata <code>to_llm_context()</code> Generate AI-ready structured context <code>iter_hierarchy()</code> Iterate with depth and parent information <code>iter_with_values()</code> Iterate only items with values <code>find_item(concept)</code> Find specific item by concept or label <code>to_dict()</code> Convert to nested dictionary structure <code>to_flat_list()</code> Convert to flat list for web APIs <code>get_period_comparison()</code> Get period-over-period analysis"},{"location":"guides/company-facts/#entityfacts-enhanced-methods","title":"EntityFacts Enhanced Methods","text":"Method Description <code>to_llm_context()</code> Comprehensive AI context with focus areas <code>to_agent_tools()</code> Export as MCP-compatible agent tools <code>calculate_ratios()</code> Financial ratio calculations <code>peer_comparison()</code> Compare with peer companies <code>detect_anomalies()</code> Identify unusual patterns"},{"location":"guides/company-facts/#new-parameters","title":"New Parameters","text":"Parameter Methods Description <code>concise_format</code> All statement methods Value display format control <code>include_metadata</code> <code>to_llm_context()</code> Include data quality metrics <code>flatten_values</code> <code>to_llm_context()</code> Flatten multi-period values <code>focus_areas</code> <code>to_llm_context()</code> Emphasize specific analysis areas <p>For complete API documentation of the underlying EntityFacts class and query interface, see the EntityFacts API Reference.</p> <p>The enhanced Company Facts API is part of EdgarTools' comprehensive SEC data platform, now with AI integration, web rendering support, and professional formatting. For more information, visit the EdgarTools Documentation.</p>"},{"location":"guides/company-insiders/","title":"Getting a list of company insiders","text":"<p>This guide shows how to get a list of insiders for a company by writing a simple script to loop through their Form 4 filings and getting the name and position.</p>"},{"location":"guides/company-insiders/#1-deciding-on-an-appropriate-date-range","title":"1. Deciding on an appropriate date range","text":"<p>The approach is to get all Form 4 Insider filings for the past 6 months. To specify the date range we use a use <code>timedelta</code> to subtract 6 months from <code>datetime.now()</code></p> <pre><code>from datetime import datetime, timedelta\nfrom edgar import *\n\ndate_range = ((datetime.now() - timedelta(days=6*30)) # Approximate 6 months\n              .strftime('%Y-%m-%d:'))  \n</code></pre>"},{"location":"guides/company-insiders/#2-getting-the-company-filings","title":"2. Getting the company filings","text":"<p>Now we can use the <code>Company</code> class to get the company filings for the past 6 months.</p> <pre><code>c: Company = Company(ticker)\nfilings: EntityFilings = c.get_filings(form='4', filing_date=date_range)\n</code></pre>"},{"location":"guides/company-insiders/#3-collecting-data-from-each-form-4","title":"3. Collecting data from each Form 4","text":"<p>Now we loop through each filing and get the ownership summary, which contains the insider names and their positions.  Each Form4 has an <code>OwnershipSummary</code> object that we can convert to a DataFrame.</p> <pre><code>dfs = [] # List to hold DataFrames for each filing\nfor filing in tqdm(filings):\n    form4: Form4 = filing.obj()\n    summary = form4.get_ownership_summary()\n    dfs.append(summary.to_dataframe()[['Insider', 'Position']])\n</code></pre>"},{"location":"guides/company-insiders/#4-combining-the-dataframes","title":"4. Combining the DataFrames","text":"<p>Finally, we can concatenate all the DataFrames into a single DataFrame and drop duplicates to get a unique list of insiders.</p> <pre><code>import pandas as pd\ninsiders = (pd.concat(dfs, ignore_index=True)\n                 .drop_duplicates().reset_index(drop=True)\n                 .sort_values(by='Position',\n                              key=lambda col: col == 'Director', \n                              ascending=True)\n            )\n</code></pre>"},{"location":"guides/company-insiders/#5-putting-it-all-together","title":"5. Putting it all together","text":"<p>The complete code to get the insiders for a company is as follows. Note that we put it inside a function so we can easily reuse it for different tickers.</p> <pre><code>import pandas as pd\nfrom rich import print\nfrom tqdm.auto import tqdm\n\nfrom edgar import *\nfrom edgar.entity import EntityFilings\nfrom edgar.ownership import Form4\nfrom datetime import datetime, timedelta\n\n\n# Calculate the date 6 months ago from today\n\ndate_range = ((datetime.now() - timedelta(days=6*30)) # Approximate 6 months\n              .strftime('%Y-%m-%d:'))\n\n\ndef get_insiders(ticker):\n    c: Company = Company(ticker)\n    filings: EntityFilings = c.get_filings(form='4', filing_date=date_range)\n\n    dfs = []\n\n    for filing in tqdm(filings):\n        form4: Form4 = filing.obj()\n        summary = form4.get_ownership_summary()\n        dfs.append(summary.to_dataframe()[['Insider', 'Position']])\n\n    insiders = (pd.concat(dfs, ignore_index=True)\n                 .drop_duplicates().reset_index(drop=True)\n                 .sort_values(by='Position', key=lambda col: col == 'Director', ascending=True)\n                 )\n    return insiders\n\nif __name__ == '__main__':\n    insiders = get_insiders(\"NFLX\")\n    print(insiders)\n</code></pre>"},{"location":"guides/current-filings/","title":"Working with Current Filings","text":""},{"location":"guides/current-filings/#overview","title":"Overview","text":"<p>Current filings represent the most recently submitted documents to the SEC, updated in real-time as companies file their reports. This guide shows you how to access, filter, and efficiently process current filings using edgartools.</p>"},{"location":"guides/current-filings/#quick-start","title":"Quick Start","text":""},{"location":"guides/current-filings/#basic-usage","title":"Basic Usage","text":"<pre><code>from edgar import get_current_filings\n\n# Get the most recent filings (default: 100 filings)\ncurrent = get_current_filings()\nprint(f\"Found {len(current)} recent filings\")\n\n# Display the first few filings\nfor filing in current[:5]:\n    print(f\"{filing.form}: {filing.company} - {filing.filing_date}\")\n</code></pre> <p>Output:</p> <pre><code>Found 100 recent filings\n8-K: Apple Inc. - 2025-01-14\n10-Q: Microsoft Corporation - 2025-01-14\n4: BEZOS JEFFREY P - 2025-01-14\n13F-HR: Berkshire Hathaway Inc - 2025-01-14\nS-3: Tesla, Inc. - 2025-01-14\n</code></pre>"},{"location":"guides/current-filings/#filter-by-form-type","title":"Filter by Form Type","text":"<pre><code># Get only Form 8-K current events\ncurrent_8k = get_current_filings(form='8-K')\n\n# Get only insider trading forms (Forms 3, 4, 5)\ncurrent_insider = get_current_filings(form='4')\n\n# Get quarterly and annual reports\ncurrent_reports = get_current_filings(form='10-K')\n</code></pre>"},{"location":"guides/current-filings/#understanding-current-filings","title":"Understanding Current Filings","text":""},{"location":"guides/current-filings/#what-are-current-filings","title":"What Are Current Filings?","text":"<p>Current filings are the most recently submitted documents to the SEC, typically updated every few minutes during business hours. They include:</p> <ul> <li>Form 8-K: Current events and corporate changes</li> <li>Forms 3, 4, 5: Insider trading transactions</li> <li>10-K/10-Q: Annual and quarterly reports</li> <li>13F: Institutional investment manager holdings</li> <li>S-1, S-3: Registration statements</li> <li>And many more...</li> </ul>"},{"location":"guides/current-filings/#pagination-system","title":"Pagination System","text":"<p>Current filings are delivered in pages to manage large volumes:</p> <pre><code># Default: Get first 100 filings\ncurrent = get_current_filings(page_size=100)\n\n# Get more filings per page (up to 100)\ncurrent = get_current_filings(page_size=80)\n\n# Navigate to next page\nnext_page = current.next()\nif next_page:\n    print(f\"Next page has {len(next_page)} filings\")\n</code></pre>"},{"location":"guides/current-filings/#core-functions","title":"Core Functions","text":""},{"location":"guides/current-filings/#get_current_filings","title":"<code>get_current_filings()</code>","text":"<p>Get a single page of current filings with filtering options.</p> <pre><code>def get_current_filings(form: str = '', \n                       owner: str = 'include', \n                       page_size: int = 100) -&gt; CurrentFilings:\n</code></pre> <p>Parameters: - <code>form</code> (str): Filter by form type (e.g., \"8-K\", \"10-K\", \"4\") - <code>owner</code> (str): Owner filter - \"include\", \"exclude\", or \"only\" - <code>page_size</code> (int): Filings per page (10, 20, 40, 80, or 100)</p> <p>Returns: <code>CurrentFilings</code> object with pagination capabilities</p>"},{"location":"guides/current-filings/#iter_current_filings_pages","title":"<code>iter_current_filings_pages()</code>","text":"<p>Iterator that yields pages of current filings until exhausted.</p> <pre><code>from edgar import iter_current_filings_pages\n\n# Process all current 8-K filings page by page\nfor page in iter_current_filings_pages(form=\"8-K\"):\n    print(f\"Processing {len(page)} 8-K filings\")\n\n    for filing in page:\n        # Process each filing\n        print(f\"  {filing.company}: {filing.filing_date}\")\n\n    # Break after first few pages for demo\n    if page.current_page &gt;= 3:\n        break\n</code></pre>"},{"location":"guides/current-filings/#get_all_current_filings","title":"<code>get_all_current_filings()</code>","text":"<p>Get ALL current filings by automatically iterating through all pages.</p> <pre><code>from edgar import get_all_current_filings\n\n# Get all current Form 4 filings (may be thousands)\nall_form4 = get_all_current_filings(form=\"4\")\nprint(f\"Total Form 4 filings: {len(all_form4)}\")\n\n# Get all current filings (no form filter)\nall_current = get_all_current_filings()\nprint(f\"Total current filings: {len(all_current)}\")\n</code></pre> <p>\u26a0\ufe0f Performance Note: This function downloads ALL available current filings, which can be thousands of documents. Use with appropriate filters.</p>"},{"location":"guides/current-filings/#filtering-options","title":"Filtering Options","text":""},{"location":"guides/current-filings/#by-form-type","title":"By Form Type","text":"<pre><code># Specific form types\nform_8k = get_current_filings(form=\"8-K\")\nform_10k = get_current_filings(form=\"10-K\") \nform_4 = get_current_filings(form=\"4\")\n\n# Form families work too\nquarterly_reports = get_current_filings(form=\"10-Q\")\n</code></pre>"},{"location":"guides/current-filings/#by-owner-type","title":"By Owner Type","text":"<p>Control whether to include filings from investment managers:</p> <pre><code># Include all filings (default)\nall_filings = get_current_filings(owner=\"include\")\n\n# Exclude ownership filings (e.g., Form 4, 144)\npublic_only = get_current_filings(owner=\"exclude\")\n\n# Only ownership filings (e.g., Form 4, 144)\nmanagers_only = get_current_filings(owner=\"only\")\n</code></pre>"},{"location":"guides/current-filings/#by-page-size","title":"By Page Size","text":"<p>Choose how many filings to get per request:</p> <pre><code># Small batches for quick processing\nsmall_batch = get_current_filings(page_size=20)\n\n# Large batches for efficiency\nlarge_batch = get_current_filings(page_size=100)  # Maximum\n</code></pre>"},{"location":"guides/current-filings/#real-world-examples","title":"Real-World Examples","text":""},{"location":"guides/current-filings/#example-1-monitor-recent-8-k-events","title":"Example 1: Monitor Recent 8-K Events","text":"<pre><code>from edgar import get_all_current_filings\nfrom datetime import datetime\n\ndef monitor_current_events():\n    \"\"\"Monitor recent 8-K filings for significant events.\"\"\"\n\n    # Get recent 8-K filings\n    current_8k = get_all_current_filings(form=\"8-K\")\n\n    print(f\"\ud83d\udcc8 Monitoring {len(current_8k)} recent 8-K filings\")\n    print(f\"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(\"-\" * 60)\n\n    for filing in current_8k:\n        # Show key information\n        print(f\"{filing.company}\")\n        print(f\"  Form: {filing.form}\")\n        print(f\"  Filed: {filing.filing_date}\")\n        print(f\"  URL: {filing.document_url}\")\n        print()\n\nmonitor_current_events()\n</code></pre>"},{"location":"guides/current-filings/#example-2-track-insider-trading-activity","title":"Example 2: Track Insider Trading Activity","text":"<pre><code>from edgar import get_all_current_filings\nimport pandas as pd\n\ndef analyze_insider_activity():\n    \"\"\"Analyze current insider trading patterns.\"\"\"\n\n    # Get all current Form 4 filings\n    print(\"\ud83d\udcca Downloading all current Form 4 filings...\")\n    insider_filings = get_all_current_filings(form=\"4\")\n\n    print(f\"Found {len(insider_filings)} insider trading filings\")\n\n    # Convert to DataFrame for analysis\n    df = insider_filings.to_pandas()\n\n    # Analyze by company\n    company_counts = df['company'].value_counts().head(10)\n\n    print(\"\\n\ud83c\udfe2 Top 10 Companies by Filing Volume:\")\n    for company, count in company_counts.items():\n        print(f\"  {company}: {count} filings\")\n\n    # Analyze by filing date\n    daily_counts = df['filing_date'].value_counts().sort_index()\n\n    print(f\"\\n\ud83d\udcc5 Daily Filing Counts (last {len(daily_counts)} days):\")\n    for date, count in daily_counts.tail(7).items():\n        print(f\"  {date}: {count} filings\")\n\n    return df\n\n# Run the analysis\ninsider_df = analyze_insider_activity()\n</code></pre>"},{"location":"guides/current-filings/#example-3-real-time-filing-feed","title":"Example 3: Real-Time Filing Feed","text":"<pre><code>from edgar import get_current_filings\nimport time\n\ndef real_time_filing_feed(max_iterations=10):\n    \"\"\"Create a real-time feed of new filings.\"\"\"\n\n    seen_filings = set()\n    iteration = 0\n\n    print(\"\ud83d\udd04 Starting real-time filing feed...\")\n    print(\"Press Ctrl+C to stop\\n\")\n\n    try:\n        while iteration &lt; max_iterations:\n            # Get latest filings\n            current = get_current_filings(page_size=20)\n            new_filings = []\n\n            for filing in current:\n                filing_id = filing.accession_no\n                if filing_id not in seen_filings:\n                    new_filings.append(filing)\n                    seen_filings.add(filing_id)\n\n            if new_filings:\n                print(f\"\ud83c\udd95 {len(new_filings)} new filings detected:\")\n                for filing in new_filings:\n                    print(f\"  {filing.form}: {filing.company}\")\n                print()\n            else:\n                print(\"\u23f3 No new filings found, waiting...\")\n\n            # Wait before next check\n            time.sleep(30)  # Check every 30 seconds\n            iteration += 1\n\n    except KeyboardInterrupt:\n        print(\"\\n\u270b Feed stopped by user\")\n\n# Run the feed (limited iterations for demo)\nreal_time_filing_feed()\n</code></pre>"},{"location":"guides/current-filings/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guides/current-filings/#memory-usage","title":"Memory Usage","text":"<pre><code># Memory efficient: Process page by page\ntotal_processed = 0\nfor page in iter_current_filings_pages(form=\"8-K\"):\n    # Process this page\n    total_processed += len(page)\n\n    # Page goes out of scope, memory is freed\n    print(f\"Processed {total_processed} total filings\")\n\n# Memory intensive: Load all at once\nall_filings = get_all_current_filings()  # May use significant memory\n</code></pre>"},{"location":"guides/current-filings/#network-efficiency","title":"Network Efficiency","text":"<pre><code># Efficient: Larger page sizes reduce requests\nefficient = get_current_filings(page_size=100)  # 1 request\n\n# Less efficient: Smaller pages mean more requests  \nless_efficient = get_current_filings(page_size=10)  # May need 10 requests for same data\n</code></pre>"},{"location":"guides/current-filings/#rate-limiting","title":"Rate Limiting","text":"<p>The SEC imposes rate limits, so avoid rapid consecutive requests:</p> <pre><code>import time\n\n# Good: Natural pacing between requests\nfor page in iter_current_filings_pages():\n    # Process page\n    time.sleep(0.1)  # Brief pause between pages\n\n# Bad: Rapid fire requests (may hit rate limits)\nfor i in range(100):\n    page = get_current_filings()  # Don't do this!\n</code></pre>"},{"location":"guides/current-filings/#choosing-the-right-function","title":"Choosing the Right Function","text":""},{"location":"guides/current-filings/#use-get_current_filings-when","title":"Use <code>get_current_filings()</code> when:","text":"<ul> <li>\u2705 You want a quick sample of recent filings</li> <li>\u2705 Building pagination in your own interface</li> <li>\u2705 Memory usage is a concern</li> <li>\u2705 You only need the first page or two</li> </ul>"},{"location":"guides/current-filings/#use-iter_current_filings_pages-when","title":"Use <code>iter_current_filings_pages()</code> when:","text":"<ul> <li>\u2705 You want to process all filings but control memory usage</li> <li>\u2705 You need page-by-page processing logic</li> <li>\u2705 You want to limit total pages processed</li> <li>\u2705 Building streaming or incremental processing</li> </ul>"},{"location":"guides/current-filings/#use-get_all_current_filings-when","title":"Use <code>get_all_current_filings()</code> when:","text":"<ul> <li>\u2705 You need the complete dataset for analysis</li> <li>\u2705 Memory usage is not a constraint</li> <li>\u2705 You want to convert to pandas DataFrame</li> <li>\u2705 Building bulk analysis or reporting</li> </ul>"},{"location":"guides/current-filings/#error-handling","title":"Error Handling","text":""},{"location":"guides/current-filings/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<pre><code>from edgar import get_current_filings\nimport time\n\ndef robust_current_filings(form=\"\", max_retries=3):\n    \"\"\"Get current filings with error handling.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            return get_current_filings(form=form)\n\n        except ConnectionError as e:\n            print(f\"\u26a0\ufe0f Connection error (attempt {attempt + 1}): {e}\")\n            if attempt &lt; max_retries - 1:\n                time.sleep(2 ** attempt)  # Exponential backoff\n            else:\n                raise\n\n        except Exception as e:\n            print(f\"\u274c Unexpected error: {e}\")\n            raise\n\n# Usage\ntry:\n    filings = robust_current_filings(form=\"8-K\")\n    print(f\"\u2705 Successfully retrieved {len(filings)} filings\")\nexcept Exception as e:\n    print(f\"\ud83d\udca5 Failed to get filings: {e}\")\n</code></pre>"},{"location":"guides/current-filings/#best-practices","title":"Best Practices","text":""},{"location":"guides/current-filings/#1-use-appropriate-filters","title":"1. Use Appropriate Filters","text":"<pre><code># Good: Specific filtering reduces data and improves performance\ninsider_filings = get_current_filings(form=\"4\")\ncorporate_events = get_current_filings(form=\"8-K\")\n\n# Okay: General purpose but processes more data\nall_filings = get_current_filings()\n</code></pre>"},{"location":"guides/current-filings/#2-handle-pagination-properly","title":"2. Handle Pagination Properly","text":"<pre><code># Good: Check for None before processing next page\ncurrent_page = get_current_filings()\nwhile current_page is not None:\n    # Process current page\n    for filing in current_page:\n        print(f\"Processing {filing.company}\")\n\n    # Get next page\n    current_page = current_page.next()\n\n# Bad: Assuming next() always returns data\n# This could cause infinite loops or errors\n</code></pre>"},{"location":"guides/current-filings/#3-be-respectful-of-sec-resources","title":"3. Be Respectful of SEC Resources","text":"<pre><code># Good: Process in reasonable batches with pauses\nfor page in iter_current_filings_pages(page_size=100):\n    # Process page\n    time.sleep(0.1)  # Brief pause\n\n# Good: Cache results when possible\ncached_filings = get_all_current_filings(form=\"8-K\")\n# Reuse cached_filings instead of re-downloading\n</code></pre>"},{"location":"guides/current-filings/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/current-filings/#research-and-analysis","title":"Research and Analysis","text":"<ul> <li>Market surveillance: Monitor 8-K filings for material events</li> <li>Insider tracking: Analyze Form 4 patterns for trading insights  </li> <li>Compliance monitoring: Track filing compliance across companies</li> </ul>"},{"location":"guides/current-filings/#application-development","title":"Application Development","text":"<ul> <li>Filing alerts: Build notifications for specific form types</li> <li>Data pipelines: Integrate current filings into larger workflows</li> <li>Dashboard feeds: Power real-time filing displays</li> </ul>"},{"location":"guides/current-filings/#academic-research","title":"Academic Research","text":"<ul> <li>Event studies: Analyze market reactions to filing events</li> <li>Disclosure analysis: Study timing and content patterns</li> <li>Regulatory compliance: Research filing behavior patterns</li> </ul>"},{"location":"guides/current-filings/#summary","title":"Summary","text":"<p>Current filings provide real-time access to the latest SEC documents, enabling immediate analysis of corporate events, insider trading, and regulatory submissions. The three main functions offer flexibility for different use cases:</p> <ul> <li><code>get_current_filings()</code>: Single page access with pagination control</li> <li><code>iter_current_filings_pages()</code>: Memory-efficient iteration through all pages  </li> <li><code>get_all_current_filings()</code>: Bulk access to complete current filing dataset</li> </ul> <p>Choose the approach that best fits your memory constraints, processing requirements, and analysis goals.</p>"},{"location":"guides/current-filings/#next-steps","title":"Next Steps","text":"<ul> <li>Guide: Working with Filings</li> <li>API Reference: Filings API</li> </ul>"},{"location":"guides/extract-statements/","title":"Extract Financial Statements","text":"<p>Learn how to extract and work with financial statements from SEC filings using EdgarTools' powerful XBRL processing capabilities.</p>"},{"location":"guides/extract-statements/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of financial statements (balance sheet, income statement, cash flow)</li> <li>Familiarity with finding companies and searching filings</li> </ul>"},{"location":"guides/extract-statements/#quick-start-single-period-statements","title":"Quick Start: Single Period Statements","text":""},{"location":"guides/extract-statements/#get-latest-financial-statements","title":"Get Latest Financial Statements","text":"<p>The fastest way to get financial statements is using the Company.financials property:</p> <pre><code>from edgar import Company\n\n# Get Apple's latest financials\ncompany = Company(\"AAPL\")\nfinancials = company.get_financials()\n\n# Access individual statements\nbalance_sheet = financials.balance_sheet\nincome_statement = financials.income_statement()\ncash_flow = financials.cashflow_statement()\n</code></pre>"},{"location":"guides/extract-statements/#alternative-from-specific-filing","title":"Alternative: From Specific Filing","text":"<p>For more control, extract statements from a specific filing:</p> <pre><code>from edgar import Company\n\n# Get a specific filing\ncompany = Company(\"AAPL\")\nfiling = company.get_filings(form=\"10-K\").latest()\n\n# Parse XBRL data\nxbrl = filing.xbrl()\n\n# Access statements through the user-friendly API\nstatements = xbrl.statements\n\n# Display financial statements\nbalance_sheet = statements.balance_sheet()\nincome_statement = statements.income_statement()\ncash_flow = statements.cashflow_statement()\n\nprint(balance_sheet)  # Rich formatted output\n</code></pre>"},{"location":"guides/extract-statements/#enhanced-dimensional-display","title":"Enhanced Dimensional Display","text":"<p>EdgarTools now automatically surfaces rich dimensional segment data in financial statements when available:</p> <pre><code># Get Microsoft's income statement - now shows product/service breakdowns\ncompany = Company(\"MSFT\")\nxbrl = company.get_filings(form=\"10-K\").latest().xbrl()\nincome_stmt = xbrl.statements.income_statement()\n\nprint(income_stmt)\n# Output shows both summary revenue AND detailed breakdowns:\n# - Product revenue: $63.9B \n# - Service revenue: $217.8B\n# - Business segment details (LinkedIn: $17.8B, Gaming: $23.5B, etc.)\n</code></pre> <p>Control Dimensional Display:</p> <pre><code># Default behavior - includes dimensional segment data\ndf_enhanced = income_stmt.to_dataframe()  # 48 rows for Microsoft\nprint(f\"Enhanced view: {len(df_enhanced)} rows\")\n\n# Traditional view - excludes dimensional data\ndf_traditional = income_stmt.to_dataframe(include_dimensions=False)  # 21 rows\nprint(f\"Traditional view: {len(df_traditional)} rows\")\n</code></pre> <p>What Gets Enhanced: - Product/service revenue breakdowns - Geographic segment data - Business unit financial details - Any ProductOrServiceAxis dimensional facts</p> <p>This enhancement works automatically across companies that provide segment data in their XBRL filings, including Microsoft, Apple, Amazon, Google, and many others.</p>"},{"location":"guides/extract-statements/#standardized-financial-data-access","title":"Standardized Financial Data Access","text":""},{"location":"guides/extract-statements/#simple-metric-extraction-new","title":"Simple Metric Extraction (New!)","text":"<p>The easiest way to get key financial metrics is using the new standardized accessor methods:</p> <pre><code>from edgar import Company\n\n# Get a company's financials\ncompany = Company(\"AAPL\")\nfinancials = company.get_financials()\n\n# Extract key metrics directly - these work across all companies!\nrevenue = financials.get_revenue()\nnet_income = financials.get_net_income()\ntotal_assets = financials.get_total_assets()\n\nprint(f\"Revenue: ${revenue:,.0f}\")\nprint(f\"Net Income: ${net_income:,.0f}\")\nprint(f\"Total Assets: ${total_assets:,.0f}\")\n</code></pre> <p>This simple API works consistently across all companies, regardless of their custom XBRL concepts!</p>"},{"location":"guides/extract-statements/#available-standardized-methods","title":"Available Standardized Methods","text":"<p>All methods support historical data via the <code>period_offset</code> parameter:</p> <pre><code># Income Statement Metrics\nrevenue_current = financials.get_revenue()           # Current period\nrevenue_previous = financials.get_revenue(1)        # Previous period\nnet_income = financials.get_net_income()\n\n# Balance Sheet Metrics  \ntotal_assets = financials.get_total_assets()\ntotal_liabilities = financials.get_total_liabilities()\nstockholders_equity = financials.get_stockholders_equity()\ncurrent_assets = financials.get_current_assets()\ncurrent_liabilities = financials.get_current_liabilities()\n\n# Cash Flow Metrics\noperating_cash_flow = financials.get_operating_cash_flow()\ncapital_expenditures = financials.get_capital_expenditures()\nfree_cash_flow = financials.get_free_cash_flow()    # Calculated automatically\n</code></pre>"},{"location":"guides/extract-statements/#comprehensive-financial-analysis","title":"Comprehensive Financial Analysis","text":"<p>Get all key metrics at once with automatic ratio calculations:</p> <pre><code># Get comprehensive metrics dictionary\nmetrics = financials.get_financial_metrics()\n\n# All the standard metrics are available\nprint(f\"Revenue: ${metrics['revenue']:,.0f}\")\nprint(f\"Net Income: ${metrics['net_income']:,.0f}\")\nprint(f\"Total Assets: ${metrics['total_assets']:,.0f}\")\n\n# Plus calculated ratios\nprint(f\"Current Ratio: {metrics['current_ratio']:.2f}\")\nprint(f\"Debt to Assets: {metrics['debt_to_assets']:.2f}\")\nprint(f\"Free Cash Flow: ${metrics['free_cash_flow']:,.0f}\")\n</code></pre>"},{"location":"guides/extract-statements/#cross-company-analysis-made-simple","title":"Cross-Company Analysis Made Simple","text":"<p>Now comparing multiple companies is trivial:</p> <pre><code>companies = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"]\n\nprint(\"Company\\t\\tRevenue\\t\\tNet Income\\tTotal Assets\")\nprint(\"-\" * 60)\n\nfor ticker in companies:\n    company = Company(ticker)\n    financials = company.get_financials()\n\n    if financials:\n        revenue = financials.get_revenue()\n        net_income = financials.get_net_income()\n        total_assets = financials.get_total_assets()\n\n        print(f\"{ticker}\\t\\t${revenue/1e9:.1f}B\\t\\t${net_income/1e9:.1f}B\\t\\t${total_assets/1e9:.1f}B\")\n</code></pre>"},{"location":"guides/extract-statements/#tesla-custom-concepts-no-problem","title":"Tesla Custom Concepts - No Problem!","text":"<p>The standardized methods automatically handle companies with custom concepts like Tesla:</p> <pre><code># Works even with companies that use non-standard XBRL concepts\ntesla = Company(\"TSLA\")\ntsla_financials = tesla.get_financials()\n\n# These work despite Tesla's custom concepts\ntsla_revenue = tsla_financials.get_revenue()\ntsla_net_income = tsla_financials.get_net_income()\n\nprint(f\"Tesla Revenue: ${tsla_revenue:,.0f}\")\nprint(f\"Tesla Net Income: ${tsla_net_income:,.0f}\")\n</code></pre>"},{"location":"guides/extract-statements/#growth-analysis-with-historical-data","title":"Growth Analysis with Historical Data","text":"<p>Calculate growth rates using the <code>period_offset</code> parameter:</p> <pre><code># Get current and previous year data\ncurrent_revenue = financials.get_revenue(0)    # Current period\nprevious_revenue = financials.get_revenue(1)   # Previous period\n\nif current_revenue and previous_revenue:\n    growth_rate = (current_revenue - previous_revenue) / previous_revenue * 100\n    print(f\"Revenue Growth: {growth_rate:.1f}%\")\n\n# Same pattern works for any metric\ncurrent_ni = financials.get_net_income(0)\nprevious_ni = financials.get_net_income(1)\n\nif current_ni and previous_ni:\n    ni_growth = (current_ni - previous_ni) / previous_ni * 100\n    print(f\"Net Income Growth: {ni_growth:.1f}%\")\n</code></pre>"},{"location":"guides/extract-statements/#multi-period-analysis","title":"Multi-Period Analysis","text":""},{"location":"guides/extract-statements/#method-1-using-multifinancials","title":"Method 1: Using MultiFinancials","text":"<p>Get financials across multiple years for trend analysis:</p> <pre><code>from edgar import Company, MultiFinancials\n\n# Get multiple years of 10-K filings\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=\"10-K\").head(3)  # Last 3 annual reports\n\n# Create multi-period financials\nmulti_financials = MultiFinancials.extract(filings)\n\n# Access statements spanning multiple years\nbalance_sheet = multi_financials.balance_sheet()\nincome_statement = multi_financials.income_statement()\ncash_flow = multi_financials.cashflow_statement()\n\nprint(\"Multi-Year Income Statement:\")\nprint(income_statement)\n</code></pre>"},{"location":"guides/extract-statements/#method-2-using-xbrl-stitching","title":"Method 2: Using XBRL Stitching","text":"<p>For more advanced multi-period analysis with intelligent period matching:</p> <pre><code>from edgar import Company\nfrom edgar.xbrl import XBRLS\n\n# Get multiple filings for trend analysis\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=\"10-K\").head(3)\n\n# Create stitched view across multiple filings\nxbrls = XBRLS.from_filings(filings)\n\n# Access stitched statements\nstitched_statements = xbrls.statements\n\n# Display multi-period statements with intelligent period selection\nincome_trend = stitched_statements.income_statement()\nbalance_sheet_trend = stitched_statements.balance_sheet()\ncashflow_trend = stitched_statements.cashflow_statement()\n\nprint(\"Three-Year Revenue Trend:\")\nrevenue_trend = income_trend.to_dataframe()\nrevenue_row = revenue_trend.loc[revenue_trend['label'] == 'Revenue']\nprint(revenue_row)\n</code></pre> <p>Dimensional Data in Stitching:</p> <p>By default, stitching uses traditional statement structures for performance and compatibility:</p> <pre><code># Default stitching - traditional structure for multi-period consistency\nincome_stmt = xbrls.render_statement(\"IncomeStatement\")  # Clean, focused view\n\n# Enable dimensional data in stitching if desired (advanced usage)\nincome_stmt_detailed = xbrls.render_statement(\"IncomeStatement\", include_dimensions=True)\n# Note: May result in missing data if not all periods have consistent dimensional coverage\n</code></pre> <p>When to Use Each: - Traditional stitching (default): Best for trend analysis, ratios, and cross-period comparisons - Dimensional stitching: Use when you specifically need segment data across periods and know the data is consistent</p>"},{"location":"guides/extract-statements/#working-with-individual-statements","title":"Working with Individual Statements","text":""},{"location":"guides/extract-statements/#balance-sheet-analysis","title":"Balance Sheet Analysis","text":"<pre><code># Get balance sheet\nbalance_sheet = statements.balance_sheet()\n\n# Convert to DataFrame for analysis\nbs_df = balance_sheet.to_dataframe()\n\n# Extract key balance sheet items\ntotal_assets = bs_df[bs_df['label'] == 'Total Assets']\ntotal_liabilities = bs_df[bs_df['label'] == 'Total Liabilities']\nshareholders_equity = bs_df[bs_df['label'] == \"Total Stockholders' Equity\"]\n\nprint(\"Balance Sheet Summary:\")\nprint(f\"Total Assets: ${total_assets.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Total Liabilities: ${total_liabilities.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Shareholders' Equity: ${shareholders_equity.iloc[0, -1]/1e9:.1f}B\")\n\n# Calculate debt-to-equity ratio\ndebt_to_equity = total_liabilities.iloc[0, -1] / shareholders_equity.iloc[0, -1]\nprint(f\"Debt-to-Equity Ratio: {debt_to_equity:.2f}\")\n</code></pre>"},{"location":"guides/extract-statements/#income-statement-analysis","title":"Income Statement Analysis","text":"<pre><code># Get income statement\nincome_statement = statements.income_statement()\n\n# Convert to DataFrame\nis_df = income_statement.to_dataframe()\n\n# Extract key income statement items\nrevenue = is_df[is_df['label'] == 'Revenue']\ngross_profit = is_df[is_df['label'] == 'Gross Profit']\noperating_income = is_df[is_df['label'] == 'Operating Income']\nnet_income = is_df[is_df['label'] == 'Net Income']\n\nprint(\"Income Statement Analysis:\")\nprint(f\"Revenue: ${revenue.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Gross Profit: ${gross_profit.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Operating Income: ${operating_income.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Net Income: ${net_income.iloc[0, -1]/1e9:.1f}B\")\n\n# Calculate margins\ngross_margin = (gross_profit.iloc[0, -1] / revenue.iloc[0, -1]) * 100\noperating_margin = (operating_income.iloc[0, -1] / revenue.iloc[0, -1]) * 100\nnet_margin = (net_income.iloc[0, -1] / revenue.iloc[0, -1]) * 100\n\nprint(f\"\\nMargin Analysis:\")\nprint(f\"Gross Margin: {gross_margin:.1f}%\")\nprint(f\"Operating Margin: {operating_margin:.1f}%\")\nprint(f\"Net Margin: {net_margin:.1f}%\")\n</code></pre>"},{"location":"guides/extract-statements/#cash-flow-analysis","title":"Cash Flow Analysis","text":"<pre><code># Get cash flow statement\ncash_flow = statements.cashflow_statement()\n\n# Convert to DataFrame\ncf_df = cash_flow.to_dataframe()\n\n# Extract cash flow components\noperating_cf = cf_df[cf_df['label'] == 'Net Cash from Operating Activities']\ninvesting_cf = cf_df[cf_df['label'] == 'Net Cash from Investing Activities']\nfinancing_cf = cf_df[cf_df['label'] == 'Net Cash from Financing Activities']\n\nprint(\"Cash Flow Analysis:\")\nprint(f\"Operating Cash Flow: ${operating_cf.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Investing Cash Flow: ${investing_cf.iloc[0, -1]/1e9:.1f}B\")\nprint(f\"Financing Cash Flow: ${financing_cf.iloc[0, -1]/1e9:.1f}B\")\n\n# Calculate free cash flow (Operating CF - Capital Expenditures)\ncapex = cf_df[cf_df['label'].str.contains('Capital Expenditures', case=False, na=False)]\nif not capex.empty:\n    free_cash_flow = operating_cf.iloc[0, -1] + capex.iloc[0, -1]  # CapEx is usually negative\n    print(f\"Free Cash Flow: ${free_cash_flow/1e9:.1f}B\")\n</code></pre>"},{"location":"guides/extract-statements/#advanced-statement-customization","title":"Advanced Statement Customization","text":""},{"location":"guides/extract-statements/#period-views-and-formatting","title":"Period Views and Formatting","text":"<pre><code># Get available period views for income statement\nperiod_views = statements.get_period_views(\"IncomeStatement\")\nprint(\"Available period views:\")\nfor view in period_views:\n    print(f\"- {view['name']}: {view['description']}\")\n\n# Render with specific period view\nannual_comparison = statements.income_statement(period_view=\"Annual Comparison\")\nquarterly_comparison = statements.income_statement(period_view=\"Quarterly Comparison\")\n\n# Show full date ranges for duration periods\nincome_with_dates = statements.income_statement(show_date_range=True)\n\nprint(\"Income Statement with Date Ranges:\")\nprint(income_with_dates)\n</code></pre>"},{"location":"guides/extract-statements/#standardized-vs-company-specific-labels","title":"Standardized vs Company-Specific Labels","text":"<pre><code># Use standardized labels for cross-company comparison (default)\nstandardized = statements.income_statement(standard=True)\n\n# Use company-specific labels as reported in filing\ncompany_specific = statements.income_statement(standard=False)\n\nprint(\"Standardized Labels:\")\nprint(standardized.to_dataframe()['label'].head(10))\n\nprint(\"\\nCompany-Specific Labels:\")\nprint(company_specific.to_dataframe()['label'].head(10))\n</code></pre>"},{"location":"guides/extract-statements/#cross-company-analysis","title":"Cross-Company Analysis","text":""},{"location":"guides/extract-statements/#compare-multiple-companies-updated-with-new-api","title":"Compare Multiple Companies (Updated with New API!)","text":"<pre><code>import pandas as pd\n\ndef get_key_metrics(ticker):\n    \"\"\"Extract key financial metrics for a company using new standardized methods.\"\"\"\n    try:\n        company = Company(ticker)\n        financials = company.get_financials()\n\n        if not financials:\n            return None\n\n        # Use the new standardized accessor methods - much simpler!\n        return {\n            'ticker': ticker,\n            'revenue': financials.get_revenue(),\n            'net_income': financials.get_net_income(),\n            'total_assets': financials.get_total_assets(),\n            'operating_cf': financials.get_operating_cash_flow(),\n            'free_cf': financials.get_free_cash_flow()\n        }\n    except Exception as e:\n        print(f\"Error processing {ticker}: {e}\")\n        return None\n\n# Analyze multiple companies\ntech_companies = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\nmetrics = []\n\nfor ticker in tech_companies:\n    result = get_key_metrics(ticker)\n    if result:\n        metrics.append(result)\n\n# Create comparison DataFrame\ncomparison_df = pd.DataFrame(metrics)\n\n# Convert to billions and calculate ratios\ncomparison_df['revenue_b'] = comparison_df['revenue'] / 1e9\ncomparison_df['net_income_b'] = comparison_df['net_income'] / 1e9\ncomparison_df['net_margin'] = (comparison_df['net_income'] / comparison_df['revenue']) * 100\ncomparison_df['roa'] = (comparison_df['net_income'] / comparison_df['total_assets']) * 100\n\nprint(\"Tech Giants Comparison:\")\nprint(comparison_df[['ticker', 'revenue_b', 'net_income_b', 'net_margin', 'roa']].round(1))\n</code></pre> <p>The new standardized methods make cross-company analysis much more reliable and easier to implement!</p>"},{"location":"guides/extract-statements/#advanced-xbrl-features","title":"Advanced XBRL Features","text":""},{"location":"guides/extract-statements/#access-raw-xbrl-facts","title":"Access Raw XBRL Facts","text":"<pre><code># Access the facts API for detailed XBRL data\nfacts = xbrl.facts\n\n# Query facts by concept\nrevenue_facts = facts.query().by_concept('Revenue').to_dataframe()\nprint(\"Revenue facts across all periods:\")\nprint(revenue_facts[['concept', 'label', 'period', 'value']])\n\n# Search for specific concepts\nearnings_facts = facts.search_facts(\"Earnings Per Share\")\nprint(\"EPS-related facts:\")\nprint(earnings_facts[['concept', 'label', 'value']])\n\n# Get facts by statement type\nbalance_sheet_facts = facts.query().by_statement_type('BalanceSheet').to_dataframe()\nprint(f\"Found {len(balance_sheet_facts)} balance sheet facts\")\n</code></pre>"},{"location":"guides/extract-statements/#time-series-analysis","title":"Time Series Analysis","text":"<pre><code># Get time series data for specific concepts\nrevenue_series = facts.time_series('Revenue')\nnet_income_series = facts.time_series('Net Income')\n\nprint(\"Revenue Time Series:\")\nprint(revenue_series)\n\n# Convert to DataFrame for analysis\nimport pandas as pd\nts_df = pd.DataFrame({\n    'revenue': revenue_series,\n    'net_income': net_income_series\n})\n\n# Calculate growth rates\nts_df['revenue_growth'] = ts_df['revenue'].pct_change() * 100\nts_df['income_growth'] = ts_df['net_income'].pct_change() * 100\n\nprint(\"Growth Analysis:\")\nprint(ts_df[['revenue_growth', 'income_growth']].round(1))\n</code></pre>"},{"location":"guides/extract-statements/#dimensional-analysis","title":"Dimensional Analysis","text":"<pre><code># Query facts by dimensions (if available)\nsegment_facts = facts.query().by_dimension('Segment').to_dataframe()\nif not segment_facts.empty:\n    print(\"Segment-specific financial data:\")\n    print(segment_facts[['concept', 'label', 'dimension_value', 'value']].head())\n\n# Get facts by geographic dimension\ngeographic_facts = facts.query().by_dimension('Geography').to_dataframe()\nif not geographic_facts.empty:\n    print(\"Geographic breakdown:\")\n    print(geographic_facts[['concept', 'dimension_value', 'value']].head())\n</code></pre>"},{"location":"guides/extract-statements/#export-and-integration","title":"Export and Integration","text":""},{"location":"guides/extract-statements/#export-to-different-formats","title":"Export to Different Formats","text":"<pre><code># Export statements to various formats\nincome_statement = statements.income_statement()\n\n# Export to pandas DataFrame\ndf = income_statement.to_dataframe()\n\n# Export to markdown\nmarkdown_text = income_statement.render().to_markdown()\n\n# Save to CSV\ndf.to_csv('apple_income_statement.csv', index=False)\n\n# Save markdown to file\nwith open('apple_income_statement.md', 'w') as f:\n    f.write(markdown_text)\n\nprint(\"Statements exported to CSV and Markdown\")\n</code></pre>"},{"location":"guides/extract-statements/#integration-with-analysis-libraries","title":"Integration with Analysis Libraries","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Get multi-period data\nfilings = company.get_filings(form=\"10-K\").head(5)\nmulti_financials = MultiFinancials.extract(filings)\nincome_df = multi_financials.income.to_dataframe()\n\n# Extract revenue data for plotting\nrevenue_data = income_df[income_df['label'] == 'Revenue'].iloc[0, 1:].astype(float)\nperiods = revenue_data.index\n\n# Create visualization\nplt.figure(figsize=(10, 6))\nplt.plot(periods, revenue_data / 1e9, marker='o', linewidth=2)\nplt.title('Apple Revenue Trend (5 Years)')\nplt.xlabel('Period')\nplt.ylabel('Revenue (Billions USD)')\nplt.xticks(rotation=45)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Calculate year-over-year growth\nrevenue_growth = revenue_data.pct_change() * 100\nprint(\"Year-over-Year Revenue Growth:\")\nfor period, growth in revenue_growth.dropna().items():\n    print(f\"{period}: {growth:.1f}%\")\n</code></pre>"},{"location":"guides/extract-statements/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guides/extract-statements/#efficient-multi-company-analysis","title":"Efficient Multi-Company Analysis","text":"<pre><code># Efficient batch processing\ndef batch_analyze_companies(tickers, max_workers=5):\n    \"\"\"Analyze multiple companies efficiently.\"\"\"\n    from concurrent.futures import ThreadPoolExecutor\n\n    def analyze_single(ticker):\n        try:\n            company = Company(ticker)\n            financials = company.financials\n            return {\n                'ticker': ticker,\n                'revenue': financials.income.loc['Revenue'].iloc[0],\n                'assets': financials.balance_sheet.loc['Total Assets'].iloc[0]\n            }\n        except Exception as e:\n            return {'ticker': ticker, 'error': str(e)}\n\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = list(executor.map(analyze_single, tickers))\n\n    return [r for r in results if 'error' not in r]\n\n# Analyze S&amp;P 100 companies efficiently\nsp100_sample = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'JPM']\nresults = batch_analyze_companies(sp100_sample)\n\ncomparison_df = pd.DataFrame(results)\nprint(\"Batch Analysis Results:\")\nprint(comparison_df.head())\n</code></pre>"},{"location":"guides/extract-statements/#caching-for-repeated-analysis","title":"Caching for Repeated Analysis","text":"<pre><code># Cache XBRL data for repeated use\ncompany = Company(\"AAPL\")\nfiling = company.get_filings(form=\"10-K\").latest()\n\n# Parse once, use multiple times\nxbrl = filing.xbrl()\n\n# Perform different analyses on same data\nbalance_sheet = xbrl.statements.balance_sheet()\nincome_statement = xbrl.statements.income_statement()\ncash_flow = xbrl.statements.cashflow_statement()\n\n# Access facts for custom queries\nfacts = xbrl.facts\nrevenue_facts = facts.query().by_concept('Revenue').to_dataframe()\nmargin_facts = facts.search_facts(\"margin\")\n</code></pre>"},{"location":"guides/extract-statements/#common-patterns-and-best-practices","title":"Common Patterns and Best Practices","text":""},{"location":"guides/extract-statements/#robust-financial-metric-extraction","title":"Robust Financial Metric Extraction","text":"<pre><code>def safe_extract_metric(statement_df, label, column=-1, default=None):\n    \"\"\"Safely extract a metric from financial statement DataFrame.\"\"\"\n    try:\n        rows = statement_df[statement_df['label'].str.contains(label, case=False, na=False)]\n        if not rows.empty:\n            return rows.iloc[0, column]\n        return default\n    except Exception:\n        return default\n\n# Use for robust metric extraction\nincome_df = statements.income_statement().to_dataframe()\n\nrevenue = safe_extract_metric(income_df, 'Revenue')\nnet_income = safe_extract_metric(income_df, 'Net Income')\noperating_income = safe_extract_metric(income_df, 'Operating Income')\n\nif revenue and net_income:\n    net_margin = (net_income / revenue) * 100\n    print(f\"Net Margin: {net_margin:.1f}%\")\n</code></pre>"},{"location":"guides/extract-statements/#handle-missing-or-inconsistent-data","title":"Handle Missing or Inconsistent Data","text":"<pre><code>def get_financial_metrics(company_ticker):\n    \"\"\"Get financial metrics with error handling.\"\"\"\n    try:\n        company = Company(company_ticker)\n        financials = company.financials\n\n        metrics = {}\n\n        # Try to get income statement metrics\n        try:\n            income = financials.income\n            metrics['revenue'] = income.loc['Revenue'].iloc[0] if 'Revenue' in income.index else None\n            metrics['net_income'] = income.loc['Net Income'].iloc[0] if 'Net Income' in income.index else None\n        except Exception as e:\n            print(f\"Income statement error for {company_ticker}: {e}\")\n\n        # Try to get balance sheet metrics\n        try:\n            balance_sheet = financials.balance_sheet\n            metrics['total_assets'] = balance_sheet.loc['Total Assets'].iloc[0] if 'Total Assets' in balance_sheet.index else None\n        except Exception as e:\n            print(f\"Balance sheet error for {company_ticker}: {e}\")\n\n        return metrics\n\n    except Exception as e:\n        print(f\"Company error for {company_ticker}: {e}\")\n        return {}\n\n# Test with various companies\ntest_companies = ['AAPL', 'INVALID_TICKER', 'MSFT']\nfor ticker in test_companies:\n    metrics = get_financial_metrics(ticker)\n    if metrics:\n        print(f\"{ticker}: {metrics}\")\n</code></pre>"},{"location":"guides/extract-statements/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"guides/extract-statements/#statement-not-available","title":"Statement Not Available","text":"<pre><code># Check what statements are available\ntry:\n    statements = xbrl.statements\n    available_statements = statements.available_statements()\n    print(f\"Available statements: {available_statements}\")\n\n    # Try alternative statement access\n    if 'IncomeStatement' in available_statements:\n        income = statements.income_statement()\n    elif 'ComprehensiveIncome' in available_statements:\n        income = statements['ComprehensiveIncome']\n    else:\n        print(\"No income statement available\")\n\nexcept Exception as e:\n    print(f\"Error accessing statements: {e}\")\n</code></pre>"},{"location":"guides/extract-statements/#period-selection-issues","title":"Period Selection Issues","text":"<pre><code># Check available periods\nreporting_periods = xbrl.reporting_periods\nprint(\"Available reporting periods:\")\nfor period in reporting_periods[:5]:  # Show first 5\n    print(f\"- {period['date']} ({period['type']}): {period.get('duration', 'N/A')} days\")\n\n# Handle quarterly vs annual periods\nif any(p.get('duration', 0) &lt; 120 for p in reporting_periods):\n    print(\"Quarterly periods detected\")\n    quarterly_income = statements.income_statement(period_view=\"Quarterly Comparison\")\nelse:\n    print(\"Annual periods only\")\n    annual_income = statements.income_statement(period_view=\"Annual Comparison\")\n</code></pre>"},{"location":"guides/extract-statements/#next-steps","title":"Next Steps","text":"<p>Now that you can extract financial statements, explore these advanced topics:</p>"},{"location":"guides/extract-statements/#-query-xbrl-data-advanced-xbrl-fact-querying-and-analysis","title":"- Query XBRL Data - Advanced XBRL fact querying and analysis","text":""},{"location":"guides/extract-statements/#related-documentation","title":"Related Documentation","text":"<ul> <li>Getting XBRL from Filings - Original XBRL documentation</li> <li>Company Financials - Company financials API</li> <li>XBRL API Reference - Complete XBRL class documentation</li> </ul>"},{"location":"guides/filing-attachments/","title":"Attachments","text":"<p>Once you have a <code>Filing</code> instance you can access the attachments for the filing using the <code>attachments</code> property.</p> <pre><code>filing.attachments\n</code></pre> <p></p>"},{"location":"guides/filing-attachments/#get-an-attachment-by-index","title":"Get an attachment by index","text":"<p>You can get an attachment by index using the <code>[]</code> operator and using the <code>Seq</code> number of the attachment. The primary filing document is always at index 1, and is usually HTML or XML.</p> <pre><code>attachment = filing.attachments[1]\nattachment\n</code></pre> <p></p>"},{"location":"guides/filing-attachments/#viewing-an-attachment","title":"Viewing an attachment","text":"<p>You can view the attachment in a browser using the <code>view()</code> method. This works if the attachment is a text or html file.</p> <pre><code>attachment.view()\n</code></pre> <p></p> <p>This extracts the text of the attachment and renders it in the console. If you need to get the text use the <code>text()</code> method.</p>"},{"location":"guides/filing-attachments/#getting-the-text-content-of-an-attachment","title":"Getting the text content of an attachment","text":"<p>You can get the text content of an attachment using the <code>text()</code> function.</p> <pre><code>text = attachment.text()\nprint(text)\n</code></pre> <p>This will print the text content of the attachment.</p>"},{"location":"guides/filing-attachments/#converting-html-attachments-to-markdown","title":"Converting HTML attachments to markdown","text":"<p>You can convert HTML attachments to markdown format using the <code>markdown()</code> method.</p> <pre><code># Convert a single HTML attachment to markdown\nattachment = filing.attachments[1]  # Get the primary document\nif attachment.is_html():\n    markdown_content = attachment.markdown()\n    print(markdown_content)\n</code></pre> <p>The <code>markdown()</code> method returns <code>None</code> for non-HTML attachments, so you can safely call it on any attachment.</p>"},{"location":"guides/filing-attachments/#page-break-delimiter-support","title":"Page Break Delimiter Support","text":"<p>The <code>markdown()</code> method supports optional page break delimiters to help you understand document structure:</p> <pre><code># Convert with page break delimiters\nattachment = filing.attachments[1]\nmarkdown_with_breaks = attachment.markdown(include_page_breaks=True)\n\n# Page breaks appear as: {1}------------------------------------------------\n# Where the number indicates the page number\n</code></pre> <p>When <code>include_page_breaks=True</code>, the markdown will include delimiters at page boundaries in the format: - <code>{0}------------------------------------------------</code> at the start of the document - <code>{1}------------------------------------------------</code> before the second page content - <code>{2}------------------------------------------------</code> before the third page content - And so on...</p>"},{"location":"guides/filing-attachments/#customizing-page-numbering","title":"Customizing Page Numbering","text":"<p>You can control the starting page number for page break markers using the <code>start_page_number</code> parameter:</p> <pre><code># Start page numbering at 1 (instead of 0)\nattachment = filing.attachments[1]\nmarkdown_with_breaks = attachment.markdown(include_page_breaks=True, start_page_number=1)\n\n# This will produce: {1}------------------------------------------------, {2}------------------------------------------------, etc.\n\n# Start page numbering at 5\nmarkdown_with_breaks = attachment.markdown(include_page_breaks=True, start_page_number=5)\n\n# This will produce: {5}------------------------------------------------, {6}------------------------------------------------, etc.\n</code></pre> <p>This is particularly useful when you want to align page numbers with external document numbering or when processing documents that are part of a larger collection.</p>"},{"location":"guides/filing-attachments/#batch-markdown-conversion","title":"Batch markdown conversion","text":"<p>You can convert all HTML attachments in a filing to markdown at once:</p> <pre><code># Convert all HTML attachments (without page breaks)\nmarkdown_dict = filing.attachments.markdown()\n\n# Convert all HTML attachments with page breaks\nmarkdown_dict = filing.attachments.markdown(include_page_breaks=True)\n\n# Convert all HTML attachments with page breaks starting at page 1\nmarkdown_dict = filing.attachments.markdown(include_page_breaks=True, start_page_number=1)\n\n# Result is a dictionary: {\"filename.htm\": \"markdown content\", ...}\nfor filename, content in markdown_dict.items():\n    print(f\"--- {filename} ---\")\n    print(content[:500])  # Show first 500 characters\n</code></pre>"},{"location":"guides/filing-attachments/#saving-markdown-content","title":"Saving markdown content","text":"<p>You can save the markdown content to files:</p> <pre><code># Save individual attachment markdown\nattachment = filing.attachments[1]\nmarkdown_content = attachment.markdown()\nif markdown_content:\n    with open(f\"{attachment.document}.md\", \"w\") as f:\n        f.write(markdown_content)\n\n# Save all HTML attachments as markdown files\nmarkdown_dict = filing.attachments.markdown()\nfor doc_name, markdown_content in markdown_dict.items():\n    # Remove extension and add .md\n    base_name = doc_name.rsplit('.', 1)[0]\n    with open(f\"{base_name}.md\", \"w\") as f:\n        f.write(markdown_content)\n</code></pre>"},{"location":"guides/filing-attachments/#downloading-an-attachment","title":"Downloading an attachment","text":"<p>You can download the attachment using the <code>download()</code> method. This will download the attachment to the current working directory.</p> <pre><code>attachment.download('/path/to/download')\n</code></pre> <p>If the path is a directory the attachment will be downloaded to that directory using the original name of the file.</p> <p>If the path is a file the attachment will be downloaded to that file. This allows you to rename the attachment.</p> <p>If you don't provide a path the content of the attachment will be returned as a string.</p>"},{"location":"guides/filtering-filings/","title":"Filtering filings","text":"<p>Filings can be filtered in many different ways like by <code>form</code>, <code>date</code>, <code>CIK</code>, <code>ticker</code>, and accession number. You also filter while getting filings using the <code>get_filings</code> function or after getting filings using the <code>filter</code> method.</p> <p>For the most part these approaches will give identical results, except that with get_filings you are filtering from all available filings in the SEC, while with <code>filter</code> you are reducing the nu,ber of filings in a <code>Filings</code> object.</p>"},{"location":"guides/filtering-filings/#filtering-using-parameters-of-get_filings","title":"Filtering using parameters of <code>get_filings</code>","text":"<p>You can filter using parameters of the <code>get_filings</code> function. </p>"},{"location":"guides/filtering-filings/#get-filings-by-form","title":"Get filings by form","text":"<p>To get filings of a specific form type like 10-K, you can use the <code>form</code> parameter. For example:</p> <pre><code>filings = get_filings(form='10-K')\n</code></pre> <p>The <code>form</code> can also be a list of forms. For example:</p> <pre><code>filings = get_filings(form=['10-K', '10-Q'])\n</code></pre> <p>By default the <code>amendments</code> parameter is set to <code>True</code> so that amended filings are included. You can set it to <code>False</code> to exclude amended filings. For example:</p> <pre><code>filings = get_filings(form='10-K', amendments=False)\n</code></pre>"},{"location":"guides/filtering-filings/#filtering-by-date","title":"Filtering by date","text":"<p>You can filter filings by date using the <code>filing_date</code> parameter. For example:</p> <pre><code>filings = get_filings(filing_date='2022-01-01')\n</code></pre> <p>You can also filter by a range of dates. For example:</p> <pre><code>filings = get_filings(filing_date='2022-01-01:2022-01-10')\n</code></pre> <p>You can filter up to a date. For example:</p> <pre><code>filings = get_filings(filing_date=':2022-01-10')\n</code></pre> <p>as well as after a date. For example:</p> <pre><code>filings = get_filings(filing_date='2022-01-10:')\n</code></pre>"},{"location":"guides/filtering-filings/#more-filtering-examples","title":"More filtering examples","text":"<pre><code>\nfrom edgar import get_filings\n\n# Get filings for 2021\nfilings_ = get_filings(2021) \n\n# Get filings for 2021 Q4\nfilings_ = get_filings(2021, 4) \n\n# Get filings for 2021 Q3 and Q4\nfilings_ = get_filings(2021, [3,4]) \n\n# Get filings for 2020 and 2021\nfilings_ = get_filings([2020, 2021]) \n\n# Get filings for Q4 of 2020 and 2021\nfilings_ = get_filings([2020, 2021], 4) \n\n# Get filings between 2010 and 2021 - does not include 2021\nfilings_ = get_filings(range(2010, 2021)) \n\n# Get filings for 2021 Q4 for form D\nfilings_ = get_filings(2021, 4, form=\"D\") \n\n# Get filings for 2021 Q4 on \"2021-10-01\"\nfilings_ = get_filings(2021, 4, filing_date=\"2021-10-01\") \n\n# Get filings for 2021 Q4 between \"2021-10-01\" and \"2021-10-10\"\nfilings_ = get_filings(2021, 4, filing_date=\"2021-10-01:2021-10-10\") \n\n</code></pre>"},{"location":"guides/filtering-filings/#filtering-using-filingsfilter","title":"Filtering using <code>Filings.filter</code>","text":"<p>You can filter filings using the <code>filter</code> method after getting filings. This work mostly identically to filtering using <code>get_filings</code>. The difference is that <code>filter</code> reduces from an existing <code>Filings</code> object rather that the entire SEC.</p> <p>Example:</p> <pre><code>filings().filter(form='10-K')\n</code></pre> <pre><code>def filter(self, *,\n    form: Optional[Union[str, List[IntString]]] = None,\n    amendments: bool = None,\n    filing_date: Optional[str] = None,\n    date: Optional[str] = None,\n    cik: Union[IntString, List[IntString]] = None,\n    exchange: Union[str, List[str], Exchange, List[Exchange]] = None,\n    ticker: Union[str, List[str]] = None,\n    accession_number: Union[str, List[str]] = None) -&gt; Optional['Filings']:\n\n    :param form: The form or list of forms to filter by\n    :param amendments: Whether to include amendments to the forms e.g. include \"10-K/A\"\n    :param filing_date: The filing date\n    :param date: An alias for the filing date\n    :param cik: The CIK or list of CIKs to filter by\n    :param exchange: The exchange or list of exchanges to filter by\n    :param ticker: The ticker or list of tickers to filter by\n    :param accession_number: The accession number or list of accession numbers to filter by\n</code></pre>"},{"location":"guides/filtering-filings/#filtering-by-cik","title":"Filtering by CIK","text":"<p>You can filter filings by CIK by using the <code>filter</code> function with the <code>cik</code> parameter to get all filings for a company. For example:</p> <pre><code>filings = get_filings.filter(cik='0000320193')\n</code></pre>"},{"location":"guides/filtering-filings/#filtering-by-ticker","title":"Filtering by ticker","text":"<p>You can filter filings by ticker  by using the <code>filter</code> function with the <code>ticker</code> parameter. For example:</p> <pre><code>filings = get_filings.filter(ticker='AAPL')\n</code></pre> <p>Note that this first does a lookup of the CIK for the ticker and then gets filings for the CIK. So if you know the CIK, it is better to use that directly.</p> <p>Note that you can also get use <code>Company(&lt;ticker&gt;)</code> OR  <code>Company(&lt;cik&gt;)</code> and then use the <code>get_filings</code> method to get filings for the company. For example:</p>"},{"location":"guides/filtering-filings/#filtering-by-exchange","title":"Filtering by exchange","text":"<p>You can filter filings by <code>exchange</code>. </p> <pre><code>filings = get_filings().filter(exchange='NASDAQ')\n</code></pre> <p>There are the following exchanges available:</p> Exchange Nasdaq NYSE CBOE OTC"},{"location":"guides/filtering-filings/#using-head-tail-and-sample","title":"Using <code>head</code>, <code>tail</code>, and <code>sample</code>","text":"<p>You can subset filings using the <code>head</code> and <code>tail</code> and <code>sample</code> methods. For example:</p> <pre><code>filings = get_filings()\nfilings.head(10)\nfilings.tail(10)\nfilings.sample(10)\n</code></pre>"},{"location":"guides/finding-companies/","title":"Find Companies by Name/Ticker","text":"<p>Learn how to locate companies in the SEC database using tickers, CIKs, or company names.</p>"},{"location":"guides/finding-companies/#method-1-find-by-ticker-symbol","title":"Method 1: Find by Ticker Symbol","text":"<p>The most common way to find a company is by its stock ticker symbol:</p> <pre><code>from edgar import Company\n\n# Find Apple by ticker (case-insensitive)\napple = Company(\"AAPL\")\nprint(apple)\n</code></pre> <p>Output:</p> <pre><code>Company(AAPL - Apple Inc.)\n  CIK: 0000320193\n  Industry: ELECTRONIC COMPUTERS\n  Website: https://www.apple.com\n  Location: Cupertino, CA\n</code></pre> <p>Key points: - Tickers are case-insensitive: <code>Company(\"aapl\")</code> works the same as <code>Company(\"AAPL\")</code> - This performs a ticker lookup then loads the company data - Some companies have multiple tickers for the same entity</p>"},{"location":"guides/finding-companies/#method-2-find-by-cik-central-index-key","title":"Method 2: Find by CIK (Central Index Key)","text":"<p>The CIK uniquely identifies every SEC filer and is more reliable than tickers:</p> <pre><code># Using numeric CIK\napple = Company(320193)\n\n# Using string CIK (with or without zero padding)\napple = Company(\"320193\")\napple = Company(\"0000320193\")\n\nprint(apple)\n</code></pre> <p>Why use CIK: - Unique: Every company has exactly one CIK - Permanent: CIKs don't change like tickers might - Faster: Direct lookup without ticker resolution</p>"},{"location":"guides/finding-companies/#method-3-search-by-company-name","title":"Method 3: Search by Company Name","text":"<p>When you don't know the exact ticker or CIK:</p> <pre><code>from edgar import find\n\n# Search for companies by name\nresults = find(\"Apple\")\nprint(f\"Found {len(results)} companies:\")\nfor company in results:\n    print(f\"  {company.ticker}: {company.name}\")\n</code></pre> <p>Output:</p> <pre><code>Found 3 companies:\n  AAPL: Apple Inc.\n  APPL: Apple Hospitality REIT Inc\n  APOG: Apogee Enterprises Inc\n</code></pre> <p>Then select the right one:</p> <pre><code># Get the first result\napple = results[0]\n\n# Or be more specific\napple = Company(\"AAPL\")  # If you know the ticker from search\n</code></pre>"},{"location":"guides/finding-companies/#working-with-company-objects","title":"Working with Company Objects","text":"<p>Once you have a Company object, you can access detailed information:</p> <pre><code>company = Company(\"MSFT\")\n\n# Basic information\nprint(f\"Name: {company.name}\")\nprint(f\"CIK: {company.cik}\")\nprint(f\"Ticker: {company.ticker}\")\nprint(f\"Industry: {company.industry}\")\nprint(f\"Website: {company.website}\")\nprint(f\"Location: {company.city}, {company.state}\")\n\n# SEC-specific information\nprint(f\"SIC Code: {company.sic}\")\nprint(f\"Fiscal Year End: {company.fiscal_year_end}\")\nprint(f\"Exchange: {company.exchange}\")\n</code></pre> <p>Output:</p> <pre><code>Name: Microsoft Corporation\nCIK: 0000789019\nTicker: MSFT\nIndustry: SERVICES-PREPACKAGED SOFTWARE\nWebsite: https://www.microsoft.com\nLocation: Redmond, WA\nSIC Code: 7372\nFiscal Year End: 0630\nExchange: Nasdaq\n</code></pre>"},{"location":"guides/finding-companies/#handling-edge-cases","title":"Handling Edge Cases","text":""},{"location":"guides/finding-companies/#company-not-found","title":"Company Not Found","text":"<pre><code>try:\n    company = Company(\"INVALID\")\nexcept Exception as e:\n    print(f\"Company not found: {e}\")\n    # Fallback to search\n    results = find(\"Invalid Corp\")\n    if results:\n        company = results[0]\n    else:\n        print(\"No companies found matching that name\")\n</code></pre>"},{"location":"guides/finding-companies/#multiple-tickers-for-same-company","title":"Multiple Tickers for Same Company","text":"<pre><code># Berkshire Hathaway has multiple share classes\nbrk_a = Company(\"BRK-A\")  # Class A shares\nbrk_b = Company(\"BRK-B\")  # Class B shares\n\n# Both point to the same CIK and SEC filings\nprint(f\"BRK-A CIK: {brk_a.cik}\")\nprint(f\"BRK-B CIK: {brk_b.cik}\")\n# Both will show: 0001067983\n</code></pre>"},{"location":"guides/finding-companies/#historical-tickers","title":"Historical Tickers","text":"<pre><code># Some companies change tickers over time\n# The Company object will find the current entity\ntry:\n    company = Company(\"FB\")  # Meta's old ticker\n    print(f\"Found: {company.name}\")  # May find Meta Platforms Inc\nexcept:\n    # Try the new ticker\n    company = Company(\"META\")\n    print(f\"Found: {company.name}\")\n</code></pre>"},{"location":"guides/finding-companies/#batch-company-lookup","title":"Batch Company Lookup","text":"<p>For analyzing multiple companies efficiently:</p> <pre><code>from edgar import Company\n\n# List of tickers to analyze\ntickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"]\ncompanies = []\n\nfor ticker in tickers:\n    try:\n        company = Company(ticker)\n        companies.append({\n            'ticker': ticker,\n            'name': company.name,\n            'cik': company.cik,\n            'industry': company.industry,\n            'market_cap': company.market_cap  # If available\n        })\n        print(f\"\u2713 Found {ticker}: {company.name}\")\n    except Exception as e:\n        print(f\"\u2717 Error with {ticker}: {e}\")\n\n# Convert to DataFrame for analysis\nimport pandas as pd\ndf = pd.DataFrame(companies)\nprint(df)\n</code></pre>"},{"location":"guides/finding-companies/#advanced-search-techniques","title":"Advanced Search Techniques","text":""},{"location":"guides/finding-companies/#search-by-industry","title":"Search by Industry","text":"<pre><code>from edgar import get_filings\n\n# Get recent filings and filter by industry keywords\nfilings = get_filings()\ntech_companies = []\n\nfor filing in filings:\n    if filing.company_name and any(keyword in filing.company_name.lower() \n                                  for keyword in ['tech', 'software', 'computer']):\n        try:\n            company = Company(filing.cik)\n            tech_companies.append(company)\n        except:\n            continue\n\n# Remove duplicates\nunique_companies = {c.cik: c for c in tech_companies}\nprint(f\"Found {len(unique_companies)} unique tech companies\")\n</code></pre>"},{"location":"guides/finding-companies/#search-by-filing-activity","title":"Search by Filing Activity","text":"<pre><code># Find companies that filed 8-K forms recently\nrecent_8k_filings = get_filings(form=\"8-K\", limit=100)\n\nactive_companies = []\nfor filing in recent_8k_filings:\n    try:\n        company = Company(filing.cik)\n        active_companies.append({\n            'ticker': company.ticker,\n            'name': company.name,\n            'filing_date': filing.filing_date,\n            'cik': company.cik\n        })\n    except:\n        continue\n\n# Show most recently active companies\ndf = pd.DataFrame(active_companies)\nrecent_activity = df.sort_values('filing_date', ascending=False).head(10)\nprint(recent_activity)\n</code></pre>"},{"location":"guides/finding-companies/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use CIK when possible: Faster than ticker lookup</li> <li>Cache company objects: If analyzing the same companies repeatedly</li> <li>Batch processing: Handle errors gracefully in loops</li> <li>Check data availability: Not all companies have all fields populated</li> </ol>"},{"location":"guides/finding-companies/#common-issues","title":"Common Issues","text":""},{"location":"guides/finding-companies/#ticker-vs-company-name-confusion","title":"Ticker vs Company Name Confusion","text":"<pre><code># This will fail - searching for ticker in name search\nresults = find(\"AAPL\")  # Returns companies with \"AAPL\" in name, not ticker\n\n# Use Company() for ticker lookup\ncompany = Company(\"AAPL\")  # Correct for ticker lookup\n</code></pre>"},{"location":"guides/finding-companies/#international-companies","title":"International Companies","text":"<pre><code># Some foreign companies trade on US exchanges\ntry:\n    company = Company(\"ASML\")  # Dutch company on NASDAQ\n    print(f\"Found: {company.name} in {company.country}\")\nexcept:\n    print(\"Company not found or not SEC-registered\")\n</code></pre>"},{"location":"guides/finding-companies/#delisted-companies","title":"Delisted Companies","text":"<pre><code># Some companies may be delisted but still have SEC filings\ntry:\n    company = Company(\"1234567\")  # Use CIK for delisted companies\n    print(f\"Company: {company.name}\")\n    print(f\"Status: {'Active' if company.ticker else 'Possibly delisted'}\")\nexcept:\n    print(\"Company not found in SEC database\")\n</code></pre>"},{"location":"guides/finding-companies/#next-steps","title":"Next Steps","text":"<p>Now that you can find companies, learn how to:</p> <ul> <li>Search for Specific Filings - Find the documents you need</li> <li>Extract Financial Statements - Get financial data</li> <li>Filter Filings by Date/Type - Narrow down your search</li> </ul>"},{"location":"guides/finding-companies/#related-documentation","title":"Related Documentation","text":"<ul> <li>Company API Reference - Complete Company class documentation</li> <li>Working with Companies - Original company documentation</li> </ul>"},{"location":"guides/local-storage/","title":"Local Storage Guide","text":"<p>edgartools is designed for interactive queries against SEC Edgar, which means it normally makes HTTP requests to the SEC website to retrieve data. For example, when you call <code>company.submissions</code> or <code>filing.attachments</code>, it makes a request to the SEC.</p> <p>There are times when you want to minimize or eliminate these requests:</p> <ol> <li>Performance: Speed up processing by avoiding network requests</li> <li>Offline usage: Work without internet access or in restricted environments</li> <li>Bandwidth efficiency: Reduce data usage and respect SEC rate limits</li> <li>Development: Use cached data for testing and development</li> </ol> <p>edgartools provides comprehensive local storage capabilities to address these needs.</p>"},{"location":"guides/local-storage/#supported-local-data-types","title":"Supported Local Data Types","text":"Data Type Description Company Submissions Company metadata and their 1000 most recent filings Company Facts Standardized company financial facts from XBRL filings Filing Attachments Complete filing documents with all attachments Reference Data Company and mutual fund tickers, exchanges, and other lookups"},{"location":"guides/local-storage/#local-data-directory","title":"Local Data Directory","text":""},{"location":"guides/local-storage/#default-location","title":"Default Location","text":"<p>The default local data directory is:</p> <pre><code>&lt;USER_HOME&gt;/.edgar\n</code></pre>"},{"location":"guides/local-storage/#setting-the-directory","title":"Setting the Directory","text":"<p>You can set the local data directory in several ways:</p> <p>Method 1: Environment Variable</p> <pre><code>export EDGAR_LOCAL_DATA_DIR=\"/path/to/local/data\"\n</code></pre> <p>Method 2: Programmatic (New)</p> <pre><code>from edgar import set_local_storage_path\nimport os\n\n# Create the directory first\nos.makedirs(\"/tmp/edgar_data\", exist_ok=True)\n\n# Set the path\nset_local_storage_path(\"/tmp/edgar_data\")\n</code></pre> <p>Method 3: One-Step Setup (New)</p> <pre><code>from edgar import use_local_storage\nimport os\n\n# Create and set directory, enable local storage in one call\nos.makedirs(\"/tmp/edgar_data\", exist_ok=True)\nuse_local_storage(\"/tmp/edgar_data\")\n</code></pre>"},{"location":"guides/local-storage/#enabling-local-storage","title":"Enabling Local Storage","text":""},{"location":"guides/local-storage/#basic-usage","title":"Basic Usage","text":"<pre><code>from edgar import use_local_storage\nimport os\n\n# Create directory\nos.makedirs(\"~/Documents/edgar\", exist_ok=True)\n\n# Set path and enable in one call\nuse_local_storage(\"~/Documents/edgar\")\n</code></pre>"},{"location":"guides/local-storage/#all-supported-patterns","title":"All Supported Patterns","text":"<pre><code># 1. BACKWARD COMPATIBLE\nuse_local_storage(True)    # Enable\nuse_local_storage(False)   # Disable  \nuse_local_storage()        # Enable (default)\n\n# 2. NEW INTUITIVE SYNTAX\nuse_local_storage(\"/tmp/edgar_data\")        # Path as string\nuse_local_storage(\"~/Documents/edgar\")      # Tilde expansion\nuse_local_storage(Path.home() / \"edgar\")    # Path object\n\n# 3. ADVANCED CONTROL\nuse_local_storage(\"/tmp/edgar\", True)       # Set path and enable\nuse_local_storage(\"/tmp/edgar\", False)      # Set path but keep disabled\n</code></pre>"},{"location":"guides/local-storage/#checking-status","title":"Checking Status","text":"<pre><code>from edgar import is_using_local_storage\n\nif is_using_local_storage():\n    print(\"Local storage is enabled\")\nelse:\n    print(\"Using remote SEC data\")\n</code></pre>"},{"location":"guides/local-storage/#downloading-data-to-local-storage","title":"Downloading Data to Local Storage","text":""},{"location":"guides/local-storage/#download-bulk-sec-data","title":"Download Bulk SEC Data","text":"<p>You can download bulk SEC data using the <code>download_edgar_data()</code> function:</p> <pre><code>from edgar import download_edgar_data\n\n# Download all data types (submissions, facts, reference data)\ndownload_edgar_data()\n\n# Download only specific data types\ndownload_edgar_data(\n    submissions=True,   # Company metadata and recent filings\n    facts=True,        # Company financial facts\n    reference=True     # Tickers, exchanges, etc.\n)\n</code></pre>"},{"location":"guides/local-storage/#download-complete-filings","title":"Download Complete Filings","text":"<p>Download individual filings with all attachments using <code>download_filings()</code>:</p> <pre><code>from edgar import download_filings\n\n# Download all filings for a specific date\ndownload_filings(\"2025-01-15\")\n\n# Download filings for a date range\ndownload_filings(\"2025-01-01:2025-01-15\")\n\n# Download from a start date onwards\ndownload_filings(\"2025-01-01:\")\n\n# Download up to an end date\ndownload_filings(\":2025-01-15\")\n</code></pre> <p>Note: Downloaded filings are stored in <code>EDGAR_LOCAL_DATA_DIR/filings/YYYYMMDD/</code>. When local storage is enabled, edgartools automatically checks local storage first before making SEC requests.</p>"},{"location":"guides/local-storage/#complete-workflow-examples","title":"Complete Workflow Examples","text":""},{"location":"guides/local-storage/#example-1-quick-setup-for-development","title":"Example 1: Quick Setup for Development","text":"<pre><code>from edgar import use_local_storage, download_edgar_data\nimport os\n\n# Setup local storage in one command\nos.makedirs(\"~/edgar_dev\", exist_ok=True)\nuse_local_storage(\"~/edgar_dev\")\n\n# Download essential data\ndownload_edgar_data(submissions=True, reference=True)\n\n# Now all queries use local data when available\nfrom edgar import Company\napple = Company(\"AAPL\")  # Uses local data\n</code></pre>"},{"location":"guides/local-storage/#example-2-high-performance-analysis-setup","title":"Example 2: High-Performance Analysis Setup","text":"<pre><code>from edgar import use_local_storage, download_filings, get_filings\nimport os\n\n# Setup high-performance storage\nos.makedirs(\"/tmp/edgar_fast\", exist_ok=True)\nuse_local_storage(\"/tmp/edgar_fast\")\n\n# Download specific filings for analysis\nfilings = get_filings(form=\"10-K\", year=2024)\ndownload_filings(filings=filings)\n\n# All subsequent operations are lightning fast\nfor filing in filings:\n    financial_data = filing.xbrl()  # Instant from local storage\n</code></pre>"},{"location":"guides/local-storage/#example-3-offline-research-environment","title":"Example 3: Offline Research Environment","text":"<pre><code>from edgar import use_local_storage, download_edgar_data, download_filings\nimport os\n\n# Setup offline-capable environment\nos.makedirs(\"~/research/edgar_offline\", exist_ok=True)\nuse_local_storage(\"~/research/edgar_offline\")\n\n# Download comprehensive dataset\ndownload_edgar_data()  # All bulk data\ndownload_filings(\"2024-01-01:2024-12-31\")  # Full year of filings\n\n# Now works completely offline\nfrom edgar import Company, get_filings\ncompanies = get_filings(form=\"10-K\", year=2024)  # From local storage\n</code></pre>"},{"location":"guides/local-storage/#filtering-downloads","title":"Filtering Downloads","text":""},{"location":"guides/local-storage/#download-specific-filings","title":"Download Specific Filings","text":"<p>Instead of downloading all filings, you can filter to download only what you need:</p> <pre><code>from edgar import get_filings, download_filings\n\n# Get filings with filters\nfilings = get_filings(form=\"10-K\", year=2024).filter(exchange=\"NYSE\")\n\n# Download only these filtered filings\ndownload_filings(filings=filings)\n</code></pre>"},{"location":"guides/local-storage/#advanced-filtering-examples","title":"Advanced Filtering Examples","text":"<pre><code># Download only tech companies' 10-K filings\ntech_filings = (get_filings(form=\"10-K\", year=2024)\n                .filter(exchange=[\"NASDAQ\", \"NYSE\"])\n\ndownload_filings(filings=tech_filings)\n\n# Download recent 8-K filings for specific analysis\nrecent_8k = get_filings(form=\"8-K\", filing_date=\"2025-01-01:\")\ndownload_filings(filings=recent_8k)\n</code></pre>"},{"location":"guides/local-storage/#performance-considerations","title":"Performance Considerations","text":""},{"location":"guides/local-storage/#storage-space","title":"Storage Space","text":"<p>Different data types require different amounts of storage:</p> Data Type Typical Size Description Reference Data ~50 MB Tickers, exchanges, mappings Company Facts ~2 GB Compressed financial facts Submissions ~5 GB Company metadata and filings Daily Filings ~100-500 MB All filings for one day"},{"location":"guides/local-storage/#download-times","title":"Download Times","text":"<ul> <li>Reference data: 1-2 seconds</li> <li>Company facts: 2-3 minutes</li> <li>Company submissions: 2-3 minutes </li> <li>Daily filings: 3-15 minutes depending on volume and time of day</li> </ul>"},{"location":"guides/local-storage/#compression","title":"Compression","text":"<p>Filings are automatically compressed to save space. The default compression level is set to 6, but you can adjust it to 9 for maximum compression:</p> <pre><code># Enable compression during download\ndownload_filings(\"2025-01-15\", compression_level=9)\n</code></pre>"},{"location":"guides/local-storage/#directory-structure","title":"Directory Structure","text":"<p>When using local storage, data is organized as follows:</p> <pre><code>EDGAR_LOCAL_DATA_DIR/\n\u251c\u2500\u2500 reference/              # Ticker and exchange data\n\u2502   \u251c\u2500\u2500 company_tickers.json\n\u2502   \u251c\u2500\u2500 ticker.txt\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 companyfacts/           # Company financial facts\n\u2502   \u2514\u2500\u2500 CIK[0-9]*.json\n\u251c\u2500\u2500 submissions/            # Company submission data  \n\u2502   \u2514\u2500\u2500 CIK[0-9]*.json\n\u2514\u2500\u2500 filings/               # Individual filing documents\n    \u251c\u2500\u2500 20250115/          # Filings by date\n    \u2502   \u251c\u2500\u2500 filing1.nc     # SGML filing documents\n    \u2502   \u2514\u2500\u2500 filing2.nc.gz  # Compressed filings\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"guides/local-storage/#best-practices","title":"Best Practices","text":""},{"location":"guides/local-storage/#1-start-small","title":"1. Start Small","text":"<pre><code># Begin with reference data only\nuse_local_storage(\"~/edgar_test\")\ndownload_edgar_data(submissions=False, facts=False, reference=True)\n</code></pre>"},{"location":"guides/local-storage/#2-use-appropriate-storage","title":"2. Use Appropriate Storage","text":"<pre><code># Fast SSD for high-performance analysis\nuse_local_storage(\"/fast_ssd/edgar_data\")\n\n# Network storage for shared team access\nuse_local_storage(\"/shared/team/edgar_data\")\n</code></pre>"},{"location":"guides/local-storage/#3-monitor-storage-usage","title":"3. Monitor Storage Usage","text":"<pre><code>from edgar.core import get_edgar_data_directory\nimport shutil\n\nstorage_path = get_edgar_data_directory()\ntotal, used, free = shutil.disk_usage(storage_path)\nprint(f\"Storage usage: {used // (1024**3)} GB used, {free // (1024**3)} GB free\")\n</code></pre>"},{"location":"guides/local-storage/#4-incremental-updates","title":"4. Incremental Updates","text":"<pre><code># Download only recent filings regularly\nfrom datetime import datetime, timedelta\n\nrecent_date = (datetime.now() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\ndownload_filings(f\"{recent_date}:\")\n</code></pre>"},{"location":"guides/local-storage/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/local-storage/#common-issues","title":"Common Issues","text":"<p>Path doesn't exist:</p> <pre><code># \u274c This will fail\nuse_local_storage(\"/nonexistent/path\")\n\n# \u2705 Create directory first\nimport os\nos.makedirs(\"/tmp/edgar\", exist_ok=True)\nuse_local_storage(\"/tmp/edgar\")\n</code></pre> <p>Insufficient space:</p> <pre><code># Check available space before large downloads\nimport shutil\n_, _, free = shutil.disk_usage(\"/tmp\")\nif free &lt; 10 * (1024**3):  # 10 GB\n    print(\"Warning: Less than 10 GB free space\")\n</code></pre> <p>Mixed local/remote data:</p> <pre><code># Ensure consistent data source\nfrom edgar import is_using_local_storage\n\nif is_using_local_storage():\n    print(\"Using local storage\")\nelse:\n    print(\"Using remote SEC data\")\n    # Enable if needed: use_local_storage(True)\n</code></pre>"},{"location":"guides/local-storage/#migration-and-backup","title":"Migration and Backup","text":""},{"location":"guides/local-storage/#moving-local-storage","title":"Moving Local Storage","text":"<pre><code># Old location\nold_path = \"~/old_edgar\"\n\n# New location  \nnew_path = \"/new/location/edgar\"\nos.makedirs(new_path, exist_ok=True)\n\n# Move data (outside Python)\n# cp -r ~/old_edgar/* /new/location/edgar/\n\n# Update edgartools\nuse_local_storage(new_path)\n</code></pre>"},{"location":"guides/local-storage/#backup-strategy","title":"Backup Strategy","text":"<pre><code># Create backup of critical data\nimport shutil\nfrom datetime import datetime\n\nbackup_name = f\"edgar_backup_{datetime.now().strftime('%Y%m%d')}\"\nshutil.copytree(get_edgar_data_directory(), f\"/backups/{backup_name}\")\n</code></pre>"},{"location":"guides/local-storage/#summary","title":"Summary","text":"<p>The enhanced local storage system in edgartools provides:</p>"},{"location":"guides/local-storage/#key-functions","title":"Key Functions","text":"<ul> <li><code>use_local_storage()</code>: Enable/disable local storage with optional path setting</li> <li><code>set_local_storage_path()</code>: Set storage directory path  </li> <li><code>is_using_local_storage()</code>: Check current status</li> <li><code>download_edgar_data()</code>: Download bulk SEC data</li> <li><code>download_filings()</code>: Download individual filings</li> </ul>"},{"location":"guides/local-storage/#benefits","title":"Benefits","text":"<ul> <li>Dramatic performance improvements: 10-100x faster than remote requests</li> <li>Offline capability: Work without internet connectivity</li> <li>Bandwidth efficiency: Reduce network usage and respect SEC limits</li> <li>Flexible configuration: Multiple ways to configure and use</li> <li>Comprehensive data: Support for all major SEC data types</li> </ul>"},{"location":"guides/local-storage/#quick-start","title":"Quick Start","text":"<pre><code>import os\nfrom edgar import use_local_storage, download_edgar_data\n\n# Setup in one line\nos.makedirs(\"~/edgar\", exist_ok=True)\nuse_local_storage(\"~/edgar\")\n\n# Download essential data\ndownload_edgar_data()\n\n# All subsequent operations use local storage when available\n</code></pre> <p>This comprehensive local storage system makes edgartools significantly more efficient for both development and production use cases.</p>"},{"location":"guides/multi-year-financial-data-api/","title":"Multi-Year Financial Data API Guide","text":"<p>Learn how to access multiple years of financial statements and serve them through FastAPI endpoints for web applications and data analysis.</p>"},{"location":"guides/multi-year-financial-data-api/#overview","title":"Overview","text":"<p>This guide demonstrates how to retrieve historical financial data (income statement, balance sheet, and cash flow) for multiple years and expose it through professional FastAPI endpoints. Perfect for building financial dashboards, analysis tools, or data APIs.</p>"},{"location":"guides/multi-year-financial-data-api/#quick-start","title":"Quick Start","text":"<pre><code>from edgar import Company\nfrom fastapi import FastAPI, HTTPException\nfrom typing import List, Dict, Any\nimport pandas as pd\n\napp = FastAPI(title=\"Financial Data API\")\n\n# Get multi-year financial data\ncompany = Company('AAPL')\n\n# Income statement - 5 years of annual data\nincome_stmt = company.income_statement(periods=5, annual=True)\n\n# Balance sheet - 5 years of annual data  \nbalance_sheet = company.balance_sheet(periods=5, annual=True)\n\n# Cash flow - 5 years of annual data\ncash_flow = company.cash_flow(periods=5, annual=True)\n\nprint(f\"Retrieved {len(income_stmt.periods)} periods of data\")\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#core-data-retrieval-patterns","title":"Core Data Retrieval Patterns","text":""},{"location":"guides/multi-year-financial-data-api/#multi-year-annual-statements","title":"Multi-Year Annual Statements","text":"<pre><code>def get_multi_year_financials(ticker: str, years: int = 5):\n    \"\"\"Get multiple years of financial statements\"\"\"\n    company = Company(ticker)\n\n    if not company.facts:\n        return None\n\n    # Get annual data for specified years\n    financial_data = {\n        'company': {\n            'name': company.name,\n            'ticker': ticker,\n            'shares_outstanding': company.shares_outstanding,\n            'public_float': company.public_float\n        },\n        'income_statement': company.income_statement(periods=years, annual=True),\n        'balance_sheet': company.balance_sheet(periods=years, annual=True),\n        'cash_flow': company.cash_flow(periods=years, annual=True)\n    }\n\n    return financial_data\n\n# Example usage\naapl_data = get_multi_year_financials('AAPL', 7)\nprint(f\"Retrieved data for periods: {aapl_data['income_statement'].periods}\")\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#mixed-period-analysis","title":"Mixed Period Analysis","text":"<pre><code>def get_comprehensive_data(ticker: str):\n    \"\"\"Get both annual and quarterly data for trend analysis\"\"\"\n    company = Company(ticker)\n\n    if not company.facts:\n        return None\n\n    return {\n        'annual': {\n            'income': company.income_statement(periods=5, annual=True),\n            'balance': company.balance_sheet(periods=5, annual=True),\n            'cashflow': company.cash_flow(periods=5, annual=True)\n        },\n        'quarterly': {\n            'income': company.income_statement(periods=12, annual=False),\n            'balance': company.balance_sheet(periods=12, annual=False), \n            'cashflow': company.cash_flow(periods=12, annual=False)\n        }\n    }\n\n# Get comprehensive view\ncomprehensive = get_comprehensive_data('MSFT')\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#fastapi-endpoint-implementation","title":"FastAPI Endpoint Implementation","text":""},{"location":"guides/multi-year-financial-data-api/#basic-financial-data-endpoints","title":"Basic Financial Data Endpoints","text":"<pre><code>from fastapi import FastAPI, HTTPException, Query\nfrom pydantic import BaseModel\nfrom typing import Optional, Dict, Any, List\nfrom edgar import Company\nimport json\n\napp = FastAPI(\n    title=\"Financial Data API\",\n    description=\"Access multi-year financial statements from SEC data\",\n    version=\"1.0.0\"\n)\n\nclass FinancialResponse(BaseModel):\n    company_info: Dict[str, Any]\n    periods: List[str]\n    data: Dict[str, Any]\n    metadata: Dict[str, Any]\n\n@app.get(\"/financial/{ticker}/income\", response_model=FinancialResponse)\nasync def get_income_statement(\n    ticker: str,\n    periods: int = Query(4, description=\"Number of periods\", ge=1, le=20),\n    annual: bool = Query(True, description=\"Annual (True) or Quarterly (False)\"),\n    concise_format: bool = Query(False, description=\"Use concise formatting ($1.0B vs $1,000,000,000)\")\n):\n    \"\"\"Get income statement data for multiple periods\"\"\"\n    try:\n        company = Company(ticker.upper())\n\n        if not company.facts:\n            raise HTTPException(status_code=404, detail=f\"No financial data available for {ticker}\")\n\n        # Get income statement\n        stmt = company.income_statement(periods=periods, annual=annual, concise_format=concise_format)\n\n        if not stmt:\n            raise HTTPException(status_code=404, detail=f\"No income statement data for {ticker}\")\n\n        # Convert to API response format\n        response_data = {\n            'company_info': {\n                'name': company.name,\n                'ticker': ticker.upper(),\n                'shares_outstanding': company.shares_outstanding,\n                'public_float': company.public_float\n            },\n            'periods': stmt.periods,\n            'data': _convert_statement_to_dict(stmt),\n            'metadata': {\n                'period_type': 'annual' if annual else 'quarterly',\n                'concise_format': concise_format,\n                'total_items': len(list(stmt.iter_with_values()))\n            }\n        }\n\n        return FinancialResponse(**response_data)\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/financial/{ticker}/balance\", response_model=FinancialResponse)  \nasync def get_balance_sheet(\n    ticker: str,\n    periods: int = Query(4, description=\"Number of periods\", ge=1, le=20),\n    annual: bool = Query(True, description=\"Annual (True) or Quarterly (False)\"),\n    concise_format: bool = Query(False, description=\"Use concise formatting\")\n):\n    \"\"\"Get balance sheet data for multiple periods\"\"\"\n    try:\n        company = Company(ticker.upper())\n\n        if not company.facts:\n            raise HTTPException(status_code=404, detail=f\"No financial data available for {ticker}\")\n\n        stmt = company.balance_sheet(periods=periods, annual=annual, concise_format=concise_format)\n\n        if not stmt:\n            raise HTTPException(status_code=404, detail=f\"No balance sheet data for {ticker}\")\n\n        response_data = {\n            'company_info': {\n                'name': company.name,\n                'ticker': ticker.upper(),\n                'shares_outstanding': company.shares_outstanding,\n                'public_float': company.public_float\n            },\n            'periods': stmt.periods,\n            'data': _convert_statement_to_dict(stmt),\n            'metadata': {\n                'period_type': 'annual' if annual else 'quarterly',\n                'concise_format': concise_format,\n                'total_items': len(list(stmt.iter_with_values()))\n            }\n        }\n\n        return FinancialResponse(**response_data)\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/financial/{ticker}/cashflow\", response_model=FinancialResponse)\nasync def get_cash_flow(\n    ticker: str,\n    periods: int = Query(4, description=\"Number of periods\", ge=1, le=20),\n    annual: bool = Query(True, description=\"Annual (True) or Quarterly (False)\"),\n    concise_format: bool = Query(False, description=\"Use concise formatting\")\n):\n    \"\"\"Get cash flow statement data for multiple periods\"\"\"\n    try:\n        company = Company(ticker.upper())\n\n        if not company.facts:\n            raise HTTPException(status_code=404, detail=f\"No financial data available for {ticker}\")\n\n        stmt = company.cash_flow(periods=periods, annual=annual, concise_format=concise_format)\n\n        if not stmt:\n            raise HTTPException(status_code=404, detail=f\"No cash flow data for {ticker}\")\n\n        response_data = {\n            'company_info': {\n                'name': company.name,\n                'ticker': ticker.upper(),\n                'shares_outstanding': company.shares_outstanding,\n                'public_float': company.public_float\n            },\n            'periods': stmt.periods,\n            'data': _convert_statement_to_dict(stmt),\n            'metadata': {\n                'period_type': 'annual' if annual else 'quarterly',\n                'concise_format': concise_format,\n                'total_items': len(list(stmt.iter_with_values()))\n            }\n        }\n\n        return FinancialResponse(**response_data)\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\ndef _convert_statement_to_dict(stmt):\n    \"\"\"Convert statement to API-friendly dictionary format\"\"\"\n    data = {}\n\n    for item in stmt.iter_with_values():\n        # Create item data with all periods\n        item_data = {\n            'label': item.label,\n            'concept': item.concept,\n            'values': {},\n            'is_total': getattr(item, 'is_total', False),\n            'depth': getattr(item, 'depth', 0)\n        }\n\n        # Add values for each period\n        for period in stmt.periods:\n            value = item.values.get(period)\n            if value is not None:\n                item_data['values'][period] = {\n                    'raw_value': value,\n                    'display_value': item.get_display_value(period)\n                }\n\n        data[item.concept] = item_data\n\n    return data\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#comprehensive-multi-statement-endpoint","title":"Comprehensive Multi-Statement Endpoint","text":"<pre><code>class ComprehensiveFinancialResponse(BaseModel):\n    company_info: Dict[str, Any]\n    periods: List[str]\n    income_statement: Dict[str, Any]\n    balance_sheet: Dict[str, Any]\n    cash_flow: Dict[str, Any]\n    key_metrics: Dict[str, Any]\n    metadata: Dict[str, Any]\n\n@app.get(\"/financial/{ticker}/comprehensive\", response_model=ComprehensiveFinancialResponse)\nasync def get_comprehensive_financials(\n    ticker: str,\n    periods: int = Query(5, description=\"Number of periods\", ge=1, le=10),\n    annual: bool = Query(True, description=\"Annual (True) or Quarterly (False)\"),\n    concise_format: bool = Query(False, description=\"Use concise formatting\"),\n    include_ratios: bool = Query(True, description=\"Calculate financial ratios\")\n):\n    \"\"\"Get comprehensive financial data including all statements and key metrics\"\"\"\n    try:\n        company = Company(ticker.upper())\n\n        if not company.facts:\n            raise HTTPException(status_code=404, detail=f\"No financial data available for {ticker}\")\n\n        # Get all three statements\n        income_stmt = company.income_statement(periods=periods, annual=annual, concise_format=concise_format)\n        balance_sheet = company.balance_sheet(periods=periods, annual=annual, concise_format=concise_format)\n        cash_flow = company.cash_flow(periods=periods, annual=annual, concise_format=concise_format)\n\n        # Get periods from the first available statement\n        available_periods = []\n        if income_stmt:\n            available_periods = income_stmt.periods\n        elif balance_sheet:\n            available_periods = balance_sheet.periods\n        elif cash_flow:\n            available_periods = cash_flow.periods\n\n        if not available_periods:\n            raise HTTPException(status_code=404, detail=f\"No financial statement data available for {ticker}\")\n\n        # Calculate key metrics if requested\n        key_metrics = {}\n        if include_ratios and income_stmt and balance_sheet:\n            key_metrics = _calculate_financial_ratios(income_stmt, balance_sheet, cash_flow)\n\n        response_data = {\n            'company_info': {\n                'name': company.name,\n                'ticker': ticker.upper(),\n                'shares_outstanding': company.shares_outstanding,\n                'public_float': company.public_float\n            },\n            'periods': available_periods,\n            'income_statement': _convert_statement_to_dict(income_stmt) if income_stmt else {},\n            'balance_sheet': _convert_statement_to_dict(balance_sheet) if balance_sheet else {},\n            'cash_flow': _convert_statement_to_dict(cash_flow) if cash_flow else {},\n            'key_metrics': key_metrics,\n            'metadata': {\n                'period_type': 'annual' if annual else 'quarterly',\n                'concise_format': concise_format,\n                'statements_available': {\n                    'income_statement': income_stmt is not None,\n                    'balance_sheet': balance_sheet is not None,\n                    'cash_flow': cash_flow is not None\n                }\n            }\n        }\n\n        return ComprehensiveFinancialResponse(**response_data)\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\ndef _calculate_financial_ratios(income_stmt, balance_sheet, cash_flow):\n    \"\"\"Calculate key financial ratios from statements\"\"\"\n    ratios = {}\n\n    try:\n        # Get latest period\n        if not income_stmt.periods:\n            return ratios\n\n        latest_period = income_stmt.periods[0]\n\n        # Find key items\n        revenue_item = income_stmt.find_item('Revenue')\n        net_income_item = income_stmt.find_item('Net Income')\n        total_assets_item = balance_sheet.find_item('Assets') if balance_sheet else None\n        total_equity_item = balance_sheet.find_item('Equity') if balance_sheet else None\n\n        # Calculate ratios for latest period\n        if revenue_item and net_income_item:\n            revenue = revenue_item.values.get(latest_period)\n            net_income = net_income_item.values.get(latest_period)\n\n            if revenue and net_income and revenue != 0:\n                ratios[f'profit_margin_{latest_period.lower().replace(\" \", \"_\")}'] = net_income / revenue\n\n        if net_income_item and total_assets_item:\n            net_income = net_income_item.values.get(latest_period)\n            total_assets = total_assets_item.values.get(latest_period)\n\n            if net_income and total_assets and total_assets != 0:\n                ratios[f'roa_{latest_period.lower().replace(\" \", \"_\")}'] = net_income / total_assets\n\n        if net_income_item and total_equity_item:\n            net_income = net_income_item.values.get(latest_period)\n            total_equity = total_equity_item.values.get(latest_period)\n\n            if net_income and total_equity and total_equity != 0:\n                ratios[f'roe_{latest_period.lower().replace(\" \", \"_\")}'] = net_income / total_equity\n\n    except Exception as e:\n        # Log error but don't fail the request\n        print(f\"Error calculating ratios: {e}\")\n\n    return ratios\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#historical-trend-analysis-endpoints","title":"Historical Trend Analysis Endpoints","text":"<pre><code>from datetime import datetime, timedelta\n\n@app.get(\"/financial/{ticker}/trends\")\nasync def get_financial_trends(\n    ticker: str,\n    metric: str = Query(..., description=\"Metric to analyze (revenue, net_income, assets)\"),\n    years: int = Query(5, description=\"Number of years\", ge=2, le=10)\n):\n    \"\"\"Get historical trends for specific financial metrics\"\"\"\n    try:\n        company = Company(ticker.upper())\n\n        if not company.facts:\n            raise HTTPException(status_code=404, detail=f\"No financial data available for {ticker}\")\n\n        # Determine which statement to use based on metric\n        if metric.lower() in ['revenue', 'net_income', 'operating_income']:\n            stmt = company.income_statement(periods=years, annual=True)\n        elif metric.lower() in ['assets', 'liabilities', 'equity']:\n            stmt = company.balance_sheet(periods=years, annual=True)\n        elif metric.lower() in ['operating_cash_flow', 'free_cash_flow']:\n            stmt = company.cash_flow(periods=years, annual=True)\n        else:\n            raise HTTPException(status_code=400, detail=f\"Unknown metric: {metric}\")\n\n        if not stmt:\n            raise HTTPException(status_code=404, detail=f\"No data available for metric: {metric}\")\n\n        # Find the requested metric\n        metric_item = stmt.find_item(metric)\n        if not metric_item:\n            # Try alternative names\n            alt_names = {\n                'revenue': ['Revenues', 'Total Revenue', 'Net Sales'],\n                'net_income': ['Net Income', 'Net Earnings', 'Net Income (Loss)'],\n                'assets': ['Total Assets', 'Assets'],\n                'equity': ['Total Equity', 'Stockholders Equity', 'Total Stockholders Equity']\n            }\n\n            for alt_name in alt_names.get(metric.lower(), []):\n                metric_item = stmt.find_item(alt_name)\n                if metric_item:\n                    break\n\n        if not metric_item:\n            raise HTTPException(status_code=404, detail=f\"Metric '{metric}' not found in financial statements\")\n\n        # Calculate trends\n        trend_data = []\n        values = []\n\n        for period in reversed(stmt.periods):  # Chronological order\n            value = metric_item.values.get(period)\n            if value is not None:\n                trend_data.append({\n                    'period': period,\n                    'value': value,\n                    'display_value': metric_item.get_display_value(period)\n                })\n                values.append(value)\n\n        # Calculate growth rates\n        growth_rates = []\n        if len(values) &gt; 1:\n            for i in range(1, len(values)):\n                if values[i-1] != 0:\n                    growth = ((values[i] - values[i-1]) / abs(values[i-1])) * 100\n                    growth_rates.append(growth)\n\n        return {\n            'company': company.name,\n            'ticker': ticker.upper(),\n            'metric': metric,\n            'periods_analyzed': len(trend_data),\n            'trend_data': trend_data,\n            'analytics': {\n                'average_growth_rate': sum(growth_rates) / len(growth_rates) if growth_rates else None,\n                'total_growth': ((values[-1] - values[0]) / abs(values[0])) * 100 if len(values) &gt; 1 and values[0] != 0 else None,\n                'compound_annual_growth_rate': (((values[-1] / values[0]) ** (1/(len(values)-1))) - 1) * 100 if len(values) &gt; 1 and values[0] &gt; 0 else None\n            }\n        }\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#bulk-company-comparison-endpoint","title":"Bulk Company Comparison Endpoint","text":"<pre><code>@app.post(\"/financial/compare\")\nasync def compare_companies(\n    tickers: List[str],\n    periods: int = Query(3, description=\"Number of periods\", ge=1, le=5),\n    metrics: List[str] = Query(['revenue', 'net_income'], description=\"Metrics to compare\")\n):\n    \"\"\"Compare financial metrics across multiple companies\"\"\"\n    try:\n        comparison_data = []\n\n        for ticker in tickers:\n            try:\n                company = Company(ticker.upper())\n\n                if not company.facts:\n                    continue\n\n                company_data = {\n                    'ticker': ticker.upper(),\n                    'name': company.name,\n                    'metrics': {}\n                }\n\n                # Get statements based on requested metrics\n                income_stmt = company.income_statement(periods=periods, annual=True)\n                balance_sheet = company.balance_sheet(periods=periods, annual=True)\n\n                for metric in metrics:\n                    if metric.lower() in ['revenue', 'net_income']:\n                        stmt = income_stmt\n                    else:\n                        stmt = balance_sheet\n\n                    if stmt:\n                        metric_item = stmt.find_item(metric)\n                        if metric_item:\n                            company_data['metrics'][metric] = {\n                                'periods': stmt.periods,\n                                'values': metric_item.values\n                            }\n\n                comparison_data.append(company_data)\n\n            except Exception as e:\n                print(f\"Error processing {ticker}: {e}\")\n                continue\n\n        return {\n            'comparison': comparison_data,\n            'metadata': {\n                'companies_compared': len(comparison_data),\n                'periods_requested': periods,\n                'metrics_requested': metrics\n            }\n        }\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#running-the-api-server","title":"Running the API Server","text":"<pre><code># Save the above code as financial_api.py and run:\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(\n        \"financial_api:app\",\n        host=\"0.0.0.0\",\n        port=8000,\n        reload=True,\n        title=\"Financial Data API\"\n    )\n\n# Or run from command line:\n# uvicorn financial_api:app --reload --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#api-usage-examples","title":"API Usage Examples","text":""},{"location":"guides/multi-year-financial-data-api/#get-7-years-of-income-statement-data","title":"Get 7 Years of Income Statement Data","text":"<pre><code># Get comprehensive income statement data\ncurl \"http://localhost:8000/financial/AAPL/income?periods=7&amp;annual=true&amp;concise_format=false\"\n\n# Get quarterly data for recent periods\ncurl \"http://localhost:8000/financial/AAPL/income?periods=12&amp;annual=false&amp;concise_format=true\"\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#get-complete-financial-profile","title":"Get Complete Financial Profile","text":"<pre><code># Get all three statements plus ratios\ncurl \"http://localhost:8000/financial/AAPL/comprehensive?periods=5&amp;include_ratios=true\"\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#analyze-revenue-trends","title":"Analyze Revenue Trends","text":"<pre><code># Get 10-year revenue trend analysis\ncurl \"http://localhost:8000/financial/AAPL/trends?metric=revenue&amp;years=10\"\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#compare-multiple-companies","title":"Compare Multiple Companies","text":"<pre><code># Compare revenue and profits across companies\ncurl -X POST \"http://localhost:8000/financial/compare\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"tickers\": [\"AAPL\", \"MSFT\", \"GOOGL\"], \"periods\": 5, \"metrics\": [\"revenue\", \"net_income\"]}'\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#client-integration-examples","title":"Client Integration Examples","text":""},{"location":"guides/multi-year-financial-data-api/#python-client","title":"Python Client","text":"<pre><code>import requests\nimport pandas as pd\n\nclass FinancialDataClient:\n    def __init__(self, base_url=\"http://localhost:8000\"):\n        self.base_url = base_url\n\n    def get_income_statement(self, ticker, periods=5, annual=True):\n        \"\"\"Get income statement data\"\"\"\n        response = requests.get(\n            f\"{self.base_url}/financial/{ticker}/income\",\n            params={'periods': periods, 'annual': annual}\n        )\n        return response.json() if response.status_code == 200 else None\n\n    def get_comprehensive_data(self, ticker, periods=5):\n        \"\"\"Get all financial statements\"\"\"\n        response = requests.get(\n            f\"{self.base_url}/financial/{ticker}/comprehensive\",\n            params={'periods': periods, 'include_ratios': True}\n        )\n        return response.json() if response.status_code == 200 else None\n\n    def get_trends(self, ticker, metric, years=5):\n        \"\"\"Get trend analysis\"\"\"\n        response = requests.get(\n            f\"{self.base_url}/financial/{ticker}/trends\",\n            params={'metric': metric, 'years': years}\n        )\n        return response.json() if response.status_code == 200 else None\n\n# Usage\nclient = FinancialDataClient()\n\n# Get Apple's financial data\naapl_data = client.get_comprehensive_data('AAPL', periods=7)\nprint(f\"Retrieved data for periods: {aapl_data['periods']}\")\n\n# Get revenue trends\nrevenue_trends = client.get_trends('AAPL', 'revenue', years=10)\nprint(f\"10-year revenue CAGR: {revenue_trends['analytics']['compound_annual_growth_rate']:.1f}%\")\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#javascriptnodejs-client","title":"JavaScript/Node.js Client","text":"<pre><code>class FinancialDataClient {\n    constructor(baseUrl = 'http://localhost:8000') {\n        this.baseUrl = baseUrl;\n    }\n\n    async getIncomeStatement(ticker, periods = 5, annual = true) {\n        const response = await fetch(\n            `${this.baseUrl}/financial/${ticker}/income?periods=${periods}&amp;annual=${annual}`\n        );\n        return response.ok ? response.json() : null;\n    }\n\n    async getComprehensiveData(ticker, periods = 5) {\n        const response = await fetch(\n            `${this.baseUrl}/financial/${ticker}/comprehensive?periods=${periods}&amp;include_ratios=true`\n        );\n        return response.ok ? response.json() : null;\n    }\n\n    async compareCompanies(tickers, periods = 3, metrics = ['revenue', 'net_income']) {\n        const response = await fetch(`${this.baseUrl}/financial/compare`, {\n            method: 'POST',\n            headers: {'Content-Type': 'application/json'},\n            body: JSON.stringify({tickers, periods, metrics})\n        });\n        return response.ok ? response.json() : null;\n    }\n}\n\n// Usage\nconst client = new FinancialDataClient();\n\n// Get multi-year data\nconst msftData = await client.getComprehensiveData('MSFT', 7);\nconsole.log(`Retrieved data for periods:`, msftData.periods);\n\n// Compare tech giants\nconst comparison = await client.compareCompanies(['AAPL', 'MSFT', 'GOOGL', 'AMZN']);\nconsole.log('Comparison data:', comparison);\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#advanced-use-cases","title":"Advanced Use Cases","text":""},{"location":"guides/multi-year-financial-data-api/#building-a-financial-dashboard","title":"Building a Financial Dashboard","text":"<pre><code># dashboard.py - Streamlit financial dashboard\nimport streamlit as st\nimport requests\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport pandas as pd\n\nst.title(\"Multi-Year Financial Analysis Dashboard\")\n\n# Input controls\nticker = st.text_input(\"Company Ticker\", value=\"AAPL\")\nyears = st.slider(\"Years of Data\", min_value=2, max_value=10, value=5)\n\nif st.button(\"Analyze\"):\n    # Get data from our API\n    client = FinancialDataClient()\n    data = client.get_comprehensive_data(ticker, periods=years)\n\n    if data:\n        st.subheader(f\"{data['company_info']['name']} ({ticker})\")\n\n        # Revenue trend chart\n        income_data = data['income_statement']\n        revenue_concept = next((k for k in income_data.keys() if 'revenue' in k.lower()), None)\n\n        if revenue_concept:\n            revenue_item = income_data[revenue_concept]\n            periods = data['periods']\n            values = [revenue_item['values'][p]['raw_value'] for p in periods if p in revenue_item['values']]\n\n            fig = go.Figure()\n            fig.add_trace(go.Scatter(x=periods, y=values, mode='lines+markers', name='Revenue'))\n            fig.update_layout(title='Revenue Trend', xaxis_title='Period', yaxis_title='Revenue ($)')\n            st.plotly_chart(fig)\n\n        # Key metrics\n        if data['key_metrics']:\n            st.subheader(\"Key Financial Ratios\")\n            for metric, value in data['key_metrics'].items():\n                if isinstance(value, (int, float)):\n                    st.metric(metric.replace('_', ' ').title(), f\"{value:.2%}\" if 'margin' in metric or 'ro' in metric else f\"{value:.2f}\")\n\n# Run with: streamlit run dashboard.py\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#data-export-and-analysis","title":"Data Export and Analysis","text":"<pre><code>def export_financial_data_to_excel(tickers, periods=5, filename=\"financial_data.xlsx\"):\n    \"\"\"Export multi-company financial data to Excel\"\"\"\n    import pandas as pd\n    from openpyxl import Workbook\n    from openpyxl.utils.dataframe import dataframe_to_rows\n\n    client = FinancialDataClient()\n\n    with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n        for ticker in tickers:\n            data = client.get_comprehensive_data(ticker, periods)\n\n            if data:\n                # Income Statement\n                income_df = _convert_api_data_to_dataframe(data['income_statement'], data['periods'])\n                income_df.to_excel(writer, sheet_name=f'{ticker}_Income')\n\n                # Balance Sheet\n                balance_df = _convert_api_data_to_dataframe(data['balance_sheet'], data['periods'])\n                balance_df.to_excel(writer, sheet_name=f'{ticker}_Balance')\n\n                # Cash Flow\n                cashflow_df = _convert_api_data_to_dataframe(data['cash_flow'], data['periods'])\n                cashflow_df.to_excel(writer, sheet_name=f'{ticker}_CashFlow')\n\n    print(f\"Financial data exported to {filename}\")\n\ndef _convert_api_data_to_dataframe(statement_data, periods):\n    \"\"\"Convert API response to pandas DataFrame\"\"\"\n    rows = []\n    for concept, item_data in statement_data.items():\n        row = {'concept': concept, 'label': item_data['label']}\n        for period in periods:\n            if period in item_data['values']:\n                row[period] = item_data['values'][period]['raw_value']\n        rows.append(row)\n\n    return pd.DataFrame(rows)\n\n# Export data for analysis\nexport_financial_data_to_excel(['AAPL', 'MSFT', 'GOOGL', 'AMZN'], periods=7)\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#best-practices","title":"Best Practices","text":""},{"location":"guides/multi-year-financial-data-api/#error-handling-and-resilience","title":"Error Handling and Resilience","text":"<pre><code>import logging\nfrom functools import wraps\n\ndef handle_api_errors(f):\n    \"\"\"Decorator for consistent API error handling\"\"\"\n    @wraps(f)\n    async def wrapper(*args, **kwargs):\n        try:\n            return await f(*args, **kwargs)\n        except Exception as e:\n            logging.error(f\"API error in {f.__name__}: {str(e)}\")\n            raise HTTPException(status_code=500, detail=f\"Internal server error: {str(e)}\")\n    return wrapper\n\n@app.get(\"/financial/{ticker}/income\")\n@handle_api_errors\nasync def get_income_statement_safe(ticker: str, periods: int = 4):\n    # Implementation with automatic error handling\n    pass\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#caching-for-performance","title":"Caching for Performance","text":"<pre><code>from functools import lru_cache\nfrom typing import Optional\nimport time\n\nclass CachedFinancialAPI:\n    def __init__(self):\n        self._cache = {}\n        self._cache_ttl = 3600  # 1 hour\n\n    def _get_cache_key(self, ticker: str, statement_type: str, periods: int, annual: bool):\n        return f\"{ticker}_{statement_type}_{periods}_{annual}\"\n\n    def _is_cache_valid(self, timestamp: float) -&gt; bool:\n        return time.time() - timestamp &lt; self._cache_ttl\n\n    @lru_cache(maxsize=100)\n    def get_cached_company(self, ticker: str):\n        \"\"\"Cache Company objects to avoid repeated API calls\"\"\"\n        return Company(ticker)\n\n    def get_financial_data(self, ticker: str, statement_type: str, periods: int, annual: bool):\n        cache_key = self._get_cache_key(ticker, statement_type, periods, annual)\n\n        # Check cache\n        if cache_key in self._cache:\n            data, timestamp = self._cache[cache_key]\n            if self._is_cache_valid(timestamp):\n                return data\n\n        # Fetch new data\n        company = self.get_cached_company(ticker)\n\n        if statement_type == 'income':\n            data = company.income_statement(periods=periods, annual=annual)\n        elif statement_type == 'balance':\n            data = company.balance_sheet(periods=periods, annual=annual)\n        elif statement_type == 'cashflow':\n            data = company.cash_flow(periods=periods, annual=annual)\n\n        # Cache the result\n        self._cache[cache_key] = (data, time.time())\n\n        return data\n\n# Use cached API in endpoints\ncached_api = CachedFinancialAPI()\n\n@app.get(\"/financial/{ticker}/income\")\nasync def get_cached_income_statement(ticker: str, periods: int = 4, annual: bool = True):\n    data = cached_api.get_financial_data(ticker, 'income', periods, annual)\n    # ... rest of endpoint logic\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guides/multi-year-financial-data-api/#batch-processing-multiple-companies","title":"Batch Processing Multiple Companies","text":"<pre><code>import asyncio\nimport aiohttp\nfrom concurrent.futures import ThreadPoolExecutor\n\nasync def process_companies_batch(tickers: List[str], periods: int = 5):\n    \"\"\"Process multiple companies in parallel\"\"\"\n\n    def get_company_data(ticker):\n        try:\n            company = Company(ticker)\n            if company.facts:\n                return {\n                    'ticker': ticker,\n                    'income': company.income_statement(periods=periods, annual=True),\n                    'balance': company.balance_sheet(periods=periods, annual=True),\n                    'cashflow': company.cash_flow(periods=periods, annual=True)\n                }\n        except Exception as e:\n            print(f\"Error processing {ticker}: {e}\")\n        return None\n\n    # Use ThreadPoolExecutor for I/O bound operations\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        loop = asyncio.get_event_loop()\n        tasks = [\n            loop.run_in_executor(executor, get_company_data, ticker) \n            for ticker in tickers\n        ]\n        results = await asyncio.gather(*tasks)\n\n    return [r for r in results if r is not None]\n\n@app.post(\"/financial/batch\")\nasync def process_batch(tickers: List[str], periods: int = Query(5, le=10)):\n    \"\"\"Process multiple companies in parallel\"\"\"\n    results = await process_companies_batch(tickers, periods)\n    return {\n        'processed': len(results),\n        'requested': len(tickers),\n        'data': results\n    }\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#deployment-considerations","title":"Deployment Considerations","text":""},{"location":"guides/multi-year-financial-data-api/#production-setup","title":"Production Setup","text":"<pre><code># production_config.py\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.middleware.gzip import GZipMiddleware\nimport logging\n\ndef create_production_app():\n    app = FastAPI(\n        title=\"Financial Data API\",\n        description=\"Production financial data service\",\n        version=\"1.0.0\",\n        docs_url=\"/docs\" if settings.DEBUG else None\n    )\n\n    # Add middleware\n    app.add_middleware(GZipMiddleware, minimum_size=1000)\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"https://yourdomain.com\"],\n        allow_credentials=True,\n        allow_methods=[\"GET\", \"POST\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Configure logging\n    logging.basicConfig(level=logging.INFO)\n\n    return app\n\napp = create_production_app()\n\n# Add rate limiting\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\n\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n@app.get(\"/financial/{ticker}/income\")\n@limiter.limit(\"10/minute\")\nasync def rate_limited_income_statement(request: Request, ticker: str):\n    # Rate-limited endpoint implementation\n    pass\n</code></pre>"},{"location":"guides/multi-year-financial-data-api/#testing","title":"Testing","text":""},{"location":"guides/multi-year-financial-data-api/#unit-tests-for-api-endpoints","title":"Unit Tests for API Endpoints","text":"<pre><code># test_financial_api.py\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom financial_api import app\n\nclient = TestClient(app)\n\ndef test_get_income_statement():\n    \"\"\"Test income statement endpoint\"\"\"\n    response = client.get(\"/financial/AAPL/income?periods=3&amp;annual=true\")\n    assert response.status_code == 200\n\n    data = response.json()\n    assert data['company_info']['ticker'] == 'AAPL'\n    assert len(data['periods']) &lt;= 3\n    assert 'income_statement' in data or 'data' in data\n\ndef test_comprehensive_endpoint():\n    \"\"\"Test comprehensive financial data endpoint\"\"\"\n    response = client.get(\"/financial/MSFT/comprehensive?periods=2&amp;include_ratios=true\")\n    assert response.status_code == 200\n\n    data = response.json()\n    assert 'income_statement' in data\n    assert 'balance_sheet' in data\n    assert 'cash_flow' in data\n    assert 'key_metrics' in data\n\ndef test_trends_analysis():\n    \"\"\"Test trends endpoint\"\"\"\n    response = client.get(\"/financial/GOOGL/trends?metric=revenue&amp;years=5\")\n    assert response.status_code == 200\n\n    data = response.json()\n    assert 'trend_data' in data\n    assert 'analytics' in data\n    assert data['metric'] == 'revenue'\n\ndef test_company_comparison():\n    \"\"\"Test company comparison endpoint\"\"\"\n    payload = {\n        \"tickers\": [\"AAPL\", \"MSFT\"],\n        \"periods\": 2,\n        \"metrics\": [\"revenue\"]\n    }\n    response = client.post(\"/financial/compare\", json=payload)\n    assert response.status_code == 200\n\n    data = response.json()\n    assert len(data['comparison']) &lt;= 2\n\ndef test_invalid_ticker():\n    \"\"\"Test handling of invalid ticker\"\"\"\n    response = client.get(\"/financial/INVALIDTICKER/income\")\n    assert response.status_code == 404\n\n# Run with: pytest test_financial_api.py -v\n</code></pre> <p>This comprehensive guide provides everything needed to build a production-ready FastAPI service for accessing multi-year financial statement data using EdgarTools. The implementation includes error handling, caching, rate limiting, and extensive examples for building financial analysis applications. ]</p>"},{"location":"guides/searching-filings/","title":"Search for Specific Filings","text":"<p>Learn how to find the exact SEC filings you need using various search criteria and filtering methods.</p>"},{"location":"guides/searching-filings/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of SEC filing types (10-K, 10-Q, 8-K, etc.)</li> </ul>"},{"location":"guides/searching-filings/#basic-filing-search","title":"Basic Filing Search","text":""},{"location":"guides/searching-filings/#get-recent-filings","title":"Get Recent Filings","text":"<p>Start with the most recent filings across all companies:</p> <pre><code>from edgar import get_filings\n\n# Get the 50 most recent filings\nrecent_filings = get_filings()\n\n# Display basic information\nfor filing in recent_filings[:5]:\n    print(f\"{filing.form}: {filing.company_name} ({filing.filing_date})\")\n</code></pre> <p>Output:</p> <pre><code>10-Q: Apple Inc. (2024-05-02)\n8-K: Microsoft Corporation (2024-05-01)\n10-K: Amazon.com Inc (2024-04-30)\n13F-HR: Berkshire Hathaway Inc (2024-04-29)\n4: Tesla Inc (2024-04-28)\n</code></pre>"},{"location":"guides/searching-filings/#search-by-filing-type","title":"Search by Filing Type","text":"<p>Find specific types of SEC forms:</p> <pre><code># Get recent 10-K annual reports\nannual_reports = get_filings(form=\"10-K\").head(20)\n\n# Get multiple form types\nquarterly_and_annual = get_filings(form=[\"10-K\", \"10-Q\"])\n\n# Exclude amendments (filings ending in /A)\noriginal_filings = get_filings(form=\"10-K\", amendments=False).head(20)\n\nprint(f\"Found {len(annual_reports)} annual reports\")\n</code></pre>"},{"location":"guides/searching-filings/#search-by-date-range","title":"Search by Date Range","text":""},{"location":"guides/searching-filings/#specific-date","title":"Specific Date","text":"<pre><code># Get all filings from a specific date\nfilings_jan_1 = get_filings(filing_date=\"2024-01-01\")\n\nprint(f\"Found {len(filings_jan_1)} filings on 2024-01-01\")\n</code></pre>"},{"location":"guides/searching-filings/#date-ranges","title":"Date Ranges","text":"<pre><code># Get filings from a date range\nq1_filings = get_filings(filing_date=\"2024-01-01:2024-03-31\")\n\n# Get filings after a specific date\nrecent_filings = get_filings(filing_date=\"2024-01-01:\")\n\n# Get filings before a specific date\nolder_filings = get_filings(filing_date=\":2023-12-31\")\n\nprint(f\"Q1 2024 filings: {len(q1_filings)}\")\n</code></pre>"},{"location":"guides/searching-filings/#year-and-quarter-search","title":"Year and Quarter Search","text":"<pre><code># Get filings for entire year\nfilings_2023 = get_filings(2023)\n\n# Get filings for specific quarter\nq4_2023 = get_filings(2023, 4)\n\n# Get multiple quarters\nq3_q4_2023 = get_filings(2023, [3, 4])\n\n# Get multiple years\nmulti_year = get_filings([2022, 2023])\n\n# Get range of years (excludes end year)\ndecade_filings = get_filings(range(2010, 2021))\n\nprint(f\"2023 filings: {len(filings_2023)}\")\nprint(f\"Q4 2023 filings: {len(q4_2023)}\")\n</code></pre>"},{"location":"guides/searching-filings/#company-specific-filing-search","title":"Company-Specific Filing Search","text":""},{"location":"guides/searching-filings/#get-all-company-filings","title":"Get All Company Filings","text":"<pre><code>from edgar import Company\n\n# Get all filings for a company\napple = Company(\"AAPL\")\nall_apple_filings = apple.get_filings()\n\nprint(f\"Apple has {len(all_apple_filings)} total filings\")\n</code></pre>"},{"location":"guides/searching-filings/#filter-company-filings","title":"Filter Company Filings","text":"<pre><code># Get specific form types for a company\napple_10k = apple.get_filings(form=\"10-K\")\napple_quarterly = apple.get_filings(form=[\"10-Q\", \"10-K\"])\n\n# Get XBRL filings only\napple_xbrl = apple.get_filings(is_xbrl=True)\n\n# Get inline XBRL filings\napple_ixbrl = apple.get_filings(is_inline_xbrl=True)\n\nprint(f\"Apple 10-K filings: {len(apple_10k)}\")\nprint(f\"Apple XBRL filings: {len(apple_xbrl)}\")\n</code></pre>"},{"location":"guides/searching-filings/#get-latest-filing","title":"Get Latest Filing","text":"<pre><code># Get the most recent filing of a specific type\nlatest_10k = apple.get_filings(form=\"10-K\").latest()\nlatest_10q = apple.get_filings(form=\"10-Q\").latest()\n\nprint(f\"Latest 10-K: {latest_10k.filing_date}\")\nprint(f\"Latest 10-Q: {latest_10q.filing_date}\")\n\n# Chain the calls for conciseness\nlatest_annual = Company(\"MSFT\").get_filings(form=\"10-K\").latest()\n</code></pre>"},{"location":"guides/searching-filings/#advanced-filtering","title":"Advanced Filtering","text":""},{"location":"guides/searching-filings/#filter-by-multiple-criteria","title":"Filter by Multiple Criteria","text":"<pre><code># Get Apple's 10-K filings from 2023 that are XBRL\napple_filtered = apple.get_filings(\n    form=\"10-K\",\n    is_xbrl=True\n).filter(filing_date=\"2023-01-01:2023-12-31\")\n\nprint(f\"Filtered results: {len(apple_filtered)}\")\n</code></pre>"},{"location":"guides/searching-filings/#filter-by-accession-number","title":"Filter by Accession Number","text":"<pre><code># Find specific filing by accession number\nspecific_filing = apple.get_filings(\n    accession_number=\"0000320193-23-000106\"\n)\n\nprint(f\"Found filing: {specific_filing[0].form}\")\n</code></pre>"},{"location":"guides/searching-filings/#filter-by-file-number","title":"Filter by File Number","text":"<pre><code># Filter by SEC file number\nfile_filtered = apple.get_filings(\n    file_number=\"001-36743\"\n)\n\nprint(f\"Filings with file number: {len(file_filtered)}\")\n</code></pre>"},{"location":"guides/searching-filings/#cross-company-search","title":"Cross-Company Search","text":""},{"location":"guides/searching-filings/#search-by-industry","title":"Search by Industry","text":"<pre><code># Get recent filings and filter by company characteristics\nall_filings = get_filings()\n\n# Filter for technology companies (requires loading each company)\ntech_filings = []\nfor filing in all_filings[:100]:  # Limit for performance\n    try:\n        company = Company(filing.cik)\n        if \"software\" in company.industry.lower() or \"computer\" in company.industry.lower():\n            tech_filings.append(filing)\n    except:\n        continue\n\nprint(f\"Found {len(tech_filings)} filings from tech companies\")\n</code></pre>"},{"location":"guides/searching-filings/#search-by-exchange","title":"Search by Exchange","text":"<pre><code># Filter existing filings by exchange\nnasdaq_filings = all_filings.filter(exchange=\"NASDAQ\")\nnyse_filings = all_filings.filter(exchange=\"NYSE\")\n\nprint(f\"NASDAQ filings: {len(nasdaq_filings)}\")\nprint(f\"NYSE filings: {len(nyse_filings)}\")\n</code></pre>"},{"location":"guides/searching-filings/#search-by-ticker-list","title":"Search by Ticker List","text":"<pre><code># Get filings for multiple specific companies\ntickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\"]\nticker_filings = all_filings.filter(ticker=tickers)\n\nprint(f\"Filings from specified tickers: {len(ticker_filings)}\")\n</code></pre>"},{"location":"guides/searching-filings/#specialized-filing-searches","title":"Specialized Filing Searches","text":""},{"location":"guides/searching-filings/#insider-trading-filings","title":"Insider Trading Filings","text":"<pre><code># Get recent insider trading filings\ninsider_filings = get_filings(form=[\"3\", \"4\", \"5\"])\n\nprint(\"Recent insider filings:\")\nfor filing in insider_filings[:10]:\n    print(f\"  Form {filing.form}: {filing.company_name} ({filing.filing_date})\")\n</code></pre>"},{"location":"guides/searching-filings/#fund-holdings-13f","title":"Fund Holdings (13F)","text":"<pre><code># Get recent 13F filings (institutional investment managers)\nfund_filings = get_filings(form=\"13F-HR\")\n\nprint(\"Recent fund holdings filings:\")\nfor filing in fund_filings:\n    print(f\"  {filing.company_name}: {filing.filing_date}\")\n</code></pre>"},{"location":"guides/searching-filings/#material-events-8-k","title":"Material Events (8-K)","text":"<pre><code># Get recent 8-K filings (material corporate events)\nevent_filings = get_filings(form=\"8-K\")\n\nprint(\"Recent material events:\")\nfor filing in event_filings[:10]:\n    print(f\"  {filing.company_name}: {filing.filing_date}\")\n</code></pre>"},{"location":"guides/searching-filings/#ipo-and-registration-statements","title":"IPO and Registration Statements","text":"<pre><code># Get S-1 filings (IPO registrations)\nipo_filings = get_filings(form=\"S-1\")\n\nprint(\"Recent IPO filings:\")\nfor filing in ipo_filings:\n    print(f\"  {filing.company_name}: {filing.filing_date}\")\n</code></pre>"},{"location":"guides/searching-filings/#working-with-search-results","title":"Working with Search Results","text":""},{"location":"guides/searching-filings/#subset-and-sample","title":"Subset and Sample","text":"<pre><code>filings = get_filings(form=\"10-K\")\n\n# Get first 10 results\nfirst_ten = filings.head(10)\n\n# Get last 10 results\nlast_ten = filings.tail(10)\n\n# Get random sample of 5 results\nrandom_sample = filings.sample(5)\n\nprint(f\"Total: {len(filings)}, Sample: {len(random_sample)}\")\n</code></pre>"},{"location":"guides/searching-filings/#convert-to-pandas-dataframe","title":"Convert to Pandas DataFrame","text":"<pre><code>import pandas as pd\n\n# Convert filings to DataFrame for analysis\nfilings_df = filings.to_pandas()\n\n# Analyze filing patterns\nfiling_counts = filings_df.groupby(['form', 'company_name']).size()\nprint(\"Filing counts by company and form:\")\nprint(filing_counts.head(10))\n</code></pre>"},{"location":"guides/searching-filings/#access-underlying-data","title":"Access Underlying Data","text":"<pre><code># Access the PyArrow table directly\nimport pyarrow as pa\n\nfilings = get_filings(form=\"10-K\")\ndata_table: pa.Table = filings.data\n\n# Convert to Pandas for advanced analysis\ndf = data_table.to_pandas()\nprint(f\"Columns available: {df.columns.tolist()}\")\n</code></pre>"},{"location":"guides/searching-filings/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guides/searching-filings/#efficient-searching","title":"Efficient Searching","text":"<pre><code># More efficient: Use specific parameters in get_filings()\nefficient = get_filings(form=\"10-K\", filing_date=\"2023-01-01:\")\n\n# Less efficient: Get all then filter\ninefficient = get_filings().filter(form=\"10-K\").filter(filing_date=\"2023-01-01:\")\n\nprint(f\"Efficient approach found: {len(efficient)} filings\")\n</code></pre>"},{"location":"guides/searching-filings/#caching-results","title":"Caching Results","text":"<pre><code># Store frequently used searches\napple = Company(\"AAPL\")\napple_10k_cache = apple.get_filings(form=\"10-K\")\n\n# Reuse cached results for different analyses\nrecent_10k = apple_10k_cache.head(5)\noldest_10k = apple_10k_cache.tail(5)\n</code></pre>"},{"location":"guides/searching-filings/#error-handling","title":"Error Handling","text":""},{"location":"guides/searching-filings/#handle-missing-data","title":"Handle Missing Data","text":"<pre><code>try:\n    filings = get_filings(form=\"INVALID-FORM\")\n    print(f\"Found {len(filings)} filings\")\nexcept Exception as e:\n    print(f\"Error searching filings: {e}\")\n</code></pre>"},{"location":"guides/searching-filings/#validate-search-results","title":"Validate Search Results","text":"<pre><code>filings = get_filings(form=\"10-K\", limit=10)\n\nif len(filings) == 0:\n    print(\"No filings found matching criteria\")\nelse:\n    print(f\"Found {len(filings)} filings\")\n    # Verify first result\n    first_filing = filings[0]\n    print(f\"First result: {first_filing.form} from {first_filing.company_name}\")\n</code></pre>"},{"location":"guides/searching-filings/#common-search-patterns","title":"Common Search Patterns","text":""},{"location":"guides/searching-filings/#earnings-season-analysis","title":"Earnings Season Analysis","text":"<pre><code># Find quarterly reports filed in typical earnings periods\nearnings_dates = [\n    \"2024-01-15:2024-02-15\",  # Q4 earnings\n    \"2024-04-15:2024-05-15\",  # Q1 earnings\n    \"2024-07-15:2024-08-15\",  # Q2 earnings\n    \"2024-10-15:2024-11-15\"   # Q3 earnings\n]\n\nearnings_filings = []\nfor date_range in earnings_dates:\n    filings = get_filings(form=\"10-Q\", filing_date=date_range)\n    earnings_filings.extend(filings)\n\nprint(f\"Found {len(earnings_filings)} earnings period filings\")\n</code></pre>"},{"location":"guides/searching-filings/#ma-activity-monitoring","title":"M&amp;A Activity Monitoring","text":"<pre><code># Look for 8-K filings that might indicate M&amp;A activity\nma_filings = get_filings(form=\"8-K\")\n\n# Filter for potential M&amp;A keywords (requires examining filing content)\npotential_ma = []\nfor filing in ma_filings[:50]:  # Limit for performance\n    try:\n        text = filing.text()\n        if any(keyword in text.lower() for keyword in \n               ['acquisition', 'merger', 'tender offer', 'purchase agreement']):\n            potential_ma.append(filing)\n    except:\n        continue\n\nprint(f\"Found {len(potential_ma)} potential M&amp;A filings\")\n</code></pre>"},{"location":"guides/searching-filings/#next-steps","title":"Next Steps","text":"<p>Now that you can search for filings effectively, learn how to:</p> <ul> <li>Filter Filings by Date/Type - Advanced filtering techniques</li> <li>Access Filing Attachments - Get supporting documents</li> </ul>"},{"location":"guides/searching-filings/#related-documentation","title":"Related Documentation","text":"<ul> <li>Filing API Reference - Complete Filing class documentation</li> <li>Filings API Reference - Filings collection methods</li> <li>Working with Filings - Original filing documentation</li> </ul>"},{"location":"guides/sgml/","title":"SGML","text":"<p>The SEC EDGAR system uses a specialized subset of SGML (Standard Generalized Markup Language) for regulatory filings.  While commonly referred to as SGML, it implements a simplified version with SEC-specific tags and structures.  This format has been the backbone of SEC filings since the 1990s, chosen for its ability to maintain consistent document structure while supporting both structured data and free-form text.</p>"},{"location":"guides/sgml/#understanding-sgml-container-formats","title":"Understanding SGML Container Formats","text":"<p>You might be familiar with SGML from having seeing the Full Text File (.txt) or the (.nc) formats in SEC filings.</p> <p>The SEC EDGAR system actually utilizes two distinct SGML container formats, each serving different purposes in the filing process:</p>"},{"location":"guides/sgml/#complete-submission-text-file-txt","title":"Complete Submission Text File (.txt)","text":"<p>The .txt format contains the complete submission as received by EDGAR, including all documents, headers, and content. This is the primary public-facing format that preserves the exact submission. A typical .txt container begins with:</p> <pre><code>&lt;SEC-DOCUMENT&gt;0000320193-24-000123.txt : 20241101\n&lt;SEC-HEADER&gt;0000320193-24-000123.hdr.sgml : 20241101\n&lt;ACCEPTANCE-DATETIME&gt;20241101060136\nACCESSION NUMBER:      0000320193-24-000123\n</code></pre> <p>The .txt container includes: - Full document content - SEC headers - Metadata - All exhibits and attachments - Processing timestamps</p>"},{"location":"guides/sgml/#non-public-complete-file-nc","title":"Non-Public Complete File (.nc)","text":"<p>The .nc format serves as a submission manifest or index file, containing metadata about the filing without the full content. This format is used for processing, validation, and internal SEC workflows. A typical .nc container starts with:</p> <pre><code>&lt;SUBMISSION&gt;\n&lt;ACCESSION-NUMBER&gt;0002002260-24-000001\n&lt;TYPE&gt;D\n&lt;PUBLIC-DOCUMENT-COUNT&gt;1\n&lt;ITEMS&gt;06b\n&lt;ITEMS&gt;3C\n</code></pre> <p>The .nc container tracks: - Submission type and status - Document counts - Reporting items - Cross-reference information - Processing instructions - Special handling requirements</p>"},{"location":"guides/sgml/#understanding-the-sec-processing-pipeline","title":"Understanding the SEC Processing Pipeline","text":"<p>Understanding the relationship between these formats is crucial for processing SEC filings:</p> <ol> <li>Initial submission includes both formats</li> <li>.nc file is processed first for validation</li> <li>.txt file is processed for content extraction</li> <li>Both files are archived for record-keeping</li> <li>Public access is primarily to the .txt content</li> </ol> <p>This dual-format system enables the SEC to maintain separate processing pipelines for submission handling and public access while ensuring comprehensive record-keeping and validation.</p>"},{"location":"guides/sgml/#how-edgartools-uses-sgml","title":"How edgartools uses SGML","text":"<p>The library uses the SGML to get the attachments and important metadata about the filing.</p> <pre><code>filing.attachments\n</code></pre> <p>the library will get the SGML file and parse it to get the attachments. You will mostly work with the objects and attributes of the <code>Filing</code> class, rather than directly with the SGML file.</p> <pre><code>    @property\n    def attachments(self):\n        # Return all the attachments on the filing\n        sgml_filing: FilingSGML = self.sgml()\n        return sgml_filing.attachments\n</code></pre> <p>The <code>sgml()</code> function will download the SGML file, or read from a file if using LocalStorage.</p>"},{"location":"guides/sgml/#the-filingsgml-class","title":"The FilingSGML class","text":"<p>The <code>FilingSGML</code> class is used to parse the SGML file. It has a few methods to get the attachments, and the text of the filing.</p>"},{"location":"guides/sgml/#parsing-sgml-from-a-file-or-a-url","title":"Parsing SGML from a file or a URL","text":"<p>The function <code>from_source</code> is used to create a <code>FilingSGML</code> object from a source. The source can be a string representing a file name or a URL, or it can be a <code>Path</code></p> <pre><code>sgml = FilingSGML.from_source(\"https://www.sec.gov/Archives/edgar/data/320193/000032019321000139/0000320193-21-000139.txt\")\n\n# OR\n\nsgml = FilingSGML.from_source(Path(\"path/to/0001398344-24-000491.nc\"))\n</code></pre> <p>This will parse either SGML format and return a <code>FilingSGML</code> object.</p>"},{"location":"guides/sgml/#getting-the-attachments","title":"Getting the attachments","text":"<p>The <code>attachments</code> property will return an <code>Attachments</code> class that contains the <code>Attachment</code>.</p> <pre><code>attachments = sgml.attachments\n</code></pre>"},{"location":"guides/sgml/#getting-the-content-of-a-file","title":"Getting the content of a file","text":"<p>You can get the content of a file using the <code>get_content</code> method.</p> <pre><code>sgml.get_content(\"EX-101.INS\")\n</code></pre>"},{"location":"guides/sgml/#getting-html","title":"Getting html","text":"<p>You can get the html for the filing using the <code>html</code> method. This will find the primary HTML document in the <code>FilingSGML:</code> attachments, find the html and return it.</p> <pre><code>html = sgml.html()\n</code></pre>"},{"location":"guides/sgml/#getting-xml","title":"Getting xml","text":"<p>You can get the xml for the filing using the <code>xml</code> method. This will find the primary XML document in the <code>FilingSGML:</code> attachments, find the xml and return it. This function will return None if no XML document is found.</p> <pre><code>sgml.xml()\n</code></pre>"},{"location":"guides/ssl_verification/","title":"SSL Verification Configuration in edgartools","text":""},{"location":"guides/ssl_verification/#overview","title":"Overview","text":"<p>This document outlines the design and recommendations for configuring SSL verification in the edgartools library, particularly useful for corporate environments with SSL inspection or similar network configurations.</p>"},{"location":"guides/ssl_verification/#implementation","title":"Implementation","text":""},{"location":"guides/ssl_verification/#1-environment-variable-control","title":"1. Environment Variable Control","text":"<p>The primary method is using the <code>EDGAR_VERIFY_SSL</code> environment variable:</p> <pre><code>verify = os.environ.get(\"EDGAR_VERIFY_SSL\", \"true\").lower() != \"false\"\n</code></pre> <ul> <li>Default: SSL verification enabled (safer default)</li> <li>To disable: Set <code>EDGAR_VERIFY_SSL=false</code></li> </ul>"},{"location":"guides/ssl_verification/#2-internal-configuration","title":"2. Internal Configuration","text":"<p>The library's HTTP client layer can be configured to disable SSL verification when needed. This is handled internally by the library and doesn't require direct interaction with the HTTP clients.</p>"},{"location":"guides/ssl_verification/#usage-examples","title":"Usage Examples","text":""},{"location":"guides/ssl_verification/#using-environment-variable","title":"Using Environment Variable","text":"<pre><code># Disable SSL verification\nexport EDGAR_VERIFY_SSL=false\npython your_script.py\n\n# Enable SSL verification (default)\nexport EDGAR_VERIFY_SSL=true\npython your_script.py\n</code></pre>"},{"location":"guides/ssl_verification/#using-direct-configuration","title":"Using Direct Configuration","text":"<pre><code>from edgar import httpclient\n\n# Disable SSL verification for specific client\nwith httpclient.http_client(verify=False) as client:\n    # Make requests...\n    ...\n</code></pre>"},{"location":"guides/ssl_verification/#security-considerations","title":"Security Considerations","text":"<ol> <li>Default Security: SSL verification is enabled by default to maintain security.</li> <li>Targeted Usage: Disable SSL verification only in controlled environments where necessary (e.g., corporate networks with SSL inspection).</li> <li>Risk Awareness: Disabling SSL verification makes HTTPS connections potentially insecure. Only use when you understand the security implications.</li> </ol>"},{"location":"guides/ssl_verification/#best-practices","title":"Best Practices","text":"<ol> <li>Prefer Environment Variables: Use environment variables for global configuration to avoid hardcoding security settings.</li> <li>Configuration Scope: The SSL verification setting applies globally to all HTTP requests made by the library.</li> <li>Documentation: Always document when and why SSL verification is disabled in your code.</li> <li>Security Review: Have your security team review any permanent SSL verification disablement.</li> </ol>"},{"location":"guides/track-form4/","title":"Tracking Insider Trading with Form 4","text":""},{"location":"guides/track-form4/#introduction","title":"Introduction","text":"<p>Form 4 filings provide valuable insights into insider trading activity. When corporate insiders (directors, officers, or beneficial owners of more than 10% of a company's stock) buy or sell shares of their company, they must report these transactions to the SEC via Form 4 filings. These filings can reveal important signals about insiders' confidence in their company's future.</p> <p>edgartools makes it easy to retrieve, parse, and analyze Form 4 filings programmatically, allowing you to track insider trading patterns without manual effort.</p>"},{"location":"guides/track-form4/#understanding-form-4-filings","title":"Understanding Form 4 Filings","text":"<p>Before diving into code, it's important to understand what Form 4 filings contain:</p> <ul> <li>Reporting Person Information: Name, relationship to the company (e.g., CEO, Director)</li> <li>Transaction Details: Date, type of security, number of shares, price per share</li> <li>Transaction Codes: Codes that indicate the nature of the transaction (e.g., P for purchase, S for sale)</li> <li>Ownership Information: Direct or indirect ownership, total shares held after transaction</li> </ul>"},{"location":"guides/track-form4/#retrieving-form-4-filings","title":"Retrieving Form 4 Filings","text":""},{"location":"guides/track-form4/#by-company","title":"By Company","text":"<p>To retrieve Form 4 filings for a specific company:</p> <pre><code>from edgar import Company, get_filings\n\n# Using Company object\ncompany = Company(\"AAPL\")\nform4_filings = company.get_filings(form=\"4\")\n\n# Or using global get_filings\nform4_filings = get_filings(form=\"4\", ticker=\"AAPL\")\n\n# View the most recent filings\nrecent_filings = form4_filings.head(5)\nfor filing in recent_filings:\n    print(f\"Date: {filing.filing_date}, Person: {filing.reporting_owner_name}\")\n</code></pre>"},{"location":"guides/track-form4/#by-date-range","title":"By Date Range","text":"<p>To find Form 4 filings within a specific date range:</p> <pre><code># Get Form 4 filings from Jan 1, 2024 to present\nform4_filings = get_filings(\n    form=\"4\",\n    ticker=\"MSFT\",\n    start_date=\"2024-01-01\",\n    end_date=\"2024-07-01\"\n)\n\nprint(f\"Found {len(form4_filings)} Form 4 filings\")\n</code></pre>"},{"location":"guides/track-form4/#by-reporting-person","title":"By Reporting Person","text":"<p>To focus on a specific insider's activity:</p> <pre><code>form4_filings = get_filings(form=\"4\", ticker=\"TSLA\")\n\n# Filter by reporting person's name\nmusk_filings = form4_filings.filter(reporting_owner_name=\"Musk Elon\")\n\nprint(f\"Found {len(musk_filings)} Form 4 filings by Elon Musk\")\n</code></pre>"},{"location":"guides/track-form4/#working-with-form-4-data-objects","title":"Working with Form 4 Data Objects","text":"<p>edgartools provides a specialized <code>Form4</code> data object that makes it easy to access structured data from these filings:</p> <pre><code># Get a specific Form 4 filing\nfiling = form4_filings.latest()\n\n# Convert to Form4 data object\nform4 = filing.obj()\n\n# Access basic metadata\nprint(f\"Filing date: {form4.filing_date}\")\nprint(f\"Reporting owner: {form4.reporting_owner_name}\")\nprint(f\"Relationship: {form4.reporting_owner_relationship}\")\nprint(f\"Company: {form4.issuer_name} ({form4.issuer_ticker})\")\n</code></pre>"},{"location":"guides/track-form4/#accessing-transaction-details","title":"Accessing Transaction Details","text":"<p>Form 4 filings can contain multiple transactions. Access them through the <code>transactions</code> property:</p> <pre><code># Examine all transactions in the filing\nfor i, transaction in enumerate(form4.transactions):\n    print(f\"\\nTransaction {i+1}:\")\n    print(f\"Date: {transaction.transaction_date}\")\n    print(f\"Type: {transaction.transaction_code} ({transaction.get_transaction_code_description()})\")\n    print(f\"Shares: {transaction.shares}\")\n    print(f\"Price: ${transaction.price_per_share:.2f}\")\n    print(f\"Value: ${transaction.value:.2f}\")\n    print(f\"Direct/Indirect: {transaction.ownership}\")\n    print(f\"Shares owned after: {transaction.shares_owned_following_transaction}\")\n</code></pre>"},{"location":"guides/track-form4/#understanding-transaction-codes","title":"Understanding Transaction Codes","text":"<p>Form 4 transactions use codes to indicate different types of transactions:</p> <pre><code># Common transaction codes and their meanings\ntransaction_codes = {\n    'P': 'Open market or private purchase of securities',\n    'S': 'Open market or private sale of securities',\n    'A': 'Grant, award, or other acquisition',\n    'D': 'Disposition to the issuer (e.g., forfeiture, cancellation)',\n    'M': 'Exercise or conversion of derivative security',\n    'G': 'Gift',\n    'V': 'Voluntary transaction with issuer'\n}\n\n# Check what type of transaction this is\nfor transaction in form4.transactions:\n    code = transaction.transaction_code\n    description = transaction_codes.get(code, \"Other transaction type\")\n    print(f\"Transaction code {code}: {description}\")\n    print(f\"Shares: {transaction.shares}\")\n</code></pre>"},{"location":"guides/track-form4/#analyzing-insider-transactions","title":"Analyzing Insider Transactions","text":""},{"location":"guides/track-form4/#calculating-net-shares-traded","title":"Calculating Net Shares Traded","text":"<p>Calculate whether an insider is buying or selling on net:</p> <pre><code># Calculate net shares traded in a filing\nnet_shares = form4.get_net_shares_traded()\nif net_shares &gt; 0:\n    print(f\"Insider BOUGHT a net {net_shares:,} shares\")\nelif net_shares &lt; 0:\n    print(f\"Insider SOLD a net {abs(net_shares):,} shares\")\nelse:\n    print(\"Insider had no net change in position\")\n</code></pre>"},{"location":"guides/track-form4/#aggregating-transactions-by-company","title":"Aggregating Transactions by Company","text":"<p>Track recent insider activity for a company:</p> <pre><code>import pandas as pd\nfrom datetime import datetime, timedelta\n\n# Get all Form 4 filings for a company in the last 90 days\nend_date = datetime.today()\nstart_date = end_date - timedelta(days=90)\n\ncompany = Company(\"NVDA\")\nrecent_form4 = company.get_filings(\n    form=\"4\",\n    start_date=start_date.strftime(\"%Y-%m-%d\"),\n    end_date=end_date.strftime(\"%Y-%m-%d\")\n)\n\n# Analyze all filings\ntransactions_data = []\nfor filing in recent_form4:\n    try:\n        form4 = filing.obj()\n        net_shares = form4.get_net_shares_traded()\n\n        transactions_data.append({\n            'date': form4.filing_date,\n            'name': form4.reporting_owner_name,\n            'relationship': form4.reporting_owner_relationship,\n            'net_shares': net_shares,\n            'transaction_type': 'BUY' if net_shares &gt; 0 else 'SELL' if net_shares &lt; 0 else 'NEUTRAL'\n        })\n    except Exception as e:\n        print(f\"Error processing filing {filing.accession_number}: {e}\")\n\n# Create a DataFrame for analysis\ndf = pd.DataFrame(transactions_data)\nif not df.empty:\n    # Summarize by person\n    person_summary = df.groupby('name').agg({\n        'net_shares': 'sum',\n        'date': 'count'\n    }).rename(columns={'date': 'num_transactions'}).sort_values('net_shares')\n\n    print(\"\\nInsider Activity by Person:\")\n    print(person_summary)\n\n    # Summarize by transaction type\n    type_counts = df['transaction_type'].value_counts()\n    print(f\"\\nTransaction Types: {dict(type_counts)}\")\n</code></pre>"},{"location":"guides/track-form4/#tracking-significant-transactions","title":"Tracking Significant Transactions","text":"<p>Identify large or otherwise noteworthy transactions:</p> <pre><code>def get_significant_transactions(company_ticker, min_value=1000000, days=180):\n    \"\"\"Find Form 4 transactions above a certain dollar value.\"\"\"\n    company = Company(company_ticker)\n    end_date = datetime.today()\n    start_date = end_date - timedelta(days=days)\n\n    form4_filings = company.get_filings(\n        form=\"4\",\n        start_date=start_date.strftime(\"%Y-%m-%d\"),\n        end_date=end_date.strftime(\"%Y-%m-%d\")\n    )\n\n    significant_transactions = []\n    for filing in form4_filings:\n        try:\n            form4 = filing.obj()\n\n            for transaction in form4.transactions:\n                if transaction.value and transaction.value &gt;= min_value:\n                    significant_transactions.append({\n                        'date': transaction.transaction_date,\n                        'filing_date': form4.filing_date,\n                        'name': form4.reporting_owner_name,\n                        'relationship': form4.reporting_owner_relationship,\n                        'shares': transaction.shares,\n                        'price': transaction.price_per_share,\n                        'value': transaction.value,\n                        'type': transaction.transaction_code,\n                        'accession': filing.accession_number\n                    })\n        except Exception as e:\n            print(f\"Error processing filing {filing.accession_number}: {e}\")\n\n    return pd.DataFrame(significant_transactions).sort_values('value', ascending=False)\n\n# Find significant transactions for a company\nsignificant_df = get_significant_transactions(\"AMZN\", min_value=5000000)\nprint(f\"\\nFound {len(significant_df)} significant transactions\")\nif not significant_df.empty:\n    print(significant_df.head())\n</code></pre>"},{"location":"guides/track-form4/#advanced-analysis-techniques","title":"Advanced Analysis Techniques","text":""},{"location":"guides/track-form4/#correlating-with-stock-price","title":"Correlating with Stock Price","text":"<p>Combine insider trading data with stock price data to identify patterns:</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport yfinance as yf  # You'll need to install this package\n\ndef analyze_insider_vs_price(ticker, days=180):\n    \"\"\"Compare insider transactions with stock price movement.\"\"\"\n    # Get stock price data\n    end_date = datetime.today()\n    start_date = end_date - timedelta(days=days)\n    stock_data = yf.download(ticker, start=start_date, end=end_date)\n\n    # Get insider transactions\n    company = Company(ticker)\n    form4_filings = company.get_filings(\n        form=\"4\",\n        start_date=start_date.strftime(\"%Y-%m-%d\"),\n        end_date=end_date.strftime(\"%Y-%m-%d\")\n    )\n\n    # Process transactions\n    insider_data = []\n    for filing in form4_filings:\n        try:\n            form4 = filing.obj()\n            net_shares = form4.get_net_shares_traded()\n\n            if net_shares != 0:  # Only include actual buys or sells\n                insider_data.append({\n                    'date': pd.to_datetime(form4.filing_date),\n                    'net_shares': net_shares,\n                    'transaction_type': 'BUY' if net_shares &gt; 0 else 'SELL'\n                })\n        except Exception as e:\n            print(f\"Error processing filing: {e}\")\n\n    insider_df = pd.DataFrame(insider_data)\n\n    # Skip plotting if we don't have both datasets\n    if insider_df.empty or stock_data.empty:\n        print(\"Insufficient data for analysis\")\n        return\n\n    # Create a plot\n    plt.figure(figsize=(12, 6))\n\n    # Plot stock price\n    plt.plot(stock_data.index, stock_data['Close'], label='Stock Price')\n\n    # Mark insider transactions\n    for _, row in insider_df.iterrows():\n        color = 'green' if row['transaction_type'] == 'BUY' else 'red'\n        marker = '^' if row['transaction_type'] == 'BUY' else 'v'\n        plt.scatter(row['date'], stock_data.loc[stock_data.index &gt;= row['date']].iloc[0]['Close'], \n                   color=color, s=100, marker=marker)\n\n    plt.title(f'{ticker} Stock Price vs Insider Transactions')\n    plt.legend(['Stock Price', 'Insider Buy', 'Insider Sell'])\n    plt.grid(True)\n    plt.savefig(f'{ticker}_insider_analysis.png')\n    plt.close()\n\n    return insider_df, stock_data\n\n# Run the analysis\nanalyze_insider_vs_price(\"MSFT\")\n</code></pre>"},{"location":"guides/track-form4/#best-practices-and-tips","title":"Best Practices and Tips","text":""},{"location":"guides/track-form4/#handling-transaction-complexities","title":"Handling Transaction Complexities","text":"<p>Form 4 filings can have complexities to watch out for:</p> <ol> <li>Multiple Transactions: A single Form 4 can contain multiple transactions</li> <li>Amended Filings: Form 4/A filings are amendments to previous filings</li> <li>Indirect Ownership: Transactions might involve indirect ownership through trusts or other entities</li> <li>Derivative Securities: Some transactions involve options, warrants, or other derivatives</li> </ol> <p>Handle these cases with careful code:</p> <pre><code>def process_form4_safely(filing):\n    try:\n        # Check if this is an amended filing\n        if filing.form_type == \"4/A\":\n            print(f\"This is an amended filing: {filing.accession_number}\")\n\n        form4 = filing.obj()\n\n        # Handle multiple transactions\n        transaction_count = len(form4.transactions)\n        if transaction_count &gt; 1:\n            print(f\"Filing has {transaction_count} transactions\")\n\n        # Check for indirect ownership\n        for transaction in form4.transactions:\n            if transaction.ownership == \"I\":  # Indirect ownership\n                print(f\"Indirect ownership transaction found: {transaction.ownership_nature}\")\n\n        # Check for derivative securities\n        if hasattr(form4, 'derivative_transactions') and form4.derivative_transactions:\n            print(f\"Filing includes {len(form4.derivative_transactions)} derivative transactions\")\n\n        return form4\n    except Exception as e:\n        print(f\"Error processing Form 4: {e}\")\n        return None\n</code></pre>"},{"location":"guides/track-form4/#performance-considerations","title":"Performance Considerations","text":"<p>When working with large volumes of Form 4 filings:</p> <ol> <li>Use Local Storage: Store filings locally to avoid repeated downloads</li> <li>Process in Batches: Process filings in manageable batches</li> <li>Filter Early: Apply filters early in your pipeline to reduce the dataset size</li> </ol> <pre><code>from edgar import enable_local_storage\n\n# Enable local storage\nenable_local_storage(\"/path/to/storage\")\n\n# Process filings in batches\nall_filings = get_filings(form=\"4\", year=2024)\nbatch_size = 100\n\nfor i in range(0, len(all_filings), batch_size):\n    batch = all_filings[i:i+batch_size]\n    print(f\"Processing batch {i//batch_size + 1} ({len(batch)} filings)\")\n\n    # Process this batch\n    for filing in batch:\n        # Your processing code here\n        pass\n</code></pre>"},{"location":"guides/track-form4/#conclusion","title":"Conclusion","text":"<p>Tracking insider trading with Form 4 filings can provide valuable insights into the sentiment of company insiders. edgartools makes it easy to retrieve, parse, and analyze these filings at scale, allowing you to incorporate insider trading data into your investment research or analysis workflows.</p> <p>By understanding the structure of Form 4 filings and leveraging edgartools' data objects, you can efficiently extract meaningful insights about insider activity without manual effort.</p> <p>Whether you're tracking transactions by company executives, monitoring significant purchases or sales, or correlating insider activity with stock price movements, edgartools provides the foundation for comprehensive insider trading analysis.</p>"},{"location":"guides/track-form4/#additional-resources","title":"Additional Resources","text":"<ul> <li>SEC Form 4 Guide</li> <li>Insider Trading Legal Framework</li> <li>Form 4 Data Objects API Reference</li> </ul>"},{"location":"guides/working-with-filing/","title":"Working with a Filing","text":"<p>A Filing represents a single SEC filing document in EdgarTools. It provides access to the filing's metadata, content, and attachments. This guide covers everything you need to know about working with Filing objects.</p>"},{"location":"guides/working-with-filing/#getting-a-filing","title":"Getting a Filing","text":"<p>There are several ways to obtain a Filing object:</p>"},{"location":"guides/working-with-filing/#from-a-filings-collection","title":"From a Filings Collection","text":"<pre><code>from edgar import get_filings\n\n# Get recent filings across all companies\nfilings = get_filings()\nfiling = filings[10]  # Get the 11th filing\n\nprint(filing)\nprint(type(filing))  # edgar._filings.Filing\n</code></pre>"},{"location":"guides/working-with-filing/#from-a-specific-company","title":"From a Specific Company","text":"<pre><code>from edgar import Company\n\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=\"10-K\")\nfiling = filings.latest()\n\nprint(filing)\nprint(type(filing))  # edgar.entity.filings.EntityFiling\n</code></pre>"},{"location":"guides/working-with-filing/#using-the-find-function","title":"Using the find() Function","text":"<pre><code>from edgar import find\n\n# Find by accession number\nfiling = find(\"0001641172-25-017130\")\n</code></pre>"},{"location":"guides/working-with-filing/#direct-construction","title":"Direct Construction","text":"<pre><code>from edgar import Filing\n\nfiling = Filing(\n    form='10-Q',\n    filing_date='2025-06-30',\n    company='Polomar Health Services, Inc.',\n    cik=1265521,\n    accession_no='0001641172-25-017130'\n)\n</code></pre>"},{"location":"guides/working-with-filing/#filing-types-and-properties","title":"Filing Types and Properties","text":"<p>EdgarTools has two main Filing classes with different sets of properties:</p>"},{"location":"guides/working-with-filing/#basic-filing-properties","title":"Basic Filing Properties","text":"<p>The basic <code>Filing</code> class includes these key properties:</p> Property Description <code>cik</code> Company's Central Index Key <code>company</code> Company name <code>form</code> SEC form type (e.g., \"10-K\", \"8-K\") <code>filing_date</code> Date when filing was submitted to SEC <code>report_date</code> Period end date for the report <code>accession_no</code> Unique SEC accession number"},{"location":"guides/working-with-filing/#entityfiling-properties","title":"EntityFiling Properties","text":"<p>When you get a filing from a specific company, you get an <code>EntityFiling</code> object (a subclass of <code>Filing</code>) with additional properties:</p> Property Description <code>cik</code> Company's Central Index Key <code>company</code> Company name <code>form</code> SEC form type (e.g., \"10-K\", \"8-K\") <code>filing_date</code> Date when filing was submitted to SEC <code>report_date</code> Period end date for the report <code>acceptance_datetime</code> SEC acceptance timestamp <code>accession_no</code> Unique SEC accession number <code>file_number</code> SEC file number <code>items</code> Form items (particularly relevant for 8-K filings) <code>size</code> Filing size in bytes <code>primary_document</code> Primary document filename <code>primary_doc_description</code> Description of the primary document <code>is_xbrl</code> Whether filing contains XBRL data <code>is_inline_xbrl</code> Whether filing uses inline XBRL format"},{"location":"guides/working-with-filing/#accessing-filing-content","title":"Accessing Filing Content","text":""},{"location":"guides/working-with-filing/#opening-in-browser","title":"Opening in Browser","text":"<p>Open the main document in your default browser:</p> <pre><code>filing.open()\n</code></pre>"},{"location":"guides/working-with-filing/#opening-the-filing-homepage","title":"Opening the Filing Homepage","text":"<p>View the SEC's landing page for the filing, which links to all documents and data files:</p> <pre><code>filing.open_homepage()\n</code></pre>"},{"location":"guides/working-with-filing/#viewing-in-consolenotebook","title":"Viewing in Console/Notebook","text":"<p>Preview the filing content directly in your console or Jupyter notebook:</p> <pre><code>filing.view()\n</code></pre> <p>Note: This downloads the HTML content and displays it as close to the original as possible, but may not be perfect. For an exact copy, use <code>filing.open()</code>.</p>"},{"location":"guides/working-with-filing/#getting-raw-content","title":"Getting Raw Content","text":""},{"location":"guides/working-with-filing/#html-content","title":"HTML Content","text":"<pre><code>html_content = filing.html()\n# Returns the filing's HTML content as a string\n</code></pre>"},{"location":"guides/working-with-filing/#text-content","title":"Text Content","text":"<pre><code>text_content = filing.text()\n# Returns the plain text content of the filing\n</code></pre>"},{"location":"guides/working-with-filing/#working-with-attachments","title":"Working with Attachments","text":"<p>Filings often contain multiple documents and attachments beyond the main filing document.</p>"},{"location":"guides/working-with-filing/#accessing-attachments","title":"Accessing Attachments","text":"<pre><code>attachments = filing.attachments\nprint(f\"Number of attachments: {len(attachments)}\")\n</code></pre>"},{"location":"guides/working-with-filing/#looping-through-attachments","title":"Looping Through Attachments","text":"<pre><code>for attachment in filing.attachments:\n    print(f\"Document: {attachment.document}\")\n    print(f\"Description: {attachment.description}\")\n    print(f\"Type: {attachment.type}\")\n    print(\"---\")\n</code></pre>"},{"location":"guides/working-with-filing/#getting-a-specific-attachment","title":"Getting a Specific Attachment","text":"<pre><code># Get the first attachment\nfirst_attachment = filing.attachments[0]\n\n# Get attachment by document name\nattachment = filing.attachments[\"ex-10_1.htm\"]\n</code></pre>"},{"location":"guides/working-with-filing/#viewing-attachment-content","title":"Viewing Attachment Content","text":"<pre><code># View text/HTML attachments in console\nattachment.view()\n\n# Get attachment content as string\ncontent = attachment.content()\n</code></pre>"},{"location":"guides/working-with-filing/#downloading-attachments","title":"Downloading Attachments","text":"<pre><code># Download all attachments to a specific folder\nfiling.attachments.download(\"/path/to/download/folder\")\n\n# Download a specific attachment\nattachment.download(\"/path/to/save/file.htm\")\n</code></pre>"},{"location":"guides/working-with-filing/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/working-with-filing/#1-analyzing-recent-10-k-filings","title":"1. Analyzing Recent 10-K Filings","text":"<pre><code>from edgar import Company\n\napple = Company(\"AAPL\")\nlatest_10k = apple.get_filings(form=\"10-K\").latest()\n\nprint(f\"Filing Date: {latest_10k.filing_date}\")\nprint(f\"Report Period: {latest_10k.report_date}\")\nprint(f\"XBRL Available: {latest_10k.is_xbrl}\")\n\n# View the business section\nlatest_10k.view()\n</code></pre>"},{"location":"guides/working-with-filing/#2-processing-multiple-filings","title":"2. Processing Multiple Filings","text":"<pre><code>from edgar import get_filings\n\nrecent_filings = get_filings(form=\"8-K\", limit=50)\n\nfor filing in recent_filings:\n    if \"earnings\" in filing.text().lower():\n        print(f\"{filing.company} - {filing.filing_date}\")\n        # Process earnings-related 8-K\n</code></pre>"},{"location":"guides/working-with-filing/#3-extracting-exhibits","title":"3. Extracting Exhibits","text":"<pre><code>filing = find(\"0001065280-24-000123\")\n\n# Find all exhibits\nexhibits = [att for att in filing.attachments if att.document.startswith(\"ex-\")]\n\nfor exhibit in exhibits:\n    print(f\"Exhibit: {exhibit.document}\")\n    print(f\"Description: {exhibit.description}\")\n    # Save exhibit content\n    exhibit.download(f\"./exhibits/{exhibit.document}\")\n</code></pre>"},{"location":"guides/working-with-filing/#error-handling","title":"Error Handling","text":"<p>When working with filings, handle common exceptions:</p> <pre><code>from edgar import Filing, EdgarError\n\ntry:\n    filing = find(\"invalid-accession-number\")\nexcept EdgarError as e:\n    print(f\"Filing not found: {e}\")\n\ntry:\n    content = filing.html()\nexcept Exception as e:\n    print(f\"Error downloading content: {e}\")\n</code></pre>"},{"location":"guides/working-with-filing/#best-practices","title":"Best Practices","text":"<ol> <li>Check Filing Type: Use <code>filing.form</code> to determine the type of filing before processing</li> <li>Verify XBRL Availability: Check <code>filing.is_xbrl</code> before attempting to extract structured data</li> <li>Handle Large Files: Some filings can be very large; consider streaming or partial downloads for large attachments</li> <li>Cache Content: Store downloaded content locally to avoid repeated API calls</li> <li>Respect Rate Limits: Be mindful of SEC rate limits when processing many filings</li> </ol>"},{"location":"guides/working-with-filing/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about extracting financial statements from XBRL-enabled filings</li> <li>Explore filing attachments in more detail</li> <li>See how to filter filings to find specific types of documents</li> </ul>"},{"location":"guides/xbrl-footnotes/","title":"XBRL Footnotes","text":"<p>EdgarTools now supports parsing and accessing footnotes from XBRL documents. Footnotes provide additional context and explanations for specific facts in financial statements.</p>"},{"location":"guides/xbrl-footnotes/#overview","title":"Overview","text":"<p>In XBRL documents, footnotes are linked to facts through a structured relationship: - Facts have unique <code>id</code> attributes (e.g., <code>id=\"ID_123\"</code>) - Footnotes contain explanatory text and have their own identifiers - FootnoteArcs connect facts to footnotes using XLink references</p> <p>EdgarTools automatically extracts these relationships, making footnotes easily accessible alongside the financial data.</p>"},{"location":"guides/xbrl-footnotes/#basic-usage","title":"Basic Usage","text":""},{"location":"guides/xbrl-footnotes/#accessing-footnotes","title":"Accessing Footnotes","text":"<pre><code>from edgar.xbrl.parser import XBRLParser\n\n# Parse an XBRL instance document\nparser = XBRLParser()\nwith open(\"instance.xml\") as f:\n    content = f.read()\nparser.parse_instance_content(content)\n\n# Access footnotes\nprint(f\"Found {len(parser.footnotes)} footnotes\")\n\n# Iterate through footnotes\nfor footnote_id, footnote in parser.footnotes.items():\n    print(f\"Footnote {footnote_id}: {footnote.text}\")\n    print(f\"Related to facts: {footnote.related_fact_ids}\")\n</code></pre>"},{"location":"guides/xbrl-footnotes/#finding-facts-with-footnotes","title":"Finding Facts with Footnotes","text":"<pre><code># Find facts that have footnotes\nfacts_with_footnotes = [\n    fact for fact in parser.facts.values() \n    if fact.footnotes\n]\n\nprint(f\"Found {len(facts_with_footnotes)} facts with footnotes\")\n\n# Show fact details\nfor fact in facts_with_footnotes[:5]:\n    print(f\"Fact: {fact.element_id} (ID: {fact.fact_id})\")\n    print(f\"Value: {fact.value}\")\n    print(f\"Footnotes: {', '.join(fact.footnotes)}\")\n    print()\n</code></pre>"},{"location":"guides/xbrl-footnotes/#using-the-xbrl-class","title":"Using the XBRL Class","text":"<p>The XBRL class provides convenient methods for working with footnotes:</p> <pre><code>from edgar.xbrl import XBRL\n\n# Initialize and parse\nxbrl = XBRL()\nxbrl.parser.parse_instance_content(content)\n\n# Access footnotes property\nfootnotes = xbrl.footnotes\nprint(f\"Document has {len(footnotes)} footnotes\")\n\n# Get footnotes for a specific fact ID\nfact_footnotes = xbrl.get_footnotes_for_fact(\"ID_123\")\nfor footnote in fact_footnotes:\n    print(f\"Footnote: {footnote.text}\")\n\n# Get all facts that have footnotes\nfacts_with_footnotes = xbrl.get_facts_with_footnotes()\n</code></pre>"},{"location":"guides/xbrl-footnotes/#data-models","title":"Data Models","text":""},{"location":"guides/xbrl-footnotes/#fact-model","title":"Fact Model","text":"<p>The <code>Fact</code> model has been enhanced with footnote support:</p> <pre><code>class Fact(BaseModel):\n    element_id: str\n    context_ref: str\n    value: str\n    unit_ref: Optional[str] = None\n    decimals: Optional[Union[int, str]] = None\n    numeric_value: Optional[float] = None\n    footnotes: List[str] = Field(default_factory=list)  # Footnote IDs\n    instance_id: Optional[int] = None\n    fact_id: Optional[str] = None  # Original XML id attribute\n</code></pre>"},{"location":"guides/xbrl-footnotes/#footnote-model","title":"Footnote Model","text":"<pre><code>class Footnote(BaseModel):\n    footnote_id: str\n    text: str\n    lang: Optional[str] = \"en-US\"\n    role: Optional[str] = None\n    related_fact_ids: List[str] = Field(default_factory=list)\n</code></pre>"},{"location":"guides/xbrl-footnotes/#real-world-example","title":"Real-World Example","text":"<p>Here's a complete example using a filing with footnotes:</p> <pre><code>from edgar import Filing\nfrom pathlib import Path\n\n# Get a filing and parse its XBRL\nfiling = Filing(form='10-K', cik=1234567, accession_no='0001234567-23-000001')\nxbrl = filing.xbrl()\n\n# Check if the document has footnotes\nif xbrl.footnotes:\n    print(f\"Document contains {len(xbrl.footnotes)} footnotes\")\n\n    # Show footnote details\n    for footnote_id, footnote in list(xbrl.footnotes.items())[:3]:\n        print(f\"\\nFootnote ID: {footnote_id}\")\n        print(f\"Text: {footnote.text[:100]}...\")\n        print(f\"Language: {footnote.lang}\")\n        print(f\"Linked to {len(footnote.related_fact_ids)} facts\")\n\n    # Find facts with footnotes in the balance sheet\n    balance_sheet = xbrl.get_statement(\"BalanceSheet\")\n    if balance_sheet:\n        for item in balance_sheet.get_all_line_items():\n            facts = item.get(\"facts\", [])\n            for fact in facts:\n                if fact.footnotes:\n                    print(f\"\\n{item['label']} has footnotes:\")\n                    for fn_id in fact.footnotes:\n                        if fn_id in xbrl.footnotes:\n                            print(f\"  \u2022 {xbrl.footnotes[fn_id].text[:80]}...\")\nelse:\n    print(\"No footnotes found in this document\")\n</code></pre>"},{"location":"guides/xbrl-footnotes/#advanced-usage","title":"Advanced Usage","text":""},{"location":"guides/xbrl-footnotes/#filtering-footnotes-by-content","title":"Filtering Footnotes by Content","text":"<pre><code># Find footnotes containing specific keywords\ndebt_footnotes = [\n    (fn_id, footnote) for fn_id, footnote in parser.footnotes.items()\n    if any(keyword in footnote.text.lower() for keyword in ['debt', 'loan', 'credit'])\n]\n\nprint(f\"Found {len(debt_footnotes)} footnotes related to debt\")\n</code></pre>"},{"location":"guides/xbrl-footnotes/#creating-a-footnote-report","title":"Creating a Footnote Report","text":"<pre><code>from rich.console import Console\nfrom rich.table import Table\n\nconsole = Console()\n\n# Create a footnote summary table\ntable = Table(title=\"Footnote Summary\", show_header=True)\ntable.add_column(\"ID\", style=\"cyan\")\ntable.add_column(\"Preview\", style=\"white\", width=60)\ntable.add_column(\"Facts\", style=\"yellow\", justify=\"right\")\n\nfor fn_id, footnote in parser.footnotes.items():\n    preview = footnote.text[:60] + \"...\" if len(footnote.text) &gt; 60 else footnote.text\n    fact_count = str(len(footnote.related_fact_ids))\n\n    table.add_row(fn_id, preview, fact_count)\n\nconsole.print(table)\n</code></pre>"},{"location":"guides/xbrl-footnotes/#cross-referencing-with-financial-statements","title":"Cross-Referencing with Financial Statements","text":"<pre><code># Find footnotes that reference specific financial statement items\ndef find_footnotes_for_concept(xbrl, concept_name):\n    \"\"\"Find footnotes related to a specific accounting concept.\"\"\"\n    related_footnotes = []\n\n    # Find facts matching the concept\n    for fact_key, fact in xbrl.parser.facts.items():\n        if concept_name.lower() in fact.element_id.lower():\n            if fact.footnotes:\n                for fn_id in fact.footnotes:\n                    if fn_id in xbrl.footnotes:\n                        related_footnotes.append((fact, xbrl.footnotes[fn_id]))\n\n    return related_footnotes\n\n# Example: Find footnotes about revenue\nrevenue_footnotes = find_footnotes_for_concept(xbrl, \"Revenue\")\nfor fact, footnote in revenue_footnotes:\n    print(f\"Revenue fact {fact.fact_id}: {footnote.text}\")\n</code></pre>"},{"location":"guides/xbrl-footnotes/#xbrl-technical-details","title":"XBRL Technical Details","text":""},{"location":"guides/xbrl-footnotes/#footnote-structure-in-xbrl","title":"Footnote Structure in XBRL","text":"<p>XBRL footnotes follow the XBRL 2.1 specification:</p> <pre><code>&lt;!-- Footnote definition --&gt;\n&lt;link:footnote id=\"fn-1\" xlink:label=\"fn-1\" \n               xlink:role=\"http://www.xbrl.org/2003/role/footnote\" \n               xml:lang=\"en-US\"&gt;\n    &lt;xhtml:div&gt;\n        &lt;xhtml:span&gt;Explanatory text about the fact.&lt;/xhtml:span&gt;\n    &lt;/xhtml:div&gt;\n&lt;/link:footnote&gt;\n\n&lt;!-- Footnote arc linking fact to footnote --&gt;\n&lt;link:footnoteArc xlink:arcrole=\"http://www.xbrl.org/2003/arcrole/fact-footnote\" \n                  xlink:from=\"fact-id-123\" \n                  xlink:to=\"fn-1\" \n                  xlink:type=\"arc\"/&gt;\n</code></pre>"},{"location":"guides/xbrl-footnotes/#supported-footnote-formats","title":"Supported Footnote Formats","text":"<p>EdgarTools handles: - Standard footnotes with <code>id</code> attributes - XLink footnotes with <code>xlink:label</code> attributes - XHTML content within footnotes (automatically extracts text) - Multiple languages via <code>xml:lang</code> attributes - Custom roles via <code>xlink:role</code> attributes</p>"},{"location":"guides/xbrl-footnotes/#namespace-handling","title":"Namespace Handling","text":"<p>The parser correctly handles all standard XBRL namespaces: - <code>http://www.xbrl.org/2003/linkbase</code> (link) - <code>http://www.w3.org/1999/xlink</code> (xlink) - <code>http://www.w3.org/1999/xhtml</code> (xhtml) - <code>http://www.w3.org/XML/1998/namespace</code> (xml)</p>"},{"location":"guides/xbrl-footnotes/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Footnote extraction adds minimal overhead to XBRL parsing</li> <li>Footnotes are parsed lazily during instance document processing</li> <li>Both fact-to-footnote and footnote-to-fact lookups are O(1) operations</li> <li>Large documents with many footnotes are handled efficiently</li> </ul>"},{"location":"guides/xbrl-footnotes/#error-handling","title":"Error Handling","text":"<p>The parser gracefully handles common footnote issues:</p> <pre><code># Parser warnings for missing footnote references\n# Warning: \"Footnote arc references undefined footnote: footnote_123\"\n\n# Missing footnote definitions are logged but don't cause parsing to fail\n# Malformed XHTML content is handled with fallback text extraction\n</code></pre>"},{"location":"guides/xbrl-footnotes/#migration-from-manual-parsing","title":"Migration from Manual Parsing","text":"<p>If you were previously parsing footnotes manually:</p> <pre><code># Before (manual parsing)\nimport xml.etree.ElementTree as ET\n\ndef extract_footnotes_manually(xml_content):\n    root = ET.fromstring(xml_content)\n    footnotes = {}\n    # ... complex manual parsing logic ...\n    return footnotes\n\n# After (using EdgarTools)\nfrom edgar.xbrl.parser import XBRLParser\n\nparser = XBRLParser()\nparser.parse_instance_content(xml_content)\nfootnotes = parser.footnotes  # Ready to use!\n</code></pre>"},{"location":"guides/xbrl-footnotes/#api-reference","title":"API Reference","text":""},{"location":"guides/xbrl-footnotes/#xbrlparserfootnotes","title":"XBRLParser.footnotes","text":"<ul> <li>Type: <code>Dict[str, Footnote]</code></li> <li>Description: Dictionary mapping footnote IDs to Footnote objects</li> </ul>"},{"location":"guides/xbrl-footnotes/#xbrlfootnotes","title":"XBRL.footnotes","text":"<ul> <li>Type: <code>Dict[str, Footnote]</code></li> <li>Description: Property providing access to parser footnotes</li> </ul>"},{"location":"guides/xbrl-footnotes/#xbrlget_footnotes_for_factfact_id-str","title":"XBRL.get_footnotes_for_fact(fact_id: str)","text":"<ul> <li>Parameters: <code>fact_id</code> - The ID of the fact to get footnotes for</li> <li>Returns: <code>List[Footnote]</code> - List of associated footnotes</li> <li>Description: Retrieves all footnotes linked to a specific fact</li> </ul>"},{"location":"guides/xbrl-footnotes/#xbrlget_facts_with_footnotes","title":"XBRL.get_facts_with_footnotes()","text":"<ul> <li>Returns: <code>Dict[str, Fact]</code> - Dictionary of facts that have footnotes</li> <li>Description: Returns all facts that reference footnotes</li> </ul>"},{"location":"guides/xbrl-footnotes/#factfootnotes","title":"Fact.footnotes","text":"<ul> <li>Type: <code>List[str]</code></li> <li>Description: List of footnote IDs that reference this fact</li> </ul>"},{"location":"guides/xbrl-footnotes/#factfact_id","title":"Fact.fact_id","text":"<ul> <li>Type: <code>Optional[str]</code></li> <li>Description: Original <code>id</code> attribute from the XML element</li> </ul> <p>This feature was implemented to support the XBRL 2.1 specification for footnotes and is compatible with all standard SEC XBRL filings.</p>"},{"location":"images/DEMO-REPLACEMENT-NOTES/","title":"Demo Asset Replacement Notes","text":""},{"location":"images/DEMO-REPLACEMENT-NOTES/#phase-4-replace-demo-asset","title":"Phase 4: Replace Demo Asset","text":""},{"location":"images/DEMO-REPLACEMENT-NOTES/#current-asset","title":"Current Asset","text":"<ul> <li><code>docs/images/edgartools-demo.gif</code> - Console output GIF</li> </ul>"},{"location":"images/DEMO-REPLACEMENT-NOTES/#requirement","title":"Requirement","text":"<p>Replace with a more compelling demo that showcases: 1. EdgarTools' rich terminal output (using <code>rich</code> library) 2. Multiple capabilities in one visual 3. Professional, polished appearance 4. Brand colors where possible</p>"},{"location":"images/DEMO-REPLACEMENT-NOTES/#options","title":"Options","text":""},{"location":"images/DEMO-REPLACEMENT-NOTES/#option-1-jupyter-notebook-screenshot-recommended","title":"Option 1: Jupyter Notebook Screenshot (Recommended)","text":"<p>Create a Jupyter notebook that demonstrates:</p> <pre><code>from edgar import *\nset_identity(\"demo@edgartools.io\")\n\n# Show company lookup with rich output\ncompany = Company(\"AAPL\")\ndisplay(company)\n\n# Show filings with rich table\nfilings = company.get_filings(form=\"10-K\").latest(3)\ndisplay(filings)\n\n# Show financials with rich formatting\nfinancials = company.get_financials()\ndisplay(financials.balance_sheet())\n</code></pre> <p>Steps: 1. Create notebook with code above 2. Execute cells to generate rich output 3. Take high-quality screenshot (1200-1600px wide) 4. Save as <code>docs/images/edgartools-demo-rich.png</code> 5. Update README to use new image</p>"},{"location":"images/DEMO-REPLACEMENT-NOTES/#option-2-terminal-recording-gif","title":"Option 2: Terminal Recording \u2192 GIF","text":"<p>Use <code>terminalizer</code> or <code>asciinema</code> to record:</p> <pre><code># Record terminal session\nterminalizer record demo\n\n# Convert to optimized GIF\nterminalizer render demo\n</code></pre> <p>Show sequence: 1. Import and identity setup 2. Company lookup 3. Filing retrieval 4. Financial data extraction 5. Rich table display</p>"},{"location":"images/DEMO-REPLACEMENT-NOTES/#option-3-beforeafter-comparison","title":"Option 3: Before/After Comparison","text":"<p>Create side-by-side comparison SVG showing: - Left: Messy HTML/web scraping code - Right: Clean EdgarTools code with rich output</p>"},{"location":"images/DEMO-REPLACEMENT-NOTES/#manual-work-required","title":"Manual Work Required","text":"<p>This phase requires manual execution: - [ ] Create demo notebook or script - [ ] Run code to generate output - [ ] Capture high-quality screenshot - [ ] Optimize image size (&lt;500KB preferred) - [ ] Update README with new asset path - [ ] Remove or archive old demo.gif</p>"},{"location":"images/DEMO-REPLACEMENT-NOTES/#recommended-dimensions","title":"Recommended Dimensions","text":"<ul> <li>Width: 1200-1600px (GitHub README optimal)</li> <li>Format: PNG (for screenshots) or GIF (for animations)</li> <li>Optimize with tools like ImageOptim or TinyPNG</li> </ul> <p>Note: This phase marked as requiring manual work. Proceeding to Phase 5 (Mermaid diagrams) which can be completed without code execution.</p>"},{"location":"images/SVG-ASSETS-INVENTORY/","title":"EdgarTools README SVG Assets Inventory","text":"<p>Created: 2025-10-14 Status: Phase 1 Complete - All Core Assets Created</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#overview","title":"Overview","text":"<p>This document catalogs all custom SVG visual assets created for the EdgarTools README modernization project. All assets use the EdgarTools brand colors: - Navy: <code>#3d5875</code> (primary) - Gold: <code>#FFD700</code> (accent)</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#asset-categories","title":"Asset Categories","text":""},{"location":"images/SVG-ASSETS-INVENTORY/#1-badges-docsimagesbadges","title":"1. Badges (<code>docs/images/badges/</code>)","text":"<p>Premium-quality badges showcasing key features and benefits.</p> <p>Specifications: - Height: 26px - Width: Variable (130-150px based on text) - Background: Navy vertical gradient (<code>#4a6885</code> \u2192 <code>#3d5875</code>) - Border radius: 13px (pill shape) - Text: Gold <code>#FFD700</code>, 12pt, bold, 0.5 letter-spacing - Icons: Custom gold symbols</p> <p>Files: - <code>badge-ai-native.svg</code> (140px) - Brain/neural icon - <code>badge-mcp-ready.svg</code> (145px) - Connected nodes icon - <code>badge-10x-faster.svg</code> (145px) - Lightning bolt icon - <code>badge-zero-cost.svg</code> (130px) - Dollar sign with slash icon - <code>badge-open-source.svg</code> (150px) - Share/fork icon - <code>badge-type-safe.svg</code> (130px) - Shield with checkmark icon</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#2-section-headers-docsimagessections","title":"2. Section Headers (<code>docs/images/sections/</code>)","text":"<p>Large banner-style headers for major README sections.</p> <p>Specifications: - Size: 800x60px - Background: Navy horizontal gradient (<code>#2a3f54</code> \u2192 <code>#3d5875</code>) - Border radius: 6px - Gold accent line: 1px, 15% opacity - Hexagonal icon: 30x30px gold outline - Text: Gold <code>#FFD700</code>, 24pt, bold, 1.0 letter-spacing</p> <p>Files: - <code>section-quick-start.svg</code> - Rocket icon - <code>section-features.svg</code> - Grid/layers icon - <code>section-ai-integration.svg</code> - Neural network icon - <code>section-performance.svg</code> - Lightning bolt icon - <code>section-community.svg</code> - Connected people icon</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#3-feature-icons-docsimagesicons","title":"3. Feature Icons (<code>docs/images/icons/</code>)","text":"<p>Hexagonal icons for feature grid and key capabilities.</p> <p>Specifications: - Size: 80x80px - Outer hexagon: Navy <code>#3d5875</code>, 2.5px stroke, 30% opacity - Inner hexagon: Gold gradient fill (<code>#FFD700</code> \u2192 <code>#FFB700</code>), 25% opacity - Inner hexagon border: Gold <code>#FFD700</code>, 2px stroke - Symbol: Navy <code>#3d5875</code>, custom for each icon</p> <p>Files: - <code>icon-speed.svg</code> - Lightning bolt (performance) - <code>icon-ai.svg</code> - Neural network (AI capabilities) - <code>icon-quality.svg</code> - Layered hexagons (data quality) - <code>icon-xbrl.svg</code> - XML brackets (XBRL processing) - <code>icon-data.svg</code> - Table/grid (data structures) - <code>icon-community.svg</code> - Connected nodes (community)</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#4-comparison-icons-docsimagesicons","title":"4. Comparison Icons (<code>docs/images/icons/</code>)","text":"<p>Small icons for comparison tables showing feature availability.</p> <p>Specifications: - Size: 24x24px - Simple, clear symbols optimized for small size - Three states: full support, no support, partial support</p> <p>Files: - <code>compare-check.svg</code> - Gold checkmark in gold circle (full support) - <code>compare-cross.svg</code> - Gray X in gray circle (no support) - <code>compare-partial.svg</code> - Gold/orange warning triangle (partial support)</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#5-dividers-docsimagesdividers","title":"5. Dividers (<code>docs/images/dividers/</code>)","text":"<p>Visual separators for content sections.</p> <p>Specifications: - Size: 600x30px - Central hexagon: Gold <code>#FFD700</code>, 20x20px - Extending lines: Gold, 2px, fade effect - Subtle, elegant design</p> <p>Files: - <code>divider-hexagons.svg</code> - Center hexagon with extending lines</p>"},{"location":"images/SVG-ASSETS-INVENTORY/#usage-guidelines","title":"Usage Guidelines","text":""},{"location":"images/SVG-ASSETS-INVENTORY/#in-readme-markdown","title":"In README Markdown","text":"<p>Badges (horizontal row):</p> <pre><code>&lt;p align=\"center\"&gt;\n  &lt;img src=\"docs/images/badges/badge-ai-native.svg\" alt=\"AI Native\"&gt;\n  &lt;img src=\"docs/images/badges/badge-mcp-ready.svg\" alt=\"MCP Ready\"&gt;\n  &lt;img src=\"docs/images/badges/badge-10x-faster.svg\" alt=\"10x Faster\"&gt;\n&lt;/p&gt;\n</code></pre> <p>Section Headers:</p> <pre><code>&lt;p align=\"center\"&gt;\n  &lt;img src=\"docs/images/sections/section-quick-start.svg\" alt=\"Quick Start\"&gt;\n&lt;/p&gt;\n</code></pre> <p>Feature Grid (3 columns):</p> <pre><code>&lt;table align=\"center\"&gt;\n&lt;tr&gt;\n  &lt;td align=\"center\" width=\"33%\"&gt;\n    &lt;img src=\"docs/images/icons/icon-speed.svg\" width=\"80\" alt=\"Fast\"&gt;&lt;br&gt;\n    &lt;b&gt;Lightning Fast&lt;/b&gt;&lt;br&gt;\n    10-30x faster than alternatives\n  &lt;/td&gt;\n  &lt;td align=\"center\" width=\"33%\"&gt;\n    &lt;img src=\"docs/images/icons/icon-ai.svg\" width=\"80\" alt=\"AI\"&gt;&lt;br&gt;\n    &lt;b&gt;AI Native&lt;/b&gt;&lt;br&gt;\n    Built-in MCP server\n  &lt;/td&gt;\n  &lt;td align=\"center\" width=\"33%\"&gt;\n    &lt;img src=\"docs/images/icons/icon-quality.svg\" width=\"80\" alt=\"Quality\"&gt;&lt;br&gt;\n    &lt;b&gt;Data Quality&lt;/b&gt;&lt;br&gt;\n    Validated, standardized\n  &lt;/td&gt;\n&lt;/tr&gt;\n&lt;/table&gt;\n</code></pre> <p>Comparison Tables:</p> <pre><code>| Feature | EdgarTools | Alternative |\n|---------|------------|-------------|\n| MCP Server | &lt;img src=\"docs/images/icons/compare-check.svg\"&gt; | &lt;img src=\"docs/images/icons/compare-cross.svg\"&gt; |\n</code></pre> <p>Dividers:</p> <pre><code>&lt;p align=\"center\"&gt;\n  &lt;img src=\"docs/images/dividers/divider-hexagons.svg\" alt=\"\"&gt;\n&lt;/p&gt;\n</code></pre>"},{"location":"images/SVG-ASSETS-INVENTORY/#design-system-notes","title":"Design System Notes","text":""},{"location":"images/SVG-ASSETS-INVENTORY/#brand-consistency","title":"Brand Consistency","text":"<ul> <li>All assets use exact brand colors from EdgarTools logo</li> <li>Hexagonal motif appears throughout (from logo shape)</li> <li>Consistent stroke widths and spacing</li> <li>Professional, technical aesthetic</li> </ul>"},{"location":"images/SVG-ASSETS-INVENTORY/#accessibility","title":"Accessibility","text":"<ul> <li>All SVGs include descriptive alt text in README usage</li> <li>WCAG AA contrast ratios maintained</li> <li>Icons supplemented with text labels</li> <li>Screen reader friendly markup</li> </ul>"},{"location":"images/SVG-ASSETS-INVENTORY/#mobile-responsiveness","title":"Mobile Responsiveness","text":"<ul> <li>Percentage-based widths in tables</li> <li>SVGs scale cleanly at any size</li> <li>Clear icons work at small sizes</li> <li>Text remains readable on mobile</li> </ul>"},{"location":"images/SVG-ASSETS-INVENTORY/#performance","title":"Performance","text":"<ul> <li>SVGs are lightweight (2-4KB each)</li> <li>No external dependencies</li> <li>Fast loading times</li> <li>Can be further optimized with SVGO if needed</li> </ul>"},{"location":"images/SVG-ASSETS-INVENTORY/#next-steps","title":"Next Steps","text":"<ol> <li>Phase 2: Draft new README content integrating these assets</li> <li>Phase 3: Create performance visualization chart SVG</li> <li>Phase 4: Replace demo console GIF with rich output screenshot</li> <li>Phase 5: Add Mermaid architecture diagram</li> <li>Phase 7: Optimize all SVGs with SVGO</li> <li>Phase 7: Accessibility audit</li> </ol>"},{"location":"images/SVG-ASSETS-INVENTORY/#verification","title":"Verification","text":"<p>All assets verified on 2025-10-14: - \u2713 Proper SVG structure and XML headers - \u2713 Consistent dimensions and styling - \u2713 Brand colors correctly applied - \u2713 Files organized in logical directory structure - \u2713 Ready for README integration</p> <p>Branch: <code>feature/readme-modernization</code> Related Docs: - Research: <code>docs-internal/research/codebase/2025-10-14-readme-visual-design-research.md</code> - Plan: <code>docs-internal/planning/active-tasks/2025-10-14-readme-modernization-plan.md</code> - Mockup: <code>docs/images/readme-mockup/README-MOCKUP.md</code></p>"},{"location":"images/readme-mockup/README-MOCKUP/","title":"README MOCKUP","text":"The AI-Native SEC Filing Analysis Platform <p> Transform SEC filing analysis from hours of wrangling to minutes of insight. The world's most powerful open-source SEC data library combines intuitive APIs, standardized financial data, and native AI agent support. </p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#why-edgartools","title":"Why EdgarTools?","text":"Lightning Fast <p>Get 5 years of financials in 2-3 seconds vs 30-60 seconds with alternatives. Built for analysts who process hundreds of filings.</p> AI-Native <p>Production MCP server for Claude Desktop, Cline, and Continue.dev. Token-optimized outputs for LLM consumption.</p> Data Quality <p>Automatic standardization across companies. Tesla's \"AutomotiveRevenue\" \u2192 \"Revenue\". Clean, analysis-ready DataFrames.</p> <p></p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#installation","title":"Installation","text":"<pre><code># Full installation with AI/MCP support\npip install edgartools[ai]\n\n# Basic installation\npip install edgartools\n</code></pre>"},{"location":"images/readme-mockup/README-MOCKUP/#your-first-analysis-3-lines","title":"Your First Analysis (3 lines)","text":"<pre><code>from edgar import Company\n\napple = Company(\"AAPL\")\nfinancials = apple.get_financials().get_revenue()\n</code></pre>"},{"location":"images/readme-mockup/README-MOCKUP/#ai-agent-integration","title":"AI Agent Integration","text":"<pre><code># Start MCP server for Claude Desktop\npython -m edgar.ai\n</code></pre> <p>Configure in Claude Desktop (<code>claude_desktop_config.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"edgartools\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"edgar.ai\"],\n      \"env\": {\n        \"EDGAR_IDENTITY\": \"Your Name your.email@example.com\"\n      }\n    }\n  }\n}\n</code></pre> <p>Now Claude can analyze any SEC filing, compare financials, or screen stocks using natural language.</p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#edgartools-vs-alternatives","title":"EdgarTools vs Alternatives","text":"Feature EdgarTools sec-api OpenEDGAR Official SEC APIs Cost Free $50-500/month Free Free XBRL Standardization \u2705 Automatic \u274c Raw only \u274c Raw only \u274c Raw only AI/MCP Integration \u2705 Production ready \u274c No \u274c No \u274c No Insider Trading (Forms 3,4,5) \u2705 Structured objects \u26a0\ufe0f Raw XML \u274c No \u26a0\ufe0f Raw XML 13F Fund Holdings \u2705 Full analysis \u26a0\ufe0f Basic \u274c No \u26a0\ufe0f Basic Performance 2-3 seconds 30-60 seconds 5-10 minutes 10-30 seconds Setup Complexity <code>pip install</code> API key required Django setup No setup View Performance Benchmarks   | Operation | EdgarTools | Alternatives | Speedup | |-----------|------------|--------------|---------| | Get 5 years of financials | 2-3 seconds | 30-60 seconds | **15-20x faster** | | Parse 100 10-K filings | 2-5 minutes | 30-60 minutes | **10-15x faster** | | Extract all insider trades | 10-15 seconds | 5-10 minutes | **30x faster** | | Query XBRL facts | Instant (cached) | 5-15 seconds | **Instant** |"},{"location":"images/readme-mockup/README-MOCKUP/#complete-feature-set","title":"Complete Feature Set","text":"<p>Filing Types Supported - Annual Reports (10-K, 20-F, 40-F) - Quarterly Reports (10-Q) - Current Reports (8-K, 6-K) - Insider Transactions (Forms 3, 4, 5) - Fund Holdings (13F-HR) - Proxy Statements (DEF 14A) - Registration Statements (S-1, S-3, S-4, S-8) - 30+ other form types</p> <p>Data Extraction - Financial statements (Balance Sheet, Income, Cash Flow) - Standardized metrics API (<code>get_revenue()</code>, <code>get_net_income()</code>, etc.) - XBRL facts with dimensional breakdowns - Clean text extraction from HTML - Section-level access (Risk Factors, MD&amp;A, etc.)</p> <p>Developer Experience - Type hints and IntelliSense support - Rich display in Jupyter notebooks - Automatic pandas DataFrame conversion - Comprehensive error handling - Smart caching and rate limiting</p> <p>AI/MCP Capabilities - <code>edgar_company_research</code> - Comprehensive company intelligence - <code>edgar_analyze_financials</code> - Multi-period financial analysis - Token-optimized for LLM consumption - Compatible with Claude Desktop, Cline, Continue.dev</p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#real-world-impact","title":"Real-World Impact","text":"<p>Financial Analysis Firm: \"EdgarTools reduced our data preparation time from 6 hours to 15 minutes. We can now analyze 500+ companies in the time it used to take for 10.\" \u2014 95% time savings</p> <p>Academic Research: \"For our corporate governance study of 3,000 companies over 10 years, EdgarTools made the impossible possible. The standardized data quality is exceptional.\"</p> <p>Investment Fund: \"We track insider trading across our entire portfolio in real-time. EdgarTools' Form 4 parsing is the most accurate we've found.\"</p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#documentation-community","title":"Documentation &amp; Community","text":"<p>Documentation - Quick Start Guide - Get started in 5 minutes - User Examples - Real-world use cases - Full API Documentation - Complete reference - MCP Quickstart - AI agent setup</p> <p>Community - GitHub Discussions - Ask questions, share insights - GitHub Issues - Bug reports and feature requests - EdgarTools Blog - Tutorials and updates</p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#contributing","title":"Contributing","text":"<p>We welcome contributions from the community! Ways to help:</p> <ul> <li>Code: Fix bugs, add features, improve documentation</li> <li>Examples: Share interesting use cases and analyses</li> <li>Feedback: Report issues or suggest improvements</li> <li>Spread the Word: Star the repo, share with colleagues</li> </ul> <p>See our Contributing Guide for details.</p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#support-edgartools","title":"Support EdgarTools","text":"<p>If you find EdgarTools valuable, please consider supporting its development:</p> <p></p> <p>Your support helps maintain and improve EdgarTools for the entire community!</p> <p></p> <p></p>"},{"location":"images/readme-mockup/README-MOCKUP/#license","title":"License","text":"<p>EdgarTools is distributed under the MIT License.</p> <p></p>   [![Star History Chart](https://api.star-history.com/svg?repos=dgunning/edgartools&amp;type=Timeline)](https://star-history.com/#dgunning/edgartools&amp;Timeline)"},{"location":"planning/architecture/xbrl-standardization-pipeline/","title":"XBRL Standardization Pipeline Architecture","text":"<p>Date: 2025-11-22 Status: Proposed Architecture Design Related: GitHub Issue #494, mpreiss9's methodology Context: Flexible granularity enhancement for XBRL standardization</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#purpose","title":"Purpose","text":"<p>This document defines the architecture for EdgarTools' XBRL processing pipeline with flexible standardization and granularity control. It establishes clear boundaries between EdgarTools' responsibilities and user customization points.</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#design-principles","title":"Design Principles","text":"<ol> <li>Clean boundaries: EdgarTools owns parsing/building, users own business logic</li> <li>Pipeline composition: Transformations are composable and chainable</li> <li>Minimal coupling: EdgarTools doesn't know about user workflows</li> <li>Opt-in complexity: Simple by default, powerful when needed</li> <li>Data &gt; Code: Configuration-driven, not code-driven</li> <li>Immutability: Transformations return new objects, never mutate</li> <li>Transparency: Original data always preserved and accessible</li> </ol>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#the-pipeline-7-stages","title":"The Pipeline (7 Stages)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 1: XBRL PARSING (EdgarTools Core)                        \u2502\n\u2502 Input:  XBRL XML files (instance, linkbases)                   \u2502\n\u2502 Output: Parsed facts, trees, contexts                          \u2502\n\u2502 Owner:  EdgarTools                                              \u2502\n\u2502 Files:  edgar/xbrl/parsers/*.py, edgar/xbrl/xbrl.py           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 2: STATEMENT BUILDING (EdgarTools Core)                  \u2502\n\u2502 Input:  Parsed XBRL + statement role/type                      \u2502\n\u2502 Output: Raw line items [concept, label, values, metadata]      \u2502\n\u2502 Owner:  EdgarTools                                              \u2502\n\u2502 Files:  edgar/xbrl/xbrl.py (get_statement method)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 3: BASE STANDARDIZATION (EdgarTools + User Config)       \u2502\n\u2502 Input:  Raw line items                                          \u2502\n\u2502 Process: Apply concept \u2192 standard label mappings               \u2502\n\u2502 Output: Base standardized items (preserves originals)          \u2502\n\u2502 Owner:  EdgarTools (engine) + User (mappings)                  \u2502\n\u2502 Files:  edgar/xbrl/standardization/core.py                    \u2502\n\u2502 Plugin: company_mappings/*.json (EXISTING mechanism)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 4: GRANULARITY TRANSFORMATION (NEW - User Controlled)    \u2502\n\u2502 Input:  Base standardized items                                \u2502\n\u2502 Process: Apply granularity profile (detailed/standard/summary) \u2502\n\u2502 Output: Transformed items at chosen granularity                \u2502\n\u2502 Owner:  User (EdgarTools provides profiles + engine)           \u2502\n\u2502 Plugin: profiles/*.json (NEW)                                  \u2502\n\u2502 Status: PROPOSED - To be implemented                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 5: CONTEXT-AWARE RESOLUTION (NEW - Optional)             \u2502\n\u2502 Input:  Granular items (may have ambiguous tags)               \u2502\n\u2502 Process: Resolve using section/parent context                  \u2502\n\u2502 Output: Disambiguated items                                    \u2502\n\u2502 Owner:  EdgarTools (algorithm) + User (ambiguity rules)        \u2502\n\u2502 Plugin: ambiguous_tags.json (NEW)                              \u2502\n\u2502 Status: PROPOSED - To be implemented                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 6: PERIOD SELECTION (EdgarTools Core)                    \u2502\n\u2502 Input:  Transformed statement                                  \u2502\n\u2502 Output: Filtered to display periods                            \u2502\n\u2502 Owner:  EdgarTools                                              \u2502\n\u2502 Files:  edgar/xbrl/periods.py                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Stage 7: RENDERING (EdgarTools Core)                           \u2502\n\u2502 Input:  Final statement + periods                              \u2502\n\u2502 Output: RenderedStatement (Rich Table)                         \u2502\n\u2502 Owner:  EdgarTools                                              \u2502\n\u2502 Files:  edgar/xbrl/rendering.py                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-details","title":"Stage Details","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-1-xbrl-parsing","title":"Stage 1: XBRL Parsing","text":"<p>Purpose: Convert XBRL XML into structured Python objects</p> <p>Input: 6 XBRL documents - Instance document (facts and contexts) - Schema (element definitions) - Presentation linkbase (hierarchy) - Calculation linkbase (arithmetic relationships) - Definition linkbase (dimensional data) - Label linkbase (human-readable labels)</p> <p>Output:</p> <pre><code>{\n    'facts': Dict[fact_key, Fact],\n    'contexts': Dict[context_id, Context],\n    'element_catalog': Dict[id, Element],\n    'presentation_trees': Dict[role, PresentationTree],\n    'calculation_trees': Dict[role, CalculationTree],\n    'reporting_periods': List[Period]\n}\n</code></pre> <p>Complexity: High (XBRL is complex) User Customization: None (parsing is deterministic)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-2-statement-building","title":"Stage 2: Statement Building","text":"<p>Purpose: Extract statement from XBRL using presentation tree</p> <p>Input: Parsed XBRL + statement identifier</p> <p>Process: 1. Resolve statement role URI 2. Traverse presentation tree depth-first 3. Match facts to concepts using contexts 4. Build line item list with hierarchy</p> <p>Output:</p> <pre><code>[\n    {\n        'concept': 'us-gaap:Revenue',\n        'label': 'Total Revenue',\n        'values': {'FY2023': 25500000000, 'FY2022': 23400000000},\n        'metadata': {\n            'level': 1,\n            'is_abstract': False,\n            'parent': 'us-gaap:Revenues',\n            'section': None,  # Determined later\n            'balance_type': None,\n            'calculation_weight': 1.0\n        }\n    },\n    ...\n]\n</code></pre> <p>Complexity: Medium (tree traversal + context matching) User Customization: Minimal (can filter periods)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-3-base-standardization","title":"Stage 3: Base Standardization","text":"<p>Purpose: Normalize concept labels for consistency</p> <p>Input: Raw line items from Stage 2</p> <p>Process: 1. ConceptMapper checks cache 2. Looks up company-specific mappings (if available) 3. Falls back to core mappings 4. Priority-based resolution (company &gt; core) 5. Preserves original labels</p> <p>Output: Line items with <code>standard_label</code> added</p> <pre><code>{\n    'concept': 'us-gaap:Revenue',\n    'label': 'Revenue',  # \u2190 Standardized\n    'original_label': 'Total Revenue',  # \u2190 Original preserved\n    ...\n}\n</code></pre> <p>Complexity: Low (dictionary lookup) User Customization: High (via company_mappings/*.json)</p> <p>Critical Insight: This is \"Reason 1\" from mpreiss9 - same facts, different names</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-4-granularity-transformation-new","title":"Stage 4: Granularity Transformation (NEW)","text":"<p>Purpose: Apply user's analytical granularity preference</p> <p>Input: Base standardized items</p> <p>Process: 1. Load granularity profile (detailed/standard/summarized) 2. Apply transformation rules:    - Rollup: Combine multiple items into summary    - Split: Break single item into components    - Rename: Change granularity level 3. Return transformed items</p> <p>Output: Items at chosen granularity</p> <pre><code># BEFORE (base standardization)\n[\n    {'label': 'Tax Liabilities', 'value': 50M},\n    {'label': 'Retirement Liabilities', 'value': 30M},\n    {'label': 'Other Non-Operating Liabilities', 'value': 20M}\n]\n\n# AFTER (summarized profile)\n[\n    {'label': 'Non-Operating Liabilities', 'value': 100M,\n     'original_items': ['Tax Liabilities', 'Retirement Liabilities', 'Other...']}\n]\n</code></pre> <p>Complexity: Medium (rule application + validation) User Customization: Very High (define custom profiles)</p> <p>Critical Insight: This is \"Reason 2\" from mpreiss9 - different granularity for different needs</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-5-context-aware-resolution-new","title":"Stage 5: Context-Aware Resolution (NEW)","text":"<p>Purpose: Resolve ambiguous tags using statement context</p> <p>Input: Items with potential ambiguities</p> <p>Process: 1. Identify ambiguous tags (from registry) 2. Determine context (section, parent concept, sign) 3. Apply resolution rules 4. Select appropriate mapping 5. Log unresolved ambiguities</p> <p>Example:</p> <pre><code># Ambiguous: DeferredTaxAssetsLiabilitiesNet\n# Context: parent='AssetsCurrent', section='Current Assets'\n# Resolution: \u2192 'Deferred Tax Assets' (not 'Deferred Tax Liabilities')\n</code></pre> <p>Complexity: High (context detection + rule application) User Customization: Medium (define ambiguity rules)</p> <p>Critical Insight: Handles mpreiss9's 215 ambiguous tags</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-6-period-selection","title":"Stage 6: Period Selection","text":"<p>Purpose: Filter statement to relevant time periods</p> <p>Input: Transformed statement</p> <p>Process: 1. Detect fiscal year/quarter from entity info 2. Select appropriate periods (e.g., 3 annual for FY) 3. Sort by date (newest first) 4. Apply user overrides if specified</p> <p>Output: Same statement with narrowed period list</p> <p>Complexity: Low (date filtering) User Customization: Low (can specify period_view)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#stage-7-rendering","title":"Stage 7: Rendering","text":"<p>Purpose: Format statement for display</p> <p>Input: Final statement + period list</p> <p>Process: 1. Determine scale (millions, thousands) 2. Apply presentation transforms (sign adjustments) 3. Format values with proper decimals 4. Create Rich Table with styling 5. Add comparison indicators</p> <p>Output: RenderedStatement (Rich Table wrapper)</p> <p>Complexity: Medium (formatting + styling) User Customization: Low (color schemes, formats)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#data-contract","title":"Data Contract","text":"<p>Every stage exchanges data in a standard format to ensure clean boundaries:</p> <pre><code># Line Item Structure (grows through pipeline)\n{\n    # From Stage 2: Statement Building\n    'concept': 'us-gaap:Revenue',           # XBRL concept name\n    'label': 'Total Revenue',                # Original label\n    'values': {                              # Period \u2192 value mapping\n        'FY2023': 25500000000,\n        'FY2022': 23400000000\n    },\n    'metadata': {\n        'level': 1,                          # Hierarchy depth\n        'is_abstract': False,\n        'parent': 'us-gaap:Revenues',       # Parent concept\n        'balance_type': None,               # Debit/credit\n        'calculation_weight': 1.0\n    },\n\n    # From Stage 3: Base Standardization\n    'standard_label': 'Revenue',             # Standardized label\n    'original_label': 'Total Revenue',       # Original preserved\n\n    # From Stage 4: Granularity Transformation (if applied)\n    'granular_label': 'Product Revenue',     # After granularity profile\n    'granularity_level': 'detailed',         # Which profile was applied\n    'rollup_source': None,                   # If this is a rollup, what items?\n\n    # From Stage 5: Context-Aware Resolution (if applied)\n    'section': 'Revenue',                    # Detected section\n    'resolution_applied': False,             # Was ambiguity resolved?\n    'ambiguity_candidates': None             # If ambiguous, what were options?\n}\n</code></pre> <p>Guarantee: Every stage preserves this contract. Transformations add fields but never remove them.</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#boundary-edgartools-vs-user","title":"Boundary: EdgarTools vs. User","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#edgartools-responsibilities","title":"EdgarTools Responsibilities","text":"<p>What we maintain: - \u2705 Parse XBRL correctly (Stage 1) - \u2705 Build accurate statements from XBRL (Stage 2) - \u2705 Apply mappings from configuration files (Stage 3, 4, 5) - \u2705 Render output beautifully (Stage 7) - \u2705 Provide transformation engines (ConceptMapper, ProfileTransformer) - \u2705 Provide default profiles (detailed, standard, summarized) - \u2705 Validate profile structure and references - \u2705 Handle errors gracefully with clear messages</p> <p>What we DON'T do: - \u274c Execute user Python code in the pipeline - \u274c Try to infer user intent - \u274c Build a general-purpose transformation language - \u274c Validate user business logic - \u274c Store state about user workflows</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#user-responsibilities","title":"User Responsibilities","text":"<p>What users control: - Define custom granularity profiles (JSON/CSV) - Choose which profile to use - Define company-specific mappings - Define ambiguous tag resolution rules - Handle their own business logic OUTSIDE the pipeline</p> <p>Critical: EdgarTools reads user config files (JSON/CSV) but doesn't execute user code. Only data, not code.</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#user-customization-3-levels","title":"User Customization: 3 Levels","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#level-1-choose-a-profile-90-of-users","title":"Level 1: Choose a Profile (90% of users)","text":"<p>Simplest approach - just pick a granularity level:</p> <pre><code># Default (balanced)\nstatement = xbrl.statements.balance_sheet()\n\n# Maximum detail\nstatement = xbrl.statements.balance_sheet(granularity='detailed')\n\n# High-level summary\nstatement = xbrl.statements.balance_sheet(granularity='summarized')\n</code></pre> <p>No config needed - EdgarTools ships with default profiles: - <code>detailed</code>: Maximum granularity (like mpreiss9's mappings) - <code>standard</code>: Balanced level (current EdgarTools behavior) - <code>summarized</code>: High-level rollups for quick analysis</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#level-2-custom-profile-file-advanced-users-like-mpreiss9","title":"Level 2: Custom Profile File (Advanced users like mpreiss9)","text":"<p>More control - provide your own mapping file:</p> <pre><code>from edgar.xbrl.standardization import Profile\n\n# Load custom profile\nprofile = Profile.from_csv('my_mappings.csv')\nstatement = xbrl.statements.balance_sheet().with_profile(profile)\n\n# Or chain transformations\nstatement = (xbrl.statements.balance_sheet()\n    .with_granularity('detailed')      # First: max detail\n    .with_profile('my_rollups.json'))  # Then: custom rollups\n</code></pre> <p>User provides: CSV/JSON file with transformation rules EdgarTools applies: The rules to transform the statement</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#level-3-programmatic-transformation-power-users","title":"Level 3: Programmatic Transformation (Power users)","text":"<p>Full control - user transforms data outside EdgarTools:</p> <pre><code># Get statement data\nstatement = xbrl.statements.balance_sheet()\ndf = statement.to_dataframe()\n\n# User's own business logic HERE\ndf_transformed = my_custom_analytics(df)\ndf_summarized = my_custom_rollups(df_transformed)\ndf_final = my_special_calculations(df_summarized)\n\n# Convert back if needed (optional)\ncustom_statement = Statement.from_dataframe(df_final)\n</code></pre> <p>Critical: Level 3 keeps EdgarTools out of user workflows. We give them data, they give us back data (if they want).</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#granularity-profiles-stage-4","title":"Granularity Profiles (Stage 4)","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#profile-format","title":"Profile Format","text":"<p>Profiles are pure data (JSON/CSV), not code:</p> <pre><code>{\n  \"profile_metadata\": {\n    \"name\": \"detailed\",\n    \"description\": \"Maximum granularity for detailed analysis\",\n    \"version\": \"1.0\",\n    \"based_on\": \"standard\"\n  },\n\n  \"transformations\": {\n    \"rollup_rules\": {\n      \"NonOperatingLiabilities\": {\n        \"combine\": [\n          \"TaxLiabilities\",\n          \"RetirementLiabilities\",\n          \"OtherNonOperatingLiabilities\"\n        ],\n        \"operation\": \"sum\"\n      }\n    },\n\n    \"split_rules\": {\n      \"Revenue\": {\n        \"split_into\": {\n          \"ProductRevenue\": {\"pattern\": \"*Product*\"},\n          \"ServiceRevenue\": {\"pattern\": \"*Service*\"}\n        }\n      }\n    },\n\n    \"rename_rules\": {\n      \"PP&amp;E\": \"PropertyPlantAndEquipment\"\n    }\n  }\n}\n</code></pre> <p>EdgarTools interprets the rules, users just provide the data.</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#default-profiles","title":"Default Profiles","text":"<p>detailed.json (like mpreiss9's mappings):</p> <pre><code>{\n  \"name\": \"detailed\",\n  \"transformations\": {\n    \"split_rules\": {\n      \"NonOperatingLiabilities\": {\n        \"TaxLiabilities\": [\"*Tax*Liab*\"],\n        \"RetirementLiabilities\": [\"*Pension*\", \"*Retirement*\"],\n        \"OtherNonOperatingLiabilities\": [\"*\"]\n      }\n    }\n  }\n}\n</code></pre> <p>summarized.json (rollups):</p> <pre><code>{\n  \"name\": \"summarized\",\n  \"transformations\": {\n    \"rollup_rules\": {\n      \"NonOperatingLiabilities\": {\n        \"combine\": [\n          \"TaxLiabilities\",\n          \"RetirementLiabilities\",\n          \"OtherNonOperatingLiabilities\"\n        ]\n      }\n    }\n  }\n}\n</code></pre> <p>standard.json (current behavior - no transformation):</p> <pre><code>{\n  \"name\": \"standard\",\n  \"transformations\": {}\n}\n</code></pre>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#composable-transformations","title":"Composable Transformations","text":"<p>Think of transformations as a pipeline you can compose:</p> <pre><code># Each transformation returns a NEW statement (immutable)\nstatement = xbrl.statements.balance_sheet()\n\n# Apply granularity\ndetailed = statement.with_granularity('detailed')\nsummarized = statement.with_granularity('summarized')\n\n# Chain transformations\ncustom = (statement\n    .with_granularity('detailed')        # First: max detail\n    .with_profile('my_rollups.json')     # Then: custom rollups\n    .filter_sections(['Assets']))        # Then: filter to assets only\n\n# Original statement unchanged\nprint(statement)    # Still original\nprint(custom)       # Transformed version\n</code></pre> <p>Key: Each transformation returns a new object. Originals never mutate. This keeps the pipeline clean and debuggable.</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#implementation-phases","title":"Implementation Phases","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#phase-1-profile-infrastructure-v4310","title":"Phase 1: Profile Infrastructure (v4.31.0)","text":"<p>Goal: Add profile loading and transformation engine</p> <p>Work: 1. Create <code>edgar/xbrl/standardization/profiles/</code> directory 2. Ship default profiles: <code>detailed.json</code>, <code>standard.json</code>, <code>summarized.json</code> 3. Implement <code>Profile</code> class (loads JSON/CSV, validates) 4. Implement <code>ProfileTransformer</code> (applies rollup/split rules) 5. Add <code>.with_granularity()</code> method to Statement class</p> <p>User-facing:</p> <pre><code># Just works with defaults\nstatement = xbrl.statements.balance_sheet(granularity='detailed')\n</code></pre> <p>Effort: 2-3 weeks Risk: Low (self-contained)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#phase-2-custom-profiles-v500","title":"Phase 2: Custom Profiles (v5.0.0)","text":"<p>Goal: Let users load custom profiles</p> <p>Work: 1. Add <code>Profile.from_csv()</code> and <code>Profile.from_json()</code> methods 2. Add profile validation (check for cycles, missing refs) 3. Document profile format in user guide 4. Provide mpreiss9's mappings as example 5. Add <code>.with_profile()</code> method</p> <p>User-facing:</p> <pre><code># Load custom profile\nprofile = Profile.from_csv('my_rollups.csv')\nstatement = xbrl.statements.balance_sheet().with_profile(profile)\n</code></pre> <p>Effort: 1-2 weeks Risk: Low (extension of Phase 1)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#phase-3-hierarchical-profiles-v510","title":"Phase 3: Hierarchical Profiles (v5.1.0)","text":"<p>Goal: Support drill-down/roll-up navigation</p> <p>Work: 1. Add parent-child relationships to profile format 2. Implement <code>.drill_down(label)</code> and <code>.roll_up(label)</code> methods 3. Add profile composition (combine multiple profiles) 4. Document hierarchical navigation</p> <p>User-facing:</p> <pre><code># Navigate hierarchy\nsummary = statement.with_granularity('summarized')\nprint(summary)  # Shows \"NonOperatingLiabilities: $100M\"\n\n# Drill down to see components\ndetailed = summary.drill_down('NonOperatingLiabilities')\nprint(detailed)  # Shows Tax ($50M), Retirement ($30M), Other ($20M)\n\n# Roll back up\nsummary_again = detailed.roll_up('NonOperatingLiabilities')\n</code></pre> <p>Effort: 2-3 weeks Risk: Medium (more complex API)</p>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#success-criteria","title":"Success Criteria","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#maintainability","title":"Maintainability","text":"<ul> <li>[ ] Profile engine is &lt;500 lines of code</li> <li>[ ] Default profiles ship with EdgarTools</li> <li>[ ] Users never need to modify EdgarTools code</li> <li>[ ] Profile format is well-documented</li> <li>[ ] Validation catches errors early with clear messages</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#flexibility","title":"Flexibility","text":"<ul> <li>[ ] Users can define any granularity via JSON/CSV</li> <li>[ ] Profiles compose cleanly (can chain transformations)</li> <li>[ ] Can always fall back to raw XBRL (no data loss)</li> <li>[ ] Support both rollup and split operations</li> <li>[ ] Custom profiles work exactly like default profiles</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#robustness","title":"Robustness","text":"<ul> <li>[ ] Profile validation catches structural errors</li> <li>[ ] Circular references detected and rejected</li> <li>[ ] Bad profiles fail gracefully with clear errors</li> <li>[ ] Original data always preserved through pipeline</li> <li>[ ] All transformations are reversible</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#accuracy","title":"Accuracy","text":"<ul> <li>[ ] Transformations are deterministic (same input \u2192 same output)</li> <li>[ ] No data loss through pipeline</li> <li>[ ] All intermediate results accessible for debugging</li> <li>[ ] Rollup calculations mathematically correct</li> <li>[ ] Split operations preserve totals</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#related-documents","title":"Related Documents","text":""},{"location":"planning/architecture/xbrl-standardization-pipeline/#research-analysis","title":"Research &amp; Analysis","text":"<ul> <li>CSV Analysis: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code></li> <li>mpreiss9's 6,177 production mappings analyzed</li> <li>\"Detailed\" profile example</li> <li> <p>Two reasons for mapping (standardization + consolidation)</p> </li> <li> <p>Comparison Research: <code>docs-internal/research/issues/issue-494-standardization-comparison.md</code></p> </li> <li>EdgarTools vs mpreiss9 approach comparison</li> <li>Hybrid architecture recommendation</li> <li>Context-aware resolution analysis</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#planning-roadmap","title":"Planning &amp; Roadmap","text":"<ul> <li>Enhancement Roadmap: <code>docs-internal/planning/future-enhancements/context-aware-standardization.md</code></li> <li>Full implementation roadmap (Phases 1-6)</li> <li>Timeline and effort estimates</li> <li>Stage 4 (Granularity) and Stage 5 (Context-Aware) details</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#implementation","title":"Implementation","text":"<ul> <li>Issue Tracking: GitHub Issue #494</li> <li>Test Data: <code>data/xbrl-mappings/*.csv</code> (mpreiss9's production data)</li> </ul>"},{"location":"planning/architecture/xbrl-standardization-pipeline/#conclusion","title":"Conclusion","text":"<p>This architecture provides:</p> <ol> <li>Clear separation between EdgarTools (infrastructure) and users (business logic)</li> <li>Flexible granularity through declarative profiles</li> <li>Composable transformations that chain cleanly</li> <li>Robust boundaries that prevent coupling to user workflows</li> <li>Simple defaults with power features for advanced users</li> </ol> <p>Key Insight: EdgarTools provides the transformation engine, users provide the transformation rules (as data, not code).</p> <p>This keeps EdgarTools focused on what it does best (XBRL parsing and statement building) while giving users full control over analytical perspective through simple, declarative configuration.</p> <p>Document Status: Proposed Architecture Last Updated: 2025-11-22 Author: EdgarTools Development Team Based on: mpreiss9's methodology and community feedback</p>"},{"location":"planning/future-enhancements/context-aware-standardization/","title":"Future Enhancement: Context-Aware XBRL Standardization","text":"<p>Status: Proposed Proposed Versions: v4.30.0 - v5.1.0 (Multi-release) Effort Estimate: Large (8-12 weeks across multiple releases) Priority: P2 (Medium) - Enhances accuracy, benefits advanced users GitHub Issue: #494 Architecture: <code>docs-internal/planning/architecture/xbrl-standardization-pipeline.md</code> Research: <code>docs-internal/research/issues/issue-494-standardization-comparison.md</code></p>"},{"location":"planning/future-enhancements/context-aware-standardization/#executive-summary","title":"Executive Summary","text":"<p>EdgarTools currently cannot handle 200+ ambiguous XBRL tags that require context to disambiguate (e.g., <code>DeferredTaxAssetsLiabilitiesNet</code> could be an asset OR liability depending on where it appears in the balance sheet).</p> <p>This proposal outlines a hybrid approach that combines EdgarTools' simplicity with context-aware resolution for ambiguous tags, inspired by @mpreiss9's proven methodology managing 390+ companies.</p> <p>Key Principles: 1. Maintain simplicity for 95% of tags, add sophistication for 5% of edge cases 2. Support flexible granularity - Users have different analytical needs (detailed vs. summarized) 3. Pipeline architecture - See full 7-stage pipeline in architecture document</p> <p>Available Data: mpreiss9 has shared production CSV mapping files containing 6,177 mappings (2,343 GAAP + 3,834 custom across 390 companies) which provide real-world validation data. See: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code></p> <p>Critical Insight from mpreiss9: There are two reasons for mapping: 1. Standardization (Stage 3): Same facts coded differently (e.g., countless revenue tag flavors) 2. Consolidation (Stage 4): Different facts combined when distinction is immaterial to the user</p> <p>This means the mapping system must be flexible - different users need different granularity levels.</p> <p>Architecture: This enhancement integrates with the XBRL processing pipeline as: - Stage 3: Base Standardization (existing - Phase 1-2) - Stage 4: Granularity Transformation (new - Phase 6) - Stage 5: Context-Aware Resolution (new - Phases 3-4)</p> <p>See: <code>docs-internal/planning/architecture/xbrl-standardization-pipeline.md</code> for complete pipeline design.</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#problem-statement","title":"Problem Statement","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#current-limitations","title":"Current Limitations","text":"<p>EdgarTools Standardization Today: - Forward mapping: <code>StandardConcept \u2192 [CompanyConcepts]</code> - Priority-based resolution works well for unambiguous tags - Context parameter exists but is completely ignored during mapping - Cannot distinguish between:   - <code>DeferredTaxAssetsLiabilitiesNet</code> as asset vs liability   - <code>AccountsPayableCurrentAndNoncurrent</code> as current vs noncurrent   - <code>DerivativeLiabilityFairValueGrossAsset</code> (3-way ambiguous)</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#user-impact","title":"User Impact","text":"<p>For Basic Users (95% of use cases): - No impact - current system works well</p> <p>For Advanced Users (5% of use cases): - Cannot reliably map 200+ ambiguous tags - Manual intervention required - Statement validation difficult - Mapping coverage incomplete</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#the-200-ambiguous-tags","title":"The 200+ Ambiguous Tags","text":"<p>Identified by @mpreiss9 in Issue #494:</p> <p>Asset/Liability Ambiguity (12 tags): - <code>DeferredTaxAssetsLiabilitiesNet</code> - Sign-dependent - <code>DerivativeAssetsLiabilitiesAtFairValueNet</code> - Net position - <code>UnamortizedDebtIssuanceExpense</code> - Asset or liability offset</p> <p>Current/Noncurrent Ambiguity (180+ tags): - <code>AccountsPayableCurrentAndNoncurrent</code> - Section-dependent - <code>DeferredRevenue</code> - Unspecified duration - <code>ConvertibleDebt</code> - Short-term or long-term</p> <p>Triple Ambiguity (1 tag): - <code>DerivativeLiabilityFairValueGrossAsset</code> - 3 dimensions of ambiguity</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#proposed-solution","title":"Proposed Solution","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#hybrid-approach","title":"Hybrid Approach","text":"<p>Keep Current System for non-ambiguous tags (fast, simple) Add Context-Aware Resolution for ambiguous tags (accurate, sophisticated)</p> <pre><code>def get_standard_concept(self, company_concept: str, context: Dict = None) -&gt; Optional[str]:\n    \"\"\"Enhanced mapping with optional context-aware disambiguation.\"\"\"\n\n    # Step 1: Check if this is a known ambiguous tag\n    if company_concept in AMBIGUOUS_TAGS:\n        # Use context-aware resolution (mpreiss9's method)\n        return self._resolve_ambiguous_tag(company_concept, context)\n\n    # Step 2: Standard priority-based resolution (EdgarTools current method)\n    return self._priority_based_resolution(company_concept)\n</code></pre>"},{"location":"planning/future-enhancements/context-aware-standardization/#key-innovations-from-mpreiss9s-approach","title":"Key Innovations from mpreiss9's Approach","text":"<ol> <li>Reverse mapping structure - O(1) hash lookup instead of O(n\u00d7m) iteration</li> <li>Section-based resolution - Uses balance sheet sections to disambiguate</li> <li>Backwards processing - Process bottom-to-top; subtotals mark section boundaries</li> <li>Balance sheet validation - Assets = Liabilities + Equity triggers mapping corrections</li> <li>Unmapped tag logging - CSV logs with suggested mappings for continuous improvement</li> <li>Enhanced context - Include parent concept, section, sign, value</li> <li>CSV workflow - Excel-friendly for managing large mapping sets</li> </ol>"},{"location":"planning/future-enhancements/context-aware-standardization/#implementation-phases","title":"Implementation Phases","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#phase-1-validation-foundation-v4300-or-v4310","title":"Phase 1: Validation Foundation (v4.30.0 or v4.31.0)","text":"<p>Goal: Add balance sheet validation without changing mapping logic</p> <p>Effort: 1-2 weeks | Risk: Low | Value: High</p> <p>Available Test Data: mpreiss9's CSV mappings (6,177 mappings from 390 companies) in <code>data/xbrl-mappings/</code></p> <p>Changes:</p> <ol> <li> <p>New Module: <code>edgar/xbrl/validation.py</code> <code>python    def validate_balance_sheet(statement_data):        \"\"\"Validate accounting equation: Assets = Liabilities + Equity\"\"\"        # Level 1: Fundamental equation        # Level 2: Section totals        # Level 3: Detail rollup</code></p> </li> <li> <p>Statement Integration: Add optional <code>validate=True</code> parameter    <code>python    statement = xbrl.statements.balance_sheet(validate=True)    # Returns ValidationResult with warnings/errors</code></p> </li> <li> <p>Validation Report:    <code>python    ValidationResult(        is_valid: bool,        errors: List[ValidationError],        warnings: List[ValidationWarning],        checks_performed: List[str]    )</code></p> </li> </ol> <p>Benefits: - High value for all users (catches data quality issues) - Low risk (no changes to mapping logic) - Foundation for future enhancements - Opt-in feature</p> <p>Tests Required: - Balance sheet equation validation - Section total validation - Detail rollup validation - Edge cases (missing sections, rounding)</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#phase-2-section-membership-dictionary-v4300","title":"Phase 2: Section Membership Dictionary (v4.30.0)","text":"<p>Goal: Define which standard concepts belong in which sections</p> <p>Effort: 1 week | Risk: Low | Value: Medium</p> <p>Changes:</p> <ol> <li> <p>New Data Structure: <code>edgar/xbrl/standardization/section_membership.json</code> <code>json    {      \"Balance Sheet\": {        \"Current Assets\": [          \"Cash and Cash Equivalents\",          \"Accounts Receivable\",          \"Inventory\",          \"Prepaid Expenses\",          \"Deferred Tax Assets\"        ],        \"Current Liabilities\": [          \"Accounts Payable, Current\",          \"Accrued Liabilities\",          \"Short Term Debt\",          \"Deferred Tax Liabilities\"        ],        ...      },      \"Income Statement\": {        \"Revenue\": [...],        \"Operating Expenses\": [...],        ...      }    }</code></p> </li> <li> <p>Section Lookup API:    <code>python    def get_section_for_concept(standard_concept: str, statement_type: str) -&gt; Optional[str]:        \"\"\"Get the section a standard concept belongs to\"\"\"</code></p> </li> </ol> <p>Benefits: - Documents standard concept organization - Enables section-based disambiguation - Foundation for context-aware resolution - Useful reference for users</p> <p>Tests Required: - Section membership completeness - No duplicate memberships - All standard concepts mapped</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#phase-3-enhanced-context-threading-v4310","title":"Phase 3: Enhanced Context Threading (v4.31.0)","text":"<p>Goal: Thread calculation parent through to standardization layer</p> <p>Effort: 2-3 weeks | Risk: Medium | Value: High (enables Phase 4)</p> <p>Changes:</p> <ol> <li>XBRL Parser Enhancement: <code>edgar/xbrl/xbrl.py</code></li> <li>Extract calculation parent from calculation trees</li> <li> <p>Include in line item data</p> </li> <li> <p>Statement Builder: <code>edgar/xbrl/statements.py</code></p> </li> <li>Pass calculation parent to standardization</li> <li> <p>Add section assignment (backwards processing)</p> </li> <li> <p>Enhanced Context:    <code>python    context = {        \"statement_type\": \"BalanceSheet\",        \"level\": 1,        \"is_total\": False,        \"calculation_parent\": \"us-gaap:AssetsCurrent\",  # NEW        \"parent_standard_concept\": \"Total Current Assets\",  # NEW        \"section\": \"Current Assets\",  # NEW (derived)        \"fact_value\": 150000000,  # NEW (for sign-based)        \"label\": \"Deferred Tax\"  # NEW (already available)    }</code></p> </li> <li> <p>Backwards Section Assignment:    <code>python    def assign_sections_backwards(line_items):        \"\"\"Process bottom-to-top: subtotals mark section boundaries\"\"\"        current_section = None        for item in reversed(line_items):            if item.is_total and item.level == 1:                current_section = item.standard_label            item.section = current_section</code></p> </li> </ol> <p>Benefits: - Enables context-aware disambiguation - Improves statement structure understanding - Foundation for advanced features</p> <p>Tests Required: - Calculation parent extraction - Section assignment correctness - Backwards processing logic - Context threading end-to-end</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#phase-4-context-aware-disambiguation-v4310-v500","title":"Phase 4: Context-Aware Disambiguation (v4.31.0 - v5.0.0)","text":"<p>Goal: Use context to resolve ambiguous tags</p> <p>Effort: 3-4 weeks | Risk: Medium-High | Value: High</p> <p>Changes:</p> <ol> <li> <p>Ambiguous Tag Registry: <code>edgar/xbrl/standardization/ambiguous_tags.json</code> <code>json    {      \"us-gaap:DeferredTaxAssetsLiabilitiesNet\": {        \"candidates\": [          \"Deferred Tax Assets\",          \"Deferred Tax Liabilities\"        ],        \"resolution_strategy\": \"section_membership\",        \"notes\": \"Depends on where it appears in balance sheet\"      }    }</code></p> </li> <li> <p>Reverse Mapping Store: <code>edgar/xbrl/standardization/reverse_mappings.py</code>    ```python    class ReverseMappingStore:        \"\"\"For ambiguous tags: CompanyConcept \u2192 [StandardConcepts]\"\"\"</p> <p>def get_candidates(self, company_concept: str) -&gt; List[str]:        \"\"\"Get all possible standard concepts for ambiguous tag\"\"\"    ```</p> </li> <li> <p>Disambiguation Logic: <code>edgar/xbrl/standardization/core.py</code>    ```python    def _resolve_ambiguous_tag(self, company_concept: str, context: Dict) -&gt; Optional[str]:        \"\"\"Use section membership to resolve ambiguity\"\"\"        candidates = self.reverse_mappings.get_candidates(company_concept)</p> <p>if not context or len(candidates) &lt;= 1:        return candidates[0] if candidates else None</p> <p># Determine section from context    section = self._determine_section(context)</p> <p># Find which candidate belongs in this section    for std_concept in candidates:        if std_concept in self.section_membership.get(section, set()):            return std_concept</p> <p># Log for manual review if ambiguous    self.unmapped_logger.log_ambiguous(company_concept, context, candidates)    return None    ```</p> </li> <li> <p>Special Case Handling:    <code>python    def _resolve_noncurrent_liabilities_special_case(self, item, context):        \"\"\"Handle tags used as both line item and total\"\"\"        # Check label for clues        if \"Other\" in item.label:            return \"Other Noncurrent Liabilities\"        elif \"Total\" in item.label:            return \"Total Noncurrent Liabilities\"        else:            # Check if value matches calculation            if self._matches_calculation(item, \"TotalLiabilities - CurrentLiabilities\"):                return \"Total Noncurrent Liabilities\"            return \"Other Noncurrent Liabilities\"</code></p> </li> </ol> <p>Benefits: - Handles 200+ ambiguous tags correctly - Maintains simplicity for non-ambiguous cases - Opt-in via ambiguous tag registry - Extensible for user-defined ambiguous tags</p> <p>Tests Required: - 12 asset/liability tags - Special case handling (Noncurrent Liabilities) - Section-based resolution - Fallback behavior - Performance benchmarks</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#phase-5-unmapped-tag-logging-v500","title":"Phase 5: Unmapped Tag Logging (v5.0.0)","text":"<p>Goal: CSV-based workflow for continuous mapping improvement</p> <p>Effort: 1-2 weeks | Risk: Low | Value: Medium</p> <p>Changes:</p> <ol> <li> <p>Unmapped Tag Logger: <code>edgar/xbrl/standardization/unmapped_logger.py</code>    ```python    class UnmappedTagLogger:        \"\"\"Log unmapped and ambiguous tags for review\"\"\"</p> <p>def log_unmapped(self, company_concept, label, context, suggested_mapping=None):        \"\"\"Log tag with suggested mapping and confidence\"\"\"</p> <p>def log_ambiguous(self, company_concept, context, candidates):        \"\"\"Log ambiguous resolution for review\"\"\"</p> <p>def save_to_csv(self, output_path):        \"\"\"Export logs in Excel-friendly CSV format\"\"\"    ```</p> </li> <li> <p>CSV Format:    <code>csv    company_concept,suggested_mapping,confidence,label,cik,statement_type,parent_concept,section,notes    us-gaap:NewConcept,Revenue,0.85,Total Revenue,1318605,Income,RevenueFromContractWithCustomer,Revenue,Review: high confidence    us-gaap:AmbiguousTag,Deferred Tax Assets,0.50,Deferred Tax,320193,Balance,AssetsCurrent,Current Assets,Ambiguous: review context</code></p> </li> <li> <p>Integration Points:</p> </li> <li>Call during statement processing when mapping returns None</li> <li>Optional output path configuration</li> <li>Batch export for multiple filings</li> </ol> <p>Benefits: - Excel-friendly workflow - Accelerates mapping coverage - Continuous improvement process - User feedback loop</p> <p>Tests Required: - CSV export format - Suggested mapping inference - Confidence calculation - Batch processing</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#phase-6-user-configurable-granularity-v510-or-later","title":"Phase 6: User-Configurable Granularity (v5.1.0 or later)","text":"<p>Pipeline Integration: This implements Stage 4: Granularity Transformation from the architecture</p> <p>Goal: Support different detail levels for different user needs</p> <p>Effort: 2-3 weeks | Risk: Medium | Value: High (different user personas)</p> <p>Motivation (from mpreiss9):</p> <p>\"There are really two reasons to map an xbrl tag to a standard tag. The first reason is to take what is exactly the same kind of fact coded different ways into a common tag (for example the seemingly countless revenue tag flavors). The second reason is often overlooked but very important - a user may want to consolidate multiple kinds of facts into a single concept because the distinction is immaterial to them.\"</p> <p>Changes:</p> <ol> <li>Granularity Profiles: <code>edgar/xbrl/standardization/profiles/</code>    ```python    # detailed.json - Maximum granularity (like mpreiss9's mappings)    {      \"us-gaap:TaxLiabilities\": \"Tax Liabilities\",      \"us-gaap:RetirementLiabilities\": \"Retirement Liabilities\",      \"us-gaap:OtherNonOperatingLiab\": \"Other Non-Operating Liabilities\"    }</li> </ol> <p># summarized.json - Consolidated for overview analysis    {      \"us-gaap:TaxLiabilities\": \"Non-Operating Liabilities\",      \"us-gaap:RetirementLiabilities\": \"Non-Operating Liabilities\",      \"us-gaap:OtherNonOperatingLiab\": \"Non-Operating Liabilities\"    }    ```</p> <ol> <li>Granularity Parameter (matches architecture):    ```python    # Level 1: Choose a profile (simple)    statement = xbrl.statements.balance_sheet(granularity='detailed')  # Max detail    statement = xbrl.statements.balance_sheet(granularity='standard')  # Default    statement = xbrl.statements.balance_sheet(granularity='summarized')  # High-level</li> </ol> <p># Level 2: Custom profile file (advanced)    from edgar.xbrl.standardization import Profile    profile = Profile.from_csv('my_mappings.csv')    statement = xbrl.statements.balance_sheet().with_profile(profile)</p> <p># Composable transformations (immutable)    custom = (statement        .with_granularity('detailed')        .with_profile('my_rollups.json'))    ```</p> <ol> <li> <p>Hierarchical Mapping Support:    <code>python    # Define parent-child relationships    {      \"Non-Operating Liabilities\": {        \"children\": [\"Tax Liabilities\", \"Retirement Liabilities\", \"Other Non-Operating Liabilities\"],        \"allow_rollup\": true,        \"allow_drilldown\": true      }    }</code></p> </li> <li> <p>Use Case Templates:</p> </li> <li>Financial Analyst: Detailed breakdowns for valuation</li> <li>Academic Researcher: Balanced detail for studies</li> <li>Casual User: High-level summaries for quick insights</li> <li>Custom: User-defined mappings</li> </ol> <p>Benefits: - Same data, different analytical perspectives - Users get exactly the granularity they need - No \"one size fits all\" constraint - Preserves simplicity (default still works)</p> <p>Tests Required: - Profile switching - Hierarchical rollup/drilldown - Custom mapping loading - Backwards compatibility with default profile</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#success-criteria","title":"Success Criteria","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>[ ] 12 asset/liability ambiguous tags handled correctly</li> <li>[ ] Balance sheet validation available (opt-in)</li> <li>[ ] Section-based resolution working</li> <li>[ ] Unmapped tag logging functional</li> <li>[ ] Context threading complete</li> <li>[ ] Backwards processing implemented</li> <li>[ ] User-configurable granularity (profiles: detailed, standard, summarized)</li> <li>[ ] Hierarchical mapping support (rollup/drilldown)</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#quality-requirements","title":"Quality Requirements","text":"<ul> <li>[ ] No regression in current functionality</li> <li>[ ] Test coverage &gt;90% for new code</li> <li>[ ] Documentation complete (API docs + user guide)</li> <li>[ ] Examples provided for all new features</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#performance-requirements","title":"Performance Requirements","text":"<ul> <li>[ ] Performance within 10% of baseline for non-ambiguous tags</li> <li>[ ] Context-aware resolution &lt;50ms per tag</li> <li>[ ] Validation overhead &lt;5% of statement processing time</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#user-experience-requirements","title":"User Experience Requirements","text":"<ul> <li>[ ] Opt-in features with sensible defaults</li> <li>[ ] Clear error messages for ambiguous cases</li> <li>[ ] Rich output for validation results</li> <li>[ ] CSV workflow user-friendly</li> <li>[ ] Simple granularity selection (detailed/standard/summarized)</li> <li>[ ] Easy custom mapping file loading</li> <li>[ ] Documentation explaining when to use which granularity</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#implementation-considerations","title":"Implementation Considerations","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#dependencies","title":"Dependencies","text":"<p>Existing: - \u2705 XBRL calculation tree parsing - \u2705 Statement type detection - \u2705 Fact value access - \u2705 Presentation tree traversal</p> <p>New: - \u2b1c Section membership definitions - \u2b1c Ambiguous tag registry - \u2b1c Reverse mapping structure - \u2b1c Backwards processing algorithm</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#backwards-compatibility","title":"Backwards Compatibility","text":"<p>Approach: All enhancements are opt-in with backwards-compatible defaults</p> <ol> <li>Validation: <code>validate=False</code> by default</li> <li>Context-aware resolution: Only for tags in ambiguous registry</li> <li>Unmapped logging: Explicit configuration required</li> <li>Existing mappings: Continue to work unchanged</li> </ol>"},{"location":"planning/future-enhancements/context-aware-standardization/#migration-path","title":"Migration Path","text":"<p>Phase 1-2: No migration needed (additive only) Phase 3: Transparent (context automatically threaded) Phase 4: Opt-in via ambiguous tag registry Phase 5: Explicit configuration</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#api-design","title":"API Design","text":"<p>Maintain EdgarTools Principles: - Simple defaults that \"just work\" - Power features for advanced users - Clear errors with actionable messages - Rich output with beautiful formatting - Beginner-friendly documentation</p> <p>Flexible Granularity Examples:</p> <pre><code># Simple: Default granularity (balanced detail)\nstatement = company.financials.balance_sheet\n\n# Power user: Choose detail level\nstatement = company.financials.balance_sheet.detailed()      # Max detail\nstatement = company.financials.balance_sheet.summarized()    # High-level\n\n# Advanced: Custom mapping\nfrom edgar.xbrl.standardization import StandardizationProfile\nprofile = StandardizationProfile.from_csv('my_mappings.csv')\nstatement = company.financials.balance_sheet.with_profile(profile)\n\n# Compare granularities\ndetailed = company.financials.balance_sheet.detailed()\nsummarized = company.financials.balance_sheet.summarized()\nprint(f\"Detailed: {len(detailed.line_items)} items\")  # e.g., 45 items\nprint(f\"Summarized: {len(summarized.line_items)} items\")  # e.g., 15 items\n</code></pre>"},{"location":"planning/future-enhancements/context-aware-standardization/#risks-and-mitigation","title":"Risks and Mitigation","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#risk-1-breaking-existing-behavior","title":"Risk 1: Breaking Existing Behavior","text":"<p>Risk: Context-aware resolution changes existing mappings Likelihood: Medium | Impact: High</p> <p>Mitigation: - Only apply to tags explicitly registered as ambiguous - Extensive regression testing - Beta testing with community - Feature flag for experimental mode - Clear migration documentation</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#risk-2-performance-degradation","title":"Risk 2: Performance Degradation","text":"<p>Risk: Context threading and resolution slow down statement processing Likelihood: Low | Impact: Medium</p> <p>Mitigation: - Benchmark at each phase - Only enable for ambiguous tags - Aggressive caching - Performance tests in CI - Optimization before release</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#risk-3-increased-complexity","title":"Risk 3: Increased Complexity","text":"<p>Risk: Additional features make system harder to understand Likelihood: Medium | Impact: Medium</p> <p>Mitigation: - Maintain simple defaults - Comprehensive documentation - Clear examples for each feature - Gradual rollout across releases - Community feedback incorporation</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#risk-4-incomplete-ambiguous-tag-coverage","title":"Risk 4: Incomplete Ambiguous Tag Coverage","text":"<p>Risk: Registry doesn't cover all ambiguous cases Likelihood: High | Impact: Low</p> <p>Mitigation: - Start with 12 well-known tags - Iterative expansion based on feedback - User-extensible registry - Unmapped tag logging identifies gaps - Community contribution process</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#community-feedback","title":"Community Feedback","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#open-questions","title":"Open Questions","text":"<ol> <li>Priority: Which is higher priority - validation or disambiguation?</li> <li>Opt-in vs Opt-out: Should features be opt-in or opt-out?</li> <li>Performance: What's acceptable performance impact?</li> <li>CSV Workflow: How important is Excel-friendly CSV support?</li> <li>Scope: Start with 12 tags or all 200+?</li> </ol>"},{"location":"planning/future-enhancements/context-aware-standardization/#community-involvement","title":"Community Involvement","text":"<p>Soliciting Input From: - @mpreiss9 - Real-world experience with 200+ companies - Advanced users - Production use cases and priorities - Beginners - Ensure simplicity not compromised - Contributors - Implementation approach feedback</p> <p>Engagement Channels: - GitHub Issue #494 comments - GitHub Discussion (if created) - Pull request reviews - Beta testing program</p>"},{"location":"planning/future-enhancements/context-aware-standardization/#success-metrics","title":"Success Metrics","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#adoption-metrics","title":"Adoption Metrics","text":"<ul> <li>Number of users enabling validation</li> <li>Number of ambiguous tags in registry</li> <li>Number of CSV logs exported</li> <li>Community contributions to registry</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#quality-metrics","title":"Quality Metrics","text":"<ul> <li>Reduction in unmapped tag issues</li> <li>Balance sheet validation success rate</li> <li>Ambiguous tag resolution accuracy</li> <li>User satisfaction (surveys/feedback)</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>Statement processing time (baseline vs enhanced)</li> <li>Context resolution overhead</li> <li>Cache hit rate</li> <li>Memory usage</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#timeline-and-milestones","title":"Timeline and Milestones","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#q1-2025-v4300-or-v4310","title":"Q1 2025 (v4.30.0 or v4.31.0)","text":"<ul> <li>[ ] Phase 1: Validation Foundation (2 weeks)</li> <li>[ ] Phase 2: Section Membership (1 week)</li> <li>[ ] Testing and documentation (1 week)</li> <li>Release: v4.30.0/v4.31.0 with validation and section definitions</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#q2-2025-v4310-or-v4320","title":"Q2 2025 (v4.31.0 or v4.32.0)","text":"<ul> <li>[ ] Phase 3: Enhanced Context Threading (3 weeks)</li> <li>[ ] Phase 4: Context-Aware Disambiguation (4 weeks)</li> <li>[ ] Testing and documentation (2 weeks)</li> <li>[ ] Beta testing period (2 weeks)</li> <li>Release: v4.31.0/v4.32.0 with context-aware resolution</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#q3-2025-v500","title":"Q3 2025 (v5.0.0)","text":"<ul> <li>[ ] Phase 5: Unmapped Tag Logging (2 weeks)</li> <li>[ ] Polish and optimization (2 weeks)</li> <li>[ ] Final testing and documentation (2 weeks)</li> <li>[ ] Community feedback incorporation (2 weeks)</li> <li>Release: v5.0.0 with complete enhancement suite</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#q4-2025-v510","title":"Q4 2025 (v5.1.0)","text":"<ul> <li>[ ] Phase 6: User-Configurable Granularity (3 weeks)</li> <li>[ ] Granularity profile creation (detailed, standard, summarized)</li> <li>[ ] Hierarchical mapping support</li> <li>[ ] API design and implementation</li> <li>[ ] Testing with different user personas</li> <li>[ ] Documentation with use case examples</li> <li>Release: v5.1.0 with flexible granularity support</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#references","title":"References","text":""},{"location":"planning/future-enhancements/context-aware-standardization/#research-and-documentation","title":"Research and Documentation","text":"<ul> <li>Research Document: <code>docs-internal/research/issues/issue-494-standardization-comparison.md</code></li> <li>CSV Analysis: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code> (NEW - 2025-11-21)</li> <li>User Documentation: <code>docs/advanced/customizing-standardization.md</code></li> <li>Implementation Plan: <code>docs-internal/planning/active-tasks/2025-11-20-issue-494-research-completion.md</code></li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#github-resources","title":"GitHub Resources","text":"<ul> <li>Issue #494: https://github.com/dgunning/edgartools/issues/494</li> <li>Comment with 200+ tags: @mpreiss9's methodology explanation (2025-11-19)</li> <li>Research summary: Comment #3557758658 (2025-11-20)</li> <li>CSV Files: @mpreiss9's production mappings (2025-11-21) - 6,177 mappings from 390 companies</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#available-test-data","title":"Available Test Data","text":"<ul> <li>Location: <code>data/xbrl-mappings/</code> (not committed - contributed data)</li> <li>Files:</li> <li><code>gaap_taxonomy_mapping.csv</code> (2,343 standard GAAP mappings)</li> <li><code>custom_taxonomy_mapping.csv</code> (3,834 company-specific mappings, 390 CIKs)</li> <li>Analysis: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code></li> <li>Key Statistics:</li> <li>215 ambiguous tags (9.2% of total)</li> <li>202 Current/NonCurrent ambiguities (94% of ambiguous tags)</li> <li>276 tags marked \"DropThisItem\"</li> <li>129 unique standard tags used</li> <li>Colon separator format for multi-mapping (e.g., <code>TagA:TagB</code>)</li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#code-references","title":"Code References","text":"<ul> <li>Current Implementation: <code>edgar/xbrl/standardization/core.py</code></li> <li>Validation Hooks: <code>edgar/xbrl/parsers/concepts.py</code> (balance types)</li> <li>Statement Processing: <code>edgar/xbrl/statements.py</code>, <code>edgar/xbrl/rendering.py</code></li> </ul>"},{"location":"planning/future-enhancements/context-aware-standardization/#approval-and-sign-off","title":"Approval and Sign-off","text":"<p>Decision Makers: Project maintainers Stakeholders: @mpreiss9, advanced users, community Status: Proposed - Awaiting feedback and prioritization</p> <p>Next Steps: 1. Gather community feedback on GitHub Issue #494 2. Prioritize phases based on user needs 3. Create detailed implementation tasks in Beads 4. Begin Phase 1 development (if approved)</p> <p>Document Status: Draft for Review Last Updated: 2025-11-20 Author: Claude (based on @mpreiss9's methodology and research findings)</p>"},{"location":"product-management/github-issue-triage-framework/","title":"GitHub Issue Triage Framework for EdgarTools","text":""},{"location":"product-management/github-issue-triage-framework/#product-managers-systematic-approach-to-issue-management","title":"Product Manager's Systematic Approach to Issue Management","text":"<p>This framework provides a structured approach for Product Managers to triage, prioritize, and convert GitHub issues into actionable development tasks while maintaining alignment with EdgarTools' core product principles.</p>"},{"location":"product-management/github-issue-triage-framework/#core-product-principles-review","title":"Core Product Principles Review","text":"<p>Before analyzing any issue, ensure alignment with: - Simple yet powerful: Every feature must surprise users with elegance and ease of use - Accurate financials: Data reliability is non-negotiable - Beginner-friendly: Complexity must be hidden from new Python users - Joyful UX: Eliminate frustrations and deliver polished experience - Beautiful output: Leverage rich library for enhanced CLI display</p>"},{"location":"product-management/github-issue-triage-framework/#1-issue-classification-framework","title":"1. Issue Classification Framework","text":""},{"location":"product-management/github-issue-triage-framework/#primary-categories","title":"Primary Categories","text":""},{"location":"product-management/github-issue-triage-framework/#a-data-quality-issues-critical-priority","title":"A. Data Quality Issues (Critical Priority)","text":"<p>Indicators: Incorrect financial data, missing values, parsing errors Examples: #408 (Cash flow missing values), #395 (Missing numeric_value column), #400 (Filing lookup discrepancies) Impact: Direct threat to core principle of accurate financials Response Time: 24-48 hours PM Action: Immediate investigation, data integrity audit</p>"},{"location":"product-management/github-issue-triage-framework/#b-feature-requests-core-enhancement-high-priority","title":"B. Feature Requests - Core Enhancement (High Priority)","text":"<p>Indicators: Requests that extend existing functionality within current scope Examples: #418 (ETF Ticker Holdings), #417 (ETF Series Search) Impact: Adds power without complexity, expands market reach Response Time: 72 hours PM Action: Evaluate against product roadmap, assess technical feasibility</p>"},{"location":"product-management/github-issue-triage-framework/#c-user-experience-issues-high-priority","title":"C. User Experience Issues (High Priority)","text":"<p>Indicators: Confusion, unexpected behavior, poor documentation Examples: #381 (Local data not working as expected), #384 (User needs major help) Impact: Violates beginner-friendly and joyful UX principles Response Time: 48 hours PM Action: UX audit, documentation review, user journey analysis</p>"},{"location":"product-management/github-issue-triage-framework/#d-standardization-requests-medium-priority","title":"D. Standardization Requests (Medium Priority)","text":"<p>Indicators: Requests for consistent APIs, data formats, naming conventions Examples: #411 (Standardization) Impact: Improves elegance and ease of use Response Time: 1 week PM Action: Architecture review, breaking change assessment</p>"},{"location":"product-management/github-issue-triage-framework/#e-documentationsupport-requests-medium-priority","title":"E. Documentation/Support Requests (Medium Priority)","text":"<p>Indicators: How-to questions, unclear documentation Examples: #412 (How to get accurate/complete data) Impact: Affects beginner-friendliness Response Time: 48 hours PM Action: Documentation gap analysis, user education content</p>"},{"location":"product-management/github-issue-triage-framework/#f-technical-debt-low-priority","title":"F. Technical Debt (Low Priority)","text":"<p>Indicators: Performance, refactoring, internal improvements Examples: #387 (Chunked data) Impact: Long-term maintainability Response Time: 2 weeks PM Action: Technical debt prioritization matrix</p>"},{"location":"product-management/github-issue-triage-framework/#priority-matrix","title":"Priority Matrix","text":"Category Severity User Impact Development Effort Priority Score Data Quality - Critical 10 10 Variable 95-100 Data Quality - Major 8 9 Variable 85-90 UX - Blocking 7 10 Low-Med 80-85 Feature - High Value 6 8 High 75-80 Feature - Medium Value 5 6 Medium 60-70 Standardization 4 7 High 55-65 Documentation 3 8 Low 50-60 Technical Debt 2 3 Variable 30-50"},{"location":"product-management/github-issue-triage-framework/#2-pm-workflow-for-issue-processing","title":"2. PM Workflow for Issue Processing","text":""},{"location":"product-management/github-issue-triage-framework/#phase-1-initial-triage-within-24-hours","title":"Phase 1: Initial Triage (Within 24 hours)","text":"<ol> <li>Issue Classification</li> <li>Assign primary category using framework above</li> <li>Tag with appropriate labels (data-quality, feature-request, ux, etc.)</li> <li> <p>Assess severity level (critical, high, medium, low)</p> </li> <li> <p>Impact Assessment</p> </li> <li>User impact: How many users affected?</li> <li>Product principle alignment: Which principles are impacted?</li> <li>Technical complexity: Initial estimate (low/medium/high)</li> <li> <p>Breaking change risk: Does this require API changes?</p> </li> <li> <p>Stakeholder Assignment</p> </li> <li>Data Quality: Assign to technical lead + PM</li> <li>Feature Requests: PM + relevant domain expert</li> <li>UX Issues: PM + documentation team</li> <li>Support: Community manager + PM for escalation</li> </ol>"},{"location":"product-management/github-issue-triage-framework/#phase-2-deep-analysis-within-72-hours","title":"Phase 2: Deep Analysis (Within 72 hours)","text":"<ol> <li>Requirements Gathering</li> <li>User story creation: \"As a [user type], I want [goal] so that [benefit]\"</li> <li>Acceptance criteria definition</li> <li>Edge case identification</li> <li> <p>Success metrics definition</p> </li> <li> <p>Technical Feasibility</p> </li> <li>Architecture impact assessment</li> <li>Integration complexity review</li> <li>Performance implications</li> <li> <p>Testing requirements</p> </li> <li> <p>Strategic Alignment</p> </li> <li>Roadmap fit assessment</li> <li>Resource allocation impact</li> <li>Competitive advantage evaluation</li> <li>User segment analysis</li> </ol>"},{"location":"product-management/github-issue-triage-framework/#phase-3-decision-planning-within-1-week","title":"Phase 3: Decision &amp; Planning (Within 1 week)","text":"<ol> <li>Go/No-Go Decision</li> <li>Product fit score (1-10)</li> <li>Development effort estimate</li> <li>ROI calculation</li> <li> <p>Risk assessment</p> </li> <li> <p>Task Breakdown (If approved)</p> </li> <li>Epic creation with user stories</li> <li>Technical tasks identification</li> <li>Testing strategy definition</li> <li> <p>Documentation requirements</p> </li> <li> <p>Sprint Planning Integration</p> </li> <li>Sprint assignment</li> <li>Dependency mapping</li> <li>Resource allocation</li> <li>Timeline estimation</li> </ol>"},{"location":"product-management/github-issue-triage-framework/#3-current-issues-analysis","title":"3. Current Issues Analysis","text":""},{"location":"product-management/github-issue-triage-framework/#immediate-action-required-critical","title":"Immediate Action Required (Critical)","text":"<p>#408: Cash flow statement missing values - Category: Data Quality - Critical - Priority Score: 100 - Action: Emergency data integrity audit - Timeline: 24 hours for initial assessment</p> <p>#395: CashFlowStatement missing numeric_value column - Category: Data Quality - Critical - Priority Score: 95 - Action: XBRL parsing investigation - Timeline: 48 hours for fix</p> <p>#400: Filing lookup discrepancies - Category: Data Quality - Major - Priority Score: 90 - Action: Filing retrieval consistency audit - Timeline: 72 hours for root cause analysis</p>"},{"location":"product-management/github-issue-triage-framework/#high-priority-development","title":"High Priority Development","text":"<p>#418: ETF Ticker Holdings Feature - Category: Feature Request - Core Enhancement - Priority Score: 80 - Analysis: Aligns with fund analysis capabilities, extends market reach - Requirements: ETF holdings extraction from 13F filings - Technical Impact: Extends existing fund analysis framework - Timeline: 2-3 sprints</p> <p>#417: ETF Series Search - Category: Feature Request - Core Enhancement - Priority Score: 75 - Analysis: Complements #418, improves fund discovery - Requirements: Series-level ETF search functionality - Dependencies: May depend on #418 implementation - Timeline: 1-2 sprints after #418</p>"},{"location":"product-management/github-issue-triage-framework/#user-experience-issues","title":"User Experience Issues","text":"<p>#384: User needs major help - Category: UX - Support Escalation - Priority Score: 85 - Action: Immediate user outreach, documentation audit - Root Cause: Likely documentation gaps or API complexity - Timeline: 48 hours for user resolution, 1 week for systemic fixes</p> <p>#381: Local data doesn't work as expected - Category: UX - Functional Issue - Priority Score: 80 - Action: Local data workflow review - Impact: Affects offline usage scenarios - Timeline: 1 sprint for investigation and fix</p>"},{"location":"product-management/github-issue-triage-framework/#medium-priority-items","title":"Medium Priority Items","text":"<p>#411: Standardization - Category: Standardization Request - Priority Score: 65 - Analysis: Broad request requiring detailed requirements gathering - Action: User interview to understand specific needs - Timeline: Requirements gathering phase - 2 weeks</p> <p>#412: How to get accurate/complete data - Category: Documentation/Education - Priority Score: 60 - Action: Create comprehensive data accuracy guide - Timeline: 1 sprint for documentation update</p> <p>#387: Chunked data - Category: Technical Enhancement - Priority Score: 45 - Analysis: Performance optimization opportunity - Timeline: Technical debt backlog</p>"},{"location":"product-management/github-issue-triage-framework/#4-integration-with-task-planning-framework","title":"4. Integration with Task Planning Framework","text":""},{"location":"product-management/github-issue-triage-framework/#task-conversion-process","title":"Task Conversion Process","text":"<ol> <li>Epic Creation</li> <li>GitHub issue becomes Epic in task planning system</li> <li>User stories derived from acceptance criteria</li> <li> <p>Technical tasks identified during planning</p> </li> <li> <p>Sprint Integration</p> </li> <li>Tasks distributed across sprints based on priority</li> <li>Dependencies mapped in task planning tool</li> <li> <p>Progress tracked against original GitHub issue</p> </li> <li> <p>Success Metrics Tracking</p> </li> <li>Issue resolution time by category</li> <li>User satisfaction scores</li> <li>Feature adoption rates</li> <li>Data quality improvement metrics</li> </ol>"},{"location":"product-management/github-issue-triage-framework/#template-structures","title":"Template Structures","text":""},{"location":"product-management/github-issue-triage-framework/#data-quality-issue-template","title":"Data Quality Issue Template","text":"<pre><code>## Issue Analysis\n- Data accuracy impact: [High/Medium/Low]\n- Affected components: [List]\n- User segments impacted: [Segments]\n\n## Investigation Plan\n- [ ] Reproduce issue\n- [ ] Root cause analysis\n- [ ] Data integrity audit\n- [ ] Fix implementation\n- [ ] Testing strategy\n- [ ] User communication plan\n\n## Success Criteria\n- Data accuracy restored\n- Regression tests added\n- Documentation updated\n</code></pre>"},{"location":"product-management/github-issue-triage-framework/#feature-request-template","title":"Feature Request Template","text":"<pre><code>## Product Fit Analysis\n- Product principle alignment: [Score 1-10]\n- User segment: [Primary/Secondary]\n- Market opportunity: [Assessment]\n\n## Implementation Plan\n- [ ] Requirements gathering\n- [ ] Technical design\n- [ ] API design review\n- [ ] Implementation\n- [ ] Testing\n- [ ] Documentation\n- [ ] User feedback collection\n\n## Success Metrics\n- Feature adoption rate target: [X%]\n- User satisfaction score: [X/10]\n- Performance impact: [Acceptable limits]\n</code></pre>"},{"location":"product-management/github-issue-triage-framework/#5-community-communication-strategy","title":"5. Community Communication Strategy","text":""},{"location":"product-management/github-issue-triage-framework/#response-templates-by-category","title":"Response Templates by Category","text":""},{"location":"product-management/github-issue-triage-framework/#data-quality-issues","title":"Data Quality Issues","text":"<pre><code>Thank you for reporting this data quality issue. EdgarTools prioritizes data accuracy above all else.\n\n**Immediate Actions:**\n- Issue escalated to our data quality team\n- Investigation underway\n- Timeline: [X] hours for initial assessment\n\n**What to Expect:**\n1. Root cause analysis within [X] hours\n2. Fix implementation and testing\n3. Release with regression prevention\n4. Follow-up to ensure resolution\n\n**Tracking:** This issue has been added to our data quality dashboard.\n</code></pre>"},{"location":"product-management/github-issue-triage-framework/#feature-requests","title":"Feature Requests","text":"<pre><code>Thank you for this feature suggestion! We appreciate community input on EdgarTools evolution.\n\n**Evaluation Process:**\n- Product fit assessment: [In Progress/Complete]\n- Technical feasibility review: [Status]\n- Roadmap integration: [Timeline]\n\n**Decision Criteria:**\nOur evaluation considers user impact, technical complexity, and alignment with our core mission of making SEC data accessible to Python developers of all skill levels.\n\n**Next Steps:**\nWe'll update this issue within [X] days with our assessment and planned timeline.\n</code></pre>"},{"location":"product-management/github-issue-triage-framework/#user-support-issues","title":"User Support Issues","text":"<pre><code>We're here to help! EdgarTools should be intuitive and joyful to use.\n\n**Immediate Support:**\n- [Specific guidance for their issue]\n- [Relevant documentation links]\n- [Code examples if applicable]\n\n**Systemic Improvements:**\nYour experience helps us identify areas for improvement. We're reviewing our documentation and user experience based on your feedback.\n\n**Follow-up:** We'll check back within [X] days to ensure you're successful.\n</code></pre>"},{"location":"product-management/github-issue-triage-framework/#communication-cadence","title":"Communication Cadence","text":"<ul> <li>Critical Issues: Updates every 24 hours until resolved</li> <li>High Priority: Updates every 72 hours</li> <li>Medium Priority: Weekly updates</li> <li>Low Priority: Bi-weekly updates or at major milestones</li> </ul>"},{"location":"product-management/github-issue-triage-framework/#community-health-metrics","title":"Community Health Metrics","text":"<ul> <li>Average response time by issue type</li> <li>Issue resolution rate</li> <li>User satisfaction scores</li> <li>Community engagement levels</li> <li>Documentation effectiveness metrics</li> </ul>"},{"location":"product-management/github-issue-triage-framework/#6-success-metrics-and-kpis","title":"6. Success Metrics and KPIs","text":""},{"location":"product-management/github-issue-triage-framework/#issue-management-metrics","title":"Issue Management Metrics","text":"<ul> <li>Time to first response: &lt;24 hours for critical, &lt;72 hours for others</li> <li>Issue resolution time by category</li> <li>Reopened issue rate: &lt;5%</li> <li>User satisfaction with support: &gt;8/10</li> </ul>"},{"location":"product-management/github-issue-triage-framework/#product-quality-metrics","title":"Product Quality Metrics","text":"<ul> <li>Data accuracy incidents: Target &lt;2 per month</li> <li>Feature adoption rate: &gt;50% for major features within 3 months</li> <li>API consistency score: Measured via automated audits</li> <li>Documentation effectiveness: Measured via user surveys</li> </ul>"},{"location":"product-management/github-issue-triage-framework/#community-health-metrics_1","title":"Community Health Metrics","text":"<ul> <li>Active contributors: Growing month-over-month</li> <li>Issue participation rate: Community engagement in discussions</li> <li>Feature request quality: Detailed requirements vs. vague requests</li> <li>User success stories: Positive outcome reports</li> </ul> <p>This framework ensures that EdgarTools maintains its commitment to elegance, accuracy, and user-friendliness while scaling community contributions and feature development effectively.</p>"},{"location":"product-management/issue-analysis-templates/","title":"GitHub Issue Analysis Templates","text":"<p>Quick-reference templates for Product Managers to systematically analyze and respond to EdgarTools GitHub issues.</p>"},{"location":"product-management/issue-analysis-templates/#quick-classification-checklist","title":"Quick Classification Checklist","text":"<pre><code>\u25a1 Data Quality Issue (immediate priority)\n\u25a1 User Experience Issue (high priority) \n\u25a1 Feature Request (evaluate against roadmap)\n\u25a1 Documentation Gap (medium priority)\n\u25a1 Technical Debt (low priority)\n\u25a1 Support Request (immediate response needed)\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#current-issues-rapid-assessment","title":"Current Issues Rapid Assessment","text":""},{"location":"product-management/issue-analysis-templates/#418-feature-request-etf-ticker-holdings","title":"#418: Feature Request: ETF Ticker Holdings","text":"<p>Classification: Feature Request - Core Enhancement Priority Score: 80/100 Product Fit Analysis: - \u2705 Simple yet powerful: Extends existing fund analysis - \u2705 Accurate financials: Builds on proven 13F data - \u2705 Beginner-friendly: Can use existing API patterns - \u2705 Joyful UX: Natural extension of current workflow - \u2705 Beautiful output: Rich formatting opportunities</p> <p>Recommendation: PROCEED - High strategic value Implementation Approach: 1. Extend existing <code>edgar.funds</code> module 2. Leverage 13F filing parsing infrastructure 3. Create ETF-specific holdings extraction 4. Add ticker-based search functionality</p> <p>User Story:</p> <pre><code>As a financial analyst,\nI want to search for ETF holdings by ticker symbol,\nSo that I can quickly analyze which ETFs hold specific stocks.\n</code></pre> <p>Acceptance Criteria: - ETF holdings searchable by underlying ticker - Holdings data includes position sizes and percentages - Integration with existing fund analysis workflow - Rich formatted output with tables and visualizations</p>"},{"location":"product-management/issue-analysis-templates/#417-feature-request-etf-series-search","title":"#417: Feature Request: ETF Series Search","text":"<p>Classification: Feature Request - Core Enhancement Priority Score: 75/100 Product Fit Analysis: - \u2705 Simple yet powerful: Complements ETF ticker holdings - \u2705 Accurate financials: Uses official SEC series data - \u2705 Beginner-friendly: Familiar search pattern - \u2705 Joyful UX: Improves fund discovery - \u2705 Beautiful output: Series listing with rich formatting</p> <p>Recommendation: PROCEED - After #418 implementation Dependencies: Should build on #418 infrastructure</p> <p>User Story:</p> <pre><code>As a fund researcher,\nI want to search for ETF series by name or partial match,\nSo that I can discover relevant ETFs for analysis.\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#412-how-to-get-accurate-and-complete-data","title":"#412: How to get accurate and complete data?","text":"<p>Classification: Documentation/Support Request Priority Score: 60/100 Root Cause Analysis: - User uncertainty about data completeness - Potential gaps in documentation about data sources - Need for data quality guidance</p> <p>Recommendation: CREATE comprehensive data accuracy guide Implementation: 1. Document data source hierarchy (XBRL vs HTML vs text) 2. Explain completeness guarantees and limitations 3. Provide data validation examples 4. Create troubleshooting guide for missing data</p> <p>Response Template:</p> <pre><code>EdgarTools prioritizes data accuracy and completeness. Here's how to ensure you're getting the most reliable data:\n\n**Data Source Hierarchy:**\n1. XBRL data (most structured and reliable)\n2. HTML tables (standardized but may require parsing)\n3. Text extraction (fallback for unstructured data)\n\n**Best Practices:**\n- Use company.facts for historical standardized data\n- Cross-reference with filing.xbrl() for detailed breakdowns\n- Validate critical numbers across multiple periods\n\n**Documentation:** [Link to comprehensive data accuracy guide]\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#411-standardization","title":"#411: Standardization","text":"<p>Classification: Standardization Request - Needs Clarification Priority Score: 65/100 Analysis: Broad request requiring detailed requirements gathering</p> <p>Immediate Response Template:</p> <pre><code>Thank you for the standardization suggestion. To provide the most valuable improvements, we'd like to understand your specific needs better.\n\n**Could you clarify:**\n- Which aspects need standardization? (API methods, data formats, naming conventions)\n- What inconsistencies are causing friction in your workflow?\n- Are there specific examples where standardization would help?\n\n**Our Approach:**\nEdgarTools follows consistent patterns across modules, but we're always looking to improve. Your specific feedback will help us prioritize the most impactful standardization efforts.\n\n**Next Steps:** We'll schedule a brief call to gather requirements and assess impact.\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#408-cash-flow-statement-is-missing-values","title":"#408: Cash flow statement is missing values","text":"<p>Classification: Data Quality Issue - Critical Priority Score: 100/100 Immediate Actions Required:</p> <ol> <li>Emergency Response (24 hours):</li> <li>Reproduce issue with specific filing</li> <li>Identify root cause (XBRL parsing vs data availability)</li> <li>Implement hotfix if possible</li> <li> <p>Document affected filings/companies</p> </li> <li> <p>Investigation Checklist: <code>\u25a1 Reproduce with specific filing example    \u25a1 Check XBRL source data availability      \u25a1 Test across multiple companies/periods    \u25a1 Identify parsing logic gaps    \u25a1 Validate against SEC source documents    \u25a1 Create regression test</code></p> </li> <li> <p>Response Template:    ```    This is a critical data quality issue. We're investigating immediately.</p> </li> </ol> <p>Immediate Actions:    - Issue escalated to data quality team    - Investigation timeline: 24 hours for root cause    - Fix implementation: 48-72 hours    - Regression prevention: New tests added</p> <p>What we need from you:    - Specific filing or company example    - Expected vs. actual values    - Your code snippet for reproduction</p> <p>We'll update this issue every 24 hours until resolved.    ```</p>"},{"location":"product-management/issue-analysis-templates/#400-discrepancy-of-filing-information-depending-on-how-it-is-looked-up","title":"#400: Discrepancy of filing information depending on how it is looked up","text":"<p>Classification: Data Quality Issue - Major Priority Score: 90/100 Root Cause Hypothesis: Inconsistent data sources or caching issues</p> <p>Investigation Plan: 1. Identify specific lookup methods showing discrepancies 2. Trace data source for each lookup path 3. Check for caching/synchronization issues 4. Validate against SEC source data 5. Implement consistency checks</p> <p>Response Template:</p> <pre><code>Data consistency is fundamental to EdgarTools reliability. We're investigating this discrepancy immediately.\n\n**Investigation Approach:**\n1. Map all filing lookup paths in codebase\n2. Identify source data differences\n3. Implement consistency validation\n4. Add automated testing for lookup consistency\n\n**Timeline:** 72 hours for root cause analysis, 1 week for comprehensive fix\n\n**Tracking:** Added to our data quality dashboard for ongoing monitoring.\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#395-cashflowstatement-doesnt-contain-numeric_value-column","title":"#395: CashFlowStatement doesn't contain numeric_value column","text":"<p>Classification: Data Quality Issue - Critical Priority Score: 95/100 Technical Analysis: Likely XBRL parsing issue with statement construction</p> <p>Immediate Debugging Steps:</p> <pre><code># Investigation script\nfiling = Filing(accession_no='[example]')\nxbrl = filing.xbrl()\ncf_statement = xbrl.statements.cashflow_statement()\n\n# Check raw data\nprint(f\"Columns: {cf_statement.columns}\")\nprint(f\"XBRL facts available: {len(xbrl.facts)}\")\nprint(f\"Cash flow facts: {xbrl.query().by_statement_type('CashFlowStatement')}\")\n</code></pre> <p>Response Template:</p> <pre><code>This is a critical data structure issue affecting financial statement analysis. \n\n**Immediate Actions:**\n- Reproducing with your specific example\n- Checking XBRL fact extraction logic  \n- Validating statement construction process\n- Testing fix across multiple filings\n\n**Timeline:** 48 hours for fix implementation and testing\n\n**Workaround:** While we fix this, you can access raw XBRL data via `xbrl.query().by_statement_type('CashFlowStatement')`\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#384-i-need-some-major-help-please","title":"#384: I need some major help please","text":"<p>Classification: User Experience Issue - Support Escalation Priority Score: 85/100 Immediate Action: Personalized support required</p> <p>Response Template:</p> <pre><code>We're here to help! EdgarTools should be intuitive and empower your financial analysis.\n\n**Immediate Support:**\nLet's schedule a brief call to understand your specific challenges and get you up and running successfully.\n\n**Common Solutions:**\n- [Link to getting started guide]\n- [Link to troubleshooting documentation]\n- [Code examples for common tasks]\n\n**What helps us help you:**\n- Your specific use case or goal\n- Any error messages you're seeing\n- Code snippet of what you're trying to accomplish\n\n**Follow-up:** I'll personally ensure you're successful with EdgarTools.\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#381-use-local-data-doesnt-work-as-expected","title":"#381: Use local data doesn't work as expected","text":"<p>Classification: User Experience Issue - Functional Priority Score: 80/100 Technical Investigation: Local data workflow and caching system</p> <p>Investigation Checklist:</p> <pre><code>\u25a1 Test local data setup process\n\u25a1 Check file path handling across OS\n\u25a1 Validate caching mechanisms\n\u25a1 Review documentation accuracy\n\u25a1 Test offline usage scenarios  \n\u25a1 Check permissions and access patterns\n</code></pre> <p>Response Template:</p> <pre><code>Local data functionality should work seamlessly. Let's get this resolved quickly.\n\n**Immediate Debugging:**\nCould you share:\n- Your operating system\n- Local data setup steps you followed\n- Any error messages\n- Code snippet showing the issue\n\n**Common Issues:**\n- File path configuration\n- Cache directory permissions\n- Data format expectations\n\n**Timeline:** 48 hours for investigation and fix once we have reproduction steps.\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#387-chunked-data","title":"#387: Chunked data","text":"<p>Classification: Technical Enhancement/Performance Priority Score: 45/100 Analysis: Performance optimization opportunity, not blocking functionality</p> <p>Evaluation Criteria: - Impact on user experience - Memory usage improvements - Processing speed gains - Implementation complexity</p> <p>Response Template:</p> <pre><code>Thank you for the performance enhancement suggestion. \n\n**Current Approach:**\nEdgarTools prioritizes ease of use and data accuracy. We're interested in performance optimizations that don't compromise these principles.\n\n**Evaluation Process:**\n- Measuring current performance bottlenecks\n- Assessing chunking implementation complexity\n- Ensuring backward compatibility\n- Testing across diverse filing sizes\n\n**Timeline:** Added to our performance optimization backlog for evaluation in Q[X] planning.\n</code></pre>"},{"location":"product-management/issue-analysis-templates/#implementation-quick-reference","title":"Implementation Quick Reference","text":""},{"location":"product-management/issue-analysis-templates/#priority-response-times","title":"Priority Response Times","text":"<ul> <li>Critical (95-100): 24 hours</li> <li>High (80-94): 48-72 hours  </li> <li>Medium (60-79): 1 week</li> <li>Low (30-59): 2 weeks</li> </ul>"},{"location":"product-management/issue-analysis-templates/#escalation-triggers","title":"Escalation Triggers","text":"<ul> <li>Data accuracy issues</li> <li>User unable to complete core workflows</li> <li>Security concerns</li> <li>API breaking changes reported</li> </ul>"},{"location":"product-management/issue-analysis-templates/#success-metrics-tracking","title":"Success Metrics Tracking","text":"<ul> <li>Issue resolution time by category</li> <li>User satisfaction scores  </li> <li>Feature adoption rates</li> <li>Data quality incident reduction</li> </ul> <p>This template system ensures consistent, product-principle-aligned responses while maintaining the high-quality user experience that EdgarTools is known for.</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/","title":"XBRL Mapping Files Analysis - mpreiss9 Contribution","text":"<p>Date: 2025-11-21 Source: GitHub Issue #494 Contributor: @mpreiss9 Files: custom_taxonomy_mapping.csv, gaap_taxonomy_mapping.csv Architecture: <code>docs-internal/planning/architecture/xbrl-standardization-pipeline.md</code></p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#executive-summary","title":"Executive Summary","text":"<p>mpreiss9 shared production XBRL mapping files containing 6,177 mappings refined over work with 390+ companies. These files represent a goldmine of real-world standardization knowledge.</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#key-statistics","title":"Key Statistics","text":"Metric Value Total mappings 6,177 GAAP mappings 2,343 Custom (company-specific) 3,834 Unique companies 390 CIKs Ambiguous tags 215 (9.2%) Current/NonCurrent ambiguities 202 (94% of ambiguous) Tags marked \"DropThisItem\" 276 Unique standard tags 129"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#file-structure","title":"File Structure","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#1-gaap-taxonomy-mapping-gaap_taxonomy_mappingcsv","title":"1. GAAP Taxonomy Mapping (gaap_taxonomy_mapping.csv)","text":"<p>Purpose: Standard XBRL \u2192 Standardized tag mappings</p> <p>Format:</p> <pre><code>xbrl_tag,std_tag,comments,deprecated\nAccountsPayableCurrentAndNoncurrent,TradePayables:OtherOperatingNonCurrentLiabilities,Curr/NonCurr ambiguity,\n</code></pre> <p>Key Features: - 2,343 mappings covering standard GAAP taxonomy - Ambiguous tags use <code>:</code> separator (e.g., <code>TagA:TagB</code>) - Comments column explains ambiguity patterns - Deprecated column flags outdated tags</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#2-custom-taxonomy-mapping-custom_taxonomy_mappingcsv","title":"2. Custom Taxonomy Mapping (custom_taxonomy_mapping.csv)","text":"<p>Purpose: Company-specific XBRL \u2192 Standardized tag mappings</p> <p>Format:</p> <pre><code>cik,xbrl_tag,std_tag,comments\n1800,AccruedAllOtherLiabilities,OtherNonOperatingCurrentLiabilities,\n</code></pre> <p>Key Features: - 3,834 mappings across 390 companies - CIK-based (not ticker, for stability) - Top company: CIK 40545 with 82 custom mappings - Avg 9.8 mappings per company</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#ambiguity-analysis","title":"Ambiguity Analysis","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#pattern-breakdown","title":"Pattern Breakdown","text":"Ambiguity Type Count % of Total Curr/NonCurr 202 93.9% Assets/Liabilities 11 5.1% Both 1 0.5% Other 1 0.5%"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#currentnoncurrent-the-core-challenge","title":"Current/NonCurrent: The Core Challenge","text":"<p>Problem: Same XBRL tag can represent current OR non-current items depending on context.</p> <p>Examples:</p> <pre><code>AccountsPayableCurrentAndNoncurrent\n  \u2192 TradePayables (if current section)\n  \u2192 OtherOperatingNonCurrentLiabilities (if non-current section)\n\nAccountsReceivableNet\n  \u2192 TradeReceivables (if current)\n  \u2192 OtherOperatingNonCurrentAssets (if non-current)\n</code></pre> <p>Resolution Strategy (from mpreiss9's methodology): 1. Parse balance sheet to identify section boundaries (Assets, Liabilities, Equity) 2. Use subtotals as section markers 3. Apply context-aware mapping based on position 4. Validate with Assets = Liabilities + Equity</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#assetsliabilities-ambiguity","title":"Assets/Liabilities Ambiguity","text":"<p>Examples:</p> <pre><code>InterestAndDividendsPayableCurrentAndNoncurrent\n  \u2192 CashAndMarketableSecurities (if asset)\n  \u2192 OtherNonOperatingCurrentLiabilities (if liability)\n</code></pre>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#standard-tag-distribution","title":"Standard Tag Distribution","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#top-15-most-used-standard-tags","title":"Top 15 Most-Used Standard Tags","text":"Standard Tag Mappings Category DropThisItem 276 Special NonoperatingIncomeExpense 199 Income Statement CostOfGoodsAndServicesSold 142 Income Statement OtherNonOperatingNonCurrentAssets 140 Balance Sheet Revenue 139 Income Statement OtherNonOperatingCurrentAssets 131 Balance Sheet OtherNonOperatingCurrentLiabilities 82 Balance Sheet OtherNonOperatingNonCurrentLiabilities 81 Balance Sheet IncomeTaxes 78 Income Statement LongTermDebt 71 Balance Sheet"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#dropthisitem-tags-276-total","title":"\"DropThisItem\" Tags (276 total)","text":"<p>Tags deliberately excluded from standardization: - EPS-related details (per-share amounts, pro-forma) - Accelerated share repurchase specifics - Antidilutive securities details - Auction market preferred stock details</p> <p>Rationale (from mpreiss9):</p> <p>\"Some xbrl tags are deliberately mapped to DropThisItem, meaning I not only don't use the item, it would confuse my code if it got mapped.\"</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#company-coverage","title":"Company Coverage","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#top-10-companies-by-custom-mapping-count","title":"Top 10 Companies by Custom Mapping Count","text":"Rank CIK Mappings Notes 1 40545 82 Highest complexity 2 1164727 67 3 1398659 45 4 1166691 43 5 78003 40 6 831259 37 7 14272 34 8 895126 33 9 37785 32 10 1099800 32 <p>Distribution: 390 companies, avg 9.8 custom mappings each</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#key-innovations-in-mpreiss9s-approach","title":"Key Innovations in mpreiss9's Approach","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#1-reverse-mapping-structure","title":"1. Reverse Mapping Structure","text":"<ul> <li>XBRL tag as primary key (unique, unchanging)</li> <li>Multiple standard tags per XBRL tag (context-dependent)</li> <li>O(1) lookup vs iteration</li> </ul>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#2-colon-separator-for-ambiguity","title":"2. Colon Separator for Ambiguity","text":"<pre><code>AccountsPayableCurrentAndNoncurrent,TradePayables:OtherOperatingNonCurrentLiabilities\n</code></pre> <ul> <li>Easy to parse programmatically</li> <li>No multi-column complexity</li> <li>Self-documenting</li> </ul> <p>From mpreiss9's follow-up comment:</p> <p>\"I forgot to mention that in the mapping files, ambiguous standard tags are separated by a colon ':'. This is easy to identify and process programatically vs multiple columns in the csv.\"</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#3-comprehensive-comments","title":"3. Comprehensive Comments","text":"<ul> <li>7 distinct ambiguity patterns documented</li> <li>Clear explanation of resolution strategy</li> <li>Aids debugging and validation</li> </ul>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#4-cik-based-company-mapping","title":"4. CIK-Based Company Mapping","text":"<ul> <li>Stable identifier (ticker can change)</li> <li>Company-level customization</li> <li>Scales to 390+ companies</li> </ul>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#5-footnote-integration","title":"5. Footnote Integration","text":"<p>From mpreiss9:</p> <p>\"Once my code has verified that I have an in balance primary statement, I look for footnotes or tree children of line items that add up to the primary item, and when found I swap in the footnote values.\"</p> <p>Example: - Primary: \"Non-operating Income and Interest\" (single line) - Footnote breakdown: Interest Income + Interest Expense + Other - Swaps if sums match for greater granularity</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#6-flexible-mapping-philosophy-two-reasons-for-mapping","title":"6. Flexible Mapping Philosophy: Two Reasons for Mapping","text":"<p>Critical Insight from mpreiss9's follow-up comment:</p> <p>\"There are really two reasons to map an xbrl tag to a standard tag. The first reason is to take what is exactly the same kind of fact coded different ways into a common tag (for example the seemingly countless revenue tag flavors). The second reason is often overlooked but very important - a user may want to consolidate multiple kinds of facts into a single concept because the distinction is immaterial to them.\"</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#reason-1-standardization-same-facts-different-tags","title":"Reason 1: Standardization (Same Facts, Different Tags)","text":"<p>Goal: Normalize identical concepts with different XBRL names</p> <p>Example: Revenue variations</p> <pre><code>us-gaap:Revenue                \u2192 \"Revenue\"\nus-gaap:Revenues               \u2192 \"Revenue\"\nus-gaap:SalesRevenueNet        \u2192 \"Revenue\"\nus-gaap:RevenueFromContractWithCustomerExcludingAssessedTax \u2192 \"Revenue\"\n</code></pre> <p>All represent the same concept, just coded differently across companies.</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#reason-2-consolidation-different-facts-users-choice","title":"Reason 2: Consolidation (Different Facts, User's Choice)","text":"<p>Goal: Combine distinct concepts when granularity doesn't matter to the user</p> <p>Example: Non-Operating Liabilities (mpreiss9's granular mapping)</p> <pre><code>us-gaap:TaxLiabilities          \u2192 \"Tax Liabilities\"\nus-gaap:RetirementLiabilities   \u2192 \"Retirement Liabilities\"\nus-gaap:OtherNonOperatingLiab   \u2192 \"Other Non-Operating Liabilities\"\n</code></pre> <p>Alternative: Another user's consolidated mapping</p> <pre><code>us-gaap:TaxLiabilities          \u2192 \"Non-Operating Liabilities\"\nus-gaap:RetirementLiabilities   \u2192 \"Non-Operating Liabilities\"\nus-gaap:OtherNonOperatingLiab   \u2192 \"Non-Operating Liabilities\"\n</code></pre> <p>Both are valid! The choice depends on the user's analytical needs.</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#implications-for-edgartools","title":"Implications for EdgarTools","text":"<p>Current Approach: One \"standard\" mapping for all users - Fixed granularity level - EdgarTools decides the level of detail - Users can't easily adjust</p> <p>Flexible Approach (mpreiss9's insight): - Users choose granularity based on their needs - Some users want detailed breakdowns - Others want high-level summaries - Same data, different views</p> <p>Quote from mpreiss9:</p> <p>\"For example, I gave you a pretty granular mapping, distinguishing between tax liabilities, retirement liabilities and other non-operating liabilities. Another user might just collapse all those xbrl tags into a single non-operating liability tag. This is why a flexible mapping scheme is so important.\"</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#design-considerations","title":"Design Considerations","text":"<p>User Profiles (suggested): - Detailed: Maximum granularity (like mpreiss9's mappings) - Standard: Balanced level of detail (EdgarTools default) - Summarized: High-level consolidation (for overview analysis)</p> <p>Configurable Granularity: - Users should be able to define their own rollup rules - CSV format supports easy customization - Multiple mapping files for different use cases</p> <p>Hierarchical Mappings: - Define parent-child relationships - Allow drill-down: \"Non-Operating Liabilities\" \u2192 Tax, Retirement, Other - Allow roll-up: Multiple detailed tags \u2192 Single summary tag</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#value-for-edgartools","title":"Value for EdgarTools","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#immediate-applications","title":"Immediate Applications","text":"<p>1. Balance Sheet Validation (edgartools-y3k) - Use as test data for Assets = Liabilities + Equity validation - Verify section boundary detection - Test rollup calculations</p> <p>2. Ambiguous Tag Catalog (edgartools-3yx) - 215 real-world ambiguous cases documented - Resolution patterns identified - Test coverage for edge cases</p> <p>3. Context-Aware Resolution - Proof that reverse mapping + context works in production - 390 companies validated - Current/NonCurrent pattern handles 94% of ambiguities</p> <p>4. Flexible Granularity Model (Pipeline Stage 4) - mpreiss9's mappings provide \"detailed\" profile example - Shows how to support different analytical needs - Template for user-configurable mapping levels - Integrates with architecture as Stage 4: Granularity Transformation</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#future-enhancements","title":"Future Enhancements","text":"<p>1. Section Membership Dictionaries - Build from these mappings - Assets vs Liabilities classification - Current vs NonCurrent heuristics</p> <p>2. CSV Workflow Tools - Import/export utilities - Excel-friendly editing - Merge with EdgarTools standard mappings</p> <p>3. Enhanced Context Threading - Parent concept tracking - Section position awareness - Sign and value validation</p> <p>4. User-Configurable Granularity (NEW from mpreiss9's insight - Pipeline Stage 4) - Mapping profiles: Detailed, Standard, Summarized - Custom granularity settings: Let users define rollup rules - Hierarchical mappings: Support drill-down and roll-up - Use case templates: Financial analyst, researcher, casual user - API design: <code>xbrl.statements.balance_sheet(granularity='detailed')</code> - Architecture integration: See Stage 4 in <code>xbrl-standardization-pipeline.md</code> - Three user levels:   - Level 1: Choose profile (<code>granularity='detailed'</code>)   - Level 2: Custom profile file (<code>Profile.from_csv()</code>)   - Level 3: Programmatic transformation (user owns logic)</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#technical-notes","title":"Technical Notes","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#mapping-logic","title":"Mapping Logic","text":"<p>Standard approach (current EdgarTools):</p> <pre><code>standard_tag = mapping[xbrl_tag]  # 1:1 mapping\n</code></pre> <p>mpreiss9 approach:</p> <pre><code>possible_tags = mapping[xbrl_tag].split(':')  # 1:N mapping\nstandard_tag = resolve_with_context(possible_tags, context)\n</code></pre>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#context-structure","title":"Context Structure","text":"<p>Based on mpreiss9's methodology:</p> <pre><code>context = {\n    'section': 'current_assets',  # or 'current_liabilities', etc.\n    'parent': 'TotalCurrentAssets',\n    'position': 5,  # Line number in statement\n    'sign': 'debit',\n    'value': 12500.00\n}\n</code></pre>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#balance-sheet-sections","title":"Balance Sheet Sections","text":"<pre><code>ASSETS\n  Current Assets\n    Cash, Receivables, Inventory, etc.\n    [Subtotal: CurrentAssets]\n  Non-Current Assets\n    PPE, Intangibles, LongTermInvestments, etc.\n    [Subtotal: NoncurrentAssets]\n  [Total: Assets]\n\nLIABILITIES\n  Current Liabilities\n    Payables, ShortTermDebt, etc.\n    [Subtotal: CurrentLiabilities]\n  Non-Current Liabilities\n    LongTermDebt, Pensions, etc.\n    [Subtotal: NoncurrentLiabilities]\n  [Total: Liabilities]\n\nEQUITY\n  [Total: StockholdersEquity]\n\nVALIDATION: Assets = Liabilities + Equity\n</code></pre>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#recommendations","title":"Recommendations","text":""},{"location":"research/xbrl-mapping-analysis-mpreiss9/#phase-1-integration-immediate","title":"Phase 1: Integration (Immediate)","text":"<ol> <li>Add to test fixtures</li> <li>Copy files to <code>tests/fixtures/xbrl-mappings/</code></li> <li> <p>Use for validation test cases</p> </li> <li> <p>Document in advanced guide</p> </li> <li>Reference as example of production usage</li> <li> <p>Show reverse mapping pattern</p> </li> <li> <p>Create comparison analysis</p> </li> <li>EdgarTools mappings vs mpreiss9 mappings</li> <li>Identify gaps and improvements</li> </ol>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#phase-2-implementation-v4310","title":"Phase 2: Implementation (v4.31.0)","text":"<ol> <li>Balance sheet validation</li> <li>Assets = Liabilities + Equity</li> <li>Section total validation</li> <li> <p>Use these mappings for test data</p> </li> <li> <p>Section membership dictionaries</p> </li> <li>Build from ambiguity comments</li> <li>Current/NonCurrent classification</li> <li>Assets/Liabilities classification</li> </ol>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#phase-3-enhancement-v500","title":"Phase 3: Enhancement (v5.0.0)","text":"<ol> <li>Context-aware disambiguation</li> <li>Implement colon-separated mapping support</li> <li>Add context resolution logic</li> <li> <p>Validate with 215 ambiguous cases</p> </li> <li> <p>CSV import/export</p> </li> <li>User-friendly mapping management</li> <li>Merge capability</li> <li>Company override support</li> </ol>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#questions-for-community","title":"Questions for Community","text":"<ol> <li>Privacy: Can we include anonymized subset in test fixtures?</li> <li>Collaboration: Interest in contributing to context-aware resolution?</li> <li>Priorities: Which enhancement is most valuable?</li> <li>Balance sheet validation</li> <li>Ambiguous tag handling</li> <li>CSV workflow tools</li> </ol>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#files","title":"Files","text":"<p>Location: <code>/data/xbrl-mappings/</code> - <code>custom_taxonomy_mapping.csv</code> (294KB, 3,834 rows) - <code>gaap_taxonomy_mapping.csv</code> (173KB, 2,343 rows)</p> <p>Git Status: Not committed (data files, user contribution)</p> <p>Usage: Test data, research, validation</p>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#references","title":"References","text":"<ul> <li>GitHub Issue: #494 - Create documentation on how to customize standardization tagging</li> <li>Architecture: <code>docs-internal/planning/architecture/xbrl-standardization-pipeline.md</code></li> <li>Enhancement Roadmap: <code>docs-internal/planning/future-enhancements/context-aware-standardization.md</code></li> <li>Epic: edgartools-ocf - Context-Aware XBRL Standardization Enhancements</li> <li>Related Issues: edgartools-y3k, edgartools-3yx, edgartools-qcd</li> <li>Documentation: <code>docs/advanced/customizing-standardization.md</code></li> </ul>"},{"location":"research/xbrl-mapping-analysis-mpreiss9/#how-this-fits-in-the-pipeline","title":"How This Fits in the Pipeline","text":"<p>mpreiss9's contributions integrate into the 7-stage XBRL processing pipeline:</p> <ul> <li>Stage 3 (Base Standardization): CSV mappings show production-scale standardization</li> <li>Stage 4 (Granularity): \"Detailed\" profile example - maximum granularity for advanced users</li> <li>Stage 5 (Context Resolution): 215 ambiguous tags document what needs context-aware handling</li> </ul> <p>See the complete pipeline architecture for how these pieces fit together.</p> <p>Analysis Date: 2025-11-21 Analyst: Claude (EdgarTools AI Assistant) Status: Complete - Ready for integration planning</p>"},{"location":"research/issues/issue-494-standardization-comparison/","title":"Research: Comparing EdgarTools Standardization with mpreiss9's Approach","text":"<p>Date: 2025-11-20 (Updated: 2025-11-22) Research Phase: 1 of 3 (FIC Workflow) Next Phase: Planning (<code>/plan</code>) - COMPLETE GitHub Issue: #494 - \"Create documentation on how to customize standardization tagging\" Architecture: <code>docs-internal/planning/architecture/xbrl-standardization-pipeline.md</code> (2025-11-22) CSV Analysis: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code> (2025-11-21)</p>"},{"location":"research/issues/issue-494-standardization-comparison/#research-question","title":"Research Question","text":"<p>Looking at Issue #494, particularly the last comment where user @mpreiss9 outlined their standardization method, could we improve how we do standardization by following their approach?</p> <p>UPDATE 2025-11-21: @mpreiss9 shared production CSV mapping files containing 6,177 mappings from 390 companies. Detailed analysis: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code></p>"},{"location":"research/issues/issue-494-standardization-comparison/#executive-summary","title":"Executive Summary","text":"<p>This research compares two fundamentally different approaches to XBRL standardization:</p> <ol> <li>EdgarTools Current Approach: Forward mapping (<code>StandardConcept \u2192 [CompanyConcepts]</code>) with priority-based resolution</li> <li>mpreiss9's Approach: Reverse mapping (<code>CompanyConcept \u2192 [StandardConcepts]</code>) with section-based context resolution</li> </ol>"},{"location":"research/issues/issue-494-standardization-comparison/#key-findings","title":"Key Findings","text":"<ul> <li>EdgarTools has the infrastructure for context-aware disambiguation BUT it's not implemented - context is passed throughout the code but completely ignored during mapping</li> <li>mpreiss9's method successfully handles 200+ ambiguous tags using backwards processing and section-based resolution</li> <li>Both approaches have merit - EdgarTools excels at simplicity and performance, mpreiss9's excels at handling ambiguity and validation</li> <li>The two approaches are complementary, not contradictory - elements from mpreiss9's method could enhance EdgarTools without replacing the current system</li> <li>Real-world validation data now available - 6,177 production mappings from 390 companies provide concrete test cases and validation data (2025-11-21)</li> <li>Architecture designed (2025-11-22) - 7-stage pipeline integrates both approaches with clean boundaries</li> </ul>"},{"location":"research/issues/issue-494-standardization-comparison/#detailed-findings","title":"Detailed Findings","text":""},{"location":"research/issues/issue-494-standardization-comparison/#1-edgartools-current-implementation","title":"1. EdgarTools Current Implementation","text":""},{"location":"research/issues/issue-494-standardization-comparison/#mapping-direction-forward-standardconcept-companyconcepts","title":"Mapping Direction: Forward (<code>StandardConcept \u2192 [CompanyConcepts]</code>)","text":"<p>File: <code>edgar/xbrl/standardization/core.py</code></p> <p>Data Structure (Lines 134-137):</p> <pre><code>class MappingStore:\n    \"\"\"\n    Attributes:\n        mappings (Dict[str, Set[str]]): Dictionary mapping standard concepts to sets of company concepts\n    \"\"\"\n</code></pre> <p>JSON Format (<code>concept_mappings.json</code>):</p> <pre><code>{\n  \"Revenue\": [\n    \"us-gaap:Revenue\",\n    \"us-gaap:Revenues\",\n    \"us-gaap:SalesRevenueNet\"\n  ],\n  \"Automotive Revenue\": [\n    \"tsla:AutomotiveRevenue\",\n    \"tsla:AutomotiveSales\"\n  ]\n}\n</code></pre> <p>Lookup Flow: 1. Given <code>company_concept</code> like <code>\"tsla:AutomotiveRevenue\"</code> 2. Iterate through ALL standard concepts 3. Check if <code>company_concept</code> is IN the set of mapped concepts 4. Return the standard concept (or None)</p> <p>Time Complexity: O(n \u00d7 m) where n = number of standard concepts, m = average set size</p>"},{"location":"research/issues/issue-494-standardization-comparison/#priority-based-resolution","title":"Priority-Based Resolution","text":"<p>File: <code>edgar/xbrl/standardization/core.py:408-449</code></p> <p>Priority Levels: - P1 (lowest): Core mappings from <code>concept_mappings.json</code> - P2 (higher): Company-specific mappings from <code>company_mappings/*.json</code> - P4 (highest): When concept prefix matches company (e.g., <code>tsla:Revenue</code> uses Tesla mappings)</p> <p>Resolution Logic (Lines 430-443):</p> <pre><code>for std_concept, mapping_list in self.merged_mappings.items():\n    for concept, source, priority in mapping_list:\n        if concept == company_concept:\n            effective_priority = priority\n            # Boost priority if it matches detected entity\n            if detected_entity and source == detected_entity:\n                effective_priority = 4  # Highest priority\n            candidates.append((std_concept, effective_priority, source))\n\n# Return highest priority match\nif candidates:\n    best_match = max(candidates, key=lambda x: x[1])\n    return best_match[0]\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#context-handling-not-implemented","title":"Context Handling: NOT IMPLEMENTED","text":"<p>Critical Finding: Context parameter exists but is completely ignored during mapping.</p> <p>Evidence (<code>core.py:493-518</code>):</p> <pre><code>def map_concept(self, company_concept: str, label: str, context: Dict[str, Any]) -&gt; Optional[str]:\n    # Use cache for faster lookups\n    cache_key = (company_concept, context.get('statement_type', ''))  # \u2190 Context only for caching\n    if cache_key in self._cache:\n        return self._cache[cache_key]\n\n    # Check if we already have a mapping in the store\n    standard_concept = self.mapping_store.get_standard_concept(company_concept)  # \u2190 NO context passed!\n    if standard_concept:\n        self._cache[cache_key] = standard_concept\n        return standard_concept\n</code></pre> <p>Documentation Confirms (<code>core.py:414</code>):</p> <pre><code>def get_standard_concept(self, company_concept: str, context: Dict = None) -&gt; Optional[str]:\n    \"\"\"\n    Args:\n        context: Optional context information (not used in current implementation)  # \u2190 Explicit statement\n    \"\"\"\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#ambiguous-tag-problem","title":"Ambiguous Tag Problem","text":"<p>Issue #494 Comment: User @mpreiss9 identified 200+ ambiguous XBRL tags including:</p> <p>Asset/Liability Ambiguity (12 tags): - <code>DeferredTaxAssetsLiabilitiesNet</code> - Could be asset OR liability depending on sign - <code>DerivativeAssetsLiabilitiesAtFairValueNet</code> - Net of assets and liabilities - <code>UnamortizedDebtIssuanceExpense</code> - Could be asset (deferred charge) OR liability offset</p> <p>Current/Noncurrent Ambiguity (180+ tags): - <code>AccountsPayableCurrentAndNoncurrent</code> - Could be current OR noncurrent - <code>DeferredRevenue</code> - Doesn't specify current vs noncurrent - <code>ConvertibleDebt</code> - Could be short-term OR long-term</p> <p>Triple Ambiguity (1 tag): - <code>DerivativeLiabilityFairValueGrossAsset</code> - Ambiguous in 3 dimensions:   1. Asset vs Liability   2. Current vs Noncurrent   3. Gross vs Net</p> <p>EdgarTools Cannot Handle These: The current system has no mechanism to map these differently based on: - Where they appear in statement hierarchy - Their calculation parent - Their sign/value - Statement context</p>"},{"location":"research/issues/issue-494-standardization-comparison/#2-mpreiss9s-standardization-method","title":"2. mpreiss9's Standardization Method","text":""},{"location":"research/issues/issue-494-standardization-comparison/#mapping-direction-reverse-companyconcept-standardconcepts","title":"Mapping Direction: Reverse (<code>CompanyConcept \u2192 [StandardConcepts]</code>)","text":"<p>From Issue #494 Comment:</p> <p>\"My tag map is reversed from yours - I have xbrl tags as a primary key (since they are unique) and then standard tags attached. So an xbrl tag can be mapped to more than one standard tag.\"</p> <p>Data Structure (Conceptual):</p> <pre><code>{\n  \"us-gaap:DeferredTaxAssetsLiabilitiesNet\": [\n    \"Deferred Tax Assets\",  # When in assets context\n    \"Deferred Tax Liabilities\"  # When in liabilities context\n  ],\n  \"us-gaap:AccountsPayableCurrentAndNoncurrent\": [\n    \"Accounts Payable, Current\",  # When parent is current liabilities\n    \"Accounts Payable, Noncurrent\",  # When parent is noncurrent liabilities\n    \"Accounts Payable, Total\"  # When it's a total line\n  ]\n}\n</code></pre> <p>Advantages: 1. Natural lookup: O(1) hash lookup instead of iteration 2. Explicit ambiguity handling: Multiple standard tags per XBRL tag 3. Context-aware by design: Same tag can map to different concepts based on context</p>"},{"location":"research/issues/issue-494-standardization-comparison/#section-based-resolution-strategy","title":"Section-Based Resolution Strategy","text":"<p>From Issue #494 Comment:</p> <p>\"I have a dictionary with balance sheet sections as keys (using a standard tag) and all the possible standard tags for that section as a set attached to the key.\"</p> <p>Section Dictionary (Conceptual):</p> <pre><code>{\n  \"Current Assets\": {\n    \"Cash and Cash Equivalents\",\n    \"Accounts Receivable\",\n    \"Inventory\",\n    \"Prepaid Expenses\",\n    ...\n  },\n  \"Current Liabilities\": {\n    \"Accounts Payable, Current\",\n    \"Accrued Liabilities\",\n    \"Short Term Debt\",\n    ...\n  }\n}\n</code></pre> <p>Resolution Algorithm (From comment):</p> <ol> <li>Assign standard tags to all items (including ambiguous ones with multiple tags)</li> <li>Assign sections working backwards using hierarchy levels and totals</li> <li>Disambiguate by checking which standard tag belongs in the assigned section</li> <li>Remove incorrect mappings leaving only the contextually appropriate one</li> </ol> <p>Quote:</p> <p>\"Then again working backwards up the balance sheet for any item that has more than one standard tag I look to see which of the standard tags matches what should be in that section (using the dictionary just described). I then remove the incorrect ones from that item.\"</p>"},{"location":"research/issues/issue-494-standardization-comparison/#backwards-processing","title":"Backwards Processing","text":"<p>Why Backwards?</p> <p>\"Working backwards is helpful because the subtotals are the trigger for a new section.\"</p> <p>Explanation: In financial statements, subtotals (like \"Total Current Assets\") define section boundaries. By processing backwards (bottom to top), you encounter the subtotal first, which tells you what section you're in.</p> <p>Example (Balance Sheet):</p> <pre><code>Total Assets                          \u2190 Process 5th: Top-level section marker\n  Total Current Assets                \u2190 Process 4th: Section marker \u2192 entering Current Assets\n    Cash                              \u2190 Process 3rd: Now we know we're in Current Assets\n    Accounts Receivable               \u2190 Process 2nd\n    Inventory                         \u2190 Process 1st: Start here\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#special-case-noncurrent-liabilities","title":"Special Case: Noncurrent Liabilities","text":"<p>From Issue #494 Comment:</p> <p>\"There is one special case in the balance sheet where different filers will use an xbrl tag either as a line item or as a total (Noncurrent liabilities). That one has to be dealt with first before doing the above process.\"</p> <p>Resolution Strategy:</p> <pre><code># Check label for clues\nif \"Other\" in label:\n    \u2192 \"Other Noncurrent Liabilities\" (line item)\nelif \"Total\" in label:\n    \u2192 \"Total Noncurrent Liabilities\" (total)\nelse:\n    # Check if it matches the calculation\n    if (total_liabilities - current_liabilities) == value:\n        \u2192 \"Total Noncurrent Liabilities\"\n    else:\n        \u2192 \"Other Noncurrent Liabilities\"\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#csv-format-for-mapping-management","title":"CSV Format for Mapping Management","text":"<p>From Issue #494 Comment:</p> <p>\"I happen to use .csv for my 2 mapping files so it's easy to edit, check for duplicates and so on in Excel.\"</p> <p>CSV Structure:</p> <pre><code>company_concept,standard_concept,company_cik,notes\nus-gaap:Revenue,Revenue,,Core GAAP\ntsla:AutomotiveRevenue,Automotive Revenue,1318605,Tesla-specific\nus-gaap:DeferredTaxAssetsLiabilitiesNet,Deferred Tax Assets,,When positive/in assets\nus-gaap:DeferredTaxAssetsLiabilitiesNet,Deferred Tax Liabilities,,When negative/in liabilities\n</code></pre> <p>Benefits: - Excel editing and duplicate detection - Easy filtering by company (CIK) - Explicit handling of multi-mapping - Notes column for context rules</p>"},{"location":"research/issues/issue-494-standardization-comparison/#unmapped-tag-logging","title":"Unmapped Tag Logging","text":"<p>From Issue #494 Comment:</p> <p>\"I also did to make the process easier was to create separate log files for unmapped tags discovered during processing that caused me to have out of balance statements. The logs are in the same format as my mapping files, and include a 'guess' as to the correct mapping.\"</p> <p>Log Format (Conceptual):</p> <pre><code>company_concept,suggested_mapping,confidence,label,cik,context,notes\nus-gaap:NewConceptFound,Revenue,0.85,Total Revenue,1318605,parent=Income,Review: high confidence\nus-gaap:AmbiguousTag,Deferred Tax Assets,0.50,Deferred Tax,0001652044,parent=Assets,Review: needs context\n</code></pre> <p>Process: 1. Discover unmapped tag during statement processing 2. Log it with suggested mapping and confidence 3. Include context (parent, statement type, etc.) 4. Review and add to mapping file</p>"},{"location":"research/issues/issue-494-standardization-comparison/#3-validation-balance-sheet-balancing","title":"3. Validation: Balance Sheet Balancing","text":""},{"location":"research/issues/issue-494-standardization-comparison/#mpreiss9s-validation-strategy","title":"mpreiss9's Validation Strategy","text":"<p>From Issue #494 Comment:</p> <p>\"For me, the validation is always can I create a statement that balances using just mapped data. That means, for Balance Sheet Total Assets = Current Assets + Noncurrent Assets (if it's provided) = all the asset detail items. Ditto Liabilities/Equity.\"</p> <p>Validation Equations:</p> <pre><code># Level 1: Fundamental equation\nTotal Assets == Total Liabilities + Total Equity\n\n# Level 2: Section totals\nTotal Assets == Current Assets + Noncurrent Assets\nTotal Liabilities == Current Liabilities + Noncurrent Liabilities\n\n# Level 3: Detail rollup\nTotal Assets == sum(all individual asset line items)\nCurrent Assets == sum(all current asset line items)\n</code></pre> <p>Validation Triggers Mapping Fixes: - If statement doesn't balance \u2192 unmapped tag or incorrect mapping - Log the unmapped tag with context - Review and add to mapping file - Reprocess to verify balance</p>"},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-validation-what-exists","title":"EdgarTools Validation: What EXISTS","text":"<p>Balance Type Validation (<code>edgar/xbrl/parsers/concepts.py</code>): - Lines 144-380: <code>US_GAAP_BALANCE_TYPES</code> dictionary mapping 155+ concepts to 'debit' or 'credit' - Assets, Expenses \u2192 debit balance - Liabilities, Equity, Revenue \u2192 credit balance</p> <p>Required Concepts (<code>edgar/xbrl/statements.py:72-87</code>):</p> <pre><code>REQUIRED_CONCEPTS = {\n    'BalanceSheet': ['Assets', 'Liabilities', 'StockholdersEquity'],\n    'IncomeStatement': ['Revenues', 'NetIncomeLoss'],\n    'CashFlowStatement': ['CashAndCashEquivalentsPeriodIncreaseDecrease', 'CashAndCashEquivalentsAtCarryingValue']\n}\n</code></pre> <p>Test-Level Validation (<code>tests/test_standardized_concepts.py:123-127</code>):</p> <pre><code># Implements accounting equation validation\nbalance_diff = abs(assets - (liabilities + equity))\nassert balance_diff &lt; (assets * 0.01)  # 1% tolerance\n</code></pre> <p>BUT: No automated balance sheet validation in production code that: - Checks Assets = Liabilities + Equity - Verifies section totals equal detail items - Triggers mapping corrections</p>"},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-period-data-quality","title":"EdgarTools Period Data Quality","text":"<p>Period Validation (<code>edgar/xbrl/period_data_check.py:111-237</code>):</p> <pre><code>def check_period_data_quality(xbrl, period_key, statement_type):\n    \"\"\"Validates period has sufficient data\"\"\"\n    return {\n        'fact_count': total_facts,\n        'meaningful_fact_count': non_zero_facts,\n        'essential_coverage': percentage,  # % of essential concepts present\n        'has_sufficient_data': fact_count &gt; min_threshold,\n        'missing_essentials': [...],\n        'found_essentials': [...]\n    }\n</code></pre> <p>What It Does: - Counts facts for specific periods - Checks essential concept coverage - Filters periods with insufficient data - Does NOT validate accounting equations</p>"},{"location":"research/issues/issue-494-standardization-comparison/#4-comparison-edgartools-vs-mpreiss9-approach","title":"4. Comparison: EdgarTools vs mpreiss9 Approach","text":""},{"location":"research/issues/issue-494-standardization-comparison/#mapping-direction","title":"Mapping Direction","text":"Aspect EdgarTools mpreiss9 Primary Key Standard Concept Company Concept (XBRL tag) Data Structure <code>{std: [company1, company2]}</code> <code>{company: [std1, std2]}</code> Lookup Complexity O(n \u00d7 m) iteration O(1) hash lookup Multi-Mapping Not supported by design Explicitly supported Ambiguity Handling Priority-based (company &gt; core) Context-based resolution"},{"location":"research/issues/issue-494-standardization-comparison/#context-awareness","title":"Context Awareness","text":"Aspect EdgarTools mpreiss9 Context Infrastructure \u2705 Exists (parameter threaded through code) \u2705 Fully implemented Context Usage \u274c Ignored during mapping \u2705 Core to disambiguation Available Context statement_type, level, is_total Parent concept, section, sign, value Resolution Strategy Priority levels (P1/P2/P4) Section membership + backwards processing"},{"location":"research/issues/issue-494-standardization-comparison/#ambiguous-tag-handling","title":"Ambiguous Tag Handling","text":"<p>EdgarTools Current: - Cannot distinguish <code>DeferredTaxAssetsLiabilitiesNet</code> as asset vs liability - Returns same mapping regardless of context - Would need significant enhancements</p> <p>mpreiss9's Method: - Explicitly handles 200+ ambiguous tags - Uses section dictionaries to determine correct mapping - Backwards processing identifies section boundaries - Special case handling (e.g., Noncurrent Liabilities total vs line item)</p>"},{"location":"research/issues/issue-494-standardization-comparison/#validation","title":"Validation","text":"Aspect EdgarTools mpreiss9 Balance Sheet Equation Test-level only Production validation Section Totals Not checked Checked during mapping Detail Rollup Not validated Validates all detail items sum to totals Validation Triggers Manual Triggers mapping corrections Out of Balance Handling No automated response Logs unmapped tags for review"},{"location":"research/issues/issue-494-standardization-comparison/#workflow","title":"Workflow","text":"<p>EdgarTools: 1. Load mappings from JSON 2. For each concept \u2192 lookup standard concept (priority-based) 3. Cache result 4. Standardize statement</p> <p>mpreiss9: 1. Load mappings from CSV (allows multi-mapping) 2. Assign ALL possible standard tags to each item 3. Assign sections working backwards (using subtotals) 4. Disambiguate by checking section membership 5. Remove incorrect mappings 6. Validate balance sheet equation 7. If out of balance \u2192 log unmapped tags 8. Review logs and update mappings</p>"},{"location":"research/issues/issue-494-standardization-comparison/#5-statement-processing-patterns-in-edgartools","title":"5. Statement Processing Patterns in EdgarTools","text":""},{"location":"research/issues/issue-494-standardization-comparison/#line-item-ordering","title":"Line Item Ordering","text":"<p>File: <code>edgar/xbrl/xbrl.py:662-1003</code></p> <p>Processing: Depth-first traversal with order attribute sorting</p> <pre><code>def _get_line_items_from_tree(node, facts_dict, level=0):\n    for child_id in node.children:  # Forward iteration\n        child_node = presentation_tree.get(child_id)\n        # Recurse depth-first\n</code></pre> <p>NOT backwards: EdgarTools processes top-to-bottom</p>"},{"location":"research/issues/issue-494-standardization-comparison/#section-identification","title":"Section Identification","text":"<p>File: <code>edgar/xbrl/rendering.py:273-290</code></p> <p>Method: Hierarchy level-based</p> <pre><code>if row.level == 0:\n    # Top-level section (like \"Total Assets\")\nelif row.level == 1:\n    # Subsection (like \"Current Assets\")\n</code></pre> <p>Limitation: Doesn't use backwards processing to identify section boundaries from subtotals</p>"},{"location":"research/issues/issue-494-standardization-comparison/#abstract-items-section-headers","title":"Abstract Items (Section Headers)","text":"<p>File: <code>edgar/xbrl/presentation.py:211-219</code></p> <p>Detection:</p> <pre><code>is_abstract = (\n    elem.attrib.get('abstract') == 'true' or\n    not elem.attrib.get('id')\n)\n</code></pre> <p>Usage: Abstract items mark section headers, but not used for section-based mapping</p>"},{"location":"research/issues/issue-494-standardization-comparison/#backwards-processing-limited-use","title":"Backwards Processing: Limited Use","text":"<p>File: <code>edgar/xbrl/rendering.py:1514-1613</code></p> <p>Only for Statement of Equity: Special handling with backwards date lookup</p> <pre><code># Backwards date lookup for beginning balance\nbeginning_period = match_date - timedelta(days=1)\n</code></pre> <p>NOT used for: - Section boundary detection - Ambiguous tag resolution - Statement validation</p>"},{"location":"research/issues/issue-494-standardization-comparison/#6-what-could-be-learned-from-mpreiss9s-approach","title":"6. What Could Be Learned from mpreiss9's Approach","text":""},{"location":"research/issues/issue-494-standardization-comparison/#1-reverse-mapping-structure-optional-alternative","title":"1. Reverse Mapping Structure (Optional Alternative)","text":"<p>Current: <code>StandardConcept \u2192 [CompanyConcepts]</code> Alternative: <code>CompanyConcept \u2192 [StandardConcepts]</code></p> <p>Advantages: - O(1) lookup instead of O(n \u00d7 m) iteration - Natural support for multi-mapping - Explicit ambiguity handling</p> <p>Implementation Path: - Create <code>ReverseMap pingStore</code> class - Load from reversed JSON or CSV - Use for ambiguous tag resolution - Keep current structure for non-ambiguous tags</p>"},{"location":"research/issues/issue-494-standardization-comparison/#2-section-based-context-resolution","title":"2. Section-Based Context Resolution","text":"<p>What to Add:</p> <pre><code># Section membership dictionary\nBALANCE_SHEET_SECTIONS = {\n    \"Current Assets\": {\n        \"Cash and Cash Equivalents\",\n        \"Accounts Receivable\",\n        \"Inventory\",\n        ...\n    },\n    \"Current Liabilities\": {\n        \"Accounts Payable, Current\",\n        \"Accrued Liabilities\",\n        ...\n    }\n}\n\ndef resolve_ambiguous_tag(company_concept, context):\n    \"\"\"Resolve ambiguous tag using section membership.\"\"\"\n    # Get all possible standard concepts\n    candidates = reverse_mapping.get(company_concept, [])\n\n    if len(candidates) &lt;= 1:\n        return candidates[0] if candidates else None\n\n    # Get section from context (parent concept or hierarchy)\n    section = determine_section(context)\n\n    # Find which candidate belongs in this section\n    for std_concept in candidates:\n        if std_concept in BALANCE_SHEET_SECTIONS.get(section, set()):\n            return std_concept\n\n    return None  # Ambiguous, needs manual resolution\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#3-enhanced-context-information","title":"3. Enhanced Context Information","text":"<p>Current Context (Lines 714-719):</p> <pre><code>context = {\n    \"statement_type\": \"BalanceSheet\",\n    \"level\": 1,\n    \"is_total\": False\n}\n</code></pre> <p>Enhanced Context (What mpreiss9 uses):</p> <pre><code>context = {\n    \"statement_type\": \"BalanceSheet\",\n    \"level\": 1,\n    \"is_total\": False,\n    \"calculation_parent\": \"us-gaap:AssetsCurrent\",  # NEW\n    \"parent_standard_concept\": \"Total Current Assets\",  # NEW\n    \"section\": \"Current Assets\",  # NEW (derived from parent)\n    \"fact_value\": 150000000,  # NEW (for sign-based disambiguation)\n    \"label\": \"Deferred Tax\"  # NEW (for \"Total\" vs \"Other\" detection)\n}\n</code></pre> <p>Where to Get This: - <code>calculation_parent</code>: From XBRL calculation trees (already parsed) - <code>parent_standard_concept</code>: Map parent concept to standard concept - <code>section</code>: Derive from parent using backwards processing - <code>fact_value</code>: From fact data - <code>label</code>: Already available</p>"},{"location":"research/issues/issue-494-standardization-comparison/#4-backwards-section-detection","title":"4. Backwards Section Detection","text":"<p>Algorithm (Adapted from mpreiss9):</p> <pre><code>def assign_sections_backwards(line_items):\n    \"\"\"Assign sections working backwards from subtotals.\"\"\"\n    current_section = None\n\n    # Process backwards (bottom to top)\n    for item in reversed(line_items):\n        # Check if this is a subtotal (section marker)\n        if item.is_total and item.level == 1:\n            # This is a section boundary\n            current_section = item.standard_label\n\n        # Assign section to this item\n        item.section = current_section\n\n    return line_items\n</code></pre> <p>Integration Point: <code>edgar/xbrl/rendering.py</code> line item processing</p>"},{"location":"research/issues/issue-494-standardization-comparison/#5-balance-sheet-validation","title":"5. Balance Sheet Validation","text":"<p>Validation Engine (Adapted from mpreiss9):</p> <pre><code>def validate_balance_sheet(statement_data):\n    \"\"\"Validate balance sheet using mapped concepts.\"\"\"\n\n    # Get key totals\n    total_assets = get_concept_value(statement_data, \"Total Assets\")\n    current_assets = get_concept_value(statement_data, \"Total Current Assets\")\n    noncurrent_assets = get_concept_value(statement_data, \"Total Noncurrent Assets\")\n    total_liabilities = get_concept_value(statement_data, \"Total Liabilities\")\n    total_equity = get_concept_value(statement_data, \"Total Stockholders' Equity\")\n\n    # Validation 1: Fundamental equation\n    if abs(total_assets - (total_liabilities + total_equity)) &gt; 1.0:\n        return ValidationError(\"Accounting equation violated\")\n\n    # Validation 2: Asset sections\n    if noncurrent_assets:  # Some companies don't report separately\n        if abs(total_assets - (current_assets + noncurrent_assets)) &gt; 1.0:\n            return ValidationError(\"Asset sections don't sum to total\")\n\n    # Validation 3: Detail rollup\n    asset_details = sum_concept_values(statement_data, section=\"Assets\", level &gt; 0)\n    if abs(total_assets - asset_details) &gt; 1.0:\n        return ValidationError(\"Asset details don't sum to total\")\n\n    return ValidationSuccess()\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#6-unmapped-tag-discovery","title":"6. Unmapped Tag Discovery","text":"<p>Logging System (Adapted from mpreiss9):</p> <pre><code>class UnmappedTagLogger:\n    \"\"\"Log unmapped tags discovered during processing.\"\"\"\n\n    def __init__(self, output_path):\n        self.output_path = output_path\n        self.unmapped = []\n\n    def log_unmapped(self, company_concept, label, context, suggested_mapping=None):\n        \"\"\"Log an unmapped tag with context.\"\"\"\n        self.unmapped.append({\n            'company_concept': company_concept,\n            'label': label,\n            'statement_type': context.get('statement_type'),\n            'parent_concept': context.get('calculation_parent'),\n            'section': context.get('section'),\n            'suggested_mapping': suggested_mapping or infer_mapping(company_concept, label),\n            'confidence': calculate_confidence(suggested_mapping),\n            'cik': context.get('cik'),\n            'notes': ''  # For manual review\n        })\n\n    def save_to_csv(self):\n        \"\"\"Save unmapped tags to CSV for Excel editing.\"\"\"\n        df = pd.DataFrame(self.unmapped)\n        df.to_csv(self.output_path, index=False)\n</code></pre> <p>Integration: Call during statement processing when mapping returns None</p>"},{"location":"research/issues/issue-494-standardization-comparison/#7-csv-workflow-support","title":"7. CSV Workflow Support","text":"<p>Already Partially Implemented: <code>edgar/xbrl/standardization/utils.py</code></p> <p>Enhancements: - Support reverse mapping CSV format - Import multi-mapping from CSV (same company_concept, multiple rows) - Export unmapped tag logs - Duplicate detection across all mappings</p>"},{"location":"research/issues/issue-494-standardization-comparison/#7-complementary-not-contradictory","title":"7. Complementary Not Contradictory","text":"<p>Important Realization: The two approaches are not mutually exclusive.</p>"},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-strengths","title":"EdgarTools Strengths","text":"<p>\u2705 Simple, elegant API \u2705 Priority-based company-specific overrides \u2705 Works well for non-ambiguous tags (majority of cases) \u2705 Good performance with caching \u2705 Modular company mapping files</p>"},{"location":"research/issues/issue-494-standardization-comparison/#mpreiss9-strengths","title":"mpreiss9 Strengths","text":"<p>\u2705 Handles ambiguous tags systematically \u2705 Validation-driven mapping correction \u2705 Section-based context resolution \u2705 Excel-friendly CSV workflow \u2705 Explicit multi-mapping support</p>"},{"location":"research/issues/issue-494-standardization-comparison/#hybrid-approach","title":"Hybrid Approach","text":"<p>Recommendation: Use EdgarTools as foundation, add mpreiss9's enhancements for edge cases</p> <p>Architecture Designed (2025-11-22): See 7-stage pipeline in <code>xbrl-standardization-pipeline.md</code></p> <p>The hybrid approach is now documented as: - Stage 3: Base Standardization (current EdgarTools - Reason 1: standardization) - Stage 4: Granularity Transformation (mpreiss9's insight - Reason 2: consolidation) - Stage 5: Context-Aware Resolution (mpreiss9's method - ambiguous tags)</p> <pre><code># Pipeline integration (from architecture)\ndef get_standard_concept(self, company_concept: str, context: Dict = None) -&gt; Optional[str]:\n    \"\"\"Enhanced mapping with optional context-aware disambiguation.\"\"\"\n\n    # Step 1: Check if this is a known ambiguous tag\n    if company_concept in AMBIGUOUS_TAGS:\n        # Use context-aware resolution (Stage 5 - mpreiss9's method)\n        return self._resolve_ambiguous_tag(company_concept, context)\n\n    # Step 2: Standard priority-based resolution (Stage 3 - EdgarTools current)\n    return self._priority_based_resolution(company_concept)\n</code></pre> <p>Benefits: - Maintain simplicity for 95% of tags - Handle edge cases systematically - Validation-driven improvement - Best of both approaches - Clear architectural boundaries (EdgarTools = infrastructure, users = config)</p>"},{"location":"research/issues/issue-494-standardization-comparison/#architecture-documentation","title":"Architecture Documentation","text":""},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-standardization-flow","title":"EdgarTools Standardization Flow","text":"<pre><code>Filing \u2192 XBRL Parser \u2192 Facts \u2192 Statement Builder\n                                      \u2193\n                              ConceptMapper (standardization)\n                                      \u2193\n                              StandardConcept (enum)\n                                      \u2193\n                              Standardized Statement\n</code></pre> <p>Current Mapping Flow:</p> <pre><code>CompanyConcept \u2192 MappingStore.get_standard_concept()\n                      \u2193\n              Iterate through all standard concepts\n                      \u2193\n              Check if CompanyConcept in concept set\n                      \u2193\n              Apply priority-based resolution\n                      \u2193\n              Return StandardConcept (or None)\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#mpreiss9s-processing-flow","title":"mpreiss9's Processing Flow","text":"<pre><code>Filing \u2192 XBRL Parser \u2192 Facts \u2192 Raw Statement\n                                      \u2193\n                          1. Assign ALL possible standard tags\n                                      \u2193\n                          2. Process backwards to assign sections\n                                      \u2193\n                          3. Disambiguate using section membership\n                                      \u2193\n                          4. Validate balance sheet equation\n                                      \u2193\n                          5. Log unmapped tags if validation fails\n                                      \u2193\n                          Standardized Statement\n</code></pre> <p>mpreiss9's Mapping Flow:</p> <pre><code>CompanyConcept \u2192 ReverseMapping[CompanyConcept]\n                      \u2193\n              Get [StandardConcept1, StandardConcept2, ...]\n                      \u2193\n              Get section from context (backwards processing)\n                      \u2193\n              Filter by section membership\n                      \u2193\n              Return contextually appropriate StandardConcept\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#key-data-flows","title":"Key Data Flows","text":""},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-statement-standardization","title":"EdgarTools: Statement Standardization","text":"<p>File: <code>edgar/xbrl/standardization/core.py:684-757</code></p> <pre><code># Input: statement_data (list of dicts)\n[\n    {\n        \"concept\": \"tsla:AutomotiveRevenue\",\n        \"label\": \"Automotive Sales\",\n        \"value\": 50000000,\n        \"statement_type\": \"IncomeStatement\",\n        \"level\": 1\n    },\n    ...\n]\n\n# Build context\ncontext = {\n    \"statement_type\": \"IncomeStatement\",\n    \"level\": 1,\n    \"is_total\": False\n}\n\n# Map concept \u2192 standard concept\nstandard_label = mapper.map_concept(\"tsla:AutomotiveRevenue\", \"Automotive Sales\", context)\n# Returns: \"Automotive Revenue\" (from tsla_mappings.json, priority 2)\n\n# Output: Standardized statement\n[\n    {\n        \"concept\": \"tsla:AutomotiveRevenue\",\n        \"label\": \"Automotive Revenue\",  # \u2190 Standardized\n        \"original_label\": \"Automotive Sales\",\n        \"value\": 50000000,\n        ...\n    }\n]\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#mpreiss9-section-based-disambiguation","title":"mpreiss9: Section-Based Disambiguation","text":"<pre><code># Input: Item with ambiguous tag\nitem = {\n    \"concept\": \"us-gaap:DeferredTaxAssetsLiabilitiesNet\",\n    \"label\": \"Deferred Tax\",\n    \"value\": 150000000,\n    \"parent\": \"us-gaap:AssetsCurrent\"\n}\n\n# Step 1: Get all possible mappings\ncandidates = reverse_mapping[\"us-gaap:DeferredTaxAssetsLiabilitiesNet\"]\n# Returns: [\"Deferred Tax Assets\", \"Deferred Tax Liabilities\"]\n\n# Step 2: Determine section (backwards processing finds parent = \"Total Current Assets\")\nsection = \"Current Assets\"\n\n# Step 3: Check section membership\nsection_concepts = BALANCE_SHEET_SECTIONS[\"Current Assets\"]\n# Returns: {\"Cash\", \"Accounts Receivable\", \"Deferred Tax Assets\", ...}\n\n# Step 4: Find matching candidate\nfor candidate in candidates:\n    if candidate in section_concepts:\n        return candidate\n# Returns: \"Deferred Tax Assets\"\n\n# Output: Disambiguated item\nitem[\"label\"] = \"Deferred Tax Assets\"  # \u2190 Contextually correct\n</code></pre>"},{"location":"research/issues/issue-494-standardization-comparison/#dependencies","title":"Dependencies","text":""},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-standardization","title":"EdgarTools Standardization","text":"<p>External: - Python 3.9+ - <code>json</code> (stdlib) - <code>difflib.SequenceMatcher</code> (for inference)</p> <p>Internal: - <code>edgar.xbrl.xbrl</code> - XBRL parser provides concepts and labels - <code>edgar.xbrl.statements</code> - Statement builder calls standardization - <code>edgar.xbrl.rendering</code> - Rendering uses standardized labels</p>"},{"location":"research/issues/issue-494-standardization-comparison/#mpreiss9s-approach-conceptual","title":"mpreiss9's Approach (Conceptual)","text":"<p>Required: - Reverse mapping data structure - Section membership dictionaries - Backwards processing algorithm - Balance sheet validation engine</p> <p>Integration Points: - XBRL calculation trees (for parent concepts) - Fact values (for sign-based disambiguation) - Presentation trees (for backwards processing)</p>"},{"location":"research/issues/issue-494-standardization-comparison/#test-coverage","title":"Test Coverage","text":""},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-standardization-tests","title":"EdgarTools Standardization Tests","text":"<p>File: <code>tests/test_xbrl_standardization.py</code></p> <p>Coverage: - \u2705 Basic concept mapping - \u2705 Priority-based resolution - \u2705 Company-specific mappings - \u2705 Context parameter passing (but not usage) - \u274c Context-aware disambiguation - \u274c Ambiguous tag handling - \u274c Balance sheet validation - \u274c Section-based resolution</p>"},{"location":"research/issues/issue-494-standardization-comparison/#mpreiss9s-approach-no-tests-in-edgartools","title":"mpreiss9's Approach (No Tests in EdgarTools)","text":"<p>Would Need: - Section assignment tests - Backwards processing tests - Ambiguous tag resolution tests (200+ tags) - Balance sheet validation tests - Special case handling (Noncurrent Liabilities total vs line item)</p>"},{"location":"research/issues/issue-494-standardization-comparison/#related-documentation","title":"Related Documentation","text":""},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-documentation","title":"EdgarTools Documentation","text":"<ul> <li>Comprehensive Guide: <code>docs/advanced/customizing-standardization.md</code> (2,408 lines)</li> <li>Created Nov 19, 2025 in response to Issue #494</li> <li>Covers current system, limitations, future enhancements</li> <li> <p>Lines 872-891: Documents planned context-based resolution (not implemented)</p> </li> <li> <p>CSV Analysis: <code>docs-internal/research/xbrl-mapping-analysis-mpreiss9.md</code> (NEW - 2025-11-21)</p> </li> <li>Detailed analysis of mpreiss9's production CSV files</li> <li>6,177 mappings: 2,343 GAAP + 3,834 custom (390 companies)</li> <li>215 ambiguous tags documented with resolution patterns</li> <li> <p>Files in <code>data/xbrl-mappings/</code> (not committed)</p> </li> <li> <p>Package README: <code>edgar/xbrl/standardization/README.md</code></p> </li> <li>Basic usage examples</li> <li> <p>Utility functions for CSV export/import</p> </li> <li> <p>GitHub Issue: #494 - \"Create documentation on how to customize standardization tagging\"</p> </li> <li>User feedback and feature requests</li> <li>mpreiss9's detailed methodology (comment 2025-11-19)</li> <li>CSV files shared (comment 2025-11-21)</li> </ul>"},{"location":"research/issues/issue-494-standardization-comparison/#internal-documentation","title":"Internal Documentation","text":"<ul> <li>XBRL Package Guide: <code>edgar/xbrl/CLAUDE.md</code></li> <li>Data availability checking methods</li> <li>Period selection logic</li> <li>Query interface documentation</li> </ul>"},{"location":"research/issues/issue-494-standardization-comparison/#open-questions-for-planning-phase","title":"Open Questions for Planning Phase","text":""},{"location":"research/issues/issue-494-standardization-comparison/#1-implementation-strategy","title":"1. Implementation Strategy","text":"<p>Question: Should we enhance the existing forward-mapping system or create a separate reverse-mapping system for ambiguous tags?</p> <p>Options: - A: Enhance existing <code>MappingStore</code> to use context (requires threading calculation parent info) - B: Create <code>ReverseMappingStore</code> for ambiguous tags only (hybrid approach) - C: Fully replace with reverse mapping (breaking change, not recommended)</p>"},{"location":"research/issues/issue-494-standardization-comparison/#2-backwards-processing","title":"2. Backwards Processing","text":"<p>Question: Where should section assignment via backwards processing happen?</p> <p>Options: - A: In statement builder before standardization - B: During standardization as part of context enrichment - C: As a separate validation/enhancement step</p>"},{"location":"research/issues/issue-494-standardization-comparison/#3-balance-sheet-validation","title":"3. Balance Sheet Validation","text":"<p>Question: Should validation be:</p> <p>Options: - A: Always-on production validation - B: Opt-in validation mode - C: Development/testing tool only</p>"},{"location":"research/issues/issue-494-standardization-comparison/#4-unmapped-tag-logging","title":"4. Unmapped Tag Logging","text":"<p>Question: How should unmapped tags be surfaced to users?</p> <p>Options: - A: Silent logging to file - B: Warning messages during processing - C: Validation report API - D: All of the above with configurable levels</p>"},{"location":"research/issues/issue-494-standardization-comparison/#5-csv-workflow","title":"5. CSV Workflow","text":"<p>Question: Should EdgarTools support:</p> <p>Options: - A: Current JSON-only format (status quo) - B: Native CSV support (as documented in future enhancements) - C: Both JSON and CSV with auto-detection - D: CSV as primary, JSON as export format</p>"},{"location":"research/issues/issue-494-standardization-comparison/#6-scope-of-ambiguous-tag-support","title":"6. Scope of Ambiguous Tag Support","text":"<p>Question: Should we handle:</p> <p>Options: - A: Only the 12 asset/liability ambiguous tags (smallest scope) - B: The 200+ ambiguous tags identified by mpreiss9 (comprehensive) - C: Provide framework for users to define their own ambiguous tags</p>"},{"location":"research/issues/issue-494-standardization-comparison/#7-backwards-compatibility","title":"7. Backwards Compatibility","text":"<p>Question: How to handle breaking changes?</p> <p>Options: - A: Add as optional feature, preserve existing behavior as default - B: Add with deprecation warnings, migrate in v5.0.0 - C: Feature flag for experimental context-aware mode</p>"},{"location":"research/issues/issue-494-standardization-comparison/#summary","title":"Summary","text":""},{"location":"research/issues/issue-494-standardization-comparison/#what-we-learned","title":"What We Learned","text":"<ol> <li>EdgarTools has the infrastructure but not the implementation</li> <li>Context parameter exists throughout the code</li> <li>Completely ignored during actual mapping</li> <li> <p>Priority system works but doesn't solve ambiguity</p> </li> <li> <p>mpreiss9's approach successfully handles 200+ ambiguous tags</p> </li> <li>Reverse mapping enables multi-mapping</li> <li>Section-based resolution using backwards processing</li> <li> <p>Validation-driven mapping improvement</p> </li> <li> <p>The approaches are complementary</p> </li> <li>EdgarTools: Simple, performant for standard cases</li> <li>mpreiss9: Robust, handles edge cases systematically</li> <li> <p>Hybrid approach leverages strengths of both</p> </li> <li> <p>Key insights from mpreiss9's method:</p> </li> <li>Backwards processing identifies section boundaries</li> <li>Section membership resolves ambiguity</li> <li>Validation triggers mapping corrections</li> <li>CSV workflow enables Excel-based management</li> <li> <p>Logging unmapped tags accelerates coverage</p> </li> <li> <p>Implementation is feasible:</p> </li> <li>Can enhance existing system without breaking changes</li> <li>Most required data already available in XBRL parser</li> <li>Would benefit 95% of use cases (validation) while solving 5% edge cases (ambiguity)</li> </ol>"},{"location":"research/issues/issue-494-standardization-comparison/#recommendations-for-planning-phase","title":"Recommendations for Planning Phase","text":"<ol> <li>Start with validation: Add balance sheet equation checking (high value, low risk)</li> <li>Enhance context: Thread calculation parent through to standardization</li> <li>Create section dictionaries: Document standard concepts by section</li> <li>Implement backwards processing: For section assignment</li> <li>Handle ambiguous tags: Start with 12 asset/liability ambiguous tags, expand to 200+</li> <li>Add unmapped tag logging: CSV-based workflow for continuous improvement</li> <li>Preserve backwards compatibility: Make all enhancements opt-in</li> </ol>"},{"location":"research/issues/issue-494-standardization-comparison/#file-references","title":"File References","text":""},{"location":"research/issues/issue-494-standardization-comparison/#edgartools-implementation","title":"EdgarTools Implementation","text":"<ul> <li>Core Standardization: <code>edgar/xbrl/standardization/core.py</code></li> <li>Lines 128-462: <code>MappingStore</code> class</li> <li>Lines 408-449: <code>get_standard_concept()</code> - Context ignored</li> <li>Lines 493-518: <code>ConceptMapper.map_concept()</code> - Context only for caching</li> <li> <p>Lines 684-757: <code>standardize_statement()</code> - Builds context</p> </li> <li> <p>Mappings: <code>edgar/xbrl/standardization/concept_mappings.json</code></p> </li> <li>Company Mappings: <code>edgar/xbrl/standardization/company_mappings/*.json</code></li> <li><code>tsla_mappings.json</code> - Tesla example</li> <li> <p><code>msft_mappings.json</code> - Microsoft example</p> </li> <li> <p>Utilities: <code>edgar/xbrl/standardization/utils.py</code></p> </li> <li>CSV export/import functions</li> <li> <p>Validation helpers</p> </li> <li> <p>Validation:</p> </li> <li><code>edgar/xbrl/parsers/concepts.py:144-380</code> - Balance types</li> <li><code>edgar/xbrl/statements.py:72-87</code> - Required concepts</li> <li> <p><code>edgar/xbrl/period_data_check.py:111-237</code> - Period data quality</p> </li> <li> <p>Statement Processing:</p> </li> <li><code>edgar/xbrl/xbrl.py:662-1003</code> - Line item traversal</li> <li><code>edgar/xbrl/rendering.py:273-290</code> - Section identification</li> <li><code>edgar/xbrl/rendering.py:1514-1613</code> - Backwards processing (equity only)</li> </ul>"},{"location":"research/issues/issue-494-standardization-comparison/#issue-494","title":"Issue #494","text":"<ul> <li>GitHub Issue: https://github.com/dgunning/edgartools/issues/494</li> <li>Last Comment: @mpreiss9's detailed methodology explanation (2025-11-19)</li> <li>200+ Ambiguous Tags: Listed in comment</li> </ul>"},{"location":"research/issues/issue-494-standardization-comparison/#documentation","title":"Documentation","text":"<ul> <li>Comprehensive Guide: <code>docs/advanced/customizing-standardization.md</code></li> <li>Lines 577-851: Ambiguous tag documentation</li> <li> <p>Lines 872-891: Planned context-based resolution</p> </li> <li> <p>XBRL Guide: <code>edgar/xbrl/CLAUDE.md</code></p> </li> </ul>"},{"location":"research/issues/issue-494-standardization-comparison/#tests","title":"Tests","text":"<ul> <li>Standardization Tests: <code>tests/test_xbrl_standardization.py</code></li> <li>Balance Tests: <code>tests/test_xbrl_balance_weight.py</code></li> <li>Concept Tests: <code>tests/test_standardized_concepts.py:115-127</code> - Accounting equation</li> </ul> <p>Research Complete: 2025-11-20 Architecture Complete: 2025-11-22 Status: Ready for Implementation (when stakeholders approve) Next Step: See <code>xbrl-standardization-pipeline.md</code> for complete design</p>"},{"location":"resources/performance/","title":"Performance Optimization","text":"<p>Working with SEC data can be resource-intensive due to the volume of data, network latency, and SEC's rate limits. This guide provides strategies to optimize your edgartools workflows for better performance.</p>"},{"location":"resources/performance/#understanding-how-edgartools-fetches-data","title":"Understanding How edgartools Fetches Data","text":"<p>To optimize performance, it's important to understand how edgartools retrieves data from the SEC EDGAR system.</p>"},{"location":"resources/performance/#how-get_filings-works","title":"How <code>get_filings()</code> Works","text":"<p>The global <code>get_filings()</code> function operates as follows:</p> <ul> <li>It fetches quarterly filing indexes to cover the requested time period</li> <li>For the current year, it fetches complete data for the year to date</li> <li>For multiple years, it fetches quarterly indexes for each year</li> <li>Each quarterly index requires a separate HTTP request</li> </ul> <p>For example, requesting filings for 2024 requires 4 HTTP requests (one for each quarter), while requesting filings for 2020-2024 requires 20 HTTP requests.</p> <pre><code># This makes 4 HTTP requests (one per quarter)\nfilings_2024 = get_filings(year=2024)\n\n# This makes 20 HTTP requests (5 years \u00d7 4 quarters)\nfilings_multi_year = get_filings(start_date=\"2020-01-01\", end_date=\"2024-12-31\")\n</code></pre>"},{"location":"resources/performance/#how-companyget_filings-works","title":"How <code>company.get_filings()</code> Works","text":"<p>The <code>company.get_filings()</code> method works differently:</p> <ul> <li>It fetches the company's submission JSON file, which contains all available filings for that company</li> <li>This requires just one HTTP request, regardless of the date range</li> <li>The data is then filtered client-side based on your criteria</li> </ul> <pre><code># This makes just 1 HTTP request, regardless of date range\ncompany = Company(\"AAPL\")\ncompany_filings = company.get_filings(form=\"10-K\")\n</code></pre>"},{"location":"resources/performance/#filing-content-retrieval","title":"Filing Content Retrieval","text":"<p>Both methods above only return filing metadata (indexes). When you access the actual content of a filing, an additional HTTP request is made:</p> <pre><code># This makes an additional HTTP request when you access the filing\nfiling = filings.latest()\nfiling_text = filing.text  # HTTP request happens here\n</code></pre>"},{"location":"resources/performance/#choosing-the-right-access-pattern","title":"Choosing the Right Access Pattern","text":"<p>Based on your specific use case, choose the most efficient access pattern:</p> If your query is... Use this approach Why Focused on specific form types across companies <code>get_filings(form=\"4\")</code> Efficiently filters by form type Focused on a single company <code>company.get_filings()</code> Makes just one HTTP request Across multiple specific companies <code>get_filings().filter(cik=[\"0000320193\", \"0000789019\"])</code> Allows precise filtering Limited to a specific year <code>get_filings(year=2024)</code> Minimizes the number of index requests Focused on recent filings <code>get_filings().latest(100)</code> Gets only the most recent filings"},{"location":"resources/performance/#rate-limiting-considerations","title":"Rate Limiting Considerations","text":"<p>By default, edgartools limits requests to a maximum of 10 per second to comply with SEC EDGAR's rate limits. Exceeding these limits can result in your IP being temporarily blocked.</p> <pre><code># Default rate limit is 10 requests per second\n# You can adjust it if needed (use with caution)\nfrom edgar import set_rate_limit\n\n# Decrease rate limit for more conservative approach\nset_rate_limit(5)  # 5 requests per second\n</code></pre>"},{"location":"resources/performance/#using-local-storage-for-performance","title":"Using Local Storage for Performance","text":"<p>One of the most effective ways to improve performance is to use local storage. This allows you to:</p> <ol> <li>Cache filings locally to avoid repeated HTTP requests</li> <li>Process filings offline without network latency</li> <li>Batch download filings for later analysis</li> </ol>"},{"location":"resources/performance/#setting-up-local-storage","title":"Setting Up Local Storage","text":"<pre><code>from edgar import enable_local_storage\n\n# Enable local storage\nenable_local_storage(\"/path/to/storage\")\n\n# Now filings will be stored locally\ncompany = Company(\"MSFT\")\nfilings = company.get_filings(form=\"10-K\")\nfiling = filings.latest()\n\n# This will use the local copy if available, or download and cache it if not\ntext = filing.text\n</code></pre>"},{"location":"resources/performance/#batch-downloading-filings","title":"Batch Downloading Filings","text":"<p>For large-scale analysis, batch download filings first, then process them offline:</p> <pre><code>from edgar import download_filings\n\n# Get filing metadata\ncompanies = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"]\nall_filings = []\n\nfor ticker in companies:\n    company = Company(ticker)\n    filings = company.get_filings(form=\"10-K\").head(5)  # Last 5 10-Ks\n    all_filings.extend(filings)\n\n# Batch download all filings (this makes HTTP requests efficiently)\ndownload_filings(all_filings, \"/path/to/storage\")\n\n# Now process them offline (no HTTP requests)\nfor filing in all_filings:\n    # Process filing without network latency\n    text = filing.text  # Uses local copy\n</code></pre>"},{"location":"resources/performance/#memory-optimization","title":"Memory Optimization","text":"<p>When working with many filings or large filings, memory usage can become a concern.</p>"},{"location":"resources/performance/#processing-large-datasets","title":"Processing Large Datasets","text":"<p>For large datasets, use generators and process filings one at a time:</p> <pre><code>def process_filings_generator(filings):\n    for filing in filings:\n        # Process one filing at a time\n        result = process_filing(filing)\n        yield result\n        # Free memory\n        del filing\n\n# Process filings one at a time\nfor result in process_filings_generator(all_filings):\n    save_or_analyze(result)\n</code></pre>"},{"location":"resources/performance/#working-with-large-filings","title":"Working with Large Filings","text":"<p>For large filings (like 10-Ks), process sections individually:</p> <pre><code>filing = company.get_latest_filing(\"10-K\").obj()\n\n# Process one section at a time\nsections = [\"business\", \"risk_factors\", \"management_discussion\"]\nfor section_name in sections:\n    if hasattr(filing, section_name):\n        section = getattr(filing, section_name)\n        # Process section\n        process_section(section_name, section)\n        # Free memory\n        del section\n</code></pre>"},{"location":"resources/performance/#parallel-processing","title":"Parallel Processing","text":"<p>For computationally intensive tasks, consider parallel processing:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\nimport time\n\ndef process_filing_with_delay(filing):\n    # Add delay to respect rate limits\n    time.sleep(0.1)\n    # Process filing\n    return {\"accession\": filing.accession_number, \"text_length\": len(filing.text)}\n\n# Process filings in parallel with a thread pool\nwith ThreadPoolExecutor(max_workers=5) as executor:\n    results = list(executor.map(process_filing_with_delay, all_filings))\n</code></pre>"},{"location":"resources/performance/#caching-strategies","title":"Caching Strategies","text":"<p>Implement caching for expensive operations:</p> <pre><code>import functools\n\n@functools.lru_cache(maxsize=128)\ndef get_filing_sentiment(filing_accession):\n    # Expensive operation to calculate sentiment\n    filing = get_filing_by_accession(filing_accession)\n    text = filing.text\n    # Calculate sentiment (expensive operation)\n    return calculate_sentiment(text)\n\n# This will be cached after the first call\nsentiment = get_filing_sentiment(\"0000320193-20-000096\")\n</code></pre>"},{"location":"resources/performance/#performance-benchmarks","title":"Performance Benchmarks","text":"<p>Here are some typical performance benchmarks to help you plan your workflows:</p> Operation Typical Time Notes <code>get_filings(year=2024)</code> 2-5 seconds Fetches 4 quarterly indexes <code>company.get_filings()</code> 1-2 seconds Single HTTP request Downloading a 10-K filing 1-3 seconds Depends on filing size Parsing a 10-K as Data Object 2-5 seconds First-time parsing Accessing a locally stored filing &lt; 0.1 seconds From disk cache Processing 100 filings sequentially 3-10 minutes With rate limiting Processing 100 filings in parallel 1-3 minutes With proper rate limiting"},{"location":"resources/performance/#best-practices-summary","title":"Best Practices Summary","text":"<ol> <li>Choose the right access pattern based on your specific use case</li> <li>Use <code>company.get_filings()</code> when focusing on a single company</li> <li>Enable local storage to avoid repeated HTTP requests</li> <li>Batch download filings before processing them</li> <li>Process filings one at a time for large datasets</li> <li>Respect SEC rate limits to avoid being blocked</li> <li>Implement caching for expensive operations</li> <li>Use parallel processing carefully with appropriate delays</li> <li>Filter filings early in your pipeline to reduce the number of filings to process</li> <li>Monitor memory usage when working with large filings or datasets</li> </ol> <p>By following these guidelines, you can significantly improve the performance of your edgartools workflows while respecting SEC EDGAR's rate limits and your system's resources.</p>"},{"location":"resources/performance/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"resources/performance/#custom-indexing","title":"Custom Indexing","text":"<p>For repeated analysis of the same dataset, consider creating your own indexes:</p> <pre><code>import pandas as pd\n\n# Create a custom index of filings\nfilings = get_filings(form=[\"10-K\", \"10-Q\"], year=2024)\nindex_data = []\n\nfor filing in filings:\n    index_data.append({\n        \"accession\": filing.accession_number,\n        \"cik\": filing.cik,\n        \"company\": filing.company_name,\n        \"form\": filing.form_type,\n        \"date\": filing.filing_date,\n        \"path\": filing.get_local_path() if filing.is_local() else None\n    })\n\n# Save as CSV for quick loading\nindex_df = pd.DataFrame(index_data)\nindex_df.to_csv(\"filings_index_2024.csv\", index=False)\n\n# Later, load the index instead of fetching again\nloaded_index = pd.read_csv(\"filings_index_2024.csv\")\n</code></pre>"},{"location":"resources/performance/#incremental-updates","title":"Incremental Updates","text":"<p>For ongoing analysis, implement incremental updates:</p> <pre><code>import datetime\n\n# Get the date of your last update\nlast_update = datetime.date(2024, 6, 1)\ntoday = datetime.date.today()\n\n# Only fetch filings since your last update\nnew_filings = get_filings(start_date=last_update, end_date=today)\n\n# Process only the new filings\nfor filing in new_filings:\n    process_filing(filing)\n\n# Update your last update date\nlast_update = today\n</code></pre> <p>By implementing these performance optimization strategies, you can make your edgartools workflows more efficient, faster, and more resilient.</p>"},{"location":"resources/sec-compliance/","title":"SEC Rate Limits &amp; Compliance","text":"<p>The SEC EDGAR system is a valuable public resource that provides access to corporate filings. To ensure fair access for all users, the SEC has established guidelines and rate limits for automated access. This guide explains these requirements and how to use edgartools in a compliant manner.</p>"},{"location":"resources/sec-compliance/#sec-edgar-access-requirements","title":"SEC EDGAR Access Requirements","text":""},{"location":"resources/sec-compliance/#fair-access-policy","title":"Fair Access Policy","text":"<p>The SEC maintains a Fair Access Policy that requires all automated EDGAR access to:</p> <ol> <li>Identify the accessing user/organization in the HTTP request</li> <li>Limit request rates to avoid overloading the system</li> <li>Respect the <code>robots.txt</code> directives</li> <li>Access data during appropriate hours</li> </ol>"},{"location":"resources/sec-compliance/#required-identity-information","title":"Required Identity Information","text":"<p>When using automated tools to access EDGAR, you must identify yourself by providing:</p> <ul> <li>Your name or organization name</li> <li>Your email address</li> </ul> <p>This allows the SEC to contact you if there are issues with your access patterns.</p>"},{"location":"resources/sec-compliance/#setting-your-identity-in-edgartools","title":"Setting Your Identity in edgartools","text":"<p>edgartools makes it easy to comply with SEC requirements by providing a simple way to set your identity:</p> <pre><code>from edgar import set_identity\n\n# Set your identity information\nset_identity(\n    name=\"Your Name\",\n    email=\"your.email@example.com\",\n    organization=\"Your Organization\"  # Optional\n)\n</code></pre> <p>This identity information will be included in the <code>User-Agent</code> header of all requests made by edgartools.</p>"},{"location":"resources/sec-compliance/#default-behavior","title":"Default Behavior","text":"<p>If you don't explicitly set your identity, edgartools will:</p> <ol> <li>Look for environment variables <code>EDGAR_NAME</code> and <code>EDGAR_EMAIL</code></li> <li>If not found, use a generic identity that indicates edgartools usage</li> </ol> <p>However, it's strongly recommended to set your own identity to ensure compliance with SEC requirements.</p>"},{"location":"resources/sec-compliance/#understanding-sec-rate-limits","title":"Understanding SEC Rate Limits","text":"<p>The SEC doesn't publish specific rate limits, but based on their guidelines and observed behavior, the following limits are recommended:</p> <ul> <li>No more than 10 requests per second</li> <li>Reasonable total volume per day</li> <li>Avoid excessive concurrent requests</li> </ul>"},{"location":"resources/sec-compliance/#edgartools-default-rate-limiting","title":"edgartools Default Rate Limiting","text":"<p>By default, edgartools implements conservative rate limiting:</p> <ul> <li>Maximum of 10 requests per second</li> <li>Built-in delays between requests</li> <li>Automatic retries with exponential backoff for 429 errors</li> </ul> <p>This default configuration is designed to keep you compliant with SEC guidelines while still providing good performance.</p>"},{"location":"resources/sec-compliance/#customizing-rate-limits","title":"Customizing Rate Limits","text":"<p>You can adjust the rate limits in edgartools if needed:</p> <pre><code>from edgar import set_rate_limit\n\n# Set a more conservative rate limit (requests per second)\nset_rate_limit(5)  # 5 requests per second\n</code></pre> <p>For high-volume or production use cases, consider being more conservative with your rate limits to avoid potential IP blocks.</p>"},{"location":"resources/sec-compliance/#signs-of-exceeding-rate-limits","title":"Signs of Exceeding Rate Limits","text":"<p>If you exceed SEC rate limits, you may experience:</p> <ol> <li>HTTP 429 (Too Many Requests) responses</li> <li>HTTP 403 (Forbidden) responses</li> <li>Temporary IP blocks (typically 10 minutes to 24 hours)</li> </ol> <p>edgartools will automatically handle 429 responses with retries, but persistent rate limit violations may result in longer blocks.</p>"},{"location":"resources/sec-compliance/#best-practices-for-compliant-access","title":"Best Practices for Compliant Access","text":""},{"location":"resources/sec-compliance/#1-always-set-your-identity","title":"1. Always Set Your Identity","text":"<pre><code>from edgar import set_identity\n\nset_identity(\n    name=\"Your Name\",\n    email=\"your.email@example.com\"\n)\n</code></pre>"},{"location":"resources/sec-compliance/#2-use-local-storage","title":"2. Use Local Storage","text":"<p>Reduce the number of requests by storing filings locally:</p> <pre><code>from edgar import enable_local_storage\n\nenable_local_storage(\"/path/to/storage\")\n</code></pre>"},{"location":"resources/sec-compliance/#3-implement-appropriate-delays","title":"3. Implement Appropriate Delays","text":"<p>For batch processing, add delays between operations:</p> <pre><code>import time\n\nfor filing in filings:\n    # Process filing\n    process_filing(filing)\n    # Add delay between filings\n    time.sleep(0.2)  # 200ms delay\n</code></pre>"},{"location":"resources/sec-compliance/#4-use-efficient-query-patterns","title":"4. Use Efficient Query Patterns","text":"<p>Choose the most efficient access pattern for your needs:</p> <pre><code># For company-specific queries, use company.get_filings()\n# (makes just one request for all filings)\ncompany = Company(\"AAPL\")\nfilings = company.get_filings(form=\"10-K\")\n\n# For form-specific queries across companies, use get_filings()\n# (makes requests for quarterly indexes)\nform4_filings = get_filings(form=\"4\", year=2024)\n</code></pre>"},{"location":"resources/sec-compliance/#5-implement-exponential-backoff","title":"5. Implement Exponential Backoff","text":"<p>For custom requests outside of edgartools:</p> <pre><code>import time\nimport random\n\ndef request_with_backoff(url, max_retries=5):\n    retries = 0\n    while retries &lt; max_retries:\n        try:\n            # Make request\n            response = make_request(url)\n            return response\n        except Exception as e:\n            if \"429\" in str(e) or \"403\" in str(e):\n                # Calculate backoff time\n                wait_time = (2 ** retries) + random.random()\n                print(f\"Rate limited. Waiting {wait_time:.1f} seconds...\")\n                time.sleep(wait_time)\n                retries += 1\n            else:\n                raise\n    raise Exception(\"Max retries exceeded\")\n</code></pre>"},{"location":"resources/sec-compliance/#handling-rate-limit-errors","title":"Handling Rate Limit Errors","text":"<p>If you encounter rate limit errors despite following best practices:</p> <ol> <li>Reduce your request rate by setting a lower rate limit</li> <li>Increase delays between requests</li> <li>Implement circuit breakers to pause requests when errors occur</li> <li>Spread requests across a longer time period</li> <li>Use a different network if your IP has been temporarily blocked</li> </ol>"},{"location":"resources/sec-compliance/#sec-access-hours","title":"SEC Access Hours","text":"<p>While the SEC EDGAR system is available 24/7, it's good practice to avoid peak hours:</p> <ul> <li>Peak hours: 9:30 AM - 4:00 PM Eastern Time (market hours)</li> <li>Maintenance: Occasionally on weekends</li> </ul> <p>For large batch operations, consider running them during off-peak hours.</p>"},{"location":"resources/sec-compliance/#additional-compliance-considerations","title":"Additional Compliance Considerations","text":""},{"location":"resources/sec-compliance/#terms-of-service","title":"Terms of Service","text":"<p>The SEC provides EDGAR data as a public service. When using this data:</p> <ul> <li>Don't misrepresent the data or its source</li> <li>Don't claim affiliation with the SEC</li> <li>Provide proper attribution when republishing data</li> </ul>"},{"location":"resources/sec-compliance/#privacy-considerations","title":"Privacy Considerations","text":"<p>Some SEC filings contain personal information. Be mindful of privacy concerns when:</p> <ul> <li>Storing filings locally</li> <li>Processing personal information in filings</li> <li>Republishing or sharing filing data</li> </ul>"},{"location":"resources/sec-compliance/#monitoring-your-usage","title":"Monitoring Your Usage","text":"<p>To monitor your usage and ensure compliance:</p> <pre><code>from edgar import get_request_stats\n\n# Get statistics about your requests\nstats = get_request_stats()\nprint(f\"Requests made: {stats['total_requests']}\")\nprint(f\"Average rate: {stats['average_rate_per_second']:.2f} requests/second\")\nprint(f\"Rate limit errors: {stats['rate_limit_errors']}\")\n</code></pre>"},{"location":"resources/sec-compliance/#conclusion","title":"Conclusion","text":"<p>Complying with SEC EDGAR access requirements is straightforward with edgartools. By setting your identity, respecting rate limits, and following best practices, you can ensure reliable and compliant access to SEC filing data.</p> <p>Remember that the SEC provides this valuable data as a public service. Responsible usage helps ensure that EDGAR remains accessible to everyone.</p>"},{"location":"resources/sec-compliance/#additional-resources","title":"Additional Resources","text":"<ul> <li>SEC EDGAR Fair Access Policy</li> <li>SEC Developer Resources</li> <li>SEC EDGAR Robots.txt</li> </ul>"},{"location":"resources/troubleshooting/","title":"Common Issues &amp; Solutions","text":"<p>This guide addresses the most common issues users encounter when working with edgartools and provides practical solutions.</p>"},{"location":"resources/troubleshooting/#connection-and-access-issues","title":"Connection and Access Issues","text":""},{"location":"resources/troubleshooting/#sec-edgar-access-denied","title":"SEC EDGAR Access Denied","text":"<p>Symptom: Receiving <code>403 Forbidden</code> errors when accessing SEC EDGAR.</p> <p>Causes: - Missing or incorrect identity information - Exceeding SEC rate limits - IP address blocked by SEC</p> <p>Solutions:</p> <ol> <li>Set proper identity information:</li> </ol> <p>Use <code>set_identity</code> to provide your identity as required by the SEC. This requires your name and email, or just your email.</p> <pre><code>from edgar import set_identity\n\nset_identity(\"Mike McCalum mcallum@gmail.com\")\n\n</code></pre> <ol> <li>Implement rate limiting:</li> </ol> <pre><code>import time\n\n# Add delay between requests\nfor filing in filings:\n    # Process filing\n    time.sleep(0.1)  # 100ms delay\n</code></pre> <ol> <li>Use a different network if your IP has been temporarily blocked.</li> </ol>"},{"location":"resources/troubleshooting/#timeout-errors","title":"Timeout Errors","text":"<p>Symptom: Requests to SEC EDGAR time out.</p> <p>Solutions:</p> <ul> <li>Try again during off-peak hours (SEC EDGAR can be slow during market hours)</li> </ul>"},{"location":"resources/troubleshooting/#data-retrieval-issues","title":"Data Retrieval Issues","text":""},{"location":"resources/troubleshooting/#filing-not-found","title":"Filing Not Found","text":"<p>Symptom: <code>FilingNotFoundError</code> when trying to access a specific filing.</p> <p>Solutions:</p> <ol> <li>Verify the filing exists:</li> </ol> <pre><code># Check if the filing exists first\nfilings = company.get_filings(form=\"10-K\")\nif filings:\n    filing = filings.latest()\nelse:\n    print(\"No 10-K filings found\")\n</code></pre> <ol> <li>Check for alternative form types:</li> </ol> <pre><code> # Some companies use variant form types\nfilings = company.get_filings(form=[\"10-K\", \"10-K/A\", \"10KSB\"])\n</code></pre> <ol> <li>Expand your date range:</li> </ol> <pre><code>filings = company.get_filings(\n       form=\"10-K\",\n       start_date=\"2010-01-01\",  # Try a wider date range\n       end_date=\"2023-12-31\"\n   )\n</code></pre>"},{"location":"resources/troubleshooting/#company-not-found","title":"Company Not Found","text":"<p>Symptom: <code>CompanyNotFoundError</code> when trying to access a company.</p> <p>Solutions:</p> <ol> <li>Check ticker symbol or CIK:</li> </ol> <pre><code># Try using CIK instead of ticker\ncompany = Company(\"0000320193\")  # Apple Inc. CIK\n\n# Or search for the company\nfrom edgar import search_companies\nresults = search_companies(\"Apple\")\nfor r in results:\n    print(f\"{r.name} - {r.ticker} - {r.cik}\")\n</code></pre> <ol> <li>For delisted companies, try using the CIK number directly.</li> </ol>"},{"location":"resources/troubleshooting/#inconsistent-financial-data-signs","title":"Inconsistent Financial Data Signs","text":"<p>Symptom: Expense values appear negative for some companies but positive for others in cross-company analysis.</p> <p>Solution: This was resolved in edgartools 4.9.2+ through enhanced calculation weight handling. Update to the latest version:</p> <pre><code>pip install --upgrade edgartools\n</code></pre> <p>Major expense categories (R&amp;D, SG&amp;A, Marketing) are now consistently positive across companies, matching SEC CompanyFacts API behavior while preserving calculation relationships for cash flow items.</p>"},{"location":"resources/troubleshooting/#missing-financial-data","title":"Missing Financial Data","text":"<p>Symptom: Financial statements are empty or missing expected values.</p> <p>Solutions:</p> <ol> <li>Check if the filing has XBRL data:</li> </ol> <pre><code>filing = company.get_latest_filing(\"10-K\")\nif filing.has_xbrl():\n    financials = filing.get_financials()\nelse:\n    print(\"Filing does not contain XBRL data\")\n</code></pre> <ol> <li>Try different concept names:</li> </ol> <pre><code># Try alternative concept names\ntry:\n    revenue = income_stmt.get_value(\"Revenues\")\nexcept:\n    try:\n        revenue = income_stmt.get_value(\"RevenueFromContractWithCustomerExcludingAssessedTax\")\n    except:\n        revenue = income_stmt.get_value(\"SalesRevenueNet\")\n</code></pre> <ol> <li>For older filings (pre-2009), XBRL data may not be available.</li> </ol>"},{"location":"resources/troubleshooting/#parsing-issues","title":"Parsing Issues","text":""},{"location":"resources/troubleshooting/#html-parsing-errors","title":"HTML Parsing Errors","text":"<p>Symptom: Errors when trying to extract sections from filings.</p> <p>Solutions:</p> <ol> <li>Access raw text instead:</li> </ol> <pre><code>   # Fall back to raw text\n   filing_text = filing.text\n</code></pre> <ol> <li>Try a different filing:</li> </ol> <pre><code># Try the previous filing\nfilings = company.get_filings(form=\"10-K\")\nif len(filings) &gt; 1:\n    previous_filing = filings[1]\n</code></pre>"},{"location":"resources/troubleshooting/#xbrl-parsing-errors","title":"XBRL Parsing Errors","text":"<p>Symptom: Errors when trying to access XBRL data.</p> <p>Solutions:</p> <ol> <li>Check if the filing has valid XBRL:</li> </ol> <pre><code>if filing.has_xbrl():\n    try:\n        xbrl = filing.get_xbrl()\n        print(\"XBRL version:\", xbrl.version)\n    except Exception as e:\n        print(f\"XBRL parsing error: {e}\")\n</code></pre>"},{"location":"resources/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"resources/troubleshooting/#slow-data-retrieval","title":"Slow Data Retrieval","text":"<p>Symptom: Operations take a long time to complete.</p> <p>Solutions:</p> <ol> <li>Use local storage:</li> </ol> <pre><code>from edgar import use_local_storage\n\n# Store filings locally\nuse_local_storage()\n</code></pre> <ol> <li>Limit the number of filings:</li> </ol> <pre><code># Only get the 5 most recent filings\nfilings = company.get_filings(form=\"10-K\").head(5)\n</code></pre> <ol> <li>Use batch processing for large datasets.</li> </ol>"},{"location":"resources/troubleshooting/#memory-issues","title":"Memory Issues","text":"<p>Symptom: Program crashes with memory errors when processing many filings.</p> <p>Solutions:</p> <ol> <li>Process filings one at a time:</li> </ol> <pre><code>for filing in filings:\n    # Process each filing\n    result = process_filing(filing)\n    # Save result and free memory\n    save_result(result)\n    del result\n</code></pre> <ol> <li>Use generators instead of lists:</li> </ol> <pre><code>def process_filings_generator(filings):\n    for filing in filings:\n        yield process_filing(filing)\n\n# Process one filing at a time\nfor result in process_filings_generator(filings):\n    save_result(result)\n</code></pre>"},{"location":"resources/troubleshooting/#installation-issues","title":"Installation Issues","text":""},{"location":"resources/troubleshooting/#dependency-conflicts","title":"Dependency Conflicts","text":"<p>Symptom: Errors related to dependencies when installing or using edgartools.</p> <p>Solutions:</p> <ol> <li>Use a virtual environment:</li> </ol> <pre><code># Create a new virtual environment\npython -m venv edgar_env\n\n# Activate it\nsource edgar_env/bin/activate  # On Windows: edgar_env\\Scripts\\activate\n\n# Install edgartools\npip install edgartools\n</code></pre> <ol> <li>Update dependencies:</li> </ol> <pre><code>pip install --upgrade edgartools\n</code></pre>"},{"location":"resources/troubleshooting/#import-errors","title":"Import Errors","text":"<p>Symptom: <code>ImportError</code> or <code>ModuleNotFoundError</code> when importing edgartools.</p> <p>Solutions:</p> <ol> <li>Verify installation:</li> </ol> <pre><code>pip show edgartools\n</code></pre> <ol> <li>Reinstall the package:</li> </ol> <pre><code>pip uninstall -y edgartools\npip install edgartools\n</code></pre> <ol> <li>Access the raw filing content:</li> </ol> <pre><code># Access the raw content instead\nhtml = filing.html\ntext = filing.text\n</code></pre>"},{"location":"resources/troubleshooting/#sec-rate-limiting","title":"SEC Rate Limiting","text":""},{"location":"resources/troubleshooting/#too-many-requests","title":"Too Many Requests","text":"<ol> <li>Spread requests over time:</li> </ol> <pre><code>companies = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"]\nresults = {}\n\nfor ticker in companies:\n    company = Company(ticker)\n    results[ticker] = company.get_latest_filing(\"10-K\")\n    time.sleep(1)  # Wait 1 second between companies\n</code></pre>"},{"location":"resources/troubleshooting/#debugging-tips","title":"Debugging Tips","text":""},{"location":"resources/troubleshooting/#enable-logging","title":"Enable Logging","text":"<p>Turn on logging to get more information about what's happening:</p> <pre><code>import logging\n\n# Set up logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# For even more detailed logs\nlogging.getLogger('edgar').setLevel(logging.DEBUG)\n</code></pre>"},{"location":"resources/troubleshooting/#check-sec-edgar-status","title":"Check SEC EDGAR Status","text":"<p>The SEC EDGAR system occasionally experiences downtime or performance issues:</p> <ol> <li>Visit the SEC EDGAR Status page to check for any announced issues.</li> </ol>"},{"location":"resources/troubleshooting/#verify-your-data","title":"Verify Your Data","text":"<p>Always verify the data you're working with:</p> <pre><code># Print filing metadata to verify\nprint(f\"Filing: {filing.accession_number}\")\nprint(f\"Form Type: {filing.form_type}\")\nprint(f\"Filing Date: {filing.filing_date}\")\nprint(f\"Has XBRL: {filing.has_xbrl()}\")\n\n# Check financial statement structure\nfinancials = filing.get_financials()\nprint(f\"Available statements: {financials.available_statements()}\")\nprint(f\"Available periods: {financials.get_periods()}\")\n</code></pre>"},{"location":"resources/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still experiencing issues:</p> <ol> <li> <p>Check the documentation: Make sure you're using the API correctly.</p> </li> <li> <p>Search GitHub Issues: Your issue may have been reported and solved already.</p> </li> <li> <p>Ask the community: Post your question on Stack Overflow with the <code>edgartools</code> tag.</p> </li> <li> <p>Report a bug: If you believe you've found a bug, report it on the GitHub repository with a minimal reproducible example.</p> </li> </ol>"},{"location":"resources/troubleshooting/#common-error-messages-and-their-meanings","title":"Common Error Messages and Their Meanings","text":"Error Message Likely Cause Solution <code>CompanyNotFoundError</code> Invalid ticker or CIK Verify the ticker or try using CIK <code>FilingNotFoundError</code> Filing doesn't exist or is not accessible Check form type and date range <code>XBRLNotFoundError</code> Filing doesn't contain XBRL data Try a different filing or use text extraction <code>ParsingError</code> Issue parsing the filing content Try accessing raw content instead <code>HTTPError 403</code> SEC has blocked your requests Set proper identity and respect rate limits <code>HTTPError 429</code> Too many requests in a short time Implement rate limiting and backoff <code>ConnectionError</code> Network issues Check your internet connection <code>UnsupportedFilingTypeError</code> Data Object not available for this filing type Use generic access methods <p>Remember that SEC filings can vary significantly in structure and content, especially across different years and companies. Always implement robust error handling in your code to deal with these variations.</p>"}]}